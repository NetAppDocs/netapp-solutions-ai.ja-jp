---
sidebar: sidebar 
permalink: infra/ai-aipod-nv-validation.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NetApp AIPodとNVIDIA DGX システム - ソリューション検証とサイジングのガイダンス 
---
= NVA-1173 NetApp AIPodとNVIDIA DGX システム - ソリューション検証およびサイジング ガイダンス
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
このセクションでは、 NetApp AIPodとNVIDIA DGX システムのソリューション検証とサイズ設定のガイダンスに焦点を当てます。



== ソリューション検証

このソリューションのストレージ構成は、オープンソース ツール FIO を使用した一連の合成ワークロードを使用して検証されました。これらのテストには、ディープラーニング トレーニング ジョブを実行する DGX システムによって生成されるストレージ ワークロードをシミュレートすることを目的とした読み取りおよび書き込み I/O パターンが含まれます。ストレージ構成は、DGX システムのクラスターをシミュレートするために、FIO ワークロードを同時に実行する 2 ソケット CPU サーバーのクラスターを使用して検証されました。各クライアントは、前述のものと同じネットワーク構成で構成され、次の詳細が追加されました。

この検証には次のマウント オプションが使用されました。

[cols="30%, 70%"]
|===


| バージョン=4.1 | 複数のストレージノードへの並列アクセスを可能にするpNFS 


| プロトコル=rdma | 転送プロトコルをデフォルトのTCPではなくRDMAに設定します 


| ポート=20049 | RDMA NFSサービスに正しいポートを指定する 


| 最大接続数=16 | NFSセッショントランキングを有効にしてストレージポートの帯域幅を集約します 


| 書き込み=熱心 | バッファ書き込みの書き込みパフォーマンスを向上 


| rsize=262144、wsize=262144 | I/O転送サイズを256kに設定する 
|===
さらに、クライアントは NFS max_session_slots 値が 1024 に設定されました。このソリューションは RDMA 経由の NFS を使用してテストされたため、ストレージ ネットワーク ポートはアクティブ/パッシブ ボンドで構成されました。この検証には次の結合パラメータが使用されました。

[cols="30%, 70%"]
|===


| モード=アクティブバックアップ | ボンドをアクティブ/パッシブモードに設定する 


| primary=<インターフェース名> | すべてのクライアントのプライマリインターフェースはスイッチに分散されていました 


| miiモニター間隔=100 | 監視間隔を100msに指定 


| フェイルオーバーMACポリシー=アクティブ | アクティブ リンクの MAC アドレスがボンドの MAC であることを指定します。これは、結合されたインターフェース上での RDMA の適切な操作に必要です。 
|===
ストレージ システムは、説明どおり、2 つの A900 HA ペア (4 つのコントローラ) と、各 HA ペアに接続された 24 個の 1.9 TB NVMe ディスク ドライブを備えた 2 つの NS224 ディスク シェルフで構成されました。アーキテクチャのセクションで説明したように、すべてのコントローラのストレージ容量はFlexGroupボリュームを使用して結合され、すべてのクライアントのデータはクラスタ内のすべてのコントローラに分散されました。



== ストレージシステムのサイズ決定ガイダンス

NetApp はDGX BasePOD 認定を正常に完了しており、テストされた 2 つの A90 HA ペアは 16 個の DGX H100 システムのクラスターを簡単にサポートできます。より高いストレージ パフォーマンス要件を持つ大規模な導入の場合、 NetApp ONTAPクラスタにAFFシステムを追加して、単一クラスタで最大 12 個の HA ペア (24 ノード) まで構成できます。このソリューションで説明されているFlexGroupテクノロジーを使用すると、24 ノードのクラスターは単一の名前空間で 79 PB 以上、最大 552 GBps のスループットを提供できます。  AFF A400 、A250、C800 などのその他のNetAppストレージ システムは、より低コストで小規模な導入向けに、より低いパフォーマンスと/またはより高い容量のオプションを提供します。 ONTAP 9 は混合モデルのクラスタをサポートしているため、お客様は小さな初期フットプリントから始めて、容量とパフォーマンスの要件の拡大に応じて、より多くのストレージ システムまたはより大きなストレージ システムをクラスタに追加することができます。以下の表は、各AFFモデルでサポートされる A100 および H100 GPU の数の概算を示しています。

_NetApp ストレージ システムのサイズ設定ガイダンス_

image:aipod-nv-a90-sizing.png["入出力ダイアログまたは書かれたコンテンツを示す図"]
