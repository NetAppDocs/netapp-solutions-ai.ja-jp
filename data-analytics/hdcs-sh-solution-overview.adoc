---
sidebar: sidebar 
permalink: data-analytics/hdcs-sh-solution-overview.html 
keywords: tr-4657, tr4657, 4657, hybrid cloud, spark, hadoop, aff, fas 
summary: このドキュメントでは、 NetApp AFFおよびFASストレージ システム、 NetApp Cloud Volumes ONTAP、 NetApp接続ストレージ、Spark および Hadoop 用のNetApp FlexCloneテクノロジーを使用したハイブリッド クラウド データ ソリューションについて説明します。これらのソリューション アーキテクチャにより、お客様は自社の環境に適したデータ保護ソリューションを選択できます。  NetApp は、顧客とのやり取りとビジネスユースケースに基づいてこれらのソリューションを設計しました。 
---
= TR-4657: NetAppハイブリッド クラウド データ ソリューション - 顧客のユースケースに基づく Spark と Hadoop
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


NetApp 、Karthikeyan Nagalingam 氏と Sathish Thyagarajan 氏

[role="lead"]
このドキュメントでは、 NetApp AFFおよびFASストレージ システム、 NetApp Cloud Volumes ONTAP、 NetApp接続ストレージ、Spark および Hadoop 用のNetApp FlexCloneテクノロジーを使用したハイブリッド クラウド データ ソリューションについて説明します。これらのソリューション アーキテクチャにより、お客様は自社の環境に適したデータ保護ソリューションを選択できます。 NetApp は、顧客とのやり取りとビジネスユースケースに基づいてこれらのソリューションを設計しました。このドキュメントでは、次の詳細情報を提供します。

* Spark および Hadoop 環境でデータ保護が必要な理由と顧客の課題。
* NetApp のビジョンとその構成要素およびサービスによって実現されるデータ ファブリック。
* これらのビルディング ブロックを使用して、柔軟なデータ保護ワークフローを構築する方法を説明します。
* 実際の顧客の使用事例に基づいた、いくつかのアーキテクチャの長所と短所。各ユースケースでは、次のコンポーネントが提供されます。
+
** 顧客シナリオ
** 要件と課題
** ソリューション
** 解決策の要約






== Hadoop データ保護の理由

Hadoop および Spark 環境では、次の懸念事項に対処する必要があります。

* *ソフトウェアまたは人為的な障害。* Hadoop データ操作の実行中にソフトウェアを更新する際に人為的なエラーが発生すると、ジョブから予期しない結果が生じる可能性のある障害が発生する可能性があります。このような場合、障害や不合理な結果を避けるためにデータを保護する必要があります。たとえば、交通信号分析アプリケーションのソフトウェア更新が適切に実行されなかった結果、新しい機能がプレーンテキスト形式の交通信号データを適切に分析できないことがあります。ソフトウェアは依然として JSON やその他のテキスト以外のファイル形式を分析するため、リアルタイムの交通制御分析システムはデータ ポイントが欠落した予測結果を生成します。この状況により出力に不具合が生じ、交通信号での事故につながる可能性があります。データ保護では、以前の動作中のアプリケーション バージョンに迅速にロールバックする機能を提供することで、この問題に対処できます。
* *サイズとスケール。*データ ソースの数と量が増え続けているため、分析データのサイズは日々大きくなっています。ソーシャル メディア、モバイル アプリ、データ分析、クラウド コンピューティング プラットフォームは、急速に拡大している現在のビッグ データ市場における主なデータ ソースであるため、正確なデータ操作を保証するためにデータを保護する必要があります。
* *Hadoop のネイティブ データ保護。* Hadoop にはデータを保護するためのネイティブ コマンドがありますが、このコマンドではバックアップ中にデータの一貫性が確保されません。ディレクトリ レベルのバックアップのみをサポートします。  Hadoop によって作成されたスナップショットは読み取り専用であり、バックアップ データを直接再利用することはできません。




== Hadoop および Spark の顧客にとってのデータ保護の課題

Hadoop および Spark の顧客にとっての共通の課題は、データ保護中に本番クラスターのパフォーマンスに悪影響を与えることなく、バックアップ時間を短縮し、バックアップの信頼性を高めることです。

顧客は、最適なビジネス継続性を確保するために、復旧ポイント目標 (RPO) と復旧時間目標 (RTO) のダウンタイムを最小限に抑え、オンプレミスとクラウドベースの災害復旧サイトを制御する必要もあります。この制御は通常、エンタープライズ レベルの管理ツールによって実現されます。

Hadoop および Spark 環境は、データ量が膨大かつ増加しているだけでなく、データの到着速度も増加しているため、複雑になっています。このシナリオでは、ソース データから効率的で最新の DevTest および QA 環境を迅速に作成することが困難になります。  NetApp はこれらの課題を認識しており、このホワイト ペーパーで紹介するソリューションを提供しています。
