---
sidebar: sidebar 
permalink: data-analytics/dremio-lakehouse-verification.html 
keywords: performance, tests, dremio 
summary: ONTAPや storagegrid などのNetAppオブジェクト ストレージを使用して、SQL ワークロードに対して 5 つのノードで tpc-ds テストを実行しました。 
---
= ソリューション検証の概要
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
このセクションでは、複数のソースから SQL テスト クエリを実行して機能を検証し、 NetAppストレージへのスピルオーバーをテストおよび検証しました。



=== オブジェクトストレージのSQLクエリ

. dremio.envでサーバーあたりのメモリを250GBに設定する
+
....
root@hadoopmaster:~# for i in hadoopmaster hadoopnode1 hadoopnode2 hadoopnode3 hadoopnode4; do ssh $i "hostname; grep -i  DREMIO_MAX_MEMORY_SIZE_MB /opt/dremio/conf/dremio-env; cat /proc/meminfo  | grep -i memtotal"; done
hadoopmaster
#DREMIO_MAX_MEMORY_SIZE_MB=120000
DREMIO_MAX_MEMORY_SIZE_MB=250000
MemTotal:       263515760 kB
hadoopnode1
#DREMIO_MAX_MEMORY_SIZE_MB=120000
DREMIO_MAX_MEMORY_SIZE_MB=250000
MemTotal:       263515860 kB
hadoopnode2
#DREMIO_MAX_MEMORY_SIZE_MB=120000
DREMIO_MAX_MEMORY_SIZE_MB=250000
MemTotal:       263515864 kB
hadoopnode3
#DREMIO_MAX_MEMORY_SIZE_MB=120000
DREMIO_MAX_MEMORY_SIZE_MB=250000
MemTotal:       264004556 kB
node4
#DREMIO_MAX_MEMORY_SIZE_MB=120000
DREMIO_MAX_MEMORY_SIZE_MB=250000
MemTotal:       263515484 kB
root@hadoopmaster:~#
....
. dremio.conf ファイルとストレージの詳細で、スピルオーバーの場所 (${DREMIO_HOME}"/dremiocache) を確認します。
+
....
paths: {
  # the local path for dremio to store data.
  local: ${DREMIO_HOME}"/dremiocache"

  # the distributed path Dremio data including job results, downloads, uploads, etc
  #dist: "hdfs://hadoopmaster:9000/dremiocache"
  dist: "dremioS3:///dremioconf"
}

services: {
  coordinator.enabled: true,
  coordinator.master.enabled: true,
  executor.enabled: false,
  flight.use_session_service: false
}

zookeeper: "10.63.150.130:2181,10.63.150.153:2181,10.63.150.151:2181"
services.coordinator.master.embedded-zookeeper.enabled: false
....
. Dremioのスピルオーバー場所をNetApp NFSストレージに向ける
+
....
root@hadoopnode1:~# ls -ltrh /dremiocache
total 4.0K
drwx------ 3 nobody nogroup 4.0K Sep 13 16:00 spilling_stlrx2540m4-12-10g_45678
root@hadoopnode1:~# ls -ltrh /opt/dremio/dremiocache/
total 8.0K
drwxr-xr-x 3 dremio dremio 4.0K Aug 22 18:19 spill_old
drwxr-xr-x 4 dremio dremio 4.0K Aug 22 18:19 cm
lrwxrwxrwx 1 root   root     12 Aug 22 19:03 spill -> /dremiocache
root@hadoopnode1:~# ls -ltrh /dremiocache
total 4.0K
drwx------ 3 nobody nogroup 4.0K Sep 13 16:00 spilling_stlrx2540m4-12-10g_45678
root@hadoopnode1:~# df -h /dremiocache
Filesystem                              Size  Used Avail Use% Mounted on
10.63.150.159:/dremiocache_hadoopnode1  2.1T  209M  2.0T   1% /dremiocache
root@hadoopnode1:~#
....
. コンテキストを選択します。私たちのテストでは、 ONTAP S3 にある TPCDS によって生成された parquet ファイルに対してテストを実行しました。  Dremioダッシュボード -> SQLランナー ->コンテキスト -> NetAppONTAPS3 -> Parquet1TB


image:ontaps3-context.png["コンテキストをontaps3 parquetフォルダに設定する"]

. DremioダッシュボードからTPC-DSクエリ67を実行する


image:tpcds-q67.png["TPC-DSの99個のクエリのうちの1つであるクエリ67を実行します。"]

. すべての実行プログラムでジョブが実行されていることを確認します。  Dremioダッシュボード -> ジョブ -> <jobid> -> 生のプロファイル -> EXTERNAL_SORTを選択 -> ホスト名


image:node-in-query.png["Q67クエリ内のノードのリスト"]

. SQL クエリが実行されている場合、 NetAppストレージ コントローラ内のデータ キャッシュの分割フォルダーを確認できます。
+
....
root@hadoopnode1:~# ls -ltrh /dremiocache
total 4.0K
drwx------ 3 nobody nogroup 4.0K Sep 13 16:00 spilling_stlrx2540m4-12-10g_45678
root@hadoopnode1:~# ls -ltrh /dremiocache/spilling_stlrx2540m4-12-10g_45678/
total 4.0K
drwxr-xr-x 2 root daemon 4.0K Sep 13 16:23 1726243167416
....
. SQLクエリはスピルオーバーで完了しましたimage:spinover.png["クエリ67が完了すると詳細が流出する"]
. ジョブ完了の概要。image:jobsummary.png["完了したクエリのジョブ概要 67"]
. こぼれたデータのサイズを確認するimage:splleddata.png["クエリ結果からのsplleddataの詳細"]


NAS およびStorageGRIDオブジェクト ストレージにも同じ手順が適用されます。
