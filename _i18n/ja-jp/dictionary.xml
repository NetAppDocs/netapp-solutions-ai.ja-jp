<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="2b185d63fe43e391e79f2722fa9c01f4" category="summary">業界のトレンド、イノベーション、現実世界への影響、開発者リソース、コミュニティの洞察、 NetApp AI ソリューションを活用するための実用的なツールを紹介する AI/ML ブログをお読みください。</block>
  <block id="7a206e7f1f7bd7df4f649256e750768b" category="doc">NetApp のエキスパートによる AI ソリューションのブログを読む</block>
  <block id="683be49e9105a56d06431bcdc1630cb6" category="paragraph">業界のトレンド、イノベーション、現実世界への影響、開発者リソース、コミュニティの洞察、 NetApp AI ソリューションを活用するための実用的なツールを紹介する AI/ML ブログをお読みください。</block>
  <block id="5bbe94ba0a14c52be3cc9534b43f4713" category="paragraph-title">AIのトレンドと業界の洞察</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">英語</block>
  <block id="69501f595c5bd3cdb17ea63c90291622" category="paragraph">さまざまな分野にわたる業界のトレンド、イノベーション、現実世界の AI の影響を探ります。<block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block> &amp;f:@facet_soultion_mktg=[AI、アナリティクス、人工知能]++[ NetAppでAIブログを読む^]</block>
  <block id="d5769d364696d52f17c7b56bd51573f8" category="paragraph-title">開発者リソースとコミュニティ</block>
  <block id="bb765a119d53333b43f301b6a00a388a" category="inline-link-macro">PubでAIブログを読む</block>
  <block id="43c273574ee7233878bcc9fc0bd893c9" category="paragraph">AI/ML 実践者向けの技術的な洞察、実用的なツール、コミュニティ主導のコンテンツ。<block ref="f89e2ffa35ae5933259a8ae6e49a69ad" category="inline-link-macro-rx"></block></block>
  <block id="e7ee239a021c71c67431ac1c23b9cf1e" category="summary">この記事では、自動化されたモデルの再トレーニング、デプロイメント、コストの最適化に焦点を当て、AWS サービスを使用して MLOps パイプラインを構築するためのガイドを提供します。</block>
  <block id="b77650c231f63812b48a3802736172ae" category="doc">パート 3 - 簡素化された MLOps パイプラインの構築 (CI/CT/CD)</block>
  <block id="3fc6ea95b9f9aac82c7a39c3743664ba" category="paragraph">この記事では、自動化されたモデルの再トレーニング、デプロイ、コストの最適化に焦点を当て、AWS サービスを使用して MLOps パイプラインを構築するためのガイドを提供します。</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">はじめに</block>
  <block id="4c04d3884cafb85369c7a0a6b81d10b0" category="paragraph">このチュートリアルでは、さまざまな AWS サービスを活用して、継続的インテグレーション (CI)、継続的トレーニング (CT)、継続的デプロイメント (CD) を含むシンプルな MLOps パイプラインを構築する方法を学習します。従来の DevOps パイプラインとは異なり、MLOps では運用サイクルを完了するために追加の考慮が必要です。このチュートリアルに従うことで、CT を MLOps ループに組み込み、モデルの継続的なトレーニングと推論のシームレスな展開を可能にする方法について理解を深めることができます。このチュートリアルでは、AWS サービスを利用してこのエンドツーエンドの MLOps パイプラインを確立するプロセスについて説明します。</block>
  <block id="76c3e002d3c052bd6a909366a8dc3845" category="section-title">マニフェスト</block>
  <block id="e7e0038bb30579a3120d266861982881" category="cell">機能</block>
  <block id="49ee3087348e8d44e1feda1917443987" category="cell">Name</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">コメント</block>
  <block id="dc21b082b0947a93d387b8c7e8f89ee5" category="cell">データストレージ</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="cell">AWS FSx ONTAP</block>
  <block id="ae8cde6d64ec0b4ed71f7e4d5a28d65f" category="inline-link-macro">パート 1 - Amazon FSx for NetApp ONTAP (FSx ONTAP) をプライベート S3 バケットとして AWS SageMaker に統合する</block>
  <block id="273b64842c06632a1f361f1a341b8c24" category="cell">。 <block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="4c5f43ed06df4b05c18ca410c7016249" category="cell">データサイエンスIDE</block>
  <block id="5a1439989b12745b5a4ed4b944539247" category="cell">AWS セージメーカー</block>
  <block id="4c99a9cb175cf27f5edb2b2a9e21f32c" category="inline-link-macro">パート 2 - SageMaker でのモデルトレーニング用のデータソースとしてAmazon FSx for NetApp ONTAP (FSx ONTAP) を活用する</block>
  <block id="077914145dbaab3cc9a1f25998b4b703" category="cell">このチュートリアルは、<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> 。</block>
  <block id="e1d9ae96a3cc2d87549ec614a5eea75b" category="cell">MLOpsパイプラインをトリガーする関数</block>
  <block id="10740b99bf79c58d32e1a8e73062d05c" category="cell">AWS Lambda関数</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="0fc1223c31c6d7d5d233235c0a8f3ee0" category="cell">Cronジョブトリガー</block>
  <block id="0abaf4e46241f987a0b4e6a434e596cd" category="cell">AWS イベントブリッジ</block>
  <block id="e015867873eac103879d29f569610c66" category="cell">ディープラーニングフレームワーク</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="cell">パイトーチ</block>
  <block id="6af8c08e3948b664c72a8cc3c2709254" category="cell">AWS Python SDK</block>
  <block id="6686853da3491a56c98917cc5c4ddea2" category="cell">ボト3</block>
  <block id="4f465e36f699fcf0570d854d9f692508" category="cell">プログラミング言語</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="cell">Python</block>
  <block id="cd9ec78e2cad962acfcab027dd62d904" category="cell">バージョン3.10</block>
  <block id="925335f81021de4d22fde55ae7f0e86a" category="section-title">前提条件</block>
  <block id="368743a79699dd2e9a1db93cb728196a" category="list-text">事前設定された FSx ONTAPファイル システム。このチュートリアルでは、トレーニング プロセスに FSx ONTAPに保存されているデータを利用します。</block>
  <block id="73d970f5582fe283900cc4b125f71ab0" category="list-text">上記の FSx ONTAPファイルシステムと同じ VPC を共有するように設定された *SageMaker Notebook インスタンス*。</block>
  <block id="cd201faac7e3cf792faa46c93195c65b" category="list-text">*AWS Lambda 関数* をトリガーする前に、*SageMaker Notebook インスタンス* が *停止* 状態であることを確認してください。</block>
  <block id="238f736fdf6bcdcd7f397969fe6eb36e" category="list-text">ディープ ニューラル ネットワークの計算に必要な GPU アクセラレーションを活用するには、*ml.g4dn.xlarge* インスタンス タイプが必要です。</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="section-title">アーキテクチャ</block>
  <block id="2c03bdafce7f1816c8faa5db2e5d1258" category="paragraph"><block ref="2c03bdafce7f1816c8faa5db2e5d1258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e320ad9e531a78d8b06272138f0f29b7" category="paragraph">この MLOps パイプラインは、cron ジョブを利用してサーバーレス関数をトリガーし、ライフサイクルコールバック関数に登録された AWS サービスを実行する実用的な実装です。 *AWS EventBridge* は cron ジョブとして機能します。モデルの再トレーニングと再デプロイを担当する *AWS Lambda 関数* を定期的に呼び出します。このプロセスでは、必要なタスクを実行するために *AWS SageMaker Notebook* インスタンスを起動する必要があります。</block>
  <block id="2f53ab942978849d906d82a87554a1e2" category="section-title">ステップバイステップの設定</block>
  <block id="ecce3b4394f7f06232bad571a96a0391" category="section-title">ライフサイクル構成</block>
  <block id="8482e23b03456ee8ac2760d540c11442" category="paragraph">AWS SageMaker Notebook インスタンスのライフサイクルコールバック関数を設定するには、*ライフサイクル設定*を利用します。このサービスを使用すると、ノートブック インスタンスを起動するときに実行する必要なアクションを定義できます。具体的には、*ライフサイクル構成*内にシェル スクリプトを実装して、トレーニングとデプロイメントのプロセスが完了するとノートブック インスタンスを自動的にシャットダウンすることができます。  MLOps ではコストが主要な考慮事項の 1 つであるため、これは必須の構成です。</block>
  <block id="79d14d6493dc1a7a7d33bf031166f9a9" category="paragraph">*ライフサイクル構成*の構成を事前に設定しておく必要があることに注意することが重要です。したがって、他の MLOps パイプラインのセットアップに進む前に、この側面の構成を優先することをお勧めします。</block>
  <block id="29beb103651093d4e75530e25a50f4bd" category="list-text">ライフサイクル構成を設定するには、*Sagemaker* パネルを開き、*管理構成* セクションの *ライフサイクル構成* に移動します。</block>
  <block id="e40d22b369f011035946ad31f47b655a" category="inline-image-macro">SageMakerパネル</block>
  <block id="808aecfbb727487113195461863f7b8f" category="paragraph"><block ref="808aecfbb727487113195461863f7b8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="706c89d427897aa8c9093c9ea4ddf1cb" category="list-text">*ノートブックインスタンス*タブを選択し、*構成の作成*ボタンをクリックします。</block>
  <block id="6d548bb5536b7ca36996b9a2bf7f3fc9" category="inline-image-macro">ライフサイクル構成のウェルカムページ</block>
  <block id="533585f6e9e5ce51a2cd2322d75dfd10" category="paragraph"><block ref="533585f6e9e5ce51a2cd2322d75dfd10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bfce2cb9f46fa7b22c7f04d6aa38b9e" category="list-text">以下のコードを入力エリアに貼り付けます。</block>
  <block id="a3c7be0a54a45c8a39d852df0ffe5795" category="list-text">このスクリプトは、推論用モデルの再トレーニングと再デプロイメントを処理する Jupyter Notebook を実行します。実行が完了すると、ノートブックは 5 分以内に自動的にシャットダウンします。問題の説明とコードの実装の詳細については、以下を参照してください。<block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block> 。</block>
  <block id="f8d2f79250f54a742eec560a47022213" category="inline-image-macro">ライフサイクル構成を作成する</block>
  <block id="32868d8eaf16b0e5d6cc389594591fa8" category="paragraph"><block ref="32868d8eaf16b0e5d6cc389594591fa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a835fb020d342258f64fe6be9b11cc29" category="list-text">作成後、ノートブックインスタンスに移動し、ターゲットインスタンスを選択して、[アクション] ドロップダウンの [*設定の更新*] をクリックします。</block>
  <block id="386c8dd530ade6b4cdc15f9f6ebad5c4" category="inline-image-macro">設定ドロップダウンを更新</block>
  <block id="c2ba792fac24b100bacf8cb5998dfc1e" category="paragraph"><block ref="c2ba792fac24b100bacf8cb5998dfc1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f80499d713c8d9fe19313ec1dc9bd45" category="list-text">作成した*ライフサイクル構成*を選択し、*ノートブックインスタンスの更新*をクリックします。</block>
  <block id="929b843b11b6f17c62198cd38020bfe6" category="inline-image-macro">ノートブックのライフサイクル構成を更新する</block>
  <block id="e0dc07a964d60792b3ec801e8395ef77" category="paragraph"><block ref="e0dc07a964d60792b3ec801e8395ef77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a0f9cbbefa9b9603cf2241f33621e37" category="section-title">AWS Lambda サーバーレス関数</block>
  <block id="4a799fa8d490fae92d630fe6cc65b928" category="paragraph">前述のように、*AWS Lambda 関数*は *AWS SageMaker Notebook インスタンス* を起動する役割を担っています。</block>
  <block id="be107f93440a41fcae408e1abec6403e" category="list-text">*AWS Lambda 関数* を作成するには、該当するパネルに移動し、*関数* タブに切り替えて、*関数の作成* をクリックします。</block>
  <block id="d28550fe1b16be91a51602ddd8c1d60f" category="inline-image-macro">AWS Lambda関数のウェルカムページ</block>
  <block id="627b95a2fda6260f5df8d487a291ceea" category="paragraph"><block ref="627b95a2fda6260f5df8d487a291ceea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a60f634c6f68222d8abaaa29bd057217" category="list-text">ページ上のすべての必須エントリを入力し、ランタイムを *Python 3.10* に切り替えることを忘れないでください。</block>
  <block id="267b7733eb14e4bbd98146ea3f8501b1" category="inline-image-macro">AWS Lambda関数を作成する</block>
  <block id="cce551decdf09efb16caf7432d6c7eba" category="paragraph"><block ref="cce551decdf09efb16caf7432d6c7eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bee22bc8ca787cbf1475d27ae7429d6" category="list-text">指定されたロールに必要な権限 *AmazonSageMakerFullAccess* があることを確認し、 *関数の作成* ボタンをクリックしてください。</block>
  <block id="3f6a1b36a855303ea55de235a44c52b0" category="inline-image-macro">実行ロールを選択</block>
  <block id="fa8e9001a3295e1f7a1f8d3ef3e92572" category="paragraph"><block ref="fa8e9001a3295e1f7a1f8d3ef3e92572" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcc43af2494337ee641b41a13f71fc46" category="list-text">作成したLambda関数を選択します。コードタブで、次のコードをコピーしてテキスト領域に貼り付けます。このコードは、*fsxn-ontap* という名前のノートブック インスタンスを起動します。</block>
  <block id="c2edd2bdf75433b7f31062be9571f528" category="list-text">このコードの変更を適用するには、[デプロイ] ボタンをクリックします。</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="inline-image-macro">導入</block>
  <block id="64446fff99d978434b172f7c745ece52" category="paragraph"><block ref="64446fff99d978434b172f7c745ece52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9bb44167ffa5f5dc2d30616b32fe21b" category="list-text">この AWS Lambda 関数をトリガーする方法を指定するには、「トリガーの追加」ボタンをクリックします。</block>
  <block id="c8d04adc09d32f5c953177228f96826b" category="inline-image-macro">AWS関数トリガーを追加する</block>
  <block id="6297ab474f745fe7abc72cd5f148311b" category="paragraph"><block ref="6297ab474f745fe7abc72cd5f148311b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba138d79283b1a8aad0ef0cc35ce105" category="list-text">ドロップダウン メニューから EventBridge を選択し、「新しいルールの作成」というラジオ ボタンをクリックします。スケジュール式フィールドに次のように入力します。<block ref="5bb28b828095c4a920fb3d34b89c2b84" prefix=" " category="inline-code"></block>をクリックし、[追加] ボタンをクリックして、この新しい cron ジョブ ルールを作成し、AWS Lambda 関数に適用します。</block>
  <block id="4ab295fce5805d57b17ce3316bf007fa" category="inline-image-macro">トリガーを確定する</block>
  <block id="46f9833b45661170323abab7808e6219" category="paragraph"><block ref="46f9833b45661170323abab7808e6219" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3643e50ab12ef03d2731f0654366409d" category="paragraph">2 段階の設定が完了すると、毎日、*AWS Lambda 関数* が *SageMaker Notebook* を起動し、*FSx ONTAP* リポジトリのデータを使用してモデルの再トレーニングを実行し、更新されたモデルを本番環境に再デプロイし、*SageMaker Notebook インスタンス* を自動的にシャットダウンしてコストを最適化します。これにより、モデルが最新の状態に保たれます。</block>
  <block id="0be5bfaeb8f14cd39a235e5050cecbc9" category="paragraph">これで、MLOps パイプラインの開発に関するチュートリアルは終了です。</block>
  <block id="fbf39511561166f560c51e6bdf601a0e" category="summary">これは、FSx ONTAP MLOps セクションの紹介ページです。</block>
  <block id="28cd7fd0e401ee73677b7f7441149a51" category="doc">MLOps 向けAmazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="fba7ee1ae1e1979f64e6e11317d235ff" category="paragraph">このセクションでは、AI インフラストラクチャ開発の実際のアプリケーションについて詳しく説明し、FSx ONTAPを使用して MLOps パイプラインを構築するエンドツーエンドのチュートリアルを提供します。  3 つの包括的な例で構成されており、この強力なデータ管理プラットフォームを介して MLOps のニーズを満たす方法をガイドします。</block>
  <block id="e2e58416305212ecee9fc44a8a57e389" category="paragraph">これらの記事は以下に焦点を当てています。</block>
  <block id="a4f6db8ee799d71c8436c5d66421c857" category="list-text"><block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block></block>
  <block id="3f7fd29e3ed2add54c00cc8c8501cde7" category="list-text"><block ref="3f7fd29e3ed2add54c00cc8c8501cde7" category="inline-link-macro-rx"></block></block>
  <block id="71b4f7c054c855f2e85df08fc5e39095" category="list-text"><block ref="71b4f7c054c855f2e85df08fc5e39095" category="inline-link-macro-rx"></block></block>
  <block id="8b34d4c412144b306293274a1964c465" category="paragraph">このセクションの終わりまでに、FSx ONTAPを使用して MLOps プロセスを効率化する方法についてしっかりと理解できるようになります。</block>
  <block id="f3be583adfbfc01a44597d4c6f7e4ef5" category="summary">この投稿では、AWS SageMaker を使用して FSx ONTAP をプライベート S3 バケットとして設定する方法についてガイドします。</block>
  <block id="405642837c20faf5ee6d81b4d039206f" category="paragraph">このセクションでは、AWS SageMaker を使用して FSx ONTAP をプライベート S3 バケットとして設定する方法について説明します。</block>
  <block id="8c52c9bdd7d9ef6a6f82004af97fae7b" category="paragraph">このページでは、SageMaker を例に、FSx ONTAP をプライベート S3 バケットとして設定する方法について説明します。</block>
  <block id="69620f6919f430e72c0f67207535605b" category="inline-link-macro">ビデオリンク</block>
  <block id="2b6442845e4dd1bf2e9140ac796e1a93" category="paragraph">FSx ONTAPの詳細については、このプレゼンテーションをご覧ください (<block ref="f781ab67717d91cabffd32c6ef2dd731" category="inline-link-macro-rx"></block> ）</block>
  <block id="7a97419a6312bf2f5dcdb87d844f3d07" category="section-title">ユーザーガイド</block>
  <block id="2f5513954af7462427835c65fbeeac6d" category="section-title">サーバーの作成</block>
  <block id="aa5fe14483191172e4fb6ae032e063db" category="section-title">SageMakerノートブックインスタンスを作成する</block>
  <block id="22a9741b15ba6b8515c1bcf1eb1e2424" category="list-text">AWS コンソールを開きます。検索パネルで SageMaker を検索し、サービス *Amazon SageMaker* をクリックします。</block>
  <block id="f81ad91c4e9a7e4840e3c7a28ad316cb" category="inline-image-macro">AWSコンソールを開く</block>
  <block id="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="paragraph"><block ref="91ff4fb5f0a57e0f0b2c24cdefb4f12b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7b8d9a34ee98c3b1e7231bdb38a022c7" category="list-text">[ノートブック] タブの [*ノートブック インスタンス*] を開き、オレンジ色のボタン [*ノートブック インスタンスの作成*] をクリックします。</block>
  <block id="519925d609277093d7d2ace0457f720a" category="inline-image-macro">AWS SageMaker ノートブックインスタンスコンソール</block>
  <block id="d8d17e525889b2a89d32645cb06938f6" category="paragraph"><block ref="d8d17e525889b2a89d32645cb06938f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b070f651df156f54539ea886d6fdb252" category="list-text">作成ページで、*ノートブックインスタンス名*を入力します。*ネットワーク*パネルを展開します。他のエントリはデフォルトのままにして、*VPC*、*サブネット*、および*セキュリティグループ*を選択します。  (この *VPC* と *サブネット* は、後で FSx ONTAPファイル システムを作成するために使用されます) 右下にあるオレンジ色のボタン *ノートブック インスタンスの作成* をクリックします。</block>
  <block id="02ca97619a6b22b9a2f189b3ebb82b57" category="inline-image-macro">ノートブックインスタンスを作成する</block>
  <block id="39578328ea9c3b8e5a35ce1c48b45447" category="paragraph"><block ref="39578328ea9c3b8e5a35ce1c48b45447" category="inline-image-macro-rx" type="image"></block></block>
  <block id="08bf44c8870f044a9c29ec0decd4506f" category="section-title">FSx ONTAPファイルシステムを作成する</block>
  <block id="a0de53cada8c076391cb766a21d191f7" category="list-text">AWS コンソールを開きます。検索パネルで「Fsx」を検索し、サービス *FSx* をクリックします。</block>
  <block id="f815343e909cc0c69784c51630a10b2d" category="inline-image-macro">FSxパネル</block>
  <block id="eb780b87d03905721f4484288ab2cde0" category="paragraph"><block ref="eb780b87d03905721f4484288ab2cde0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55ecf05d044f8d3b179ea6daf134664f" category="list-text">*ファイルシステムの作成*をクリックします。</block>
  <block id="77d148bb10790640cfe7639dbc11e075" category="inline-image-macro">ファイルシステムを作成する</block>
  <block id="af10909a9067ddaba9079a1b5b37ca6d" category="paragraph"><block ref="af10909a9067ddaba9079a1b5b37ca6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83c8e65862a92cd7eadb9812c8c5f780" category="list-text">最初のカード *FSx ONTAP* を選択し、*次へ* をクリックします。</block>
  <block id="6277f28f413aee819a82e3e0058bc5ee" category="inline-image-macro">ファイルシステムの種類を選択</block>
  <block id="03ad22f430d1bae0e9c295ff4191eac1" category="paragraph"><block ref="03ad22f430d1bae0e9c295ff4191eac1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b05d3465523c46c6ece6e36ff05bba" category="list-text">詳細設定ページで。</block>
  <block id="720e4d0907f5f98d25c99b23a410c93c" category="list-text">*標準作成*オプションを選択します。</block>
  <block id="fb23d0162f70b1382f3c50cb5b513f4d" category="inline-image-macro">ファイルシステムパネルの作成</block>
  <block id="69ff48a0fa8eb8c1e7999c1ff581fe73" category="paragraph"><block ref="69ff48a0fa8eb8c1e7999c1ff581fe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bea7f738749e0c476b2d1c016021ec5b" category="list-text">*ファイルシステム名*と*SSDストレージ容量*を入力します。</block>
  <block id="aad9529851b728c0fb560a0f7d9b8a5b" category="inline-image-macro">ファイルシステムの詳細を指定する</block>
  <block id="1c15f13ef7a0d9e6720f0178a39c5dde" category="paragraph"><block ref="1c15f13ef7a0d9e6720f0178a39c5dde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5db4aeb81b94a1ba5cdcc12c96b36cb1" category="list-text">*SageMaker Notebook* インスタンスと同じ *VPC* と *サブネット* を使用するようにしてください。</block>
  <block id="84e88a3298035d04334f19541c31a16a" category="inline-image-macro">ネットワークとセキュリティの構成</block>
  <block id="3788a93ec701a347dfa0def01330fa09" category="paragraph"><block ref="1832dc909b2a82e8c4b70afb493963cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb695bdcb362931108f41ff0ec65293" category="list-text">*ストレージ仮想マシン* 名を入力し、SVM (ストレージ仮想マシン) の *パスワードを指定* します。</block>
  <block id="691a3c3a3ffee99887addcf66bcceeec" category="inline-image-macro">デフォルトのストレージ仮想マシン構成</block>
  <block id="68cc70fed3a17a1a1caec811e0d01f03" category="paragraph"><block ref="68cc70fed3a17a1a1caec811e0d01f03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4c7ba1524cf2b18e8592e9ceb83df71" category="list-text">他のエントリはデフォルトのままにして、右下にあるオレンジ色のボタン「次へ」をクリックします。</block>
  <block id="38f46900c7e5018a4d712fad6dde98ea" category="inline-image-macro">設定を確認する</block>
  <block id="c715f26fb866d18303643cfaf886a63c" category="paragraph"><block ref="c715f26fb866d18303643cfaf886a63c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5ce0306761971a734da357efdf9e6f" category="list-text">レビュー ページの右下にあるオレンジ色のボタン * ファイル システムの作成 * をクリックします。</block>
  <block id="c0e0aca15b43c5f4360b8e6c8f2451d9" category="inline-image-macro">構成を確認し、作成を確認する</block>
  <block id="29fe6a20d375efc9f6e4ae1a07258da3" category="paragraph"><block ref="29fe6a20d375efc9f6e4ae1a07258da3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c12346192a59739b1315d8d07143db6e" category="list-text">FSx ファイル システムの起動には約 *20 ～ 40 分* かかる場合があります。</block>
  <block id="391b09977b768e724f35dad726f1f3ef" category="inline-image-macro">FSxコンソールを検査する</block>
  <block id="37f274b71add0d0952db64f7c20abd4f" category="paragraph"><block ref="37f274b71add0d0952db64f7c20abd4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01ecbbb2b353cf4d915bbe1c1cd5505c" category="section-title">サーバー構成</block>
  <block id="d36647d06b353fcd6fedc60898e43187" category="section-title">ONTAP構成</block>
  <block id="07afa2af969623c48103624cdb58551c" category="list-text">作成された FSx ファイル システムを開きます。ステータスが「利用可能」であることを確認してください。</block>
  <block id="69d4f895c19503f5e9f518c3b74993bb" category="inline-image-macro">バックエンドの作成を待つ</block>
  <block id="a29e057394c30462c97d0a046428ccc6" category="paragraph"><block ref="a29e057394c30462c97d0a046428ccc6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6cbcfc771dc80f5ee77c4deba078b135" category="list-text">*管理*タブを選択し、*管理エンドポイント - IP アドレス*と* ONTAP管理者ユーザー名*を保持します。</block>
  <block id="a63e6273ab6f9d27c79b63c3e31a3f35" category="inline-image-macro">ファイルシステム詳細コンソール</block>
  <block id="3a0eb32361b0c7bfba5fc5c8da00fec5" category="paragraph"><block ref="3a0eb32361b0c7bfba5fc5c8da00fec5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0164aebedfb5a99b6386ba01ffbc963" category="list-text">作成された*SageMaker Notebookインスタンス*を開き、*JupyterLabを開く*をクリックします。</block>
  <block id="5f42fc26006705fa3b9ffe25fe3d881d" category="inline-image-macro">AWS SageMaker Notebookインスタンスコンソール</block>
  <block id="85c4a421924bf2d8fbb4d65b5fcd0317" category="paragraph"><block ref="85c4a421924bf2d8fbb4d65b5fcd0317" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12dbc394c66b065a1aef771f11914dad" category="list-text">Jupyter Lab ページで、新しい *ターミナル* を開きます。</block>
  <block id="f3970717b786c14ff186b01681be062f" category="inline-image-macro">Jupyter Lab ウェルカムページ</block>
  <block id="6774664dc7058399d3db96209da79e83" category="paragraph"><block ref="6774664dc7058399d3db96209da79e83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ad2ec02537c0b93a2b5a7937ea89048" category="list-text">FSx ONTAPファイル システムにログインするには、ssh コマンド ssh &lt;admin user name&gt;@&lt; ONTAP server IP&gt; を入力します。  (ユーザー名とIPアドレスは手順2で取得します) *ストレージ仮想マシン*作成時に使用したパスワードを使用してください。</block>
  <block id="7d71a86e3b4885ad307f3e18ba62c9cb" category="inline-image-macro">Jupyter Labターミナル</block>
  <block id="3907af7edeccc904e748efdec97a698b" category="paragraph"><block ref="3907af7edeccc904e748efdec97a698b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7fe5b2fa5a8ec0c7d2b2e65bce4c302" category="list-text">次の順序でコマンドを実行します。  *FSx ONTAPプライベート S3 バケット名* の名前として *fsxn-ontap* を使用します。  *-vserver* 引数には *ストレージ仮想マシン名* を使用してください。</block>
  <block id="9166665a24ce86a4cdc78ee5dc10b99e" category="inline-image-macro">Jupyter Labターミナル出力</block>
  <block id="f953d25a23501b488d1729dde1bcbfec" category="paragraph"><block ref="f953d25a23501b488d1729dde1bcbfec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09b48d43c330baa7527d4d5b785ddc78" category="list-text">以下のコマンドを実行して、FSx ONTAPプライベート S3 のエンドポイント IP と資格情報を取得します。</block>
  <block id="1025c82e986534d7a6a941036fce2afd" category="list-text">将来使用するためにエンドポイントの IP と資格情報を保持します。</block>
  <block id="8d5111b0ef521165f30cc6043e79b8b4" category="paragraph"><block ref="8d5111b0ef521165f30cc6043e79b8b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb11dcb3b0575af26386e753c028e37d" category="section-title">クライアント構成</block>
  <block id="d885926aec2cdf1253c078102968eb8d" category="list-text">SageMaker Notebook インスタンスで、新しい Jupyter ノートブックを作成します。</block>
  <block id="6aa1a9a77e640f5f5edc06a932b6ed8a" category="inline-image-macro">新しいJupyterノートブックを開く</block>
  <block id="28f138d5d6604c9e1a6788b166239c3f" category="paragraph"><block ref="28f138d5d6604c9e1a6788b166239c3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e248de3aba6cefa5adacaaee03aaa6e8" category="inline-link-macro">fsxn_demo.ipynb</block>
  <block id="3161057d478204432fe5225e86346e57" category="list-text">以下のコードを回避策として使用して、FSx ONTAPプライベート S3 バケットにファイルをアップロードします。包括的なコード例については、このノートブックを参照してください。<block ref="5926c62f2c3d59c789081e1f0aff3f08" category="inline-link-macro-rx"></block></block>
  <block id="9c715084d36062c3ee5a47d1e528cd94" category="paragraph">これで、FSx ONTAPと SageMaker インスタンスの統合は完了です。</block>
  <block id="6d8aee76fb8c09877162ad6d9e5fdac9" category="section-title">便利なデバッグチェックリスト</block>
  <block id="c00ea068fc81a9c0fcad0e38fbc7bb94" category="list-text">SageMaker Notebook インスタンスと FSx ONTAPファイルシステムが同じ VPC にあることを確認します。</block>
  <block id="2ec57b268e910c39ad70e1b259d09e1a" category="list-text">権限レベルを *dev* に設定するには、 ONTAPで *set dev* コマンドを実行することを忘れないでください。</block>
  <block id="5a7d7d5f81481db284cc081576a810b0" category="section-title">よくある質問（2023年9月27日現在）</block>
  <block id="de9370dee0783c12eee2dcba49377c0c" category="paragraph">Q: FSx ONTAPにファイルをアップロードするときに、「*CreateMultipartUpload 操作の呼び出し時にエラーが発生しました (NotImplemented): 要求した s3 コマンドは実装されていません*」というエラーが表示されるのはなぜですか?</block>
  <block id="b17f3ba7d3e19cd555784a4d2fd9e51b" category="paragraph">A: プライベート S3 バケットとして、FSx ONTAP は最大 100 MB のファイルのアップロードをサポートします。 S3 プロトコルを使用する場合、100 MB を超えるファイルは 100 MB のチャンクに分割され、「CreateMultipartUpload」関数が呼び出されます。ただし、FSx ONTAPプライベート S3 の現在の実装では、この機能はサポートされていません。</block>
  <block id="89551e14b23206a9d9d14f16530fc28d" category="paragraph">Q: FSx ONTAPにファイルをアップロードするときに、「*PutObject 操作の呼び出し時にエラーが発生しました (AccessDenied)。アクセスが拒否されました*」というエラーが表示されるのはなぜですか?</block>
  <block id="21ba2b927703c559d6b74e6dbc961ebb" category="paragraph">A: SageMaker Notebook インスタンスから FSx ONTAPプライベート S3 バケットにアクセスするには、AWS 認証情報を FSx ONTAP認証情報に切り替えます。ただし、インスタンスに書き込み権限を付与するには、バケットをマウントし、「chmod」シェル コマンドを実行して権限を変更するという回避策が必要です。</block>
  <block id="a713cfa91c4b5642352b00e081eca0ce" category="paragraph">Q: FSx ONTAPプライベート S3 バケットを他の SageMaker ML サービスと統合するにはどうすればよいですか?</block>
  <block id="eae99a039ae09d5e28c061d7218d0efb" category="paragraph">A: 残念ながら、SageMaker サービス SDK では、プライベート S3 バケットのエンドポイントを指定する方法は提供されていません。その結果、FSx ONTAP S3 は、Sagemaker Data Wrangler、Sagemaker Clarify、Sagemaker Glue、Sagemaker Athena、Sagemaker AutoML などの SageMaker サービスと互換性がありません。</block>
  <block id="7892d93cdad4bcd1c3e8157592ed858e" category="summary">この記事は、Amazon FSx for NetApp ONTAP (FSx ONTAP) を使用して SageMaker で PyTorch モデルをトレーニングする方法、具体的にはタイヤ品質分類プロジェクトに関するチュートリアルです。</block>
  <block id="ecccb638c3da2e33f2ce538fc895233a" category="doc">パート 2 - SageMaker でのモデルトレーニングのデータソースとして AWS Amazon FSx for NetApp ONTAP (FSx ONTAP) を活用する</block>
  <block id="ca3ef01192dfa69eac50d8be997f6b51" category="paragraph">この記事は、Amazon FSx for NetApp ONTAP (FSx ONTAP) を使用して SageMaker で PyTorch モデルをトレーニングする方法について、具体的にはタイヤ品質分類プロジェクト向けのチュートリアルです。</block>
  <block id="23851f05df4c2ebe4433cd559cf23e55" category="paragraph">このチュートリアルでは、コンピューター ビジョン分類プロジェクトの実用的な例を示し、SageMaker 環境内で FSx ONTAP をデータ ソースとして利用する ML モデルの構築に関する実践的な体験を提供します。このプロジェクトは、ディープラーニング フレームワークである PyTorch を使用して、タイヤ画像に基づいてタイヤの品質を分類することに重点を置いています。  Amazon SageMaker のデータソースとして FSx ONTAPを使用した機械学習モデルの開発に重点を置いています。</block>
  <block id="516bec227f44816f7ecc2d58aae01bb2" category="section-title">FSx ONTAPとは</block>
  <block id="e586360cf616ba9b2800383d7e36b444" category="paragraph">Amazon FSx ONTAP は、AWS が提供する完全に管理されたストレージソリューションです。  NetApp のONTAPファイル システムを活用して、信頼性が高く高性能なストレージを提供します。 NFS、SMB、iSCSI などのプロトコルをサポートしているため、さまざまなコンピューティング インスタンスやコンテナーからのシームレスなアクセスが可能になります。このサービスは、優れたパフォーマンスを提供し、高速かつ効率的なデータ操作を保証するように設計されています。また、高い可用性と耐久性も提供し、データのアクセスと保護が維持されます。さらに、 Amazon FSx ONTAPのストレージ容量はスケーラブルなので、ニーズに応じて簡単に調整できます。</block>
  <block id="05ec336213c5aa3c3a49c743c5fbad19" category="section-title">ネットワーク環境</block>
  <block id="9e7ee35cf251304984a47d590762e1d2" category="inline-image-macro">ネットワーク環境</block>
  <block id="8ebf7b35e6a40f5a75092ae4b590f9d1" category="paragraph"><block ref="8ebf7b35e6a40f5a75092ae4b590f9d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a431daf3a478d96ed5ffc10a4056228" category="paragraph">FSx ONTAP (Amazon FSx ONTAP) は AWS ストレージサービスです。これには、 NetApp ONTAPシステム上で実行されるファイルシステムと、それに接続する AWS 管理のシステム仮想マシン (SVM) が含まれます。提供された図では、AWS によって管理されるNetApp ONTAPサーバーは VPC の外部に配置されています。  SVM は SageMaker とNetApp ONTAPシステム間の仲介役として機能し、SageMaker から操作要求を受信して、基盤となるストレージに転送します。 FSx ONTAPにアクセスするには、SageMaker を FSx ONTAPデプロイメントと同じ VPC 内に配置する必要があります。この構成により、SageMaker と FSx ONTAP間の通信とデータ アクセスが保証されます。</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="section-title">データ アクセス</block>
  <block id="70385d02db6379c01d4b7b17101f2004" category="paragraph">実際のシナリオでは、データ サイエンティストは通常、FSx ONTAPに保存されている既存のデータを活用して機械学習モデルを構築します。ただし、デモンストレーションの目的では、FSx ONTAPファイル システムは作成後最初は空であるため、トレーニング データを手動でアップロードする必要があります。これは、FSx ONTAP をボリュームとして SageMaker にマウントすることで実現できます。ファイルシステムが正常にマウントされると、マウントされた場所にデータセットをアップロードして、SageMaker 環境内でモデルをトレーニングするためにアクセスできるようになります。このアプローチにより、モデルの開発とトレーニングに SageMaker を使用しながら、FSx ONTAPのストレージ容量と機能を活用できます。</block>
  <block id="23ea498668d1fa717fb7cfb600bf3238" category="inline-link-macro">パート 1 - Amazon FSx for NetApp ONTAP (FSx ONTAP) をプライベート S3 バケットとして AWS SageMaker に統合する</block>
  <block id="95d89db7f4a106e280e1c30cde658610" category="paragraph">データ読み取りプロセスでは、FSx ONTAP をプライベート S3 バケットとして構成する必要があります。詳細な設定手順については、以下を参照してください。<block ref="8e7379c67a0724b1a49308a7ae6ac3d5" category="inline-link-macro-rx"></block></block>
  <block id="30eaeebc8f9611f55e018d1dd51789ba" category="section-title">統合の概要</block>
  <block id="7ffc912d31a398685c5667622bb5ed7f" category="inline-image-macro">トレーニングワークフロー</block>
  <block id="29e5f040e75c8e4e628e90efc594e3ef" category="paragraph"><block ref="29e5f040e75c8e4e628e90efc594e3ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da4169484addf29c5d1d35a28a5073fd" category="paragraph">FSx ONTAPのトレーニング データを使用して SageMaker でディープ ラーニング モデルを構築するワークフローは、データ ローダーの定義、モデルのトレーニング、およびデプロイメントという 3 つの主なステップに要約できます。大まかに言えば、これらのステップは MLOps パイプラインの基盤を形成します。ただし、包括的な実装のために、各ステップにはいくつかの詳細なサブステップが含まれます。これらのサブステップには、データの前処理、データセットの分割、モデルの構成、ハイパーパラメータの調整、モデルの評価、モデルの展開などのさまざまなタスクが含まれます。これらの手順により、SageMaker 環境内で FSx ONTAPのトレーニング データを使用してディープ ラーニング モデルを構築および展開するための徹底的かつ効果的なプロセスが保証されます。</block>
  <block id="2870e83ec05413b09bc7de07f60f54fa" category="section-title">ステップバイステップの統合</block>
  <block id="e3364bc8e125077137411ae17c13b771" category="section-title">データLoader</block>
  <block id="220b880a3d218e80d8fde5901827649a" category="paragraph">PyTorch ディープラーニング ネットワークをデータでトレーニングするために、データのフィードを容易にするデータ ローダーが作成されます。データ ローダーはバッチ サイズを定義するだけでなく、バッチ内の各レコードを読み取って前処理する手順も決定します。データ ローダーを構成することで、データの処理をバッチで処理し、ディープ ラーニング ネットワークのトレーニングが可能になります。</block>
  <block id="cc0322e5278f21d6001e3995e46e2810" category="paragraph">データ ローダーは 3 つの部分で構成されます。</block>
  <block id="0cee527e2a952dcfca00fb6de192e2a1" category="section-title">前処理関数</block>
  <block id="50a46eb952358276ed306b6d88aadc7d" category="paragraph">上記のコード スニペットは、*torchvision.transforms* モジュールを使用した画像前処理変換の定義を示しています。このチュートリアルでは、一連の変換を適用するための前処理オブジェクトが作成されます。まず、*ToTensor()* 変換により、画像をテンソル表現に変換します。その後、*Resize((224,224))* 変換により、画像のサイズが 224x224 ピクセルの固定サイズに変更されます。最後に、*Normalize()* 変換は、各チャネルに沿って平均を減算し、標準偏差で割ることでテンソル値を正規化します。正規化に使用される平均値と標準偏差値は、事前トレーニング済みのニューラル ネットワーク モデルでよく使用されます。全体として、このコードは、画像データをテンソルに変換し、サイズを変更し、ピクセル値を正規化することで、画像データをさらに処理したり、事前トレーニング済みモデルに入力したりできるように準備します。</block>
  <block id="578a55cb1cfe6e1363a1c73fec7d9c6f" category="section-title">PyTorch データセットクラス</block>
  <block id="7895a195c178ff4c5e59638a3c762dd2" category="paragraph">このクラスは、データセット内のレコードの合計数を取得する機能を提供し、各レコードのデータを読み取るメソッドを定義します。  *__getitem__* 関数内で、コードは boto3 S3 バケット オブジェクトを使用して、FSx ONTAPからバイナリ データを取得します。 FSx ONTAPからデータにアクセスするためのコード スタイルは、Amazon S3 からデータを読み取る場合と似ています。以降の説明では、プライベート S3 オブジェクト *bucket* の作成プロセスについて詳しく説明します。</block>
  <block id="76d805ebfad939474c22611b1a64ec91" category="section-title">プライベートS3リポジトリとしてのFSx ONTAP</block>
  <block id="3d67de2c700f42063d686e92a37a82aa" category="paragraph">SageMaker で FSx ONTAPからデータを読み取るために、S3 プロトコルを使用して FSx ONTAPストレージを指すハンドラーが作成されます。これにより、FSx ONTAP をプライベート S3 バケットとして扱うことができます。ハンドラーの設定には、FSx ONTAP SVM の IP アドレス、バケット名、および必要な資格情報の指定が含まれます。これらの構成項目の取得に関する詳細な説明については、次の文書を参照してください。<block ref="a4f6db8ee799d71c8436c5d66421c857" category="inline-link-macro-rx"></block> 。</block>
  <block id="ac5d6406e8dadcbc23e9cf65fe528510" category="paragraph">上記の例では、バケット オブジェクトを使用して PyTorch データセット オブジェクトをインスタンス化しています。データセット オブジェクトについては、後続のセクションでさらに詳しく説明します。</block>
  <block id="e03717a5c1692689919250506bf382a0" category="section-title">PyTorchデータLoader</block>
  <block id="0c919f2bf87f2c6df41e7bbc52c68d04" category="paragraph">提供されている例では、バッチ サイズ 64 が指定されており、各バッチに 64 個のレコードが含まれることを示しています。 PyTorch *Dataset* クラス、前処理関数、およびトレーニング バッチ サイズを組み合わせることで、トレーニング用のデータ ローダーを取得します。このデータ ローダーは、トレーニング フェーズ中にデータセットをバッチで反復処理するプロセスを容易にします。</block>
  <block id="74415cec8ae4d65c228c7fa8da8eae8a" category="section-title">モデルトレーニング</block>
  <block id="74492eb8210f5168d9ee3eff7524ecde" category="paragraph">このコードは標準の PyTorch トレーニング プロセスを実装します。これは、畳み込み層と線形層を使用してタイヤの品質を分類する *TyreQualityClassifier* と呼ばれるニューラル ネットワーク モデルを定義します。トレーニング ループはデータ バッチを反復処理し、損失を計算し、バックプロパゲーションと最適化を使用してモデルのパラメータを更新します。さらに、監視の目的で現在の時刻、エポック、バッチ、損失を出力します。</block>
  <block id="4d2e185dfba9f3df542300054ad07998" category="section-title">モデルの展開</block>
  <block id="6116a0f9a85671aec95cc56a205cf186" category="paragraph">SageMaker ではモデルをデプロイするために S3 に保存する必要があるため、コードは PyTorch モデルを *Amazon S3* に保存します。モデルを *Amazon S3* にアップロードすると、SageMaker からアクセスできるようになり、デプロイされたモデルのデプロイと推論が可能になります。</block>
  <block id="075e4fb3d67ee1fb4bc39dbc5d72b129" category="paragraph">このコードは、SageMaker への PyTorch モデルのデプロイを容易にします。これは、入力データを PyTorch テンソルとして前処理してシリアル化するカスタム シリアライザー *TyreQualitySerializer* を定義します。 *TyreQualityPredictor* クラスは、定義されたシリアライザーと *JSONDeserializer* を利用するカスタム予測子です。このコードは、モデルの S3 の場所、IAM ロール、フレームワークのバージョン、推論のエントリ ポイントを指定するための *PyTorchModel* オブジェクトも作成します。コードはタイムスタンプを生成し、モデルとタイムスタンプに基づいてエンドポイント名を構築します。最後に、インスタンス数、インスタンスタイプ、生成されたエンドポイント名を指定して、deploy メソッドを使用してモデルがデプロイされます。これにより、PyTorch モデルをデプロイし、SageMaker で推論にアクセスできるようになります。</block>
  <block id="bfc7647fbfe6e589911d2da73377b475" category="section-title">推論</block>
  <block id="99e1766840e675b2dbd8230be049188f" category="paragraph">これは、デプロイされたエンドポイントを使用して推論を行う例です。</block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">このセクションでは、Apache Spark 用のNetAppストレージ ソリューションに関するこのドキュメントの概要を説明します。</block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">まとめ</block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">このドキュメントでは、ビッグ データ、最新の分析、AI、ML、DL に関連する Apache Spark アーキテクチャ、顧客のユースケース、 NetAppストレージ ポートフォリオについて説明します。業界標準のベンチマーク ツールと顧客の要求に基づくパフォーマンス検証テストでは、 NetApp Spark ソリューションはネイティブ Hadoop システムに比べて優れたパフォーマンスを示しました。このレポートで紹介されている顧客のユースケースとパフォーマンス結果を組み合わせることで、導入に適した Spark ソリューションを選択するのに役立ちます。</block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">このドキュメントでは、Apache Spark アーキテクチャ、顧客のユースケース、およびビッグ データ分析と人工知能に関連するNetAppストレージ ポートフォリオに焦点を当てています。また、一般的な Hadoop システムに対して業界標準の AI、機械学習、ディープラーニング ツールを使用してさまざまなテスト結果も提示し、適切な Spark ソリューションを選択できるようにします。</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Apache Spark 向けNetAppストレージ ソリューション: アーキテクチャ、ユースケース、パフォーマンス結果</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang、Karthikeyan Nagalingam、 NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">このドキュメントでは、Apache Spark アーキテクチャ、顧客のユースケース、およびビッグ データ分析と人工知能 (AI) に関連するNetAppストレージ ポートフォリオに焦点を当てています。また、一般的な Hadoop システムに対して業界標準の AI、機械学習 (ML)、ディープラーニング (DL) ツールを使用してさまざまなテスト結果を示し、適切な Spark ソリューションを選択できるようにします。まず、Spark アーキテクチャ、適切なコンポーネント、および 2 つのデプロイメント モード (クラスターとクライアント) が必要です。</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">このドキュメントでは、構成の問題に対処するための顧客の使用事例も提供し、ビッグ データ分析や Spark を使用した AI、ML、DL に関連するNetAppストレージ ポートフォリオの概要についても説明します。最後に、Spark 固有のユースケースとNetApp Spark ソリューション ポートフォリオから得られたテスト結果を紹介します。</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="section-title">顧客の課題</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">このセクションでは、小売、デジタル マーケティング、銀行、個別製造、プロセス製造、政府、専門サービスなどのデータ増加産業におけるビッグ データ分析と AI/ML/DL に関する顧客の課題に焦点を当てます。</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">予測不可能なパフォーマンス</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">従来の Hadoop の導入では、通常、市販のハードウェアが使用されます。パフォーマンスを向上させるには、ネットワーク、オペレーティング システム、Hadoop クラスター、Spark などのエコシステム コンポーネント、およびハードウェアを調整する必要があります。各レイヤーをチューニングしても、Hadoop は環境内での高パフォーマンス向けに設計されていない汎用ハードウェア上で実行されるため、望ましいパフォーマンス レベルを達成するのは難しい場合があります。</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">メディアとノードの障害</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">通常の状況でも、市販のハードウェアは故障しやすいものです。データ ノード上の 1 つのディスクに障害が発生した場合、Hadoop マスターはデフォルトでそのノードが正常でないと見なします。次に、そのノードの特定のデータをネットワーク経由でレプリカから正常なノードにコピーします。このプロセスにより、Hadoop ジョブのネットワーク パケットの速度が低下します。クラスターは、異常なノードが正常な状態に戻ったときに、データを再度コピーし、過剰に複製されたデータを削除する必要があります。</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoopベンダーロックイン</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop ディストリビューターは独自のバージョン管理を備えた独自の Hadoop ディストリビューションを持っているため、顧客はそれらのディストリビューションに縛られてしまいます。ただし、多くの顧客は、特定の Hadoop ディストリビューションに縛られないインメモリ分析のサポートを必要としています。彼らには、配信を変更しながらも分析を持ち運べる自由が必要です。</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">複数の言語のサポートが不足している</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">多くの場合、顧客はジョブを実行するために MapReduce Java プログラムに加えて複数の言語のサポートを必要とします。  SQL やスクリプトなどのオプションにより、回答を得るための柔軟性が向上し、データを整理および取得するためのオプションが増え、データを分析フレームワークに移動する速度が速くなります。</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">使いにくさ</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">以前から、Hadoop は使いにくいという不満の声が上がっていました。  Hadoop は新しいバージョンが出るたびによりシンプルかつ強力になっているにもかかわらず、この批判は続いています。  Hadoop では、Java および MapReduce プログラミング パターンを理解する必要がありますが、これはデータベース管理者や従来のスクリプト スキルを持つ人にとっては難しい課題です。</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">複雑なフレームワークとツール</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">企業の AI チームはさまざまな課題に直面しています。専門的なデータ サイエンスの知識があっても、さまざまなデプロイメント エコシステムおよびアプリケーション用のツールとフレームワークを、単純に相互に変換できるとは限りません。データ サイエンス プラットフォームは、データの移動が容易で、モデルを再利用可能、すぐに使用できるコード、モデルのプロトタイピング、検証、バージョン管理、共有、再利用、本番環境への迅速な導入に関するベスト プラクティスをサポートするツールを備え、Spark 上に構築された対応するビッグ データ プラットフォームとシームレスに統合される必要があります。</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">NetAppを選ぶ理由</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp は、次の方法で Spark エクスペリエンスを向上できます。</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFS ダイレクト アクセス (下の図を参照) を使用すると、データを移動またはコピーすることなく、既存または新規の NFSv3 または NFSv4 データに対してビッグ データ分析ジョブを実行できます。データの複数のコピーを防ぎ、ソースとデータを同期する必要がなくなります。</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">より効率的なストレージとより少ないサーバーレプリケーション。たとえば、 NetApp E シリーズ Hadoop ソリューションでは、データのレプリカが 3 つではなく 2 つ必要であり、 FAS Hadoop ソリューションではデータ ソースは必要ですが、データのレプリケーションやコピーは必要ありません。  NetAppストレージ ソリューションでは、サーバー間のトラフィックも削減されます。</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">ドライブおよびノード障害時の Hadoop ジョブとクラスターの動作が改善されました。</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">データ取り込みパフォーマンスが向上します。</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">代替の Apache Spark 構成。</block>
  <block id="0c0038bcea5bace3c716607bdf5ea55f" category="paragraph"><block ref="0c0038bcea5bace3c716607bdf5ea55f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">たとえば、金融や医療の分野では、ある場所から別の場所へのデータの移動は法的義務を満たす必要があり、これは簡単な作業ではありません。このシナリオでは、 NetApp NFS ダイレクト アクセスが、元の場所から財務データと医療データを分析します。もう 1 つの重要な利点は、 NetApp NFS ダイレクト アクセスを使用すると、ネイティブ Hadoop コマンドを使用して Hadoop データの保護が簡素化され、 NetAppの豊富なデータ管理ポートフォリオを使用してデータ保護ワークフローが実現されることです。</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS ダイレクト アクセスは、Hadoop/Spark クラスターに 2 種類の導入オプションを提供します。</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">デフォルトでは、Hadoop または Spark クラスターは、データ ストレージとデフォルトのファイル システムとして Hadoop 分散ファイル システム (HDFS) を使用します。  NetApp NFS ダイレクト アクセスでは、デフォルトの HDFS を NFS ストレージに置き換えてデフォルトのファイル システムとして使用できるため、NFS データの直接分析が可能になります。</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">別の導入オプションとして、 NetApp NFS ダイレクト アクセスでは、単一の Hadoop または Spark クラスター内の HDFS とともに NFS を追加ストレージとして構成することがサポートされています。この場合、顧客は NFS エクスポートを通じてデータを共有し、HDFS データと同じクラスターからデータにアクセスできます。</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">NetApp NFS ダイレクト アクセスを使用する主な利点は次のとおりです。</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">現在の場所からデータを分析することで、分析データを HDFS などの Hadoop インフラストラクチャに移動する、時間とパフォーマンスを消費するタスクを回避します。</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">レプリカの数を 3 個から 1 個に減らします。</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">ユーザーがコンピューティングとストレージを切り離して、個別に拡張できるようにします。</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">ONTAPの豊富なデータ管理機能を活用して、エンタープライズ データ保護を提供します。</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Hortonworks データ プラットフォームの認定。</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">ハイブリッド データ分析の展開を可能にします。</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">動的マルチスレッド機能を活用してバックアップ時間を短縮します。</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="inline-link-macro">TR-4657: NetAppハイブリッド クラウド データ ソリューション - 顧客のユースケースに基づく Spark と Hadoop</block>
  <block id="c5153856e4d13c48696624c702620995" category="paragraph">見る<block ref="46ae0631eaa2b1a19769e051f280e3cf" category="inline-link-macro-rx"></block>Hadoop データのバックアップ、クラウドからオンプレミスへのバックアップと災害復旧、既存の Hadoop データでの DevTest の有効化、データ保護とマルチクラウド接続、分析ワークロードの高速化を実現します。</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">次のセクションでは、Spark のお客様にとって重要なストレージ機能について説明します。</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">ストレージ階層化</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Hadoop ストレージ階層化を使用すると、ストレージ ポリシーに従って、異なるストレージ タイプでファイルを保存できます。ストレージの種類には以下が含まれます<block ref="27369b3bf4483e8dcfd85ba9a39a947f" prefix=" " category="inline-code"></block>、<block ref="75e52a0ecfafeda17a34fc60111c1f0b" prefix=" " category="inline-code"></block> 、<block ref="a957a3153eb7126b1c5f8b6aac35de53" prefix=" " category="inline-code"></block> 、<block ref="714f8e54e71566bd1c2e29328288a62c" prefix=" " category="inline-code"></block> 、<block ref="7fc1aa11178f33b4f796d69c73f7f0b4" prefix=" " category="inline-code"></block> 、 そして<block ref="fa4fdcc80e19a0848c6360538fdd86ef" prefix=" " category="inline-code"></block>。</block>
  <block id="c2398745386edbb0221cc4ee496ff79f" category="paragraph">異なるストレージ ポリシーを持つ SSD および SAS ドライブを搭載したNetApp AFFストレージ コントローラと E シリーズ ストレージ コントローラで Hadoop ストレージ階層化の検証を実行しました。 AFF-A800 の Spark クラスターには 4 つのコンピューティング ワーカー ノードがありますが、E シリーズのクラスターには 8 つのコンピューティング ワーカー ノードがあります。これは主に、ソリッド ステート ドライブ (SSD) とハード ドライブ ディスク (HDD) のパフォーマンスを比較するためのものです。</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">次の図は、Hadoop SSD に対するNetAppソリューションのパフォーマンスを示しています。</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">1TB のデータをソートする時間。</block>
  <block id="12b6622989087d668bc9d1da31e9fb70" category="paragraph"><block ref="12b6622989087d668bc9d1da31e9fb70" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 NetApp Eシリーズ Hadoop ソリューション</block>
  <block id="bd9ad8221382748a4f008c3af02731bd" category="list-text">ベースライン NL-SAS 構成では、8 つのコンピューティング ノードと 96 個の NL-SAS ドライブが使用されました。この構成では、4 分 38 秒で 1 TB のデータが生成されました。見る<block ref="264d8d379e3a34fdac32f9057509bf65" category="inline-link-rx"></block>クラスターとストレージ構成の詳細については、こちらをご覧ください。</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">TeraGen を使用すると、SSD 構成では NL-SAS 構成よりも 15.66 倍高速に 1 TB のデータを生成しました。さらに、SSD 構成では、コンピューティング ノードの数とディスク ドライブの数も半分になりました (合計 24 台の SSD ドライブ)。ジョブの完了時間に基づくと、NL-SAS 構成のほぼ 2 倍の速度でした。</block>
  <block id="459f180fc71a8f8bb773d3c879314e39" category="list-text">TeraSort を使用すると、SSD 構成では 1 TB のデータを NL-SAS 構成よりも 1138.36 倍速くソートできました。さらに、SSD 構成では、コンピューティング ノードの数とディスク ドライブの数も半分になりました (合計 24 台の SSD ドライブ)。したがって、ドライブあたりでは、NL-SAS 構成よりも約 3 倍高速になりました。</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">重要なのは、回転ディスクからオールフラッシュへの移行によりパフォーマンスが向上することです。コンピューティングノードの数はボトルネックではありませんでした。  NetApp のオールフラッシュ ストレージを使用すると、ランタイム パフォーマンスが適切に拡張されます。</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">NFS では、データはすべて一緒にプールされることと機能的に同等であり、ワークロードに応じてコンピューティング ノードの数を削減できます。  Apache Spark クラスター ユーザーは、コンピューティング ノードの数を変更するときにデータを手動で再バランスする必要がありません。</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">パフォーマンスのスケーリング - スケールアウト</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">AFFソリューションの Hadoop クラスターからさらに計算能力が必要な場合は、適切な数のストレージ コントローラーを備えたデータ ノードを追加できます。  NetApp、ストレージ コントローラ アレイごとに 4 つのデータ ノードから開始し、ワークロードの特性に応じて、ストレージ コントローラごとに 8 つのデータ ノードまで増やすことを推奨しています。</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFFとFAS はインプレース分析に最適です。コンピューティング要件に基づいてノード マネージャーを追加でき、中断のない操作により、ダウンタイムなしでオンデマンドでストレージ コントローラーを追加できます。当社は、NVME メディア サポート、効率保証、データ削減、QOS、予測分析、クラウド階層化、レプリケーション、クラウド展開、セキュリティなど、 AFFおよびFASの豊富な機能を提供します。お客様が要件を満たせるよう、 NetApp は追加のライセンス費用なしで、ファイルシステム分析、クォータ、オンボックス負荷分散などの機能を提供します。 NetApp は、同時ジョブ数、低レイテンシ、シンプルな操作、および 1 秒あたりのギガバイト単位のスループットにおいて競合他社よりも優れたパフォーマンスを発揮します。さらに、 NetApp Cloud Volumes ONTAP は3 つの主要クラウド プロバイダーすべてで実行されます。</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">パフォーマンスのスケーリング - スケールアップ</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">スケールアップ機能を使用すると、追加のストレージ容量が必要な場合に、 AFF、 FAS、および E シリーズ システムにディスク ドライブを追加できます。  Cloud Volumes ONTAPでは、ストレージを PB レベルに拡張するために、使用頻度の低いデータをブロック ストレージからオブジェクト ストレージに階層化し、追加のコンピューティングなしでCloud Volumes ONTAPライセンスをスタックするという 2 つの要素を組み合わせています。</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">複数のプロトコル</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetAppシステムは、SAS、iSCSI、FCP、InfiniBand、NFS など、Hadoop 展開のほとんどのプロトコルをサポートしています。</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">運用およびサポートソリューション</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">ホートンワークス</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">認証</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">partner</block>
  <block id="24cd9f53ddcc21c3360cfbf1ab787373" category="paragraph">このドキュメントで説明されている Hadoop ソリューションは、 NetAppによってサポートされています。これらのソリューションは、主要な Hadoop ディストリビューターによって認定されています。詳細については、<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block>サイトとCloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block>そして<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block>サイト。</block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">このセクションでは、Apache Spark の性質とコンポーネント、およびそれらがどのようにこのソリューションに貢献するかについて説明します。</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="doc">ソリューション技術</block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark は、Hadoop 分散ファイル システム (HDFS) と直接連携する Hadoop アプリケーションを作成するための人気のプログラミング フレームワークです。  Spark は本番環境に対応しており、ストリーミング データの処理をサポートし、MapReduce よりも高速です。  Spark には、効率的な反復処理のために構成可能なメモリ内データ キャッシュがあり、Spark シェルはインタラクティブにデータを学習および探索できます。  Spark を使用すると、Python、Scala、または Java でアプリケーションを作成できます。  Spark アプリケーションは、1 つ以上のタスクを持つ 1 つ以上のジョブで構成されます。</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">すべての Spark アプリケーションには Spark ドライバーがあります。  YARN クライアント モードでは、ドライバーはクライアント上でローカルに実行されます。 YARN クラスター モードでは、ドライバーはアプリケーション マスター上のクラスターで実行されます。クラスター モードでは、クライアントが切断されてもアプリケーションは実行を継続します。</block>
  <block id="5e8f0f670e38fbdf628b0883f946934f" category="inline-image-macro">入出力ダイアログまたは書かれたコンテンツを示す図</block>
  <block id="bb21b729c47dce20f94160002efec039" category="paragraph"><block ref="bb21b729c47dce20f94160002efec039" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">クラスター マネージャーは 3 つあります。</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">*スタンドアロン*このマネージャーは Spark の一部であり、クラスターのセットアップを容易にします。</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">*Apache Mesos。*これは、MapReduce やその他のアプリケーションも実行する一般的なクラスター マネージャーです。</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">*Hadoop YARN。*これは Hadoop 3 のリソース マネージャーです。</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">復元力のある分散データセット (RDD) は、Spark の主要コンポーネントです。  RDD は、クラスター内のメモリに保存されたデータから失われたデータや欠落したデータを再作成し、ファイルから取得された初期データやプログラムによって作成された初期データを保存します。  RDD は、ファイル、メモリ内のデータ、または別の RDD から作成されます。 Spark プログラミングでは、変換とアクションという 2 つの操作を実行します。変換では、既存の RDD に基づいて新しい RDD が作成されます。アクションは RDD から値を返します。</block>
  <block id="1af693ed22a2df92eb5adff8c506d0ef" category="paragraph">変換とアクションは、Spark データセットとデータフレームにも適用されます。データセットは、RDD (強力な型指定、ラムダ関数の使用) の利点と Spark SQL の最適化された実行エンジンの利点を兼ね備えた分散型データ コレクションです。データセットは JVM オブジェクトから構築し、関数変換 (map、flatMap、filter など) を使用して操作できます。 DataFrame は、名前付きの列に編成されたデータセットです。概念的には、リレーショナル データベースのテーブルまたは R/Python のデータ フレームと同等です。  DataFrames は、構造化データ ファイル、Hive/HBase 内のテーブル、オンプレミスまたはクラウド内の外部データベース、既存の RDD など、さまざまなソースから構築できます。</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">Spark アプリケーションには、1 つ以上の Spark ジョブが含まれます。ジョブはエグゼキュータ内でタスクを実行し、エグゼキュータは YARN コンテナ内で実行されます。各エグゼキュータは単一のコンテナ内で実行され、アプリケーションの存続期間中ずっと存在します。アプリケーションの起動後にエグゼキュータが固定され、YARN はすでに割り当てられているコンテナのサイズを変更しません。  Executor はメモリ内のデータに対してタスクを同時に実行できます。</block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">このセクションでは、このソリューションの内容に興味を持つ可能性のある人について説明します。</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="doc">対象</block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">分析とデータ サイエンスの世界は、IT とビジネスの複数の分野に関係しています。</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">データ サイエンティストには、選択したツールとライブラリを使用できる柔軟性が必要です。</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">データ エンジニアは、データがどのように流れ、どこに存在するかを知る必要があります。</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps エンジニアには、新しい AI および ML アプリケーションを CI および CD パイプラインに統合するためのツールが必要です。</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">クラウド管理者とアーキテクトは、ハイブリッド クラウド リソースをセットアップおよび管理できる必要があります。</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">ビジネス ユーザーは、分析、AI、ML、DL アプリケーションにアクセスしたいと考えています。</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">この技術レポートでは、 NetApp AFF、E シリーズ、 StorageGRID、NFS ダイレクト アクセス、Apache Spark、Horovod、Keras が、これらのそれぞれの役割にどのように役立ち、ビジネスに価値をもたらすかについて説明します。</block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">TeraGen ベンチマーク ツールの TeraSort および TeraValidate スクリプトを使用して、E5760、E5724、およびAFF-A800 構成での Spark パフォーマンス検証を測定しました。さらに、Spark NLP パイプラインと TensorFlow 分散トレーニング、Horovod 分散トレーニング、DeepFM による CTR 予測のための Keras を使用したマルチワーカー ディープラーニングという 3 つの主要なユース ケースがテストされました。</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">テスト結果</block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">TeraGen ベンチマーク ツールの TeraSort および TeraValidate スクリプトを使用して、E5760、E5724、およびAFF-A800 構成での Spark パフォーマンス検証を測定しました。さらに、Spark NLP パイプラインと TensorFlow 分散トレーニング、Horovod 分散トレーニング、DeepFM による CTR 予測のための Keras を使用したマルチワーカー ディープラーニングという 3 つの主要なユース ケースがテストされました。</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">E シリーズとStorageGRID の両方の検証では、Hadoop レプリケーション ファクター 2 を使用しました。  AFF検証では、1 つのデータ ソースのみを使用しました。</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">次の表は、Spark パフォーマンス検証のハードウェア構成を示しています。</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">タイプ</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoopワーカーノード</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">ドライブ タイプ</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">ノードあたりのドライブ数</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">ストレージ コントローラ</block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="cell">SG6060</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">単一の高可用性（HA）ペア</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">単一のHAペア</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">次の表にソフトウェア要件を示します。</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">ソフトウェア</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">version</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK ランタイム環境</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64 ビット サーバー VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="cell">ギット</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">スパーク</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">パイスパーク</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">スパークNLP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">テンソルフロー</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">ケラス</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">ホロヴォド</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">金融感情分析</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="inline-link-macro">TR-4910: NetApp AIによる顧客コミュニケーションからの感情分析</block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link">NetApp DataOps ツールキット</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">タオフレームワーク</block>
  <block id="460926218a6b1ab3e124f410ee69f408" category="paragraph">我々は出版した<block ref="d791c48f7898bbaecde983abed6ac7c1" category="inline-link-macro-rx"></block>エンドツーエンドの会話型AIパイプラインを構築した。<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block> 、 AFFストレージ、 NVIDIA DGX システム。パイプラインは、DataOpsツールキットを活用して、バッチオーディオ信号処理、自動音声認識（ASR）、転移学習、感情分析を実行します。<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block> 、そして<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>。感情分析のユースケースを金融サービス業界に拡大し、SparkNLP ワークフローを構築し、名前付きエンティティの認識などのさまざまな NLP タスク用に 3 つの BERT モデルをロードし、NASDAQ トップ 10 企業の四半期決算発表の文章レベルの感情を取得しました。</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">次のスクリプト<block ref="e313c2865ad76497c3eaf980ccfa3d03" prefix=" " category="inline-code"></block>FinBERT モデルを使用して HDFS 内のトランスクリプトを処理し、次の表に示すように、肯定的、中立的、否定的な感情カウントを生成します。</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">次の表は、2016 年から 2020 年までの NASDAQ トップ 10 企業の収益報告の文章レベルの感情分析を示しています。</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">感情の数と割合</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">全10社</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">アマゾン</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">グーグル</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">INTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">マイクロソフト</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">陽性数</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">中立カウント</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">マイナスカウント</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">分類されていない数</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">（合計数）</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">パーセンテージで見ると、CEO や CFO が話した文章のほとんどは事実に基づいており、したがって中立的な感情を伝えています。決算説明会では、アナリストは肯定的または否定的な感情を伝える可能性のある質問をします。ネガティブまたはポジティブな感情が、取引当日または翌日の株価にどのような影響を与えるかを定量的にさらに調査する価値があります。</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">次の表は、NASDAQ 上位 10 社の文章レベルの感情分析をパーセンテージで示したものです。</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">感情の割合</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">ポジティブ</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="doc"></block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">中性</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">ネガティブ</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">未分類</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">ワークフロー実行時間に関しては、4.78倍の大幅な改善が見られました。<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>モードを HDFS の分散環境に移行し、NFS を活用することでさらに 0.14% の改善が実現しました。</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">次の図に示すように、データとモデルの並列処理により、データ処理と分散 TensorFlow モデル推論速度が向上しました。ワークフローのボトルネックは事前トレーニング済みモデルのダウンロードであるため、NFS にデータを配置すると実行時間がわずかに改善されました。トランスクリプト データセットのサイズを増やすと、NFS の利点がより明らかになります。</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">Spark NLP 感情分析エンドツーエンドのワークフロー ランタイム。</block>
  <block id="44ec3b18d4516fc85f1a9789d47bd91c" category="paragraph"><block ref="44ec3b18d4516fc85f1a9789d47bd91c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovodパフォーマンスによる分散トレーニング</block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="inline-link-macro">主要なユースケースごとの Python スクリプト</block>
  <block id="1bdfd0f4247bc70668e65a97471adcb5" category="paragraph">次のコマンドは、Sparkクラスタ内の実行時情報とログファイルを単一のコマンドで生成しました。<block ref="eb0a191797624dd3a48fa681d3061212" prefix=" " category="inline-code"></block>それぞれ 1 つのコアを持つ 160 個のエグゼキュータを持つノード。メモリ不足エラーを回避するために、実行メモリは 5 GB に制限されました。セクションを参照<block ref="bda46a99ea3f7d5775466396b660e993" category="inline-link-macro-rx"></block>データ処理、モデルトレーニング、モデル精度計算の詳細については、<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block> 。</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">10 回のトレーニング エポックで実行された結果は次のとおりです。</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">入力データの処理、DNN モデルのトレーニング、精度の計算、TensorFlow チェックポイントと予測結果の CSV ファイルの生成には 43 分以上かかりました。トレーニング エポックの数を 10 に制限しましたが、実際には、十分なモデル精度を確保するために 100 に設定されることが多いです。トレーニング時間は通常、エポック数に比例して増加します。</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">次に、クラスタ内で利用可能な4つのワーカーノードを使用して、同じスクリプトを実行しました。<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block> HDFS 内のデータを使用するモード:</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">結果として、実行時間は次のように改善されました。</block>
  <block id="68b0154732e3239041317d0c7d4ac636" category="paragraph">HorovodのモデルとSparkのデータ並列処理により、実行速度が5.29倍向上しました。<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>対<block ref="f5ddaf0ca7929578b408c909429f68f2" prefix=" " category="inline-code"></block>10 回のトレーニング エポックを含むモード。これは次の図に凡例とともに示されています。<block ref="99c35850ff7cf7e436b03acedd4c59b3" prefix=" " category="inline-code"></block>そして<block ref="509820290d57f333403f490dde7316f4" prefix=" " category="inline-code"></block>。基盤となる TensorFlow DNN モデルのトレーニングは、利用可能な場合は GPU を使用してさらに高速化できます。私たちはこのテストを実施し、その結果を今後の技術レポートで公開する予定です。</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">次のテストでは、NFS と HDFS にある入力データの実行時間を比較しました。 AFF A800のNFSボリュームは、<block ref="e5f5dfd1cb98e0a4c27a3ce6df3ca358" prefix=" " category="inline-code"></block> Spark クラスター内の 5 つのノード (マスター 1 つ、ワーカー 4 つ) にわたって。前回のテストと同様のコマンドを実行したが、<block ref="97a9c2c856bc676ba715d3eecc314be6" prefix=" " category="inline-code"></block>パラメータはNFSマウントを指すようになりました:</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">NFS を使用した場合の実行時間は次のようになりました。</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">次の図に示すように、さらに 1.43 倍の高速化が実現しました。したがって、 NetAppオールフラッシュ ストレージをクラスターに接続することで、顧客は Horovod Spark ワークフローの高速データ転送と配信のメリットを享受でき、単一ノードで実行する場合と比較して 7.55 倍の高速化を実現できます。</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark ワークフロー ランタイム。</block>
  <block id="aab5160a7c41d499723acfc13e430eef" category="paragraph"><block ref="aab5160a7c41d499723acfc13e430eef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR予測パフォーマンスのためのディープラーニングモデル</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">CTR を最大化するように設計されたレコメンデーション システムでは、低次から高次まで数学的に計算できるユーザー ビヘイビアの背後にある高度な機能の相互作用を学習する必要があります。低次の機能と高次の機能の相互作用は、どちらか一方に偏ることなく、優れたディープラーニング モデルにとって同等に重要です。因数分解マシン ベースのニューラル ネットワークである Deep Factorization Machine (DeepFM) は、推奨用の因数分解マシンと特徴学習用のディープラーニングを新しいニューラル ネットワーク アーキテクチャに組み合わせています。</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">ワイド＆ディープモデル</block>
  <block id="8a7e0c5a65151889fa193b20e6ea6484" category="paragraph">従来の因数分解マシンは、特徴間の潜在ベクトルの内積としてペアワイズ特徴相互作用をモデル化し、理論的には高次の情報を取得できますが、実際には、機械学習の専門家は、計算とストレージの複雑さが高いため、通常、2 次特徴相互作用のみを使用します。  Googleのようなディープニューラルネットワークの変種<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block>一方、線形ワイドモデルとディープモデルを組み合わせることで、ハイブリッドネットワーク構造における洗練された機能の相互作用を学習します。</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">このワイド＆ディープ モデルには 2 つの入力があります。1 つは基礎となるワイド モデル用、もう 1 つはディープ モデル用です。後者の部分では依然として専門家による特徴エンジニアリングが必要であり、そのためこの手法を他のドメインに一般化することは困難です。ワイド＆ディープ モデルとは異なり、DeepFM は、ワイド部分とディープ部分が同じ入力と埋め込みベクトルを共有するため、特徴エンジニアリングなしで生の特徴を使用して効率的にトレーニングできます。</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">それぞれの主要なユースケース向けの Python スクリプト。</block>
  <block id="e78769fdc1aff8f5383517c0dc3ec750" category="paragraph">まずCriteo<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block> （11GB）ファイルをCSVファイルに<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>NFSマウントに保存<block ref="17d831727f14e5379e2f4773837ccfa4" prefix=" " category="inline-code"></block>使用して<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>セクションから<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>このスクリプト内では、関数<block ref="000f75d2ea65c8a3d82d62e405ce82ee" prefix=" " category="inline-code"></block>タブを削除して挿入するためのいくつかの文字列メソッドを実行します<block ref="433beb9a090abf694184e96d76b3046d" prefix=" " category="inline-code"></block>区切り文字として<block ref="11b282e345a74511901532f5c84b59ee" prefix=" " category="inline-code"></block>改行として。元のファイルのみを処理する必要があることに注意してください<block ref="171acae65b8e3fcd025aa9ba171b4a96" prefix=" " category="inline-code"></block>一度実行すると、コード ブロックがコメントとして表示されます。</block>
  <block id="02aeed17192e292b1708094a50785b65" category="paragraph">さまざまなDLモデルの以下のテストでは、<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>入力ファイルとして。その後のテスト実行では、入力CSVファイルは、次のフィールドを含むスキーマを持つSpark DataFrameに読み込まれました。<block ref="182ea3b4ea8b947ba1626831aa9debbe" prefix=" " category="inline-code"></block>整数密な特徴<block ref="2c94c76f60323031573497e25961744a" prefix=" " category="inline-code"></block>、およびスパースな特徴<block ref="57fae172685844997d173fa4248d66f8" prefix=" " category="inline-code"></block>。次の<block ref="78d07f07ead3482e696c0c224c2a7ed5" prefix=" " category="inline-code"></block>コマンドは入力 CSV を受け取り、クロス検証のために 20% 分割して DeepFM モデルをトレーニングし、10 回のトレーニング エポック後に最適なモデルを選択して、テスト セットでの予測精度を計算します。</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">データファイルは<block ref="a39c9c52aed083c0688cd4974ec80881" prefix=" " category="inline-code"></block>11GBを超える場合は、十分な容量を設定する必要があります<block ref="af770896b1954b7c355d9becfe487e40" prefix=" " category="inline-code"></block>エラーを回避するには、データセットのサイズよりも大きくする必要があります。</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">アパッチアロー</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">上記において<block ref="0ce62b6d4610e91242b63139adeb9432" prefix=" " category="inline-code"></block>有効にした設定<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>はSpark DataFrameをPandas DataFrameに変換します。<block ref="5d77cff4a1fdffb38c875e9a11a310fb" prefix=" " category="inline-code"></block>方法。</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">ランダムに分割した後、トレーニング データセットには 3600 万行以上、テスト セットには 900 万のサンプルが含まれます。</block>
  <block id="a390a463e93dd87edffb2c8b23242507" category="paragraph">この技術レポートは GPU を使用せずに CPU テストに焦点を当てているため、適切なコンパイラ フラグを使用して TensorFlow をビルドすることが不可欠です。このステップでは、GPU アクセラレーション ライブラリの呼び出しを回避し、TensorFlow の Advanced Vector Extensions (AVX) と AVX2 命令を最大限に活用します。これらの機能は、ベクトル化された加算、フィードフォワード内の行列乗算、バックプロパゲーション DNN トレーニングなどの線形代数計算用に設計されています。  256 ビット浮動小数点 (FP) レジスタを使用する AVX2 で利用可能な Fused Multiply Add (FMA) 命令は、整数コードとデータ型に最適であり、最大 2 倍の速度向上をもたらします。  FP コードとデータ型の場合、AVX2 は AVX よりも 8% 高速化します。</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">バゼル</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">ソースからTensorFlowを構築するには、 NetAppは以下を使用することを推奨しています。<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block> 。私たちの環境では、シェルプロンプトで次のコマンドを実行してインストールしました。<block ref="ffd93b30364fb8893d5bbb6fdb312666" prefix=" " category="inline-code"></block> 、<block ref="1208feb4bf9c4dd21156d8231d098ba1" prefix=" " category="inline-code"></block> 、そしてバゼル。</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">ビルド プロセス中に C++17 機能を使用するには、GCC 5 以降を有効にする必要があります。これは、RHEL によって Software Collections Library (SCL) とともに提供されます。次のコマンドはインストールします<block ref="188b06575e77785e6b73e5e85b8e6ada" prefix=" " category="inline-code"></block>RHEL 7.9 クラスター上の GCC 11.2.1:</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">記事</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">最後の2つのコマンドは<block ref="1dde0514b51c7c8f49cc63e4b54b8b37" prefix=" " category="inline-code"></block>、使用する<block ref="03fec70ce2bd12477f18ac0667e43d67" prefix=" " category="inline-code"></block>（GCC 11.2.1）。また、<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>バージョンは 1.8.3 より大きいです (RHEL 7.9 に付属)。こちらを参照してください<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block>更新用<block ref="ba9f11ecc3497d9993b933fdc2bd61e5" prefix=" " category="inline-code"></block>2.24.1 まで。</block>
  <block id="ba89c701879ec1f07e28185e3446d252" category="inline-link-macro">主要なユースケースごとのPythonスクリプト</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="inline-link">CUDA</block>
  <block id="e63cc75a56452201d199b8b0694ad9c1" category="paragraph">最新の TensorFlow マスター リポジトリのクローンがすでに作成されているものと想定します。次に、<block ref="1629dee48cc4e53161f9b2be8614e062" prefix=" " category="inline-code"></block>ディレクトリ<block ref="09498dbadf45966909850dc8a47ebb13" prefix=" " category="inline-code"></block>AVX、AVX2、FMA を使用してソースから TensorFlow をビルドするためのファイル。実行<block ref="e2d5a00791bce9a01f99bc6fd613a39d" prefix=" " category="inline-code"></block>ファイルを開き、正しい Python バイナリの場所を指定します。<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> GPU を使用していないため、テストでは無効になっています。あ<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>ファイルは設定に従って生成されます。さらに、ファイルを編集して設定しました<block ref="4e1b2fd49a68e112bae6de1bc453f18c" prefix=" " category="inline-code"></block>HDFS サポートを有効にします。参照<block ref="f55b2f358053ad76fb5ac3f776f78ef8" prefix=" " category="inline-code"></block>セクション内<block ref="f76831928c99e33a4e51e1e38bb9ab3c" category="inline-link-macro-rx"></block>設定とフラグの完全なリストについては、こちらをご覧ください。</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">正しいフラグを使用して TensorFlow をビルドした後、次のスクリプトを実行して Criteo ディスプレイ広告データセットを処理し、DeepFM モデルをトレーニングし、予測スコアから受信者操作特性曲線の下の領域 (ROC AUC) を計算します。</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">10 回のトレーニング エポック後、テスト データセットの AUC スコアを取得しました。</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">以前のユースケースと同様に、Spark ワークフロー ランタイムをさまざまな場所に存在するデータと比較しました。次の図は、Spark ワークフロー ランタイムのディープラーニング CTR 予測の比較を示しています。</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Spark ワークフロー ランタイムのディープラーニング CTR 予測の比較。</block>
  <block id="f68ffbfae290c4d8a7f8381ad0cad4ff" category="paragraph"><block ref="f68ffbfae290c4d8a7f8381ad0cad4ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">このページでは、このソリューションを使用できるさまざまな領域について説明します。</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">ユースケースの概要</block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">ストリーミングデータ</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark は、ストリーミング抽出、変換、ロード (ETL) プロセス、データ拡充、イベント検出のトリガー、複雑なセッション分析に使用されるストリーミング データを処理できます。</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">*ストリーミング ETL*データは、データストアにプッシュされる前に継続的にクリーンアップされ、集約されます。 Netflix は、Kafka と Spark ストリーミングを使用して、さまざまなデータ ソースから毎日数十億のイベントを処理できるリアルタイムのオンライン映画推奨およびデータ監視ソリューションを構築しています。ただし、バッチ処理用の従来の ETL は異なる方法で処理されます。このデータは最初に読み取られ、データベースに書き込まれる前にデータベース形式に変換されます。</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">*データの拡充* Spark ストリーミングは、ライブ データを静的データで強化し、よりリアルタイムなデータ分析を可能にします。たとえば、オンライン広告主は、顧客の行動に関する情報に基づいて、パーソナライズされたターゲット広告を配信できます。</block>
  <block id="c8fc01958b8b24afef85387342bc2aef" category="list-text">*トリガーイベント検出。* Spark ストリーミングを使用すると、潜在的に深刻な問題を示唆する異常な動作を迅速に検出して対応できます。たとえば、金融機関はトリガーを使用して不正な取引を検出して阻止し、病院はトリガーを使用して患者のバイタルサインで検出された危険な健康状態の変化を検出します。</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">*複雑なセッション分析。* Spark ストリーミングは、Web サイトまたはアプリケーションにログインした後のユーザー アクティビティなどのイベントを収集し、それらをグループ化して分析します。たとえば、Netflix はこの機能を使用して、リアルタイムの映画推奨を提供しています。</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="inline-link-macro">TR-4912: NetAppを使用した Confluent Kafka 階層型ストレージのベストプラクティスガイドライン</block>
  <block id="519be207be9b1131f1e8524db61cf335" category="paragraph">ストリーミングデータの設定、Confluent Kafkaの検証、パフォーマンステストの詳細については、<block ref="474863345040f8931cecadcc38733702" category="inline-link-macro-rx"></block> 。</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">機械学習</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark 統合フレームワークは、機械学習ライブラリ (MLlib) を使用してデータセットに対して繰り返しクエリを実行するのに役立ちます。  MLlib は、予測インテリジェンス、マーケティング目的の顧客セグメンテーション、感情分析などの一般的なビッグ データ機能のクラスタリング、分類、次元削減などの分野で使用されます。 MLlib は、ネットワーク セキュリティで使用され、悪意のあるアクティビティの兆候がないかデータ パケットをリアルタイムで検査します。セキュリティ プロバイダーが新しい脅威を把握し、ハッカーに先手を打つと同時にクライアントをリアルタイムで保護するのに役立ちます。</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">ディープラーニング</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow は、業界全体で使用されている人気のディープラーニング フレームワークです。 TensorFlow は、CPU または GPU クラスターでの分散トレーニングをサポートします。この分散トレーニングにより、ユーザーは多数の深いレイヤーを持つ大量のデータに対してトレーニングを実行できます。</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">つい最近まで、Apache Spark で TensorFlow を使用する場合は、PySpark で TensorFlow に必要なすべての ETL を実行し、データを中間ストレージに書き込む必要がありました。そのデータは、実際のトレーニング プロセスのために TensorFlow クラスターにロードされます。このワークフローでは、ユーザーは ETL 用と TensorFlow の分散トレーニング用の 2 つの異なるクラスターを維持する必要がありました。複数のクラスターの実行と維持は、通常、面倒で時間がかかります。</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">以前のバージョンの Spark の DataFrames と RDD は、ランダム アクセスが制限されていたため、ディープラーニングには適していませんでした。プロジェクト Hydrogen を使用した Spark 3.0 では、ディープラーニング フレームワークのネイティブ サポートが追加されます。このアプローチにより、Spark クラスター上で MapReduce ベース以外のスケジューリングが可能になります。</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">インタラクティブ分析</block>
  <block id="9650da7c8eb40c14055202b3dd7f4443" category="paragraph">Apache Spark は、SQL、R、Python など、Spark 以外の開発言語でサンプリングせずに探索クエリを実行できるほど高速です。 Spark は視覚化ツールを使用して複雑なデータを処理し、インタラクティブに視覚化します。構造化ストリーミングを備えた Spark は、Web 分析のライブ データに対して対話型クエリを実行し、Web 訪問者の現在のセッションに対して対話型クエリを実行できるようにします。</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">レコメンデーションシステム</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">長年にわたり、企業や消費者がオンライン ショッピング、オンライン エンターテイメント、その他多くの業界における劇的な変化に対応するにつれ、レコメンデーション システムは私たちの生活に多大な変化をもたらしてきました。実際、これらのシステムは、生産における AI の最も明らかな成功事例の 1 つです。多くの実際の使用例では、レコメンデーション システムは、NLP バックエンドとインターフェースされた会話型 AI またはチャットボットと組み合わせられ、関連情報を取得して有用な推論を生成します。</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">今日、多くの小売業者は、オンラインで購入して店舗で受け取る、カーブサイドピックアップ、セルフチェックアウト、スキャンアンドゴーなどの新しいビジネスモデルを採用しています。これらのモデルは、消費者にとってショッピングをより安全で便利なものにすることで、COVID-19パンデミック中に注目を集めるようになりました。 AI は、消費者の行動に影響を受け、またその逆も起こる、こうした成長を続けるデジタル トレンドにとって極めて重要です。NetAppは、消費者の高まる需要に応え、顧客体験を強化し、運用効率を改善し、収益を増やすために、エンタープライズ顧客と企業が機械学習とディープラーニングのアルゴリズムを使用して、より高速で正確な推奨システムを設計できるよう支援します。</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">推奨事項を提供するために使用される一般的な手法としては、協調フィルタリング、コンテンツ ベース システム、ディープラーニング レコメンデーション モデル (DLRM)、ハイブリッド手法などがあります。これまで、顧客は PySpark を利用して、推奨システムを作成するための協調フィルタリングを実装していました。  Spark MLlib は、DLRM が登場する以前から企業の間で非常に人気があったアルゴリズムである協調フィルタリング用の交代最小二乗法 (ALS) を実装しています。</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">自然言語処理</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">ガートナー</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">自然言語処理 (NLP) によって可能になる会話型 AI は、コンピューターが人間とコミュニケーションするのを支援する AI の分野です。 NLP は、スマート アシスタントやチャットボットから Google 検索や予測テキストまで、あらゆる業界のさまざまなユース ケースで普及しています。ある<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block>予測によると、2022 年までに 70% の人々が会話型 AI プラットフォームを日常的に利用するようになるでしょう。人間と機械の間で質の高い会話をするには、応答が迅速で、インテリジェントで、自然な響きでなければなりません。</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">顧客は、NLP および自動音声認識 (ASR) モデルを処理およびトレーニングするために大量のデータを必要とします。また、エッジ、コア、クラウド間でデータを移動する必要があり、人間との自然なコミュニケーションを確立するために、数ミリ秒単位で推論を実行する能力も必要です。  NetApp AI と Apache Spark は、コンピューティング、ストレージ、データ処理、モデル トレーニング、微調整、および導入に最適な組み合わせです。</block>
  <block id="6ecf226f4b849e3111584c1eebd25f3c" category="paragraph">感情分析は、テキストから肯定的、否定的、または中立的な感情を抽出する NLP の研究分野です。感情分析には、発信者との会話におけるサポート センターの従業員のパフォーマンスを判断することから、適切な自動チャットボット応答を提供することまで、さまざまな使用例があります。また、四半期ごとの収益報告の電話会議における企業代表者と聴衆とのやり取りに基づいて、企業の株価を予測するためにも使用されています。さらに、感情分析を使用すると、ブランドが提供する製品、サービス、またはサポートに対する顧客の見解を判断することもできます。</block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="inline-link">スパークNLP</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">ジョン・スノー・ラボ</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">金融ニュースの感情</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">フィンバート</block>
  <block id="c1856f13b6ce4dd1f710cf08138e0c51" category="paragraph">私たちは<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block>図書館から<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block>事前学習済みのパイプラインとBERT（Bidirectional Encoder Representations from Transformers）モデルをロードする。<block ref="1a3a0057856cc0bfa7cb2c9343eb2415" category="inline-link-rx"></block>そして<block ref="ac723dc3fc44f63057a74e935ae9db52" category="inline-link-rx"></block>トークン化、固有表現認識、モデルトレーニング、フィッティング、感情分析を大規模に実行します。 Spark NLP は、BERT、ALBERT、ELECTRA、XLNet、DistilBERT、RoBERTa、DeBERTa、XLM-RoBERTa、Longformer、ELMO、Universal Sentence Encoder、Google T5、MarianMT、GPT2 などの最先端のトランスフォーマーを提供する、実稼働中の唯一のオープンソース NLP ライブラリです。このライブラリは、Apache Spark をネイティブに拡張することで、Python や R だけでなく、JVM エコシステム (Java、Scala、Kotlin) でも大規模に動作します。</block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">概要</block>
  <block id="c9da861bd07fd9446a0e4f9108517532" category="paragraph">このドキュメントでは、ビッグデータ分析および高性能コンピューティング (HPC) システムからデータを移動して、人工知能 (AI) ワークフローで使用できるようにする方法について説明します。 AI は通常、NFS エクスポートを通じて NFS データを処理します。ただし、AI データはビッグ データ分析および高性能コンピューティング (HPC) プラットフォームに保存されている可能性があります。これは、Hadoop 分散ファイル システム (HDFS)、バイナリ ラージ オブジェクト (Blob)、S3 ストレージ、または IBM の General Parallel File System (GPFS) のいずれかになります。このドキュメントでは、Hadoop ネイティブ コマンド、 NetApp In-Place Analytics Module (NIPAM)、およびNetApp XCP を使用して、ビッグ データ分析プラットフォームと GPFS から NFS にデータを移動する方法について説明します。このドキュメントでは、ビッグデータや HPC から AI にデータを移行することによるビジネス上のメリットについても説明します。</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="doc">詳細情報の入手方法</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">このドキュメントに記載されている情報の詳細については、次のドキュメントや Web サイトを参照してください。</block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroupボリュームのベストプラクティスと実装ガイド</block>
  <block id="7d72333a4556beea0bd57e4b8a007b47" category="paragraph"><block ref="7d72333a4556beea0bd57e4b8a007b47" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp製品ドキュメント</block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">このセクションでは、このソリューションのビジネス上の利点について説明します。</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">ビジネス上のメリット</block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">ビッグデータ分析から AI にデータを移動すると、次のような利点があります。</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">異なる Hadoop ファイルシステムと GPFS からデータを抽出し、統合された NFS ストレージシステムに統合する機能</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">Hadoopを統合した自動化されたデータ転送方法</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoopファイルシステムからデータを移動するためのライブラリ開発コストの削減</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM を使用することで、単一のデータソースから複数のネットワーク インターフェースの集約されたスループットによってパフォーマンスが最大化されます。</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">スケジュールされた方法とオンデマンドの方法によるデータ転送</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAPデータ管理ソフトウェアを使用した統合NFSデータのストレージ効率とエンタープライズ管理機能</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">データ転送にHadoop方式を採用し、データ移動コストをゼロに</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">このページでは、AI 運用のためにビッグデータ分析からデータにアクセスしようとする際に顧客が直面する可能性のある課題について説明します。</block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">AI 運用のためにビッグデータ分析からデータにアクセスしようとすると、顧客は次の課題に直面する可能性があります。</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">顧客データはデータ レイク リポジトリに保存されます。データ レイクには、構造化データ、非構造化データ、半構造化データ、ログ、マシン間データなど、さまざまな種類のデータを含めることができます。これらすべてのデータ タイプは AI システムで処理する必要があります。</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI は Hadoop ファイル システムと互換性がありません。一般的な AI アーキテクチャでは、HDFS および HCFS データに直接アクセスできないため、これらのデータは AI が理解できるファイル システム (NFS) に移動する必要があります。</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">データレイクのデータを AI に移行するには、通常、特殊なプロセスが必要です。データレイク内のデータの量は非常に大きくなる可能性があります。顧客は、データを AI システムに移動するための効率的でスループットが高く、コスト効率の高い方法を持っている必要があります。</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">データを同期しています。お客様がビッグデータプラットフォームと AI 間でデータを同期したい場合、AI で処理したデータをビッグデータと組み合わせて分析処理できる場合があります。</block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">ビッグ データ クラスターでは、データは MapR-FS、Windows Azure Storage Blob、S3、Google ファイル システムなどの HDFS または HCFS に保存されます。ソースから hadoop distcp コマンドを使用して NIPAM の助けを借りて、HDFS、MapR-FS、S3 をソースとして使用し、 NetApp ONTAP NFS エクスポートにデータをコピーするテストを実行しました。</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="doc">データムーバーソリューション</block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">ビッグ データ クラスターでは、データは MapR-FS、Windows Azure Storage Blob、S3、Google ファイル システムなどの HDFS または HCFS に保存されます。  NIPAMの助けを借りて、HDFS、MapR-FS、S3をソースとしてNetApp ONTAP NFSエクスポートにデータをコピーするテストを実施しました。<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>ソースからのコマンド。</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">次の図は、 NVIDIA がAI 操作を処理できるように、HDFS ストレージで実行されている Spark クラスターからNetApp ONTAP NFS ボリュームへの一般的なデータ移動を示しています。</block>
  <block id="67ed14506d4065a668f7cb0136039d8b" category="paragraph"><block ref="67ed14506d4065a668f7cb0136039d8b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">その<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>コマンドは MapReduce プログラムを使用してデータをコピーします。  NIPAM は MapReduce と連携して、データをコピーするときに Hadoop クラスターのドライバーとして機能します。 NIPAM は、単一のエクスポートに対して複数のネットワーク インターフェイスに負荷を分散できます。このプロセスは、HDFS または HCFS から NFS にデータをコピーするときに、複数のネットワーク インターフェイスにデータを分散することで、ネットワーク スループットを最大化します。</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM は MapR ではサポートも認定もされていません。</block>
  <block id="20220b4c576eeca673151438f5ee1da9" category="summary">AI 向けデータ ムーバー ソリューションは、AI 操作からの Hadoop データを処理するという顧客のニーズに基づいています。 NetApp はNIPAM を使用して HDFS から NFS にデータを移動します。あるユースケースでは、顧客はオンプレミスの NFS にデータを移動する必要があり、別の顧客はクラウド内の GPU クラウド インスタンスからのデータを処理するために、Windows Azure Storage Blob からGoogle Cloud NetApp Volumesにデータを移動する必要がありました。</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI向けデータムーバーソリューション</block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">次の図は、データ ムーバー ソリューションの詳細を示しています。</block>
  <block id="44c3f61c0684bc5b43b5e243a139152c" category="paragraph"><block ref="44c3f61c0684bc5b43b5e243a139152c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">データ ムーバー ソリューションを構築するには、次の手順が必要です。</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN は HDFS を提供し、NAS は NIPAM を介して実稼働データ レイク クラスターに NFS ボリュームを提供します。</block>
  <block id="625dd6cfdf4a097dff4340366eec8942" category="list-text">顧客のデータは HDFS と NFS に保存されています。  NFS データは、ビッグ データ分析や AI 操作に使用される他のアプリケーションからの実稼働データである場合があります。</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexCloneテクノロジーは、本番環境の NFS ボリュームのクローンを作成し、オンプレミスの AI クラスターにプロビジョニングします。</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUNからのデータはNIPAMを使用してNFSボリュームにコピーされ、<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>指示。 NIPAM は複数のネットワーク インターフェイスの帯域幅を使用してデータを転送します。このプロセスによりデータのコピー時間が短縮され、より多くのデータを転送できるようになります。</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">両方の NFS ボリュームは、AI 操作用に AI クラスターにプロビジョニングされます。</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">オンプレミスの NFS データをクラウドの GPU で処理するために、NFS ボリュームはNetApp SnapMirrorテクノロジーを使用してNetApp Private Storage (NPS) にミラーリングされ、GPU のクラウド サービス プロバイダーにマウントされます。</block>
  <block id="98105737f8ac55863a4e0763f588cab5" category="list-text">顧客は、クラウド サービス プロバイダーの GPU で EC2/EMR、HDInsight、または DataProc サービスのデータを処理したいと考えています。  HadoopデータムーバーはHadoopサービスからNIPAMを使用してGoogle Cloud NetApp Volumesにデータを移動し、<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>指示。</block>
  <block id="f490cd633c8e7648911d95daf043af8f" category="list-text">Google Cloud NetApp Volumes のデータは、NFS プロトコルを通じて AI にプロビジョニングされます。AI を通じて処理されたデータは、NIPAM、 SnapMirror 、NPS を通じてNVIDIAクラスタだけでなく、オンプレミスの場所にビッグ データ分析のために送信することもできます。</block>
  <block id="f13f02e9fbfc272070bb10c4ae60e707" category="paragraph">このシナリオでは、お客様は、オンプレミスのNetAppストレージ コントローラでの AI 処理に必要な、リモート ロケーションの NAS システムに大量のファイル数のデータを保持しています。このシナリオでは、XCP 移行ツールを使用して、より高速にデータを移行することをお勧めします。</block>
  <block id="74c03e6f525ff7a5f56d15dd77d9d7ee" category="paragraph">ハイブリッド ユース ケースのお客様は、 BlueXP Copy and Sync を使用してオンプレミスのデータを NFS、CIFS、S3 データからクラウドに移行したり、その逆を行ったりして、 NVIDIAクラスターなどの GPU を使用して AI 処理を行うことができます。  BlueXP Copy and Sync と XCP Migration Tool の両方が、 NetApp ONTAP NFS への NFS データ移行に使用されます。</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">この検証では、GPFS に物理ディスクを提供するために、4 台のサーバーをネットワーク共有ディスク (NSD) サーバーとして使用しました。下の図に示すように、GPFS は NSD ディスク上に作成され、NFS エクスポートとしてエクスポートされるため、NFS クライアントがアクセスできるようになります。  XCP を使用して、GPFS でエクスポートされた NFS からNetApp NFS ボリュームにデータをコピーしました。</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS からNetApp ONTAP NFS へ</block>
  <block id="f0987b9b1ed71523f2b4be4961e35e12" category="paragraph"><block ref="f0987b9b1ed71523f2b4be4961e35e12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFSの基本</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS では次のノード タイプが使用されます。</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">*管理ノード*ノード間の通信に管理コマンドによって使用されるノード名を含むオプション フィールドを指定します。たとえば、管理ノード<block ref="f2fde43b571e78e29f67743af45165cb" prefix=" " category="inline-code"></block>クラスター内の他のすべてのノードにネットワーク チェックを渡すことができました。</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">*クォーラムノード*クォーラムの派生元となるノードのプールにノードが含まれるかどうかを決定します。クォーラム ノードとして少なくとも 1 つのノードが必要です。</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">*マネージャーノード*ノードが、ファイル システム マネージャーおよびトークン マネージャーを選択できるノード プールの一部であるかどうかを示します。複数のノードをマネージャー ノードとして定義することをお勧めします。マネージャーとして指定するノードの数は、ワークロードと保有する GPFS サーバー ライセンスの数によって異なります。大規模な並列ジョブを実行している場合は、Web アプリケーションをサポートする 4 ノード クラスターよりも多くのマネージャー ノードが必要になることがあります。</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">*NSD サーバー*  GPFS で使用するために各物理ディスクを準備するサーバー。</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">*プロトコル ノード*任意の Secure Shell (SSH) プロトコルを介して NFS と直接 GPFS データを共有するノード。このノードには GPFS サーバー ライセンスが必要です。</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS、NFS、XCP の操作リスト</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">このセクションでは、GPFS を作成し、GPFS を NFS エクスポートとしてエクスポートし、XCP を使用してデータを転送する操作のリストを示します。</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFSを作成する</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS を作成するには、次の手順を実行します。</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">サーバーの 1 つに、Linux バージョンの Spectrum-Scale Data Access をダウンロードしてインストールします。</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">すべてのノードに前提条件パッケージ (chef など) をインストールし、すべてのノードで Security-Enhanced Linux (SELinux) を無効にします。</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">インストール ノードをセットアップし、管理ノードと GPFS ノードをクラスター定義ファイルに追加します。</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">マネージャー ノード、クォーラム ノード、NSD サーバー、および GPFS ノードを追加します。</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI、管理、GPFS ノードを追加し、必要に応じて追加の GUI サーバーを追加します。</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">別の GPFS ノードを追加し、すべてのノードのリストを確認します。</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">クラスター定義ファイルで、すべての GPFS ノードに設定するクラスター名、プロファイル、リモート シェル バイナリ、リモート ファイル コピー バイナリ、およびポート範囲を指定します。</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 構成設定を表示し、追加の管理ノードを追加します。</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">データ収集を無効にして、データ パッケージを IBM サポート センターにアップロードします。</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">インストール前に NTP を有効にして構成を事前チェックします。</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD ディスクを構成、作成、および確認します。</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFSを作成</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS をマウントします。</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS に必要な権限を確認して提供します。</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">GPFSの読み取りと書き込みを確認するには、<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>指示。</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFSをNFSにエクスポートする</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">GPFSをNFSとしてエクスポートする<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>ファイル。</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">必要な NFS サーバー パッケージをインストールします。</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS サービスを開始します。</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">NFS クライアントを検証するために、GPFS 内のファイルを一覧表示します。</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFSクライアントを構成する</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS クライアントを構成するには、次の手順を実行します。</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">GPFSをNFSとしてエクスポートするには、<block ref="9c8ea389db0c545c0a8c9ca08caecb34" prefix=" " category="inline-code"></block>ファイル。</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS クライアント サービスを開始します。</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS クライアントで NFS プロトコルを介して GPFS をマウントします。</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS マウントされたフォルダー内の GPFS ファイルのリストを検証します。</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP を使用して、GPFS からエクスポートされた NFS からNetApp NFS にデータを移動します。</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS クライアント上の GPFS ファイルを検証します。</block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">このセクションでは、 NetApp XCP を使用して GPFS を構成し、データを NFS に移動するために必要な詳細な手順について説明します。</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFSからNFSへ - 詳細な手順</block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFSの設定</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">サーバーの 1 つに Spectrum Scale Data Access for Linux をダウンロードしてインストールします。</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">すべてのノードに前提条件パッケージ (chef とカーネル ヘッダーを含む) をインストールします。</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">すべてのノードで SELinux を無効にします。</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">インストール ノードをセットアップします。</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">管理ノードと GPFS ノードをクラスター定義ファイルに追加します。</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">マネージャー ノードと GPFS ノードを追加します。</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">クォーラム ノードと GPFS ノードを追加します。</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD サーバーと GPFS ノードを追加します。</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI、管理、GPFS ノードを追加します。</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">別の GUI サーバーを追加します。</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">別の GPFS ノードを追加します。</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">すべてのノードを検証して一覧表示します。</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">クラスタ定義ファイルでクラスタ名を指定します。</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">プロファイルを指定します。</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFSが使用するリモートシェルバイナリを指定します。<block ref="f8b2a03096b35c105ccb9e1687ea4d21" prefix=" " category="inline-code"></block> 。</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFSが使用するリモートファイルコピーバイナリを指定します。<block ref="795f05204859c09fe2f151b742bf82f9" prefix=" " category="inline-code"></block> 。</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">すべてのGPFSノードに設定するポート範囲を指定します。<block ref="3b552a3fb3ecdff1af07892680e6d03a" prefix=" " category="inline-code"></block> 。</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 構成設定を表示します。</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">管理ノードを追加します。</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP を有効にします。</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">インストール前に構成を事前に確認してください。</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD ディスクを構成します。</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD ディスクを作成します。</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD ディスクのステータスを確認します。</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS に必要な権限を確認して付与します。</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">GPFSの読み取りと書き込みをチェックするには、<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>指示。</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS を NFS にエクスポートするには、次の手順を実行します。</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">NFS クライアントを検証するために、GPFS 内のファイルを一覧表示します。</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFSクライアントを構成する</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS クライアントにパッケージをインストールします。</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS マウントされたフォルダー内の GPFS ファイルのリストを検証します。</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP を使用して、GPFS エクスポートされた NFS からNetApp NFS にデータを移動します。</block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">このソリューションでは、 NetApp はデータ レイク (HDFS) および MapR クラスタ データからONTAP NFS へのデータの移行を検証しました。データは MapR-FS と HDFS に保存されていました。  NetApp XCP では、HDFS や MapR-FS などの分散ファイルシステムからONTAP NFS にデータを直接移行する新しい機能が導入されました。</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS と MapR-FS からONTAP NFS へ</block>
  <block id="676df8e27b06b6dd639822191d432dc2" category="paragraph">このソリューションでは、 NetApp はデータ レイク (HDFS) および MapR クラスタ データからONTAP NFS へのデータの移行を検証しました。データは MapR-FS と HDFS に保存されていました。  NetApp XCP では、HDFS や MapR-FS などの分散ファイルシステムからONTAP NFS にデータを直接移行する新しい機能が導入されました。  XCP は非同期スレッドと HDFS C API 呼び出しを使用して、MapR-FS および HDFS との通信とデータの転送を行います。</block>
  <block id="adc95e83c5f5ce743bb6468ffdef4fc3" category="paragraph">下の図は、データ レイク (HDFS) および MapR-FS からONTAP NFS へのデータ移行を示しています。この新しい機能を使用すると、ソースを NFS 共有としてエクスポートする必要がなくなります。</block>
  <block id="3789ec0eac19c6a55506d3fe4f2e880e" category="paragraph"><block ref="3789ec0eac19c6a55506d3fe4f2e880e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">顧客が HDFS および MapR-FS から NFS に移行するのはなぜですか?</block>
  <block id="8616e2393304ffc26da9b5e853b8db33" category="paragraph">Cloudera や Hortonworks などの Hadoop ディストリビューションのほとんどは HDFS を使用し、MapR ディストリビューションは Mapr-FS と呼ばれる独自のファイルシステムを使用してデータを保存します。  HDFS および MapR-FS データは、機械学習 (ML) およびディープラーニング (DL) で活用できる貴重な洞察をデータ サイエンティストに提供します。 HDFS と MapR-FS のデータは共有されないため、他のアプリケーションでは使用できません。特に顧客の機密データが複数のアプリケーションで使用される銀行業界では、顧客は共有データを求めています。最新バージョンの Hadoop (3.x 以降) は NFS データ ソースをサポートしており、追加のサードパーティ ソフトウェアなしでアクセスできます。新しいNetApp XCP機能を使用すると、HDFSおよびMapR-FSからNetApp NFSにデータを直接移動して、複数のアプリケーションにアクセスできるようになります。</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">12 個の MAPR ノードと 4 個の NFS サーバーを使用した初期パフォーマンス テストでは、MapR-FS から NFS にデータを転送するテストが Amazon Web Services (AWS) で実行されました。</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">数量</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">サイズ</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">メモリ</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="cell">ストレージ</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">ネットワーク</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS サーバ</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xlarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapRノード</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xlarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">初期テストでは、20GBps のスループットを実現し、1 日あたり 2PB のデータ転送が可能になりました。</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link-macro">TR-4863: TR-4863: NetApp XCP - データムーバー、ファイル移行、分析のベストプラクティスガイドライン</block>
  <block id="d7b251f310540db8b677090e4068b718" category="paragraph">HDFSをNFSにエクスポートせずにHDFSデータを移行する方法の詳細については、「導入手順 - NAS」セクションを参照してください。<block ref="8057f0a15e6751a5fa14293a5e88f017" category="inline-link-macro-rx"></block> 。</block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">このホワイト ペーパーでは、 NetApp XCP と NIPAM を使用してビッグ データ分析データと HPC データを AI に移行するためのガイドラインを示します。また、ビッグデータや HPC から AI にデータを移行することによるビジネス上のメリットについても説明します。</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: ビッグデータ分析データから人工知能へ</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">カーティケヤン ナガリンガム、NetApp</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">このドキュメントでは、ビッグデータ分析データと HPC データを AI に移動する方法について説明します。 AI は NFS エクスポートを通じて NFS データを処理しますが、顧客は多くの場合 AI データを HDFS、Blob、S3 ストレージなどのビッグ データ分析プラットフォームや GPFS などの HPC プラットフォームに保存しています。このホワイト ペーパーでは、 NetApp XCP と NIPAM を使用してビッグ データ分析データと HPC データを AI に移行するためのガイドラインを示します。また、ビッグデータや HPC から AI にデータを移行することによるビジネス上のメリットについても説明します。</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">概念とコンポーネント</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">ビッグデータ分析ストレージ</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">ビッグデータ分析は、HDFS の主要なストレージ プロバイダーです。顧客は、Windows Azure Blob Storage、MapR ファイル システム (MapR-FS)、S3 オブジェクト ストレージなどの Hadoop 互換ファイル システム (HCFS) をよく使用します。</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">汎用並列ファイルシステム</block>
  <block id="510b2e746f7cab5126465c64edad8541" category="paragraph">IBM の GPFS は、HDFS の代替となるエンタープライズ ファイル システムです。  GPFS は、アプリケーションがブロック サイズとレプリケーション レイアウトを決定できる柔軟性を提供し、優れたパフォーマンスと効率を実現します。</block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="section-title">NetAppインプレース分析モジュール</block>
  <block id="f1b570aebec7f92867ad62cf2fe7c50c" category="paragraph">NetApp In-Place Analytics Module (NIPAM) は、Hadoop クラスターが NFS データにアクセスするためのドライバーとして機能します。接続プール、NFS InputStream、ファイル ハンドル キャッシュ、NFS OutputStream の 4 つのコンポーネントがあります。詳細については、以下を参照してください。 <block ref="ead8bf031afc74347ebd06de968e5895" category="inline-link-rx"></block> 。</block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 分散コピー</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy (DistCp) は、大規模なクラスター間およびクラスター内のコピータスクに使用される分散コピー ツールです。このツールは、データの配布、エラー処理、レポートに MapReduce を使用します。ファイルとディレクトリのリストを展開し、マップ タスクに入力して、ソース リストからデータをコピーします。下の画像は、HDFS および非 HDFS での DistCp 操作を示しています。</block>
  <block id="513bd70b6fe800dda2548dae1bc404df" category="paragraph"><block ref="513bd70b6fe800dda2548dae1bc404df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp は、追加のドライバーを使用せずに 2 つの HDFS システム間でデータを移動します。  NetApp は、HDFS 以外のシステム用のドライバーを提供します。  NFS 宛先の場合、NIPAM は、データをコピーするときに Hadoop DistCp が NFS 宛先と通信するために使用する、データをコピーするためのドライバーを提供します。</block>
  <block id="1215f8190533dfdf63d2224a6d88266f" category="section-title">Google Cloud NetApp Volumes</block>
  <block id="e6b6086807cb6588f15ae36a2a999e8f" category="paragraph">Google Cloud NetApp Volumes は、極めて優れたパフォーマンスを備えたクラウドネイティブのファイル サービスです。このサービスは、リソースを迅速に起動および停止し、 NetApp の機能を使用して生産性を向上させ、スタッフのダウンタイムを削減することで、顧客の市場投入までの時間を短縮するのに役立ちます。  Google Cloud NetApp Volumes は、データセンター全体のフットプリントを削減し、ネイティブのパブリック クラウド ストレージの消費量を抑えるため、災害復旧やクラウドへのバックアップに最適な代替手段です。</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP は、あらゆるデバイスからNetAppへ、またNetAppからNetAppへのデータ移行を高速かつ確実に実行できるクライアント ソフトウェアです。このツールは、任意の NAS システムからNetAppストレージ コントローラに大量の非構造化 NAS データをコピーするように設計されています。 XCP 移行ツールは、データ移行、ファイルまたはディレクトリのリスト、スペース レポートなど、多数の要求を並行して処理できるマルチコア、マルチチャネル I/O ストリーミング エンジンを使用します。これはデフォルトのNetAppデータ移行ツールです。 XCP を使用して、Hadoop クラスターおよび HPC からNetApp NFS ストレージにデータをコピーできます。下の図は、XCP を使用した Hadoop および HPC クラスターからNetApp NFS ボリュームへのデータ転送を示しています。</block>
  <block id="31e2e6a49223ff3b99782fced8ae2f33" category="paragraph"><block ref="31e2e6a49223ff3b99782fced8ae2f33" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf66760432e212bf920c4b630bf24a8" category="section-title">NetApp BlueXPコピーと同期</block>
  <block id="182c915d2a513090f731fbf85d4576bd" category="paragraph">NetApp BlueXP Copy and Sync は、オンプレミス ストレージとクラウド ストレージ間で NFS、S3、CIFS データをシームレスかつ安全に転送および同期するハイブリッド データ レプリケーション ソフトウェア サービスです。このソフトウェアは、データの移行、アーカイブ、コラボレーション、分析などに使用されます。データが転送された後、 BlueXP Copy and Sync はソースと宛先の間でデータを継続的に同期します。次に、デルタを転送します。また、独自のネットワーク内、クラウド内、オンプレミス内のデータも保護します。このソフトウェアは従量課金モデルに基づいており、コスト効率の高いソリューションを提供し、データ転送の監視およびレポート機能も提供します。</block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">このセクションでは、 NetApp XCP を使用して MapR-FS データをONTAP NFS に移動するために必要な詳細な手順について説明します。</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FSからONTAP NFSへ</block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">各 MapR ノードに 3 つの LUN をプロビジョニングし、LUN にすべての MapR ノードの所有権を付与します。</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">インストール中に、MapR-FS に使用される MapR クラスター ディスクに新しく追加された LUN を選択します。</block>
  <block id="87ae055df3def21f83bbbb9e287167b6" category="list-text">MapR 6.1 のドキュメントに従って MapR クラスターをインストールします。</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">MapReduceコマンドを使用して、基本的なHadoop操作を確認します。<block ref="b5a58cfcf19813db2fae678c75e004c8" prefix=" " category="inline-code"></block> 。</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">顧客データを MapR-FS に保存します。たとえば、Teragen を使用して MapR-FS で約 1 テラバイトのサンプル データを生成しました。</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR-FS を NFS エクスポートとして設定します。</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">すべての MapR ノードで nlockmgr サービスを無効にします。</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">すべてのMapRノード上のMapR-FSから特定のフォルダをエクスポートします。<block ref="84a05a173e6cd86a4169f3dbd5897873" prefix=" " category="inline-code"></block>ファイル。サブフォルダーをエクスポートするときに、親フォルダーを異なる権限でエクスポートしないでください。</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR-FS NFS サービスを更新します。</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">MapR クラスター内の特定のサーバーまたはサーバー セットに仮想 IP 範囲を割り当てます。次に、MapR クラスターは、NFS データ アクセス用の特定のサーバーに IP を割り当てます。  IP により高可用性が実現されます。つまり、特定の IP を持つサーバーまたはネットワークに障害が発生した場合、IP 範囲の次の IP を NFS アクセスに使用できます。</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">すべての MapR ノードから NFS アクセスを提供する場合は、各サーバーに仮想 IP のセットを割り当て、各 MapR ノードのリソースを NFS データ アクセスに使用できます。</block>
  <block id="c508683f7afca451e58f95b67197d51f" category="paragraph"><block ref="c508683f7afca451e58f95b67197d51f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b9596f082ff106a71134b100eee486" category="paragraph"><block ref="54b9596f082ff106a71134b100eee486" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be91199bb393028826e953c78a526a54" category="paragraph"><block ref="be91199bb393028826e953c78a526a54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">各 MapR ノードに割り当てられた仮想 IP を確認し、NFS データ アクセスに使用します。</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS 操作を確認するために、割り当てられた仮想 IP を使用して NFS エクスポートされた MapR-FS をマウントします。ただし、 NetApp XCP を使用したデータ転送ではこの手順は必要ありません。</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">NetApp XCP を構成して、MapR-FS NFS ゲートウェイからONTAP NFS にデータを転送します。</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">XCP のカタログの場所を構成します。</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">ライセンスファイルをコピーする<block ref="0c8468e8bc6e9c8ce8e4de412fee0c10" prefix=" " category="inline-code"></block>。</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">XCPをアクティブ化するには、<block ref="974d7928831087bfbec5968aec9bea85" prefix=" " category="inline-code"></block>指示。</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">NFS エクスポートのソースを確認します。</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">複数のソース IP と複数の宛先 IP (ONTAP LIF) から複数の MapR ノードから XCP を使用してデータを転送します。</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">ストレージ コントローラ上の負荷分散を確認します。</block>
  <block id="af7ba099603ccd4070a5102166f2c998" category="summary">この検証に基づいて、データ サイエンティストとエンジニアは、 NetApp Cloud Volumes ONTAPの S3 バケットを介して AWS SageMaker Jupyter Notebook の NFS データにアクセスできるようになります。このアプローチにより、追加のソフトウェアを必要とせずに、NFS と S3 の両方から同じデータに簡単にアクセスして共有できるようになります。</block>
  <block id="8053f00cf5e08f449b7cafe189c73a39" category="list-text">SageMaker BlazingText を使用したテキスト分類</block>
  <block id="d6667429b7c60bcbf5e5d593e91d6cae" category="list-text">ONTAPバージョンとS3オブジェクト ストレージのサポート</block>
  <block id="91ef54d96688b56bf968f57803df6675" category="inline-link"><block ref="91ef54d96688b56bf968f57803df6675" category="inline-link-rx"></block></block>
  <block id="53a581d907d105a589be9419e91b16fa" category="paragraph"><block ref="53a581d907d105a589be9419e91b16fa" category="inline-link-rx"></block></block>
  <block id="6e74710636e2da95cda4899adcdf891e" category="summary">データは NFS で利用可能であり、AWS SageMaker の S3 からアクセスできます。</block>
  <block id="8394db253ec71ed9d59b9429983b8eb4" category="doc">データサイエンティストやその他のアプリケーションのためのデータの二重性</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">技術要件</block>
  <block id="f4900d1d4a0a26325c4c9514e57c2c75" category="paragraph">データ二重性のユースケースには、 NetApp BlueXP、 NetApp Cloud Volumes ONTAP、AWS SageMaker Notebooks が必要です。</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">ソフトウェア要件</block>
  <block id="6e6b6052efed2574e2dc05cbdc5d66d5" category="paragraph">次の表は、ユースケースを実装するために必要なソフトウェア コンポーネントを示しています。</block>
  <block id="9b9477e579c3b44dd623d5a6e1ea8d78" category="cell">BlueXP</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="cell">NetAppCloud Volumes ONTAP</block>
  <block id="dda9f6d67571441afa5cfb6b54b70873" category="cell">AWS SageMaker ノートブック</block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="section-title">展開手順</block>
  <block id="cc5f7f3bee6dcb16913051d6fc267977" category="paragraph">データ二重性ソリューションの展開には、次のタスクが含まれます。</block>
  <block id="6bb1f60bf0d00924a1bba54557e1feae" category="list-text">BlueXPコネクタ</block>
  <block id="cf25fa6cf104cc1a67119acb6d4d364d" category="list-text">機械学習用データ</block>
  <block id="59b20c2117a395af59d54a6533498e99" category="list-text">Jupyter Notebook からの検証済み機械学習</block>
  <block id="46e0bb4f28dbf5013a68a8a69a3cf9f5" category="section-title">BlueXPコネクタ</block>
  <block id="6ff27f6b5b95b177c735d22a2783e9ef" category="paragraph">今回の検証ではAWSを使用しました。  Azure および Google Cloud にも適用できます。  AWS でBlueXPコネクタを作成するには、次の手順を実行します。</block>
  <block id="4d7b48a5181bdd203b2ff52910c67d94" category="list-text">BlueXPの mcarl-marketplace-subscription に基づく資格情報を使用しました。</block>
  <block id="c0caffb5ab49caead75d39f6416ba841" category="list-text">環境に適したリージョン (例: us-east-1 [N. Virginia]) を選択し、認証方法 (例: Assume Role または AWS キー) を選択します。この検証では、AWS キーを使用します。</block>
  <block id="86b72593a2ce2f4e46e7669ced916111" category="list-text">コネクタの名前を指定してロールを作成します。</block>
  <block id="71ffd00d3592df40d0db94a71ceab12d" category="list-text">パブリック IP が必要かどうかに応じて、VPC、サブネット、キーペアなどのネットワークの詳細を指定します。</block>
  <block id="b5b37cef840fa0a17af0ef55c09a0e1f" category="list-text">セキュリティ グループの詳細 (ソース タイプからの HTTP、HTTPS、SSH アクセスなど) と、任意の場所や IP 範囲情報などを指定します。</block>
  <block id="45b20434e20aeebd5991cd84f2cf11c9" category="list-text">BlueXPコネクタを確認して作成します。</block>
  <block id="92043f8a1dc0b0180854c25bcf5ff79d" category="list-text">AWS コンソールでBlueXP EC2 インスタンスの状態が実行中であることを確認し、[ネットワーク] タブから IP アドレスを確認します。</block>
  <block id="7044ee6a43ee2152ca6d008fcb8228c3" category="list-text">BlueXPポータルからコネクタ ユーザー インターフェイスにログインするか、IP アドレスを使用してブラウザーからアクセスすることもできます。</block>
  <block id="064d933c0c02c4fe7ef1a07ad3a537d7" category="paragraph">BlueXPでCloud Volumes ONTAPインスタンスを作成するには、次の手順を実行します。</block>
  <block id="35d88740e5ca53f6cabb06b3fce807b7" category="list-text">新しい作業環境を作成し、クラウドプロバイダーを選択して、 Cloud Volumes ONTAPインスタンスのタイプ（シングル CVO、HA、 Amazon FSx ONTAP for ONTAPなど）を選択します。</block>
  <block id="dcb89e397dde3dedb1a32224f0c15b78" category="list-text">Cloud Volumes ONTAPクラスター名や資格情報などの詳細を提供します。この検証では、 Cloud Volumes ONTAPインスタンスを作成しました。<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block> 。</block>
  <block id="9cf479af21359b2928a1b672d60577f2" category="list-text">Cloud Volumes ONTAPに必要なサービスを選択します。この検証では監視のみを選択したため、*データセンスとコンプライアンス*と*クラウド サービスへのバックアップ*を無効にしました。</block>
  <block id="cb95ef3838d59d553c71f50b1cadee27" category="list-text">*場所と接続*セクションで、AWS リージョン、VPC、サブネット、セキュリティグループ、SSH 認証方法、およびパスワードまたはキーペアのいずれかを選択します。</block>
  <block id="fdd5d37c21ee01084537317345b3d78b" category="list-text">充電方法を選択してください。この検証には *Professional* を使用しました。</block>
  <block id="00efec60d606ea6ad0bafe93bc77df92" category="list-text">*POC および小規模ワークロード*、*データベースおよびアプリケーション データの運用ワークロード*、*コスト効率の高い DR*、*最高パフォーマンスの運用ワークロード* などの事前構成済みパッケージを選択できます。この検証では、*Poc と小規模ワークロード*を選択します。</block>
  <block id="f22934293c2f2a761ea26fa4ae1828e1" category="list-text">特定のサイズ、許可されたプロトコル、およびエクスポート オプションを使用してボリュームを作成します。この検証では、<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block> 。</block>
  <block id="f2706214c4a60177d14fb8495cbc6924" category="list-text">プロファイル ディスク タイプと階層化ポリシーを選択します。この検証では、*ストレージ効率*と*汎用 SSD – 動的パフォーマンス*を無効にしました。</block>
  <block id="40d3f73a73f67ce67b286aef7a5d3ecb" category="list-text">最後に、 Cloud Volumes ONTAPインスタンスを確認して作成します。次に、 BlueXPがCloud Volumes ONTAP作業環境を作成するまで 15 ～ 20 分待ちます。</block>
  <block id="a8b538b74c3f662c2248af9c6d4742db" category="list-text">Duality プロトコルを有効にするには、次のパラメータを設定します。  Duality プロトコル (NFS/S3) はONTAP 9 からサポートされます。  12.1 以降。</block>
  <block id="15b53c14b58ee146309847451d1eb90a" category="list-text">この検証では、SVMと呼ばれるものを作成しました。<block ref="c7e44ecb645a5c83f843ae05090c5940" prefix=" " category="inline-code"></block>とボリューム<block ref="2b0d59c7031769e80c8e5118b6ec7694" prefix=" " category="inline-code"></block>。</block>
  <block id="3514969b2381af83551c246e34b74403" category="list-text">SVM が NFS および S3 のプロトコルをサポートしていることを確認します。そうでない場合は、それらをサポートするように SVM を変更します。</block>
  <block id="e41c06ffff0f8c9cadbc7f8bb37f8ae5" category="list-text">必要に応じて CA 証明書を作成してインストールします。</block>
  <block id="0395f8062a8a7f4af05113bae8133737" category="list-text">サービス データ ポリシーを作成します。</block>
  <block id="6e16e110899749a795fe713253d850e7" category="list-text">集計の詳細を確認します。</block>
  <block id="5d3f8e127103f0d5cf3de305db892b4d" category="list-text">ユーザーとグループを作成します。</block>
  <block id="efa22127bde2d3ab2e4f5b9a42d14814" category="list-text">NFS ボリューム上にバケットを作成します。</block>
  <block id="c3fd6f44bf88d3f0eae4742edb58eafc" category="paragraph">AWS SageMaker から AWS ノートブックを作成するには、次の手順を実行します。</block>
  <block id="31378aab1ee6190e0b7fe33c501a5625" category="list-text">ノートブックインスタンスを作成するユーザーに AmazonSageMakerFullAccess IAM ポリシーがあること、または AmazonSageMakerFullAccess 権限を持つ既存のグループに属していることを確認します。この検証では、ユーザーは既存のグループの一部です。</block>
  <block id="13c1455885d16af64f1bb96c4e48680a" category="list-text">次の情報を入力します。</block>
  <block id="bb8101aed18120fa18dedaa994ffeea0" category="list-text">ノートブックインスタンス名。</block>
  <block id="6239d232142a089e53e7a13fa721237a" category="list-text">インスタンスタイプ。</block>
  <block id="37056dac7373f7e1b74382036d25b69e" category="list-text">プラットフォーム識別子。</block>
  <block id="38e2059c32c628cf89e90a6844a93800" category="list-text">AmazonSageMakerFullAccess 権限を持つ IAM ロールを選択します。</block>
  <block id="55d7da5ede713135b1c2ebd7a615c3b4" category="list-text">ルートアクセス – 有効。</block>
  <block id="8f0e92e4434abc32ff62a914ae9f2ba6" category="list-text">暗号化キー - カスタム暗号化を選択しません。</block>
  <block id="8b77028d248afd826900d895636b4e98" category="list-text">残りのデフォルトオプションはそのままにしておきます。</block>
  <block id="78456ee20793f732edfa9105bbb4e490" category="list-text">この検証では、SageMaker インスタンスの詳細は次のとおりです。</block>
  <block id="e90e797343ea3f751b0c32e808edaff8" category="inline-image-macro">ステップを示すスクリーンショット。</block>
  <block id="e987fe9ec5699958a73a8f310b4d99e8" category="paragraph"><block ref="e987fe9ec5699958a73a8f310b4d99e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4414f1275568cfaaea91b68f1514516e" category="paragraph"><block ref="4414f1275568cfaaea91b68f1514516e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4789a9ab6472480889e111503d068623" category="list-text">AWS ノートブックを起動します。</block>
  <block id="ce1d8475b6a4d461318eb3139cc54a3b" category="paragraph"><block ref="ce1d8475b6a4d461318eb3139cc54a3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbfbebd805ee7945ad38bc26f8fa9f1b" category="list-text">Jupyter ラボを開きます。</block>
  <block id="d81c10b932515c107a06a3737d985eaf" category="paragraph"><block ref="d81c10b932515c107a06a3737d985eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab3269ab0de58f5611205f6ace06f3af" category="list-text">ターミナルにログインし、 Cloud Volumes ONTAPボリュームをマウントします。</block>
  <block id="cc0649b0871fde24c4a46e09186a36e0" category="list-text">AWS CLI コマンドを使用して、 Cloud Volumes ONTAPボリュームに作成されたバケットを確認します。</block>
  <block id="4f31ff9815d3a8a959e7c557213068d6" category="paragraph">この検証では、クラウドソーシングのコミュニティ活動である DBpedia のデータセットを使用して、さまざまなウィキメディア プロジェクトで作成された情報から構造化されたコンテンツを抽出しました。</block>
  <block id="06d6ccf33b49ed20a34cdc26b6820253" category="list-text">DBpedia GitHub の場所からデータをダウンロードして抽出します。前のセクションで使用したのと同じ端末を使用します。</block>
  <block id="7f50b7f719282741fdf7ce5b8ca1f3dd" category="list-text">データをCloud Volumes ONTAP の場所にコピーし、AWS CLI を使用して S3 バケットから確認します。</block>
  <block id="0ecfbac978ab3f5979ec31eb5574d93e" category="list-text">基本的な検証を実行して、S3 バケットで読み取り/書き込み機能が動作することを確認します。</block>
  <block id="877169a066e14f0512d5f119945ef14d" category="section-title">Jupyter Notebook から機械学習を検証する</block>
  <block id="6f73420916237ed836932ccf967d82ba" category="paragraph">次の検証では、以下の SageMaker BlazingText の例を使用して、テキスト分類を通じて機械学習モデルを構築、トレーニング、およびデプロイする方法を示します。</block>
  <block id="3cf03767e04159d1ec88e7fb0827b487" category="list-text">boto3 および SageMaker パッケージをインストールします。</block>
  <block id="b1282d58a4dcde0a2015d98ad33afd4c" category="paragraph">出力：</block>
  <block id="39017441ac701ebaef8de7116e7f71a0" category="list-text">次のステップでは、データが<block ref="0a726fdd06082d233cd4eade40f12612" prefix="(" category="inline-code"></block>）はs3バケットからダウンロードされます<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block>機械学習で使用される Jupyter Notebook インスタンスに。</block>
  <block id="a270350e3527fea9a36815fa5fe04ba0" category="list-text">次のコードは、推論中に実際のクラス名を取得するために使用される整数インデックスからクラス ラベルへのマッピングを作成します。</block>
  <block id="d17fa3d0aed3f8aaa5e78b447054126d" category="paragraph">出力には、<block ref="90d9a986b9b5e7c07c50a03ccc06a244" prefix=" " category="inline-code"></block> AWS SageMaker 機械学習検証のデータとして使用されるバケット。</block>
  <block id="0cfbf64679378e3e5367734fd2bd69aa" category="list-text">データ前処理フェーズを開始して、トレーニング データをスペースで区切られたトークン化されたテキスト形式に前処理します。この形式は、BlazingText アルゴリズムと nltk ライブラリで使用でき、DBPedia データセットからの入力文をトークン化します。 nltk トークナイザーとその他のライブラリをダウンロードします。その<block ref="6d49a792c1080aa5b33d27ec694621b6" prefix=" " category="inline-code"></block>各データ インスタンスに並列に適用するには、Python マルチプロセッシング モジュールを使用します。</block>
  <block id="d68566815a7248bae03e105c2db8853a" category="list-text">フォーマットされたトレーニング データセットを S3 にアップロードして、SageMaker がトレーニング ジョブを実行するために使用できるようにします。次に、Python SDK を使用して、バケットとプレフィックスの場所に 2 つのファイルをアップロードします。</block>
  <block id="e886ad36e527d85b26c492618651edad" category="list-text">モデル成果物がロードされる S3 に出力場所を設定し、成果物をアルゴリズムのトレーニング ジョブの出力にできるようにします。作成する<block ref="6e3281884db83f9ee468a6e798b6bdfb" prefix=" " category="inline-code"></block>トレーニング ジョブを起動するオブジェクト。</block>
  <block id="41215e143c2b3810b37c4e4f47819077" category="list-text">SageMakerを定義する<block ref="a0b1f5f7b93af313b6e2452f52c8f3f6" prefix=" " category="inline-code"></block>c4.4xlarge インスタンスの教師ありモードを使用して、DBPedia データセットでテキスト分類をトレーニングするためのリソース構成とハイパーパラメータ。</block>
  <block id="6c773c4d6e4a7dda7e00352894786bdb" category="list-text">データ チャネルとアルゴリズム間のハンドシェイクを準備します。これを行うには、<block ref="0e021845d2c0e4ad94a91ce444c13681" prefix=" " category="inline-code"></block>データ チャネルからオブジェクトを取得し、アルゴリズムが使用できるように辞書に保存します。</block>
  <block id="3b29bef19a742b8ab66cddf620871d31" category="list-text">ジョブが完了すると、「ジョブ完了」メッセージが表示されます。トレーニング済みのモデルは、S3バケットに保存されています。<block ref="212ad7a4c11069727ffd02f333d7d8b1" prefix=" " category="inline-code"></block>推定値で。</block>
  <block id="6cb5683d87e53b375bd915572f960759" category="list-text">トレーニングが完了したら、トレーニング済みのモデルを Amazon SageMaker リアルタイムホストエンドポイントとしてデプロイし、予測を行います。</block>
  <block id="4254a612097ca58653de7c0c39da8df2" category="list-text">デフォルトでは、モデルは最も高い確率を持つ 1 つの予測を返します。上部を取得するには<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>予測、設定<block ref="8ce4b16b22b58894aa86c421e8759df3" prefix=" " category="inline-code"></block>設定ファイル内。</block>
  <block id="67be4f1bb90039baec0d8f73ff82a47e" category="list-text">ノートブックを閉じる前にエンドポイントを削除します。</block>
  <block id="16147684eb6910d9d73a43bb83091da4" category="summary">データ サイエンティストやエンジニアは、NFS 形式で保存されたデータにアクセスする必要がよくありますが、AWS は S3 バケット アクセスのみをサポートしているため、AWS SageMaker の S3 プロトコルからこのデータに直接アクセスするのは難しい場合があります。ただし、 NetApp ONTAP は、NFS と S3 のデュアルプロトコル アクセスを有効にすることでソリューションを提供します。このソリューションにより、データ サイエンティストやエンジニアは、 NetApp Cloud Volumes ONTAPの S3 バケットを介して AWS SageMaker ノートブックの NFS データにアクセスできるようになります。このアプローチにより、追加のソフトウェアを必要とせずに、NFS と S3 の両方から同じデータに簡単にアクセスして共有できるようになります。</block>
  <block id="e8ce8afdd7d335aed5b93d4a41ae0115" category="doc">TR-4967: NetAppファイル・オブジェクト・デュアリティと AWS SageMaker によるクラウドデータ管理</block>
  <block id="7caace9abf76a798c629a9134d1bb259" category="summary">NFS と S3 のデュアル プロトコル アクセスの潜在的な使用例としては、機械学習とデータ サイエンスの分野が挙げられます。たとえば、データ サイエンティストのチームが AWS SageMaker を使用して機械学習プロジェクトに取り組んでいる場合、NFS 形式で保存されたデータにアクセスする必要があります。ただし、他のチーム メンバーと共同作業したり、S3 を使用する他のアプリケーションと統合したりするには、S3 バケットを介してデータにアクセスして共有する必要がある場合もあります。</block>
  <block id="ee8cf3bf54dea46135e299d79fa1c179" category="paragraph">このソリューションでは、次のテクノロジーが活用されています。</block>
  <block id="a03ea23912d3b35c875ff398aa4888af" category="list-text">*AWS SageMaker ノートブック*開発者やデータ サイエンティストに機械学習機能を提供し、高品質の ML モデルを効率的に作成、トレーニング、デプロイできるようにします。</block>
  <block id="bbe2552dc6295d353c02fd85c243f334" category="list-text">* NetApp BlueXP。*オンプレミスだけでなく、AWS、Azure、Google Cloud 上のストレージの検出、展開、操作を可能にします。データ損失、サイバー脅威、予期しない停止に対するデータ保護を提供し、データ ストレージとインフラストラクチャを最適化します。</block>
  <block id="aa6fa71ab9848c5875470d36bbc2138a" category="list-text">* NetApp Cloud Volumes ONTAP*  AWS、Azure、Google Cloud 上で NFS、SMB/CIFS、iSCSI、S3 プロトコルを使用したエンタープライズ グレードのストレージ ボリュームを提供し、ユーザーにクラウド内のデータへのアクセスと管理の柔軟性を提供します。</block>
  <block id="eea496572a01ca3e5ced1dfe99a5809c" category="paragraph">ML データを保存するためにBlueXPから作成されたNetApp Cloud Volumes ONTAP 。</block>
  <block id="923baf107dc23ca10f968a4fdecd4f4f" category="paragraph">次の図は、ソリューションの技術コンポーネントを示しています。</block>
  <block id="8afbfe3aeb9c594404d5c244cf8f6024" category="inline-image-macro">この図はソリューションの技術的なコンポーネントを示しています。</block>
  <block id="d3d9ae40ce6d205245ae4b8c9649b6e2" category="paragraph"><block ref="d3d9ae40ce6d205245ae4b8c9649b6e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="55c5281d80934f950192f768715495f0" category="paragraph">NetApp Cloud Volumes ONTAP を利用することで、チームはデータを 1 つの場所に保存し、NFS プロトコルと S3 プロトコルの両方でアクセスできるようになります。データ サイエンティストは AWS SageMaker から NFS 形式のデータに直接アクセスでき、他のチーム メンバーやアプリケーションは S3 バケットを介して同じデータにアクセスできます。</block>
  <block id="f8ba1b513231e9ca54a5c3b94733c28d" category="paragraph">このアプローチにより、追加のソフトウェアや異なるストレージ ソリューション間のデータ移行を必要とせずに、データに簡単かつ効率的にアクセスして共有できるようになります。また、より合理化されたワークフローとチームメンバー間のコラボレーションが可能になり、機械学習モデルの開発がより迅速かつ効果的になります。</block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">このドキュメントでは、Confluent Kafka 認定テスト、パフォーマンス結果、チューニング、Kafka コネクタ、セルフリバランス機能など、 NetAppストレージで Kafka を使用するためのベスト プラクティス ガイドラインを示します。</block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">このドキュメントでは、検証テスト、階層化ストレージのパフォーマンス結果、チューニング、Confluent S3 コネクタ、自己バランス機能など、Confluent 階層化ストレージをNetAppストレージと共に使用するためのベスト プラクティス ガイドラインを示します。  ILM ポリシー、検証のための複数のパフォーマンス テストによる Confluent のパフォーマンス、業界標準の S3 API を考慮すると、 NetApp StorageGRIDオブジェクト ストレージは Confluent 階層型ストレージに最適な選択肢です。</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">Apache Kafkaとは</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3シンクパラメータの詳細</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="list-text">Apache Kafka</block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent Platform の無限ストレージ</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">Confluent 階層型ストレージ - ベストプラクティスとサイジング</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent Platform 用 Amazon S3 シンクコネクタ</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka のサイズ設定</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRIDのサイズ設定</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafkaのユースケース</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">Confluent Platform 6.0 における Kafka クラスターの自己バランス</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">このドキュメントでは、 NetAppストレージ コントローラで Kafka を使用するためのベスト プラクティス ガイドラインについて説明します。</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthikeyan Nagalingam、JosephKantilparambil、 NetApp Rankesh Kumar、Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka は、1 日に数兆件のイベントを処理できるコミュニティ分散型のイベント ストリーミング プラットフォームです。当初はメッセージング キューとして考案された Kafka は、分散コミット ログの抽象化に基づいています。  Kafka は 2011 年に LinkedIn によって作成され、オープンソース化されて以来、メッセージ キューから本格的なイベント ストリーミング プラットフォームへと進化してきました。  Confluent は、Confluent Platform を通じて Apache Kafka のディストリビューションを提供します。  Confluent Platform は、大規模な運用におけるオペレーターと開発者の両方のストリーミング エクスペリエンスを強化するように設計された追加のコミュニティ機能と商用機能を Kafka に補完します。</block>
  <block id="4a967c3b711955b2fd888bf0abedb515" category="paragraph">このドキュメントでは、次の内容を提供して、NetApp のオブジェクト ストレージ サービスで Confluent Tiered Storage を使用するためのベスト プラクティス ガイドラインについて説明します。</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">NetAppオブジェクトストレージによる合流性検証 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">階層型ストレージのパフォーマンステスト</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetAppストレージ システム上の Confluent に関するベスト プラクティス ガイドライン</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">Confluent 階層型ストレージを選ぶ理由</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">Confluentによるこの記事</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent は、特にビッグ データ、分析、ストリーミング ワークロードなど、多くのアプリケーションのデフォルトのリアルタイム ストリーミング プラットフォームになっています。階層型ストレージを使用すると、ユーザーは Confluent プラットフォームでコンピューティングとストレージを分離できます。これにより、データの保存にかかるコスト効率が向上し、事実上無制限の量のデータを保存して、オンデマンドでワークロードをスケールアップ (またはスケールダウン) できるようになり、データやテナントの再調整などの管理タスクが容易になります。  S3 互換ストレージ システムは、これらすべての機能を活用して、すべてのイベントを 1 か所に集めてデータを民主化し、複雑なデータ エンジニアリングの必要性を排除できます。  Kafkaに階層型ストレージを使用する理由の詳細については、以下を参照してください。<block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block> 。</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">階層型ストレージにNetApp StorageGRID を選ぶ理由</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRIDは、 NetAppによる業界をリードするオブジェクト ストレージ プラットフォームです。  StorageGRID は、Amazon Simple Storage Service (S3) API を含む業界標準のオブジェクト API をサポートする、ソフトウェア定義のオブジェクトベースのストレージ ソリューションです。 StorageGRID は、大規模に非構造化データを保存および管理し、安全で耐久性のあるオブジェクト ストレージを提供します。コンテンツは適切な場所、適切な時間、適切なストレージ層に配置され、ワークフローが最適化され、グローバルに分散されたリッチ メディアのコストが削減されます。</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRIDの最大の差別化要因は、ポリシー主導のデータ ライフサイクル管理を可能にする情報ライフサイクル管理 (ILM) ポリシー エンジンです。ポリシー エンジンはメタデータを使用して、データの存続期間全体にわたってデータの保存方法を管理し、最初にパフォーマンスを最適化し、データが古くなるにつれてコストと耐久性を自動的に最適化します。</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">Confluent階層化ストレージの有効化</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">階層型ストレージの基本的な考え方は、データ保存のタスクとデータ処理のタスクを分離することです。この分離により、データ ストレージ層とデータ処理層を個別に拡張することがはるかに容易になります。</block>
  <block id="ec4d623bd1019ab2fabc3a02ae9dc70d" category="paragraph">Confluent の階層型ストレージ ソリューションは、2 つの要素に対処する必要があります。まず、LIST 操作の不整合や、時々発生するオブジェクトの利用不可など、一般的なオブジェクト ストアの一貫性と可用性の特性を回避または回避する必要があります。次に、ゾンビ リーダーがオフセット範囲を階層化し続ける可能性を含め、階層化ストレージと Kafka のレプリケーションおよびフォールト トレランス モデル間のやり取りを正しく処理する必要があります。  NetAppオブジェクト ストレージは、一貫したオブジェクト可用性と HA モデルの両方を提供し、疲れたストレージを階層オフセット範囲で利用できるようにします。  NetAppオブジェクト ストレージは、一貫したオブジェクト可用性と HA モデルを提供し、疲れたストレージを階層オフセット範囲で利用できるようにします。</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">階層型ストレージを使用すると、ストリーミング データの末尾付近の低レイテンシの読み取りと書き込みに高性能プラットフォームを使用できるほか、高スループットの履歴読み取りにNetApp StorageGRIDなどの安価でスケーラブルなオブジェクト ストアを使用することもできます。また、NetApp ストレージ コントローラを使用した Spark 向けの技術ソリューションも用意しており、詳細はこちらをご覧ください。次の図は、Kafka がリアルタイム分析パイプラインにどのように適合するかを示しています。</block>
  <block id="eea5b5aaa7bc893f83efe26850f04584" category="paragraph"><block ref="eea5b5aaa7bc893f83efe26850f04584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0977e5b84fa31f5087efbbc1dc355236" category="paragraph">次の図は、 NetApp StorageGRID がConfluent Kafka のオブジェクト ストレージ層としてどのように適合するかを示しています。</block>
  <block id="baa92f35a9209359bb52e9fa325d0e29" category="paragraph"><block ref="baa92f35a9209359bb52e9fa325d0e29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">このセクションでは、Confluent 認定に使用されるハードウェアとソフトウェアについて説明します。この情報は、 NetAppストレージを使用した Kafka のデプロイメントに適用されます。</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">サイジング</block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka のサイズ設定は、シンプル、詳細、リバース、パーティションの 4 つの構成モードで実行できます。</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">単純</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">シンプル モードは、Apache Kafka を初めて使用するユーザーや初期状態のユース ケースに適しています。このモードでは、スループット MBps、読み取りファンアウト、保持期間、リソース使用率 (デフォルトは 60%) などの要件を指定します。また、オンプレミス (ベアメタル、VMware、Kubernetes、OpenStack) やクラウドなどの環境も入力します。この情報に基づいて、Kafka クラスターのサイズを決定すると、ブローカー、Zookeeper、Apache Kafka Connect Workers、スキーマ レジストリ、REST プロキシ、ksqlDB、および Confluent コントロール センターに必要なサーバーの数がわかります。</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">階層型ストレージの場合、Kafka クラスターのサイズ設定にはきめ細かな構成モードを検討してください。粒度モードは、経験豊富な Apache Kafka ユーザーや明確に定義されたユースケースに適しています。このセクションでは、プロデューサー、ストリーム プロセッサ、およびコンシューマーのサイズ設定について説明します。</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">プロデューサー</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka のプロデューサー (ネイティブ クライアント、REST プロキシ、Kafka コネクタなど) を記述するには、次の情報を提供します。</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">*名前。*スパーク。</block>
  <block id="b39a7ae16ea364375daa4f600ebed072" category="list-text">*プロデューサータイプ。*アプリケーションまたはサービス、プロキシ (REST、MQTT、その他)、既存のデータベース (RDBMS、NOSQL、その他)。  「分からない」を選択することもできます。</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">*平均スループット*  1 秒あたりのイベント数 (たとえば 1,000,000)。</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">*ピークスループット*  1 秒あたりのイベント数 (たとえば 4,000,000)。</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">*平均メッセージサイズ*バイト単位、非圧縮（最大 1 MB、たとえば 1000）。</block>
  <block id="f56fd2104d8bf51910ee81196e8b4751" category="list-text">*メッセージ形式*オプションには、Avro、JSON、プロトコル バッファー、バイナリ、テキスト、「わかりません」などがあります。</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">*複製係数*オプションは 1、2、3 (Confluent 推奨)、4、5、または 6 です。</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">*保持時間*ある日（例えば）。  Apache Kafka にデータをどれくらいの期間保存しますか? 任意の単位で -1 を入力すると、無限の時間になります。計算機では、無限保持の場合の保持期間を 10 年と想定しています。</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">「階層化ストレージを有効にしてブローカー数を減らし、無制限のストレージを可能にしますか?」のチェックボックスを選択します。</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">階層化ストレージが有効な場合、保持フィールドはブローカーにローカルに保存されるホット データ セットを制御します。アーカイブ保持フィールドは、アーカイブ オブジェクト ストレージにデータが保存される期間を制御します。</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">*アーカイブストレージの保持。* 1年（例）。データをアーカイブストレージにどれくらいの期間保存しますか? 任意の単位で -1 を入力すると、継続時間は無制限になります。計算機では、無制限の保持期間として 10 年間を想定しています。</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">*成長乗数* 1 (例)このパラメータの値が現在のスループットに基づいている場合は、1 に設定します。追加の成長に基づいてサイズを決定するには、このパラメータを成長乗数に設定します。</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">*プロデューサーインスタンスの数。* 10（例）。いくつのプロデューサーインスタンスが実行されますか? この入力は、CPU 負荷をサイズ計算に組み込むために必要です。空白の値は、CPU 負荷が計算に組み込まれていないことを示します。</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">このサンプル入力に基づくと、サイズ設定はプロデューサーに次のような影響を及ぼします。</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">非圧縮バイトでの平均スループット: 1GBps。非圧縮バイトでのピーク スループット: 4GBps。圧縮バイトでの平均スループット: 400MBps。圧縮バイトでのピーク スループット: 1.6GBps。これはデフォルトの 60% の圧縮率に基づいています (この値は変更できます)。</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">必要なブローカー上のホットセット ストレージの合計: レプリケーション、圧縮を含む 31,104 TB。必要なブローカー外アーカイブ ストレージの合計: 378,432 TB (圧縮済み)。使用<block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block>StorageGRID のサイズ設定用。</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">ストリーム プロセッサは、Apache Kafka からデータを消費し、Apache Kafka にデータを返すアプリケーションまたはサービスを記述する必要があります。ほとんどの場合、これらは ksqlDB または Kafka Streams に組み込まれています。</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">*名前。*スパークストリーマー。</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">*処理時間*このプロセッサは 1 つのメッセージを処理するのにどのくらいの時間がかかりますか?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1 ミリ秒 (単純なステートレス変換) [例]、10 ミリ秒 (ステートフルなメモリ内操作)。</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100 ミリ秒 (ステートフル ネットワークまたはディスク操作)、1000 ミリ秒 (サードパーティの REST 呼び出し)。</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">私はこのパラメータをベンチマークし、どれくらいの時間がかかるかを正確に把握しています。</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">*出力保持* 1日（例）ストリーム プロセッサは、Apache Kafka に出力を返します。この出力データを Apache Kafka にどれくらいの期間保存しますか? 任意の単位で -1 を入力すると、継続時間は無制限になります。</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">「階層化ストレージを有効にしてブローカー数を減らし、無制限のストレージを可能にしますか?」のチェックボックスを選択します。</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">*アーカイブストレージの保持。* 1年（例）。データをアーカイブストレージにどれくらいの期間保存しますか? 任意の単位で -1 を入力すると、継続時間は無制限になります。計算機では、無制限の保持期間として 10 年間を想定しています。</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">*出力パススルー率。* 100（例）。ストリーム プロセッサは、Apache Kafka に出力を返します。受信スループットの何パーセントが Apache Kafka に出力されますか? たとえば、受信スループットが 20MBps で、この値が 10 の場合、出力スループットは 2MBps になります。</block>
  <block id="aa35062fd231efb888b1d664e6480c1d" category="list-text">これはどのアプリケーションから読み取るのでしょうか? プロデューサー タイプに基づくサイズ設定で使用される名前「Spark」を選択します。上記の入力に基づいて、ストリーム プロセッサ インスタンスとトピック パーティションの推定に対するサイズ設定の次のような影響が予想されます。</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">このストリーム プロセッサ アプリケーションには、次の数のインスタンスが必要です。着信トピックにも、おそらくこれだけのパーティションが必要になります。このパラメータを確認するには、Confluent にお問い合わせください。</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">成長乗数なしの平均スループットは 1,000</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">成長乗数なしのピークスループットの場合は 4,000</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">成長乗数付き平均スループットは1,000</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">成長乗数によるピークスループット4,000</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">消費者</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka からデータを消費し、Apache Kafka にデータを返さないアプリケーションまたはサービス (ネイティブ クライアントや Kafka コネクタなど) について説明します。</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">*名前。*  Spark の消費者。</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">*処理時間*このコンシューマーが 1 つのメッセージを処理するのにどれくらいの時間がかかりますか?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1 ミリ秒 (たとえば、ログ記録のような単純でステートレスなタスク)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10 ミリ秒 (データストアへの高速書き込み)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100 ミリ秒 (データストアへの書き込みが遅い)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ミリ秒（サードパーティのREST呼び出し）</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">期間が既知のその他のベンチマーク プロセス。</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">*消費者タイプ。*既存のデータストア (RDBMS、NoSQL、その他) へのアプリケーション、プロキシ、またはシンク。</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">これはどのアプリケーションから読み取るのでしょうか? このパラメータを、以前に決定したプロデューサーおよびストリームのサイズに接続します。</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">上記の入力に基づいて、コンシューマー インスタンスのサイズとトピック パーティションの見積りを決定する必要があります。コンシューマー アプリケーションには次の数のインスタンスが必要です。</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">平均スループットは2,000、成長乗数なし</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">ピーク時のスループットは8,000、成長乗数なし</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">成長乗数を含む平均スループットは2,000</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">成長乗数を含むピークスループットは8,000</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">着信トピックにもこの数のパーティションが必要になる可能性があります。確認するには Confluent にお問い合わせください。</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">プロデューサー、ストリーム プロセッサ、コンシューマーの要件に加えて、次の追加要件も提供する必要があります。</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">*再建の時間です。*たとえば、4 時間。  Apache Kafka ブローカー ホストに障害が発生し、そのデータが失われ、障害が発生したホストの代わりに新しいホストがプロビジョニングされた場合、この新しいホストはどのくらいの速さで再構築する必要がありますか? 値が不明な場合は、このパラメータを空白のままにしておきます。</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">*リソース使用率目標（パーセント）*たとえば、60。平均スループット時にホストをどの程度利用したいですか?  Confluent では、Confluent 自己バランス クラスターを使用している場合を除き、60% の使用率を推奨しています。その場合、使用率はさらに高くなります。</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">あなたの環境を説明してください</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">*クラスターはどのような環境で実行されますか?*  Amazon Web Services、Microsoft Azure、Google Cloud Platform、オンプレミスのベアメタル、オンプレミスの VMware、オンプレミスの OpenStack、オンプレミスの Kubernates のどれですか?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">*ホストの詳細*コア数: 48 (例)、ネットワーク カードの種類 (10GbE、40GbE、16GbE、1GbE、またはその他の種類)。</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">*ストレージボリューム*ホスト: 12 (例)ホストごとにいくつのハードドライブまたは SSD がサポートされますか?  Confluent では、ホストごとに 12 台のハード ドライブを推奨しています。</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">*ストレージ容量/ボリューム（GB単位）*  1000（例）。  1 つのボリュームにはギガバイト単位でどれくらいのストレージを保存できますか?  Confluent では 1 TB のディスクを推奨します。</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">*ストレージ構成*ストレージ ボリュームはどのように構成されますか?  Confluent では、Confluent のすべての機能を活用するために RAID10 を推奨しています。  JBOD、SAN、RAID 1、RAID 0、RAID 5 などのタイプもサポートされています。</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">*単一ボリュームのスループット (MBps)。* 125（例）。単一のストレージ ボリュームは、メガバイト/秒単位でどのくらいの速度で読み取りまたは書き込みできますか?  Confluent では、通常 125MBps のスループットを持つ標準ハードドライブを推奨しています。</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">*メモリ容量(GB)*  64（例）。</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">環境変数を決定したら、「クラスターのサイズを設定」を選択します。上記の例のパラメータに基づいて、Confluent Kafka のサイズを次のように決定しました。</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">*Apache Kafka。*ブローカー数: 22。クラスターはストレージに制限されています。ホスト数を減らし、無制限のストレージを可能にするために、階層化ストレージを有効にすることを検討してください。</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">*Apache ZooKeeper。*数: 5、Apache Kafka Connect Workers: 数: 2、スキーマ レジストリ: 数: 2、REST プロキシ: 数: 2、ksqlDB: 数: 2、Confluent Control Center: 数: 1。</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">ユースケースを考慮しないプラットフォーム チームにはリバース モードを使用します。パーティション モードを使用して、1 つのトピックに必要なパーティションの数を計算します。見る<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block>リバースおよびパーティション モードに基づいてサイズを決定します。</block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">ソリューションアーキテクチャの詳細</block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">このセクションでは、Confluent 検証に使用されるハードウェアとソフトウェアについて説明します。この情報は、 NetAppストレージを使用した Confluent Platform の展開に適用されます。次の表は、テストされたソリューション アーキテクチャと基本コンポーネントを示しています。</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">ソリューションコンポーネント</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">詳細</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka バージョン 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">3人の動物園飼育員</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">5つのブローカーサーバー</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5つのツールサーバー</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">グラファナ1個</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">1つのコントロールセンター</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux（Ubuntu 18.04）</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">すべてのサーバー</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">階層型ストレージ向けNetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRIDソフトウェア</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">1 x SG1000（ロードバランサー）</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">4 x SGF6024</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">4 x 24 x 800 SSD</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3プロトコル</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE (ブローカーとStorageGRIDインスタンス間のネットワーク接続)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">富士通 PRIMERGY RX2540 サーバ 15 台</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">それぞれに以下の機能が搭載されています: * 2つのCPU、合計16個の物理コア * Intel Xeon * 256GBの物理メモリ * 100GbEデュアルポート</block>
  <block id="06a768157cb89879ca041da1b730da6e" category="summary">このドキュメントでは、TPCDS 認定テスト、チューニング、顧客のユースケースの詳細など、 NetAppストレージで Dremio を使用するためのベスト プラクティス ガイドラインを示します。</block>
  <block id="5539c6da3e2032488a631305f1265434" category="paragraph">結論として、この技術レポートでは、 ONTAP S3、NAS、 StorageGRIDなどのNetAppストレージ コントローラーのさまざまなデータ ソースと組み合わせた、Dremio を使用した q Hybrid Iceberg Lakehouse の包括的な展開の詳細について説明しました。展開プロセスは正常に実行され、TPC-DS ベンチマーク ツールを使用して、さまざまなデータ ソースにわたって 99 個の SQL クエリが実行されました。このレポートでは、 NetApp内の顧客の使用事例も調査し、多様なビジネス要件を満たす Dremio の汎用性と有効性を実証しました。さらに、自動車部品販売の顧客を対象とする特定のユースケースが検討され、データ分析と洞察のために Dremio を活用する実際的なアプリケーションと利点が強調されました。</block>
  <block id="682cc1e627af4457882db17515ccaf5b" category="paragraph">全体として、このドキュメントは、 NetAppストレージ コントローラを使用した Dremio の導入と使用方法を理解するための貴重なリソースとして機能し、さまざまな業界でデータ主導の意思決定と最適化を推進する機能と可能性を示しています。</block>
  <block id="c63354da3a3a21f3ae0083d0a275540c" category="list-text">Zookeeperのインストール</block>
  <block id="661fab58be11f3fe0e5fd03c183c9a3b" category="paragraph"><block ref="661fab58be11f3fe0e5fd03c183c9a3b" category="inline-link-rx"></block></block>
  <block id="288e0e9ab8b8ac8737afefecf16f61fd" category="list-text">ドレミオ</block>
  <block id="d9f3b0f9c66b1c99f5e01fefb31f3280" category="paragraph"><block ref="d9f3b0f9c66b1c99f5e01fefb31f3280" category="inline-link-rx"></block></block>
  <block id="7d56340ec96dd44dedf67654c4b228a9" category="list-text">storageGRIDを使用したDremioの設定</block>
  <block id="d6a7c21494adf18f10c2f9b2b6da5584" category="paragraph"><block ref="d6a7c21494adf18f10c2f9b2b6da5584" category="inline-link-rx"></block></block>
  <block id="719a5826913817829f2d138a33720835" category="list-text">NetAppのユースケース</block>
  <block id="abd766d13b2562c1684015edb41ddc75" category="paragraph"><block ref="abd766d13b2562c1684015edb41ddc75" category="inline-link-rx"></block></block>
  <block id="108f231402daaaf5b7a58841053615dd" category="summary">NetAppオブジェクト ストレージのレイクハウス検証を使用して、Dremio プラットフォームで認証を実行しました。</block>
  <block id="3cd3290a9231e38be51fc2cb3ce01572" category="doc">展開手順</block>
  <block id="d44c5f08c906e8f8bc746c8e4083522e" category="inline-image-macro">NetAppストレージコントローラを使用したdremioアーキテクチャを示す図</block>
  <block id="5e5f3a2661fa2ba525c6c6d493b1058d" category="paragraph">このリファレンスアーキテクチャの検証では、1つのコーディネータと4つのエグゼキュータで構成されるDremio構成を使用しました。<block ref="b76f8c360d80a001aee0571894d68ba2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="07efd46e12f0d695c6aa9e2abf057781" category="section-title">NetAppのセットアップ</block>
  <block id="82c8a5cee83d98576ecd7fb9135c1b41" category="list-text">ストレージシステムの初期化</block>
  <block id="8028442c79907b3f88933ff5c16fac5e" category="list-text">ストレージ仮想マシン（SVM）の作成</block>
  <block id="ff602335ea946bbb0494a8ca5aa58bf5" category="list-text">論理ネットワークインターフェースの割り当て</block>
  <block id="c1d1275f7bc999e53ce84a9b2a48cc7f" category="list-text">NFS、S3 の設定とライセンス</block>
  <block id="bbc1adf735eb5e7f9c1e5bae1fb2aed8" category="paragraph">NFS (ネットワーク ファイル システム) の場合は、次の手順に従ってください。1. NFSv4 または NFSv3 用の Flex Group ボリュームを作成します。この検証のセットアップでは、48 台の SSD を使用しました。1 台の SSD はコントローラのルート ボリューム専用で、47 台の SSD は NFSv4 用に分散されています。  Flex Group ボリュームの NFS エクスポート ポリシーに、Dremio サーバー ネットワークに対する読み取り/書き込み権限があることを確認します。</block>
  <block id="77cf539931cef9f508e194dbd28a0bc0" category="list-text">すべての Dremio サーバーでフォルダーを作成し、各 Dremio サーバーの論理インターフェイス (LIF) を介してこのフォルダーに Flex Group ボリュームをマウントします。</block>
  <block id="575afa472f95d77f2af74b7f99bc9d28" category="paragraph">S3 (Simple Storage Service) の場合は以下の手順に従ってください。</block>
  <block id="28863b320894e844cb1d2df9a479aa31" category="list-text">「vserver object-store-server create」コマンドを使用して、HTTP が有効で管理ステータスが「up」に設定されたオブジェクト ストア サーバーをセットアップします。  HTTPS を有効にしてカスタム リスナー ポートを設定するオプションがあります。</block>
  <block id="993520e0cce3e5f87179d01caa10a746" category="list-text">「vserver object-store-server user create -user &lt;username&gt;」コマンドを使用して、オブジェクト ストア サーバー ユーザーを作成します。</block>
  <block id="4c7b617c418e3a5f7073d2d64ba8cb1c" category="list-text">アクセス キーとシークレット キーを取得するには、次のコマンドを実行します: "set diag; vserver object-store-server user show -user &lt;username&gt;"。ただし、今後はこれらのキーはユーザー作成プロセス中に提供されるか、REST API 呼び出しを使用して取得できるようになります。</block>
  <block id="c3d4f7a6161c482cb921db78c64d1543" category="list-text">手順 2 で作成したユーザーを使用して object-store-server グループを確立し、アクセスを許可します。この例では、「FullAccess」を指定しました。</block>
  <block id="f346ebaf71f9d3850361e0b732a352f5" category="list-text">タイプを「S3」に設定して 2 つの S3 バケットを作成します。  1 つは Dremio 構成用、もう 1 つは顧客データ用です。</block>
  <block id="3c29c74ed24f85f4cf464243c6d69bc7" category="section-title">飼育員のセットアップ</block>
  <block id="a284e9d9802d2b863fce5aa237106342" category="paragraph">Dremio が提供する Zookeeper 構成を使用できます。この検証では、別のZookeeperを使用しました。このWebリンクに記載されている手順に従いました。<block ref="757110f854f50ea29baeb536bc067417" category="inline-link-rx"></block></block>
  <block id="fb6e0f74d4f2cd819e198308d0e560c8" category="section-title">Dremioのセットアップ</block>
  <block id="3e793dc4b6b41d43692a24d29150ed55" category="paragraph">この Web リンクに従って、tar ボール経由で Dremio をインストールしました。</block>
  <block id="694299a05f621f9d6c47fbc0cdd75cdb" category="list-text">Dremio グループを作成します。</block>
  <block id="28b115fb542519f28216941113c7fc69" category="list-text">dremio ユーザーを作成します。</block>
  <block id="6190c0f96190f68e7387989b98fecd3c" category="list-text">Dremio ディレクトリを作成します。</block>
  <block id="b8d53340c1af1590a07a31d4782e75c8" category="list-text">tarファイルをダウンロードしてください<block ref="993599c5d8336ec040e5e84c23246c65" category="inline-link-rx"></block></block>
  <block id="38152bcebb8f6d46160b6d2462ce40a0" category="list-text">Dremio を /opt/dremio ディレクトリに解凍します。</block>
  <block id="9af78d03c81be6e6dd350c73be883f9b" category="list-text">構成フォルダーへのシンボリック リンクを作成します。</block>
  <block id="a16cec17e87f61728dcdd563b7d8ecc7" category="list-text">サービス構成を設定します (SystemD セットアップ)。</block>
  <block id="44aba27523001647040cfa3dab851cbb" category="list-text">dremio デーモンのユニット ファイルを /opt/dremio/share/dremio.service から /etc/systemd/system/dremio.service にコピーします。</block>
  <block id="617a522470fb25e0b60757c2347779fd" category="list-text">システムを再起動する</block>
  <block id="b0a645a7658dbbe597c81a61d8095535" category="list-text">起動時に dremio が起動するようにします。</block>
  <block id="715ae8a49286aaa14659522218602fba" category="list-text">コーディネーター上で Dremio を構成します。詳細については、Dremio 構成を参照してください。</block>
  <block id="940845b76f9832cb794ce21b8053c3d9" category="list-text">Dremio.conf</block>
  <block id="e49741f6cfbc4fdc21eaf59a034e694c" category="list-text">コアサイト.xml</block>
  <block id="157bf0c98c644ad5d09f3dda0843bb8d" category="list-text">Dremio 構成はNetAppオブジェクト ストレージに保存されます。私たちの検証では、「dremioconf」バケットは ontap S3 バケットに存在します。下の図は、「dremioconf」S3 バケットの「scratch」および「uploads」フォルダの詳細を示しています。</block>
  <block id="dec65ddc4408a5fd22bf6eef9c5dc2c4" category="inline-image-macro">NetAppオブジェクトストレージを搭載したdremioを示す図</block>
  <block id="3f6534c1dba4ce90c550aec7ec304146" category="paragraph"><block ref="3f6534c1dba4ce90c550aec7ec304146" category="inline-image-macro-rx" type="image"></block></block>
  <block id="536241c2f7d1f3fbe227bc001b56b949" category="list-text">実行者で Dremio を構成します。私たちのセットアップには 3 つのエグゼキュータがあります。</block>
  <block id="98acd539813ecdb677a633c1e8d72ba9" category="list-text">dremio.conf</block>
  <block id="19aac463221a9324b146be45c5f27561" category="list-text">Core-site.xml – コーディネーターの構成と同じです。</block>
  <block id="9ebe81db6df147f3eea7002c858d2821" category="admonition">NetApp は、Datalake および Lakehouse 環境の主要なオブジェクト ストレージ ソリューションとしてStorageGRID を推奨しています。さらに、ファイル/オブジェクトの二重性のためにNetApp ONTAPが採用されています。このドキュメントでは、お客様のご要望に応じてONTAP S3 のテストを実施し、データ ソースとして正常に機能していることが確認されています。</block>
  <block id="5b8d6104bd7d25e99e47f619fdfd8f81" category="section-title">複数のソースの設定</block>
  <block id="4ee12bc75bcc4f7fb3bbf527ef1d2720" category="list-text">Dremio でONTAP S3 と storageGRID を s3 ソースとして設定します。</block>
  <block id="dbd1ae231acf755d63de74b16a8cbeb7" category="list-text">Dremio ダッシュボード -&gt; データセット -&gt; ソース -&gt; ソースの追加。</block>
  <block id="c102e8893995a295f2cc62063b2e0cd5" category="list-text">一般セクションでAWSアクセスキーとシークレットキーを更新してください</block>
  <block id="71a7d593565f192b138481a0e8d335c4" category="list-text">詳細オプションで互換モードを有効にし、以下の詳細で接続プロパティを更新します。  ontap S3 または storageGRID のいずれかのNetAppストレージ コントローラからのエンドポイント IP/名前。</block>
  <block id="4f594a255a564afe3df4ac263caedbb5" category="list-text">可能な場合はローカル キャッシュを有効にする、可能な場合に使用する利用可能なキャッシュの合計の最大パーセント = 100</block>
  <block id="c71df1ddac771fdc9b484b0ed6f6d9f7" category="inline-image-macro">NetAppオブジェクトストレージのファイルリストを示す図</block>
  <block id="a4d1986a0b1a4f12d2237b0963d2e43d" category="list-text">次に、 NetAppオブジェクト ストレージからバケットのリストを表示します。<block ref="3774299f093c28855158f425c629b55d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c80afe9a6ef853e0d394059a332a406d" category="list-text">storageGRID バケットの詳細のサンプルビュー<block ref="e0f51eae5ca0e68849adc9661a7def73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18ebb902e9ccb331331d9d1b8b5e0f76" category="list-text">Dremio で NAS (具体的には NFS) をソースとして設定します。</block>
  <block id="08a5aec8691cede64f84acb42700e07d" category="list-text">一般セクションで、名前と NFS マウント パスを入力します。  NFS マウント パスが Dremio クラスター内のすべてのノード上の同じフォルダーにマウントされていることを確認してください。</block>
  <block id="eaa2d3817be8fb7b330c01f9605f0808" category="paragraph"><block ref="eaa2d3817be8fb7b330c01f9605f0808" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26b17225b626fb9238849fd60eabdf60" category="paragraph">+</block>
  <block id="b134468afaa618eaef2e7bfaf5f30da7" category="summary">このドキュメントでは、 NetAppストレージ コントローラで Dremio を使用するためのベスト プラクティス ガイドラインについて説明します。</block>
  <block id="53bd7dac219a2662a137c6de870224d2" category="doc">NetAppとDremioの次世代ハイブリッドIceberg Lakehouseソリューション</block>
  <block id="0c74f27a6d1c41b83e5cc59468f24a0d" category="paragraph">このドキュメントでは、 ONTAP S3、NAS、 StorageGRIDなどのNetAppストレージ コントローラからのさまざまなデータ ソースを使用した Dremio の展開の詳細について説明します。展開中に、TPC-DS ベンチマーク ツールを使用して、さまざまなソースに対して 99 個の SQL クエリを実行しました。このドキュメントでは、 NetApp内の顧客ユースケースや、自動車部品販売の顧客に関連するユースケースについても説明します。</block>
  <block id="d4b28ab5babb078bc6498faee7c53a81" category="summary">このセクションでは、dremio 認証に使用されるハードウェアとソフトウェアについて説明します。この情報は、 NetAppストレージを使用した dremio の展開に適用されます。</block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">ソリューションの概要</block>
  <block id="9953e901936889810e67ec0949c6b2fc" category="paragraph">Hybrid Iceberg Lakehouse ソリューションは、データ レイクの顧客が直面する顧客の課題に対処するための独自の利点を提供します。 Dremio Unified Lakehouse プラットフォームとNetApp ONTAP、 StorageGRID、 NetApp Cloud ソリューションを活用することで、企業はビジネス運営に大きな価値を付加できます。このソリューションは、 NetAppソースを含む複数のデータ ソースへのアクセスを提供するだけでなく、全体的な分析パフォーマンスを向上させ、企業がビジネスの成長につながるビジネス インサイトを獲得できるよう支援します。</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetAppの概要</block>
  <block id="b630104207f28e8a0523849fe77c1e9f" category="list-text">ONTAPやStorageGRIDなどの NetApp の製品は、ストレージとコンピューティングの分離を可能にし、特定の要件に基づいて最適なリソース利用を実現します。この柔軟性により、お客様はNetAppストレージソリューションを使用してストレージを独自に拡張できるようになります。</block>
  <block id="bc213af00312a8c2d752b8b42715eed6" category="list-text">NetApp のストレージ コントローラを活用することで、顧客は NFS および S3 プロトコルを使用してベクター データベースにデータを効率的に提供できます。これらのプロトコルは、顧客データの保存を容易にし、ベクター データベース インデックスを管理するため、ファイルやオブジェクトの方法を通じてアクセスされるデータの複数のコピーが不要になります。</block>
  <block id="1557c431be0fea4f212f4006eafc9a8c" category="list-text">NetApp ONTAP は、AWS、Azure、Google Cloud などの主要なクラウド サービス プロバイダー全体で NAS およびオブジェクト ストレージのネイティブ サポートを提供します。この幅広い互換性により、シームレスな統合が保証され、顧客データのモビリティ、グローバルなアクセス性、災害復旧、動的なスケーラビリティ、高パフォーマンスが実現します。</block>
  <block id="392d70ca39f31f10bd637936769788df" category="section-title">StorageGRID</block>
  <block id="9409f64cd9405163cc619bf89c44eaf4" category="paragraph">業界をリードする当社のオブジェクト ストレージ storageGRID は、自動データ配置、柔軟な導入オプション、階層化された消去コーディングによる比類のない耐久性を実現する強力なポリシー エンジンを提供します。単一の名前空間で数十億のオブジェクトとペタバイトのデータをサポートするスケーラブルなアーキテクチャを備えています。このソリューションはハイブリッド クラウド統合を可能にし、主要なクラウド プラットフォームへのデータ階層化を可能にします。  2019 年の IDC Marketscape Worldwide Object-Based Vendor Assessment でリーダーとして認められました。</block>
  <block id="546a8027b219510c369554288fd7eff4" category="paragraph">さらに、storageGRID は、ソフトウェア定義のオブジェクト ストレージ、地理的冗長性、およびマルチサイト機能により、大規模な非構造化データの管理に優れています。ポリシーベースの情報ライフサイクル管理が組み込まれており、ミラーリングや検索などのクラウド統合機能を提供します。  Common Criteria、NF203 Digital Safe Component、ISO/IEC 25051、KPMG、Cohasset Compliance Assessment など、さまざまな認証を取得しています。</block>
  <block id="030de30483fabd3aca42be7503592961" category="paragraph">要約すると、 NetApp storageGRID は、大規模な非構造化データを効率的に管理するための強力な機能、スケーラビリティ、ハイブリッド クラウド統合、コンプライアンス認定を提供します。</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="section-title">NetApp ONTAP</block>
  <block id="185a43d593912638c2bb37ef99444fc9" category="paragraph">NetApp ONTAPは、幅広いエンタープライズ機能を提供する堅牢なストレージ ソリューションです。これには、アプリケーションの一貫性と改ざん防止を備えた即時バックアップを提供するスナップショットが含まれています。 SnapRestore はオンデマンドでのバックアップのほぼ瞬時の復元を可能にし、 SnapMirror は統合されたリモート バックアップおよび災害復旧機能を提供します。このソリューションには、自律ランサムウェア保護 (ARP) も組み込まれており、複数の管理者による検証、FIPS 認定による保存データの暗号化、転送中のデータの暗号化、多要素認証 (MFA)、ロールベースのアクセス制御 (RBAC) などの機能によってデータのセキュリティを確保します。包括的なログ記録、監査、オンボードおよび外部キー管理、安全な消去、複数のテナントの安全な管理により、データのセキュリティとコンプライアンスがさらに強化されます。</block>
  <block id="48af054a9eb5d217f15aab37f5fe9b91" category="paragraph">NetApp ONTAP には、低い総所有コストで、高いレベルの整合性、パフォーマンス、保持力を備えた規制に準拠したデータ保持を提供するSnapLockも搭載されています。  NetApp ONTAP 9 と完全に統合されており、悪意のある行為、不正な管理者、ランサムウェアに対する保護を提供します。</block>
  <block id="afd4da5566327275499951d8db99e683" category="paragraph">このソリューションには、転送中および保存中のデータの暗号化のための NSE/NVE 暗号化、多要素管理者アクセス、および複数管理者検証が含まれます。 Active IQ はAI を活用した予測分析と修正アクションを提供し、QoS はサービス品質のワークロード制御を保証します。管理と自動化の統合は、SysMgr/GUI/CLI/API を通じて直感的に行えます。  FabricPool は自動データ階層化を可能にし、インライン データ圧縮、重複排除、および圧縮を通じて効率性を実現します。  NetApp は、顧客に費用をかけずにワークロード効率の目標を達成することを保証します。</block>
  <block id="327b294a4782dbbd617ca02b0227198e" category="paragraph">NetApp ONTAP は、NVMe/FC、FC、NVMe/TCP、iSCSI、NFS、SMB、S3 などのさまざまなプロトコルをサポートし、統合ストレージ ソリューションを実現します。全体として、 NetApp ONTAP は、多様なストレージ ニーズを満たすための広範なエンタープライズ機能、強力なセキュリティ、コンプライアンス、効率性、汎用性を提供します。</block>
  <block id="5504df296ab63119754ecfd92e6a07d7" category="section-title">Dremioの概要</block>
  <block id="46664b9047c24c224cf4898236ac4159" category="paragraph">Dremio は、セルフサービス分析と AI のための統合レイクハウス プラットフォームです。  Dremio 統合分析プラットフォームは、従来のデータ ウェアハウス ソリューションの数分の 1 のコストで、レイクハウスの柔軟性、拡張性、パフォーマンスを実現し、ユーザーをデータに近づけます。  Dremio は、「シフトレフト」分析を可能にして、複雑でコストのかかるデータ統合と ETL を排除し、データ移動のないシームレスなエンタープライズ規模の分析を実現します。  Dremio には以下の機能もあります:</block>
  <block id="2f0acfc3dbf17a0571810cc0dedaf64f" category="list-text">ユニバーサルなセマンティック レイヤーと緊密に統合された高性能な SQL クエリ エンジンによって実現される使いやすいセルフサービス分析により、クラウドとオンプレミスの両方ですべてのデータの接続、管理、分析が容易になります。</block>
  <block id="88be140c20067da1baf354c05223a2c6" category="list-text">Dremio の Apache Iceberg ネイティブのレイクハウス管理機能は、データ検出を簡素化し、データ最適化を自動化して、Git にヒントを得たデータ バージョン管理による高性能分析を実現します。</block>
  <block id="fe08740b7cac34b055da6ec6bfe79c3f" category="list-text">Dremio はオープンソースとオープン スタンダードに基づいて構築されており、企業がロックインを回避し、イノベーションの態勢を維持できるようにします。エンタープライズ企業は、あらゆるワークロードで最高の価格性能比を備えた、最も使いやすいレイクハウス プラットフォームとして Dremio を信頼しています。</block>
  <block id="e95806f0d7b4743b250387c094acef2b" category="section-title">Dremio とNetApp のハイブリッド Iceberg Lakehouse ソリューションは顧客にどのような価値をもたらしますか?</block>
  <block id="81c79525dc5cb78051ffe86a4b85377f" category="list-text">*データ管理とアクセス性の向上*: Dremio は、組織がデータ レイクから直接高速にデータをクエリできるようにするデータ レイクハウス プラットフォームでよく知られています。一方、 NetApp は、クラウド データ サービスとデータ ストレージ ソリューションの大手プロバイダーです。この共同オファーにより、お客様は企業のデータを効率的かつ効果的に保存、管理、アクセス、分析するための包括的なソリューションを利用できるようになります。</block>
  <block id="4bb8954089d2a9fb6c99825861c39f62" category="list-text">*パフォーマンスの最適化*: NetApp のデータ ストレージに関する専門知識と Dremio のデータ処理およびデータ最適化の機能を組み合わせたパートナーシップにより、データ操作のパフォーマンスを向上させ、レイテンシを削減し、ビジネス インサイトを迅速に得るソリューションが提供されます。  Dremio は、NetApp 独自の社内 IT 分析インフラストラクチャにもパフォーマンス上のメリットをもたらしました。</block>
  <block id="737f740962d700c8fb65a99e34900bc9" category="list-text">*スケーラビリティ*: Dremio とNetApp はどちらも、拡張性を考慮して設計されたソリューションを提供しています。この共同ソリューションは、顧客に高度にスケーラブルなデータ ストレージ、データ管理、および分析環境を提供します。ハイブリッド Iceberg Lakehouse 環境では、Dremio SQL クエリ エンジンとNetApp StorageGRIDを組み合わせることで、比類のないスケーラビリティ、同時実行性、クエリ パフォーマンスを実現し、あらゆるビジネスの分析ニーズに対応できます。</block>
  <block id="38eb37e9ecd9ccb05b8fda4a7890c571" category="list-text">*データ セキュリティとガバナンス*: 両社とも、データ セキュリティとガバナンスに重点を置いています。これらを組み合わせることで、強力なセキュリティとデータ ガバナンス機能が提供され、データが保護され、データ ガバナンスの要件が満たされることが保証されます。ロールベースのきめ細かなアクセス制御、包括的な監査、エンドツーエンドのデータ系統、統合 ID 管理、広範なコンプライアンスとセキュリティ フレームワークを備えた SSO などの機能により、企業の分析データ環境が安全に管理されます。</block>
  <block id="b10c860483a8763cd915a0459af4c444" category="list-text">*コスト効率*: Dremio のデータ レイク エンジンを NetApp のストレージ ソリューションと統合することで、顧客はデータ管理とデータ移動に関連するコストを削減できます。組織は、従来のデータ レイク環境から、 NetAppと Dremio で構成されたより最新のレイクハウス ソリューションに移行することもできます。このハイブリッド Iceberg Lakehouse ソリューションは、高速クエリ パフォーマンスと市場をリードするクエリ同時実行性を提供し、TCO を削減し、ビジネス洞察を得るまでの時間を短縮します。</block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">このセクションでは、このソリューションで使用されるテクノロジについて説明します。</block>
  <block id="910af13beca7193218f534b5af1d8881" category="doc">テクノロジ要件</block>
  <block id="915f99cb757b24fafb485b82cc5fe20e" category="paragraph">このドキュメントで実行された検証には、以下に概説するハードウェアおよびソフトウェア構成が使用されました。これらの構成は、環境を設定するためのガイドラインとして役立ちます。ただし、具体的なコンポーネントは個々の顧客の要件に応じて異なる場合があることに注意してください。</block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">ハードウェア要件</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="cell">ハードウェア</block>
  <block id="74cc4ae913d72260c083ab2b346121ec" category="cell">NetApp AFFストレージアレイ HA ペア</block>
  <block id="e4044b704224bc11ad4a58e92f2131d7" category="list-text">A800</block>
  <block id="8020ad245e7cbc2ac49c84b7f4ace684" category="list-text">ONTAP 9.14.1</block>
  <block id="4c365c4afab33ac328254bd7c2ae19a9" category="list-text">48 x 3.49TB SSD-NVM</block>
  <block id="fe001f20ed0495ea55b4938631878b7a" category="list-text">2 つの S3 バケット: Dremio メタデータと顧客データ。</block>
  <block id="637071f2d4a8f15942d2e18657010fa9" category="cell">富士通 PRIMERGY RX2540 M4 x 4</block>
  <block id="e0c5e2628a6e691fa3fafe35f3bf20c3" category="list-text">CPU×64</block>
  <block id="319d86787ef65ef260e666cc63f6e1a3" category="list-text">インテル Xeon Gold 6142 CPU @ 2.60GHz</block>
  <block id="d6b9b9dc5caf5833c325bc02278f4817" category="list-text">256 GM 物理メモリ</block>
  <block id="81555075e106886f4be11de9599425a6" category="list-text">1 x 100GbE ネットワークポート</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="cell">ネットワーク</block>
  <block id="edcd3f3adc6d51b309e9115847fa497f" category="list-text">100ギガビットイーサネット</block>
  <block id="9de4526063d2d5dc8600f1abb273fb87" category="cell">* 1 x SG100、3xSGF6024 * 3 x 24 x 7.68TB * 2 つの S3 バケット:Dremio メタデータと顧客データ。</block>
  <block id="500084ff15a1d3831b2b0a0cc8efb3b4" category="list-text">バージョン - 25.0.3-202405170357270647-d2042e1b</block>
  <block id="b5251cb924b1e27d2fa914e7b3dbd75c" category="list-text">エンタープライズエディション</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="cell">オンプレミス</block>
  <block id="fd50fb0f59921345e87394051ed99e40" category="list-text">5ノードのDremioクラスター</block>
  <block id="743d1e7bf62dfc8a183c666693662dc6" category="list-text">マスターコーディネーター1名とエグゼキューター4名</block>
  <block id="cce86ec0e697036ce6aa6105904b06de" category="summary">このセクションでは、ネットアップ オブジェクト ストレージを使用した Dremio の顧客ユースケースの詳細について説明します。</block>
  <block id="fe0bd5fc290c9a203c8e8f18a2b6e647" category="doc">顧客ユースケース</block>
  <block id="46233f9bd0306ff790c810922b25e957" category="section-title">NetApp ActiveIQ のユースケース</block>
  <block id="994534c401b3a0f86cd899f3b7b6ec57" category="inline-image-macro">ActiveIQの旧アーキテクチャ</block>
  <block id="3002c8327e7407633cb1d61c6e798c05" category="paragraph"><block ref="3002c8327e7407633cb1d61c6e798c05" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e9e9a9c8ceef33ee9b9839f01cdf06a" category="paragraph">*課題*: 当初は多数のユースケースをサポートするために設計された NetApp 独自の社内Active IQソリューションは、社内ユーザーと顧客の両方に包括的なサービスを提供するソリューションへと進化しました。しかし、基盤となる Hadoop/MapR ベースのバックエンド インフラストラクチャでは、データの急速な増加と効率的なデータ アクセスの必要性により、コストとパフォーマンスに関する課題が生じていました。ストレージを拡張すると、不要なコンピューティング リソースが追加され、コストが増加します。</block>
  <block id="66c90395e80a7e0f428abf5cf77fa1f4" category="paragraph">さらに、Hadoop クラスターの管理には時間がかかり、専門知識が必要でした。データのパフォーマンスと管理の問題により状況はさらに複雑になり、クエリには平均 45 分かかり、誤った構成によりリソースが不足するようになりました。これらの課題に対処するため、 NetApp は既存のレガシー Hadoop 環境に代わる手段を模索し、Dremio 上に構築された新しい最新ソリューションによってコストが削減され、ストレージとコンピューティングが分離され、パフォーマンスが向上し、データ管理が簡素化され、きめ細かな制御が可能になり、災害復旧機能も提供されると判断しました。</block>
  <block id="f4327571cd8b76a68a25a1d8487a0db0" category="inline-image-macro">ActiveIQとdremioの新しいアーキテクチャ</block>
  <block id="954cc37909c75a2221a99b0c02a26f82" category="paragraph">*解決*：<block ref="4a878fba67d10f0324250d8d1dafdcc5" category="inline-image-macro-rx" type="image"></block> Dremio により、 NetApp は段階的なアプローチで Hadoop ベースのデータ インフラストラクチャを最新化し、統合分析のロードマップを提供できるようになりました。データ処理に大幅な変更を必要とする他のベンダーとは異なり、Dremio は既存のパイプラインとシームレスに統合し、移行時の時間と費用を節約しました。  NetApp は、完全にコンテナ化された環境に移行することで、管理オーバーヘッドを削減し、セキュリティを強化し、耐障害性を強化しました。  Dremio は、Apache Iceberg や Arrow などのオープン エコシステムを採用することで、将来性、透明性、拡張性を確保しました。</block>
  <block id="6f323477260e85221bf9876e157b69d0" category="paragraph">Dremio は、Hadoop/Hive インフラストラクチャの代替として、セマンティック レイヤーを通じて二次的なユース ケース向けの機能を提供しました。既存の Spark ベースの ETL およびデータ取り込みメカニズムはそのままに、Dremio は、重複のないデータの検出と探索を容易にする統合アクセス レイヤーを提供しました。このアプローチにより、データ複製係数が大幅に削減され、ストレージとコンピューティングが分離されました。</block>
  <block id="ef3e4aef01dbcfe8475e127bc34ac240" category="paragraph">*メリット*: Dremio を使用することで、 NetApp はデータ環境におけるコンピューティング消費とディスク容量要件を最小限に抑え、大幅なコスト削減を実現しました。新しいActive IQデータ レイクは、3 ペタバイトのデータを保持する 8,900 個のテーブルで構成されています。以前のインフラストラクチャでは、7 ペタバイト以上でした。 Dremio への移行には、33 個のミニ クラスターと 4,000 個のコアから Kubernetes クラスター上の 16 個のエグゼキューター ノードへの移行も含まれていました。コンピューティング リソースが大幅に減少したにもかかわらず、 NetApp はパフォーマンスの顕著な向上を実現しました。 Dremio を介してデータに直接アクセスすることで、クエリの実行時間が 45 分から 2 分に短縮され、予測メンテナンスと最適化のための洞察を得るまでの時間が 95% 高速化されました。この移行により、コンピューティング コストが 60% 以上削減され、クエリが 20 倍以上高速化され、総所有コスト (TCO) が 30% 以上節約されました。</block>
  <block id="a0c64f41c7126c9e86274e0e58d4bc01" category="section-title">自動車部品販売の顧客ユースケース。</block>
  <block id="866dec6bda5d640e2bb5d1c8de8d6f67" category="paragraph">*課題*: この世界的な自動車部品販売会社では、経営陣と企業財務計画および分析グループが販売レポートの統合ビューを取得できず、個々の事業ラインの販売指標レポートを読み取って統合するしかありませんでした。その結果、顧客は少なくとも 1 日前のデータに基づいて意思決定を行うようになりました。新しい分析情報を取得するには、通常 4 週間以上かかります。データ パイプラインのトラブルシューティングにはさらに多くの時間が必要となり、すでに長いタイムラインにさらに 3 日以上が追加されます。レポート開発プロセスとレポートのパフォーマンスが遅いため、アナリスト コミュニティは、新しいビジネス インサイトを見つけたり、新しいビジネス行動を推進したりするのではなく、データの処理または読み込みが完了するまで継続的に待機する必要がありました。これらの問題のある環境は、さまざまな事業部門の多数の異なるデータベースで構成されており、多数のデータ サイロが発生していました。遅くて断片化された環境では、アナリストが単一の真実のソースではなく独自の真実を導き出す方法が多すぎるため、データ ガバナンスが複雑になりました。このアプローチでは、データ プラットフォームと人件費で 190 万ドル以上かかりました。レガシー プラットフォームを維持し、データ要求に応えるには、年間 7 人のフィールド テクニカル エンジニア (FTE) が必要でした。データ要求の増加に伴い、データ インテリジェンス チームは、将来のニーズに合わせてレガシー環境を拡張することができませんでした。</block>
  <block id="9de1ea6ce232738b38a6f50397411de0" category="paragraph">*ソリューション*: NetApp Object Store で大規模な Iceberg テーブルをコスト効率よく保存および管理します。  Dremio のセマンティック レイヤーを使用してデータ ドメインを構築し、ビジネス ユーザーがデータ製品を簡単に作成、検索、共有できるようにします。</block>
  <block id="859dc66fff375d140e35011f5d94d363" category="paragraph">*顧客へのメリット*: • 既存のデータアーキテクチャを改善および最適化し、洞察を得るまでの時間を4週間から数時間に短縮 • トラブルシューティング時間を3日から数時間に短縮 • データプラットフォームと管理コストを38万ドル以上削減 • 年間2 FTEのデータインテリジェンス作業を削減</block>
  <block id="4bf80525d5b2bad7362ea2ddc1239135" category="summary">ONTAPや storagegrid などのNetAppオブジェクト ストレージを使用して、SQL ワークロードに対して 5 つのノードで tpc-ds テストを実行しました。</block>
  <block id="07c6b8ec7b7d3f9f4e97f8cab49e9952" category="doc">ソリューション検証の概要</block>
  <block id="d234b1c706880318f115c69f47d6dfa1" category="paragraph">このセクションでは、複数のソースから SQL テスト クエリを実行して機能を検証し、 NetAppストレージへのスピルオーバーをテストおよび検証しました。</block>
  <block id="399acee44d644dcec9afa1fb807677db" category="section-title">オブジェクトストレージのSQLクエリ</block>
  <block id="fdbf3a00f4ffd80f1b71f818ac8c17b1" category="list-text">dremio.envでサーバーあたりのメモリを250GBに設定する</block>
  <block id="f01e72d5763f7ff9b6212ae55fe5a618" category="list-text">dremio.conf ファイルとストレージの詳細で、スピルオーバーの場所 (${DREMIO_HOME}"/dremiocache) を確認します。</block>
  <block id="c1fd3f5160a9be68b59f1459ab2d43ab" category="list-text">Dremioのスピルオーバー場所をNetApp NFSストレージに向ける</block>
  <block id="876f04ac63af2ea2d5f8fa3785b310ca" category="list-text">コンテキストを選択します。私たちのテストでは、 ONTAP S3 にある TPCDS によって生成された parquet ファイルに対してテストを実行しました。  Dremioダッシュボード -&gt; SQLランナー -&gt;コンテキスト -&gt; NetAppONTAPS3 -&gt; Parquet1TB</block>
  <block id="005d28008e05dae0767805243a8fb4e4" category="inline-image-macro">コンテキストをontaps3 parquetフォルダに設定する</block>
  <block id="1737725edbb24ea279e1a45444de8083" category="paragraph"><block ref="1737725edbb24ea279e1a45444de8083" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d627092b3c15550dd7a319a2762deb9" category="list-text">DremioダッシュボードからTPC-DSクエリ67を実行する</block>
  <block id="d73e35125ec82123636d65f59cd30912" category="inline-image-macro">TPC-DSの99個のクエリのうちの1つであるクエリ67を実行します。</block>
  <block id="af576e90e15d8a6ff15105e65b4de6ca" category="paragraph"><block ref="af576e90e15d8a6ff15105e65b4de6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2f6a29c6a6cbd53a7eb78e09592b591" category="list-text">すべての実行プログラムでジョブが実行されていることを確認します。  Dremioダッシュボード -&gt; ジョブ -&gt; &lt;jobid&gt; -&gt; 生のプロファイル -&gt; EXTERNAL_SORTを選択 -&gt; ホスト名</block>
  <block id="cc8a9d0051ce4ea66245ee1201332dba" category="inline-image-macro">Q67クエリ内のノードのリスト</block>
  <block id="de7e26680d69dfee92356b33d4b9e852" category="paragraph"><block ref="de7e26680d69dfee92356b33d4b9e852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8ae43960f655adfac548cc72fd74e60" category="list-text">SQL クエリが実行されている場合、 NetAppストレージ コントローラ内のデータ キャッシュの分割フォルダーを確認できます。</block>
  <block id="a6b711eedf77bebde70bdfc6f869c41f" category="inline-image-macro">クエリ67が完了すると詳細が流出する</block>
  <block id="9e9d6f8f3555c800bdfb98b69c82c2df" category="list-text">SQLクエリはスピルオーバーで完了しました<block ref="d1b3ed2b7bf78249ccd584f190063118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="29f8ef4d2e7065fbaf7af29841718352" category="inline-image-macro">完了したクエリのジョブ概要 67</block>
  <block id="af756b25baef2ba53e554daaf6f7d4b3" category="list-text">ジョブ完了の概要。<block ref="91ffddffe841fcfba2fc7aad3683dff3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0de80fdbcc7438b84f536fcf74c03921" category="inline-image-macro">クエリ結果からのsplleddataの詳細</block>
  <block id="eacfb80ed9b3da589a06f11817a18a8e" category="list-text">こぼれたデータのサイズを確認する<block ref="c25c4cfe2a16a40eeaf1652c7ba5d9f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f8d7f6ab5b07156f7006507270c9869" category="paragraph">NAS およびStorageGRIDオブジェクト ストレージにも同じ手順が適用されます。</block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">このセクションでは、さまざまな Hadoop データ保護要件を満たすためにNetAppが提供するユースケースとソリューションの概要を示します。</block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">このセクションでは、さまざまな Hadoop データ保護要件を満たすためにNetAppが提供するユースケースとソリューションの概要を示します。  NetAppが提供するデータ ファブリックを使用すると、お客様は次のことが可能になります。</block>
  <block id="095ece35729c37846889cf00d16bb141" category="list-text">NetApp の豊富なデータ管理機能と Hadoop ネイティブ ワークフローとの統合を活用することで、適切なデータ保護ソリューションを柔軟に選択できます。</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop クラスターのバックアップ ウィンドウ時間を約 70% 削減します。</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop クラスターのバックアップによって生じるパフォーマンスへの影響を排除します。</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">マルチクラウド データ保護と、さまざまなクラウド プロバイダーから単一の分析データ ソースへのデータ アクセスを同時に提供します。</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexCloneテクノロジーを使用して、高速かつスペース効率の高い Hadoop クラスターのコピーを作成します。</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">このドキュメントに記載されている情報の詳細は、以下のドキュメントやウェブサイトをご参照ください。</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetAppビッグデータ分析ソリューション</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">NetAppストレージを使用した Apache Spark ワークロード</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Apache Spark向けNetAppストレージソリューション</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetAppによって実現されるデータファブリック上の Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">謝辞</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">ポール・バーランド、 NetApp 、ANZビクトリア地区営業担当</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">NetAppビジネス開発マネージャー、Hoseb Dermanilian</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier、 NetApp MPSG ディレクター</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen、システム エンジニア、ANZ Victoria District SE、 NetApp</block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">バージョン履歴</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">日付</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">ドキュメントのバージョン履歴</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">バージョン1.0</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018年1月</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">初版リリース</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">バージョン2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021年10月</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">ユースケース#5を更新: 分析ワークロードの高速化</block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">バージョン3.0</block>
  <block id="fb784db76f57bc935639ba5340089d77" category="cell">2023年11月</block>
  <block id="11ec45d75a4ad726423d44fadee3074a" category="cell">NIPAM の詳細を削除しました</block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetAppが提供するデータ ファブリックは、クラウド環境とオンプレミス環境全体のデータ管理を簡素化および統合し、デジタル変革を加速します。  NetAppが提供するデータ ファブリックは、データの可視性と分析、データのアクセスと制御、データの保護とセキュリティのための、一貫性のある統合データ管理サービスとアプリケーション (構成要素) を提供します。</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">ビッグデータ アーキテクチャ向けのNetApp搭載データ ファブリック</block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetAppが提供するデータ ファブリックは、クラウド環境とオンプレミス環境全体のデータ管理を簡素化および統合し、デジタル変革を加速します。</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp搭載のデータ ファブリックは、次の図に示すように、データの可視性と分析、データのアクセスと制御、データの保護とセキュリティを実現する、一貫性のある統合データ管理サービスとアプリケーション (構成要素) を提供します。</block>
  <block id="42e5faac50fa6c299b9293560a7e7052" category="paragraph"><block ref="42e5faac50fa6c299b9293560a7e7052" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">実証済みのデータファブリックの顧客ユースケース</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetAppを搭載したデータ ファブリックは、顧客に次の 9 つの実証済みユース ケースを提供します。</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">分析ワークロードを加速</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps変革を加速</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">クラウドホスティングインフラストラクチャの構築</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">クラウドデータサービスを統合する</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">データの保護とセキュリティ確保</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">非構造化データを最適化する</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">データセンターの効率化</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">データの洞察と制御を提供</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">簡素化と自動化</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">このドキュメントでは、9 つのユースケースのうち 2 つ (およびそのソリューション) について説明します。</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS ダイレクトアクセス</block>
  <block id="c2915c2b980396a00c86766bff7195e3" category="paragraph">NetApp NFS を使用すると、データを移動またはコピーすることなく、既存または新規の NFSv3 または NFSv4 データに対してビッグ データ分析ジョブを実行できます。データの複数のコピーを防ぎ、ソースとデータを同期する必要がなくなります。たとえば、金融分野では、ある場所から別の場所へのデータの移動は法的義務を満たす必要があり、これは簡単な作業ではありません。このシナリオでは、 NetApp NFS ダイレクト アクセスが元の場所から財務データを分析します。もう 1 つの重要な利点は、 NetApp NFS ダイレクト アクセスを使用すると、ネイティブ Hadoop コマンドを使用して Hadoop データの保護が簡素化され、NetApp の豊富なデータ管理ポートフォリオを活用したデータ保護ワークフローが実現されることです。</block>
  <block id="1e72dcaa767fcc4be580ce5e9e1b52ea" category="paragraph"><block ref="1e72dcaa767fcc4be580ce5e9e1b52ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS ダイレクト アクセスは、Hadoop/Spark クラスターに対して 2 種類の導入オプションを提供します。</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">デフォルトでは、Hadoop/Spark クラスターは、データ ストレージとデフォルトのファイル システムとして Hadoop Distributed File System (HDFS) を使用します。  NetApp NFS ダイレクト アクセスでは、デフォルトの HDFS を NFS ストレージに置き換えてデフォルトのファイル システムとして使用できるため、NFS データに対する直接的な分析操作が可能になります。</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">別の導入オプションとして、 NetApp NFS ダイレクト アクセスでは、単一の Hadoop/Spark クラスター内の HDFS とともに NFS を追加ストレージとして構成することがサポートされています。この場合、顧客は NFS エクスポートを通じてデータを共有し、HDFS データと同じクラスターからデータにアクセスできます。</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS ダイレクト アクセスを使用する主な利点は次のとおりです。</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">現在の場所からデータを分析することで、分析データを HDFS などの Hadoop インフラストラクチャに移動する、時間とパフォーマンスを消費するタスクを回避します。</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">レプリカの数を 3 から 1 に減らします。</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">ユーザーはコンピューティングとストレージを切り離して、個別に拡張できます。</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAPの豊富なデータ管理機能を活用して、エンタープライズ データ保護を提供します。</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks データ プラットフォームの認定を受けています。</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">ハイブリッド データ分析の展開を可能にします。</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">動的マルチスレッド機能を活用してバックアップ時間を短縮します。</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">ビッグデータの構成要素</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetAppが提供するデータ ファブリックは、次の図に示すように、データ アクセス、制御、保護、セキュリティのためのデータ管理サービスとアプリケーション (ビルディング ブロック) を統合します。</block>
  <block id="daa25861e76d8b4617b478f8cd89c0b2" category="paragraph"><block ref="daa25861e76d8b4617b478f8cd89c0b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">上の図の構成要素は次のとおりです。</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS ダイレクト アクセス。*追加のソフトウェアやドライバーを必要とせずに、最新の Hadoop および Spark クラスターにNetApp NFS ボリュームへの直接アクセスを提供します。</block>
  <block id="f79865a14977797753199d8c238eade6" category="list-text">* NetApp Cloud Volumes ONTAPとGoogle Cloud NetApp Volumes 。*  Amazon Web Services (AWS) または Microsoft Azure クラウド サービスのAzure NetApp Files (ANF) で実行されるONTAPに基づくソフトウェア定義の接続ストレージ。</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">* NetApp SnapMirrorテクノロジー*。オンプレミスとONTAP Cloud または NPS インスタンス間のデータ保護機能を提供します。</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">*クラウド サービス プロバイダー*これらのプロバイダーには、AWS、Microsoft Azure、Google Cloud、IBM Cloud が含まれます。</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">*PaaS*  AWS の Amazon Elastic MapReduce (EMR) や Databricks、Microsoft Azure HDInsight や Azure Databricks などのクラウドベースの分析サービス。</block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp は、大規模なクラスター間およびクラスター内のコピーに使用されるネイティブ ツールです。  Hadoop DistCp の基本プロセスは、MapReduce などの Hadoop ネイティブ ツールを使用して Hadoop データを HDFS ソースから対応するターゲットにコピーする一般的なバックアップ ワークフローです。</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoopデータ保護とNetApp</block>
  <block id="1d766990d66db8e06b462398928288cd" category="paragraph">Hadoop DistCp は、大規模なクラスター間およびクラスター内のコピーに使用されるネイティブ ツールです。下の図に示す Hadoop DistCp の基本プロセスは、MapReduce などの Hadoop ネイティブ ツールを使用して Hadoop データを HDFS ソースから対応するターゲットにコピーする一般的なバックアップ ワークフローです。</block>
  <block id="7cded69de10ed23fb288e8f481913718" category="paragraph">NetApp NFS ダイレクト アクセスを使用すると、顧客は Hadoop DistCp ツールのターゲット デスティネーションとして NFS を設定し、MapReduce を介して HDFS ソースから NFS 共有にデータをコピーできます。  NetApp NFS ダイレクト アクセスは、DistCp ツールの NFS ドライバーとして機能します。</block>
  <block id="3225c81e14f83a90295391be9d81302a" category="paragraph"><block ref="3225c81e14f83a90295391be9d81302a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">このドキュメントでは、 NetApp AFFおよびFASストレージ システム、 NetApp Cloud Volumes ONTAP、 NetApp接続ストレージ、Spark および Hadoop 用のNetApp FlexCloneテクノロジーを使用したハイブリッド クラウド データ ソリューションについて説明します。これらのソリューション アーキテクチャにより、お客様は自社の環境に適したデータ保護ソリューションを選択できます。  NetApp は、顧客とのやり取りとビジネスユースケースに基づいてこれらのソリューションを設計しました。</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">NetApp 、Karthikeyan Nagalingam 氏と Sathish Thyagarajan 氏</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">このドキュメントでは、 NetApp AFFおよびFASストレージ システム、 NetApp Cloud Volumes ONTAP、 NetApp接続ストレージ、Spark および Hadoop 用のNetApp FlexCloneテクノロジーを使用したハイブリッド クラウド データ ソリューションについて説明します。これらのソリューション アーキテクチャにより、お客様は自社の環境に適したデータ保護ソリューションを選択できます。 NetApp は、顧客とのやり取りとビジネスユースケースに基づいてこれらのソリューションを設計しました。このドキュメントでは、次の詳細情報を提供します。</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark および Hadoop 環境でデータ保護が必要な理由と顧客の課題。</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">NetApp のビジョンとその構成要素およびサービスによって実現されるデータ ファブリック。</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">これらのビルディング ブロックを使用して、柔軟なデータ保護ワークフローを構築する方法を説明します。</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">実際の顧客の使用事例に基づいた、いくつかのアーキテクチャの長所と短所。各ユースケースでは、次のコンポーネントが提供されます。</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">顧客シナリオ</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="list-text">要件と課題</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">ソリューション</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">解決策の要約</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop データ保護の理由</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop および Spark 環境では、次の懸念事項に対処する必要があります。</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">*ソフトウェアまたは人為的な障害。* Hadoop データ操作の実行中にソフトウェアを更新する際に人為的なエラーが発生すると、ジョブから予期しない結果が生じる可能性のある障害が発生する可能性があります。このような場合、障害や不合理な結果を避けるためにデータを保護する必要があります。たとえば、交通信号分析アプリケーションのソフトウェア更新が適切に実行されなかった結果、新しい機能がプレーンテキスト形式の交通信号データを適切に分析できないことがあります。ソフトウェアは依然として JSON やその他のテキスト以外のファイル形式を分析するため、リアルタイムの交通制御分析システムはデータ ポイントが欠落した予測結果を生成します。この状況により出力に不具合が生じ、交通信号での事故につながる可能性があります。データ保護では、以前の動作中のアプリケーション バージョンに迅速にロールバックする機能を提供することで、この問題に対処できます。</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">*サイズとスケール。*データ ソースの数と量が増え続けているため、分析データのサイズは日々大きくなっています。ソーシャル メディア、モバイル アプリ、データ分析、クラウド コンピューティング プラットフォームは、急速に拡大している現在のビッグ データ市場における主なデータ ソースであるため、正確なデータ操作を保証するためにデータを保護する必要があります。</block>
  <block id="612be5fe1026c2566014b79f77403701" category="list-text">*Hadoop のネイティブ データ保護。* Hadoop にはデータを保護するためのネイティブ コマンドがありますが、このコマンドではバックアップ中にデータの一貫性が確保されません。ディレクトリ レベルのバックアップのみをサポートします。  Hadoop によって作成されたスナップショットは読み取り専用であり、バックアップ データを直接再利用することはできません。</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop および Spark の顧客にとってのデータ保護の課題</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop および Spark の顧客にとっての共通の課題は、データ保護中に本番クラスターのパフォーマンスに悪影響を与えることなく、バックアップ時間を短縮し、バックアップの信頼性を高めることです。</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">顧客は、最適なビジネス継続性を確保するために、復旧ポイント目標 (RPO) と復旧時間目標 (RTO) のダウンタイムを最小限に抑え、オンプレミスとクラウドベースの災害復旧サイトを制御する必要もあります。この制御は通常、エンタープライズ レベルの管理ツールによって実現されます。</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop および Spark 環境は、データ量が膨大かつ増加しているだけでなく、データの到着速度も増加しているため、複雑になっています。このシナリオでは、ソース データから効率的で最新の DevTest および QA 環境を迅速に作成することが困難になります。  NetApp はこれらの課題を認識しており、このホワイト ペーパーで紹介するソリューションを提供しています。</block>
  <block id="7d617748001976c06ae87f824ca77b2d" category="summary">このシナリオでは、大手金融サービスおよび投資銀行の分析プラットフォームがNetApp NFS ストレージ ソリューションを使用して最新化され、資産管理および定量ビジネス ユニットの投資リスクとデリバティブの分析が大幅に改善されました。</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">ユースケース5: 分析ワークロードの高速化</block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">シナリオ</block>
  <block id="f3274c43bc916b05ebe766167f47a1ad" category="paragraph">顧客の既存の環境では、分析プラットフォームに使用されている Hadoop インフラストラクチャは、Hadoop サーバーの内部ストレージを活用していました。 JBOD 環境の独自仕様のため、組織内の多くの内部顧客は、リアルタイム データの定期的なサンプルに依存するシミュレーションであるモンテ カルロ定量モデルを活用できませんでした。市場動向の不確実性の影響を理解する能力が最適ではなかったため、定量資産運用事業部門にとって不利な状況となっていました。</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">銀行の定量ビジネス部門は、正確でタイムリーな予測を達成するための効率的な予測方法を求めていました。これを実現するために、チームは、投資モデルを効率的にシミュレートし、潜在的な利益を測定し、リスクを分析するために、インフラストラクチャを最新化し、既存の I/O 待機時間を短縮し、Hadoop や Spark などの分析アプリケーションのパフォーマンスを向上させる必要があることを認識しました。</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">解決策</block>
  <block id="43b3ece7a28edcf11ee066112179b834" category="paragraph">顧客は既存の Spark ソリューションに JBOD を導入していました。その後、 NetApp ONTAP、 NetApp StorageGRID、および MinIO Gateway to NFS を活用して、潜在的な利益とリスクを評価する投資モデルのシミュレーションと分析を実行する銀行の定量財務グループの I/O 待機時間を短縮しました。この画像は、 NetAppストレージを使用した Spark ソリューションを示しています。</block>
  <block id="d9e962022f714fc5ed8bccce82c920ac" category="paragraph"><block ref="d9e962022f714fc5ed8bccce82c920ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">上の図に示すように、 AFF A800、A700 システム、およびStorageGRIDが導入され、データ分析操作用の Spark、YARN、および Hive メタデータ サービスを備えた 6 ノードの Hadoop クラスターで NFS および S3 プロトコルを介して parquet ファイルにアクセスしました。</block>
  <block id="473d88a5512cc81d2571425bbea591d2" category="paragraph">顧客の古い環境における直接接続ストレージ (DAS) ソリューションには、コンピューティングとストレージを個別に拡張できないという欠点がありました。同銀行の金融分析事業部門は、Spark 向けNetApp ONTAPソリューションを導入することで、ストレージをコンピューティングから切り離し、必要に応じてインフラストラクチャ リソースをより効率的にシームレスに提供できるようになりました。</block>
  <block id="fceb3129a02a41b3231baa9b6f633217" category="paragraph">ONTAP をNFS と併用することで、コンピューティング サーバーの CPU が Spark SQL ジョブにほぼ完全に利用され、I/O 待機時間が 70% 近く短縮され、Spark ワークロードのコンピューティング能力とパフォーマンスが向上しました。その後、CPU 使用率の向上により、顧客は GPUDirect などの GPU を活用してプラットフォームをさらに近代化することも可能になりました。さらに、 StorageGRID はSpark ワークロードに低コストのストレージ オプションを提供し、MinIO Gateway は S3 プロトコルを介して NFS データへの安全なアクセスを提供します。クラウド内のデータについては、 NetApp はCloud Volumes ONTAP、 Azure NetApp Files、 Google Cloud NetApp Volumes を推奨しています。</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">このユースケースは、クラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある放送業界の顧客に基づいています。</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">ユースケース 2: クラウドからオンプレミスへのバックアップと災害復旧</block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">このユースケースは、下の図に示すように、クラウドベースの分析データをオンプレミスのデータセンターにバックアップする必要がある放送業界の顧客に基づいています。</block>
  <block id="56f5fb8db5f5326b20e3fe17ce11efa4" category="paragraph"><block ref="56f5fb8db5f5326b20e3fe17ce11efa4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">このシナリオでは、IoT センサー データがクラウドに取り込まれ、AWS 内のオープン ソース Apache Spark クラスターを使用して分析されます。要件は、処理されたデータをクラウドからオンプレミスにバックアップすることです。</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">このユースケースの主な要件と課題は次のとおりです。</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">データ保護を有効にしても、クラウド内の本番環境の Spark/Hadoop クラスターのパフォーマンスには影響しません。</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">クラウド センサー データは、効率的かつ安全な方法でオンプレミスに移動され、保護される必要があります。</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">オンデマンド、瞬時、クラスター負荷が低い時間など、さまざまな条件下でクラウドからオンプレミスにデータを転送する柔軟性。</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">顧客は、Spark クラスターの HDFS ストレージに AWS Elastic Block Store (EBS) を使用して、Kafka を介してリモート センサーからデータを受信して取り込みます。したがって、HDFS ストレージはバックアップ データのソースとして機能します。</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">これらの要件を満たすために、 NetApp ONTAP Cloud が AWS に導入され、Spark/Hadoop クラスターのバックアップ ターゲットとして機能する NFS 共有が作成されます。</block>
  <block id="3c0f76e2d6fa82b2004270ec86f39aa7" category="paragraph">NFS 共有が作成されたら、HDFS EBS ストレージからONTAP NFS 共有にデータをコピーします。データがONTAP Cloud の NFS に保存された後、 SnapMirrorテクノロジーを使用して、必要に応じてクラウドのデータをオンプレミスのストレージに安全かつ効率的にミラーリングできます。</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">この画像は、クラウドからオンプレミス ソリューションへのバックアップと災害復旧を示しています。</block>
  <block id="6d742f93cf04e332b07c93ce2bc96163" category="paragraph"><block ref="6d742f93cf04e332b07c93ce2bc96163" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">このシナリオでは、顧客はオンプレミスの大規模な Hadoop リポジトリを所有しており、災害復旧のためにそれをバックアップしたいと考えています。しかし、顧客の現在のバックアップ ソリューションはコストが高く、バックアップ ウィンドウが 24 時間を超える長い時間を要するという問題がありました。</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">ユースケース1: Hadoopデータのバックアップ</block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">ソフトウェアの下位互換性:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">提案される代替バックアップ ソリューションは、実稼働 Hadoop クラスターで使用されている現在実行中のソフトウェア バージョンと互換性がある必要があります。</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">約束された SLA を満たすには、提案された代替ソリューションでは非常に低い RPO と RTO を実現する必要があります。</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetAppバックアップ ソリューションによって作成されたバックアップは、データセンターにローカルに構築された Hadoop クラスターだけでなく、リモート サイトの災害復旧場所で稼働している Hadoop クラスターでも使用できます。</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">提案されるソリューションはコスト効率がよいものでなければなりません。</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">提案されたソリューションは、バックアップ時間中に、現在実行中の本番環境の分析ジョブに対するパフォーマンスの影響を軽減する必要があります。</block>
  <block id="265e759e2a3b4c55776e0de53887b3b4" category="section-title">顧客の既存のバックアップソリューションx</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">下の図は、元の Hadoop ネイティブ バックアップ ソリューションを示しています。</block>
  <block id="f9efb12aa8582a65d79ac1fcd7574665" category="paragraph"><block ref="f9efb12aa8582a65d79ac1fcd7574665" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">実稼働データは中間バックアップ クラスターを通じてテープに対して保護されます。</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1のデータは、以下のコマンドを実行することでHDFS2にコピーされます。<block ref="56eafdf3e9748260b9403493314dc20d" prefix=" " category="inline-code"></block>指示。</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">バックアップクラスタはNFSゲートウェイとして機能し、データはLinux経由で手動でテープにコピーされます。<block ref="9c95319bf274672d6eae7eb97c3dfda5" prefix=" " category="inline-code"></block>テープライブラリを介してコマンドを実行します。</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">オリジナルの Hadoop ネイティブ バックアップ ソリューションの利点は次のとおりです。</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">このソリューションは Hadoop ネイティブ コマンドに基づいているため、ユーザーは新しい手順を学習する必要がありません。</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">このソリューションは、業界標準のアーキテクチャとハードウェアを活用します。</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">オリジナルの Hadoop ネイティブ バックアップ ソリューションの欠点は次のとおりです。</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">長いバックアップウィンドウの時間が 24 時間を超えると、運用データが脆弱になります。</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">バックアップ時間中にクラスターのパフォーマンスが大幅に低下します。</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">テープへのコピーは手動で行います。</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">バックアップ ソリューションは、必要なハードウェアと手動プロセスに必要な人的時間の点で高価です。</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">バックアップソリューション</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">これらの課題と要件に基づき、既存のバックアップ システムを考慮して、3 つのバックアップ ソリューションが提案されました。次のサブセクションでは、ソリューション A からソリューション C までの 3 つの異なるバックアップ ソリューションのそれぞれについて説明します。</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">解決策A</block>
  <block id="bc98837ed486c01d428d23d0c3a83d6a" category="paragraph">ソリューション A では、バックアップ Hadoop クラスターがセカンダリ バックアップをNetApp NFS ストレージ システムに送信するため、下の図に示すように、テープは不要になります。</block>
  <block id="c7446a7fd101a1f229e62b8dfc3f2627" category="paragraph"><block ref="c7446a7fd101a1f229e62b8dfc3f2627" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">ソリューション A の詳細なタスクは次のとおりです。</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">実稼働 Hadoop クラスターには、保護が必要な顧客の分析データが HDFS 内にあります。</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS を使用したバックアップ Hadoop クラスターは、データの中間場所として機能します。  JBOD (Just a Bunch of Disks) は、本番環境とバックアップ環境の両方の Hadoop クラスターで HDFS のストレージを提供します。</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Hadoopの本番データは、本番クラスタのHDFSからバックアップクラスタのHDFSまで、以下のコマンドを実行することで保護されます。<block ref="900bb9daf20a55f63530a23a8ff21d21" prefix=" " category="inline-code"></block>指示。</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop スナップショットは、本番環境からバックアップ Hadoop クラスターまでのデータを保護するために使用されます。</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAPストレージ コントローラは、バックアップ Hadoop クラスターにプロビジョニングされる NFS エクスポート ボリュームを提供します。</block>
  <block id="1b449b0ea4a324dc81f41259db2c13e9" category="list-text">実行することで<block ref="e23fdb1dae75e2830274d92fdf2535ed" prefix=" " category="inline-code"></block>MapReduce と複数のマッパーを活用したコマンドにより、分析データはバックアップ Hadoop クラスターから NFS に保護されます。</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">データがNetAppストレージ システム上の NFS に保存された後、必要に応じてNetApp Snapshot、 SnapRestore、 FlexCloneテクノロジを使用して Hadoop データのバックアップ、復元、複製が行われます。</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">SnapMirrorテクノロジーを使用すると、Hadoop データをクラウドや災害復旧場所まで保護できます。</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">ソリューション A の利点は次のとおりです。</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 実稼働データはバックアップ クラスターから保護されます。</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS データは NFS を通じて保護され、クラウドおよび災害復旧場所への保護が可能になります。</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">バックアップ操作をバックアップ クラスターにオフロードすることでパフォーマンスが向上します。</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">手動のテープ操作を排除</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">NetAppツールを通じてエンタープライズ管理機能を実現します。</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">既存の環境への変更は最小限で済みます。</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">コスト効率の高いソリューションです。</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">このソリューションの欠点は、パフォーマンスを向上させるためにバックアップ クラスターと追加のマッパーが必要になることです。</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">顧客は最近、シンプルさ、コスト、全体的なパフォーマンスを理由にソリューション A を導入しました。</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">このソリューションでは、JBOD の代わりにONTAPの SAN ディスクを使用できます。このオプションは、バックアップ クラスタ ストレージの負荷をONTAPにオフロードしますが、SAN ファブリック スイッチが必要になるという欠点があります。</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">解決策B</block>
  <block id="099eafc2208317136c2902383d7b0755" category="paragraph">ソリューション B は、本番 Hadoop クラスターに NFS ボリュームを追加し、下の図に示すように、バックアップ Hadoop クラスターの必要性を排除します。</block>
  <block id="5b70fb212e3f22443316e06668fb7eaf" category="paragraph"><block ref="5b70fb212e3f22443316e06668fb7eaf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">ソリューション B の詳細なタスクは次のとおりです。</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAPストレージ コントローラは、本番 Hadoop クラスターに NFS エクスポートをプロビジョニングします。</block>
  <block id="b8c0e409f361575b0a2787968f3e6737" category="paragraph">Hadoopネイティブ<block ref="4ac6e29f0a48949098d034a028773150" prefix=" " category="inline-code"></block>コマンドは、本番クラスターの HDFS から NFS への Hadoop データを保護します。</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">データがNetAppストレージ システム上の NFS に保存された後、必要に応じて Snapshot、 SnapRestore、 FlexCloneテクノロジを使用して Hadoop データのバックアップ、復元、複製が行われます。</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">ソリューション B の利点は次のとおりです。</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">運用クラスターはバックアップ ソリューション用にわずかに変更されており、実装が簡素化され、追加のインフラストラクチャ コストが削減されます。</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">バックアップ操作用のバックアップ クラスターは必要ありません。</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 実稼働データは、NFS データへの変換中に保護されます。</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">このソリューションは、 NetAppツールを通じてエンタープライズ管理機能を実現します。</block>
  <block id="f4ffcfc00594c5a445a43499130eb8d3" category="paragraph">このソリューションの欠点は、本番クラスターに実装されるため、本番クラスターに追加の管理者タスクが追加される可能性があることです。</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">解決策C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">ソリューション C では、下の図に示すように、 NetApp SAN ボリュームが HDFS ストレージの Hadoop 本番クラスターに直接プロビジョニングされます。</block>
  <block id="016077aafc394500fb21c4f233724258" category="paragraph"><block ref="016077aafc394500fb21c4f233724258" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">ソリューション C の詳細な手順は次のとおりです。</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN ストレージは、HDFS データ ストレージ用に本番 Hadoop クラスターにプロビジョニングされます。</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot およびSnapMirrorテクノロジーは、実稼働 Hadoop クラスターから HDFS データをバックアップするために使用されます。</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">バックアップはストレージ レイヤーで行われるため、スナップショット コピーのバックアップ プロセス中に Hadoop/Spark クラスターの運用パフォーマンスに影響はありません。</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">スナップショット テクノロジーは、データのサイズに関係なく、数秒で完了するバックアップを提供します。</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">ソリューション C の利点は次のとおりです。</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">スナップショット テクノロジーを使用することで、スペース効率の高いバックアップを作成できます。</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">このユースケースでは、顧客の要件は、同じデータセンターとリモート ロケーションで、DevTest とレポート作成の目的で大量の分析データを含む既存の Hadoop クラスターに基づいて、新しい Hadoop/Spark クラスターを迅速かつ効率的に構築することです。</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">ユースケース3: 既存のHadoopデータでDevTestを有効にする</block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">このシナリオでは、オンプレミスおよび災害復旧場所の大規模な Hadoop データ レイク実装から複数の Spark/Hadoop クラスターが構築されます。</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest、QA、または同じ本番データへのアクセスが必要なその他の目的のために、複数の Hadoop クラスターを作成します。ここでの課題は、非常に大規模な Hadoop クラスターを、瞬時に、かつ非常にスペース効率の高い方法で複数回複製することです。</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">運用効率を高めるために、Hadoop データを DevTest およびレポート チームと同期します。</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">同じ資格情報を使用して、本番環境と新しいクラスター全体で Hadoop データを分散します。</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">スケジュールされたポリシーを使用して、本番クラスターに影響を与えずに QA クラスターを効率的に作成します。</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexCloneテクノロジーは、前述の要件に応えるために使用されます。 FlexCloneテクノロジーは、スナップショット コピーの読み取り/書き込みコピーです。親スナップショット コピー データからデータを読み取り、新しいブロックまたは変更されたブロックに対してのみ追加のスペースを消費します。高速かつスペース効率に優れています。</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">まず、 NetApp整合性グループを使用して、既存のクラスターのスナップショット コピーを作成しました。</block>
  <block id="ff0e15997f709c232408a5055738df05" category="paragraph">NetApp System Manager またはストレージ管理プロンプト内のスナップショット コピー。整合性グループのスナップショット コピーは、アプリケーション整合性グループのスナップショット コピーであり、 FlexCloneボリュームは整合性グループのスナップショット コピーに基づいて作成されます。 FlexCloneボリュームは親ボリュームの NFS エクスポート ポリシーを継承することに注意してください。スナップショット コピーが作成された後、次の図に示すように、DevTest とレポート作成の目的で新しい Hadoop クラスターをインストールする必要があります。新しい Hadoop クラスターからクローンされた NFS ボリュームは NFS データにアクセスします。</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">この画像は、DevTest の Hadoop クラスターを示しています。</block>
  <block id="abc9a1c20fcf276389f79d3093665e5c" category="paragraph"><block ref="abc9a1c20fcf276389f79d3093665e5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">このユースケースは、顧客のビッグ データ分析データにマルチクラウド接続を提供する役割を担うクラウド サービス パートナーに関係します。</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">ユースケース4: データ保護とマルチクラウド接続</block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">このシナリオでは、さまざまなソースから AWS に受信された IoT データが NPS の中央の場所に保存されます。  NPS ストレージは、AWS および Azure にある Spark/Hadoop クラスターに接続され、複数のクラウドで実行されるビッグ データ分析アプリケーションが同じデータにアクセスできるようになります。</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">顧客は複数のクラウドを使用して同じデータに対して分析ジョブを実行したいと考えています。</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">データは、さまざまなセンサーやハブを介して、オンプレミスやクラウドなどのさまざまなソースから受信する必要があります。</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">ソリューションは効率的かつ費用対効果の高いものでなければなりません。</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">主な課題は、オンプレミスとさまざまなクラウド間でハイブリッド分析サービスを提供する、コスト効率が高く効率的なソリューションを構築することです。</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">この画像は、データ保護とマルチクラウド接続ソリューションを示しています。</block>
  <block id="5308dad4844e43fdad02844ec50752c0" category="paragraph"><block ref="5308dad4844e43fdad02844ec50752c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ea48e5206de42785842cb864377766c" category="paragraph">上の図に示すように、センサーからのデータは Kafka を介してストリーミングされ、AWS Spark クラスターに取り込まれます。データは、Equinix データセンター内のクラウド プロバイダーの外部にある NPS にある NFS 共有に保存されます。 NetApp NPS は、それぞれ Direct Connect 接続と Express Route 接続を介して Amazon AWS と Microsoft Azure に接続されているため、顧客は Amazon と AWS の両方の分析クラスターから NFS データにアクセスできます。このアプローチは、複数のハイパースケーラーにわたるクラウド分析の問題を解決します。</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">その結果、オンプレミスと NPS ストレージの両方でONTAPソフトウェアが実行されるため、 SnapMirror はNPS データをオンプレミス クラスターにミラーリングし、オンプレミスと複数のクラウドにわたるハイブリッド クラウド分析を提供できます。</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">最高のパフォーマンスを得るために、 NetAppでは通常、複数のネットワーク インターフェイスと直接接続/高速ルートを使用してクラウド インスタンスからデータにアクセスすることをお勧めします。</block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">このセクションでは、このホワイト ペーパーの焦点となるデータ保護のユース ケースの概要を説明します。残りのセクションでは、顧客の問題 (シナリオ)、要件と課題、解決策など、各ユースケースの詳細について説明します。</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop データ保護のユースケースの概要</block>
  <block id="6f2c5dcd0294b9c34430b1de4713c06d" category="paragraph">このユースケースでは、 NetApp NFS ボリュームにより、大手金融機関は長いバックアップ ウィンドウ時間を 24 時間以上から数時間未満に短縮することができました。</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">大手放送会社は、 NetAppを搭載したデータ ファブリックを構成要素として使用することで、オンデマンド、瞬時、Hadoop/Spark クラスターの負荷に基づくなど、さまざまなデータ転送モードに応じてクラウド データをオンプレミスのデータ センターにバックアップするという要件を満たすことができました。</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetAppソリューションは、オンライン音楽配信会社がさまざまなブランチに複数のスペース効率の高い Hadoop クラスターを迅速に構築し、レポートを作成し、スケジュールされたポリシーを使用して毎日の DevTest タスクを実行するのに役立ちました。</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">大手サービス プロバイダーは、 NetAppが提供するデータ ファブリックを使用して、さまざまなクラウド インスタンスから顧客にマルチクラウド分析を提供しました。</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">最大規模の金融サービスおよび投資銀行の 1 社は、 NetAppネットワーク接続ストレージ ソリューションを使用して、I/O 待機時間を短縮し、定量的金融分析プラットフォームを高速化しました。</block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">このセクションでは、この認定から得られた教訓を紹介します。</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">ベストプラクティスガイドライン</block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">当社の検証によると、Confluent がデータを保存するには S3 オブジェクト ストレージが最適です。</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">Confluent 階層型ストレージ構成では、ブローカー データ ディレクトリに保持されるデータのサイズは、データがオブジェクト ストレージに移動されるときのセグメント サイズと保持期間に基づいているため、高スループット SAN (具体的には FC) を使用してブローカーのホット データまたはローカル ディスクを保持できます。</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">オブジェクト ストアでは、segment.bytes が大きいほどパフォーマンスが向上します。512 MB でテストしました。</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafkaでは、トピックに生成される各レコードのキーまたは値の長さ（バイト単位）は、<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block>パラメータ。 StorageGRIDの場合、S3 オブジェクトの取り込みおよび取得のパフォーマンスがより高い値に向上しました。たとえば、512 バイトでは 5.8 GBps の取得、1024 バイトでは 7.5 GBps の s3 取得、2048 バイトでは 10 GBps に近い取得が実現しました。</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">次の図は、S3オブジェクトの取り込みと取得を次の表に基づいて示しています。<block ref="89a621c030df783ee8eee89dd8f42cb9" prefix=" " category="inline-code"></block> 。</block>
  <block id="88108446d5ab5e54118010ab8c716e93" category="paragraph"><block ref="88108446d5ab5e54118010ab8c716e93" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">*Kafka のチューニング。*階層化ストレージのパフォーマンスを向上させるには、TierFetcherNumThreads と TierArchiverNumThreads を増やすことができます。一般的なガイドラインとして、TierFetcherNumThreads を物理 CPU コアの数に合わせて増やし、TierArchiverNumThreads を CPU コアの数の半分まで増やします。たとえば、サーバーのプロパティで、8 つの物理コアを持つマシンがある場合は、confluent.tier.fetcher.num.threads = 8 および confluent.tier.archiver.num.threads = 4 に設定します。</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">*トピック削除の時間間隔。*トピックが削除されても、オブジェクト ストレージ内のログ セグメント ファイルの削除はすぐには開始されません。むしろ、それらのファイルが削除されるまでの期間が、デフォルト値の 3 時間に設定されています。この間隔の値を変更するには、構成 confluent.tier.topic.delete.check.interval.ms を変更します。トピックまたはクラスターを削除する場合は、それぞれのバケット内のオブジェクトを手動で削除することもできます。</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">*階層化ストレージの内部トピックに関する ACL。*オンプレミス展開で推奨されるベスト プラクティスは、階層化ストレージに使用される内部トピックで ACL 承認者を有効にすることです。 ACL ルールを設定して、このデータへのアクセスをブローカー ユーザーのみに制限します。これにより、内部トピックが保護され、階層化ストレージ データとメタデータへの不正アクセスが防止されます。</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">ユーザーを置き換える<block ref="a802c5bf62b7c5970725474468cf46f4" prefix=" " category="inline-code"></block>デプロイメント内の実際のブローカー プリンシパルを使用します。</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">例えば、コマンド<block ref="bccf46e0861de44696513d6cbea91e4c" prefix=" " category="inline-code"></block>階層化ストレージの内部トピックに ACL を設定します。現在、階層化ストレージに関連する内部トピックは 1 つだけです。この例では、内部トピックのすべての操作に対してプリンシパル Kafka 権限を提供する ACL を作成します。</block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">NetApp StorageGRIDの階層化ストレージ向けに、Kafka を使用した Confluent Platform の認定を実施しました。</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">合流検証</block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRIDの Confluent Platform 6.2 Tiered Storage を使用して検証を実施しました。  NetAppチームと Confluent チームが協力してこの検証に取り組み、検証に必要なテスト ケースを実行しました。</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent Platform のセットアップ</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">検証には次の設定を使用しました。</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">検証には、3 つの動物園管理人、5 つのブローカー、5 つのテスト スクリプト実行サーバー、256 GB の RAM と 16 個の CPU を備えた名前付きツール サーバーを使用しました。 NetAppストレージには、4 つの SGF6024 を搭載した SG1000 ロード バランサーを備えたStorageGRIDを使用しました。ストレージとブローカーは 100GbE 接続を介して接続されました。</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">次の図は、Confluent 検証に使用される構成のネットワーク トポロジを示しています。</block>
  <block id="275745d9c13bf80b7275e6f8633d15e4" category="paragraph"><block ref="275745d9c13bf80b7275e6f8633d15e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">ツール サーバーは、Confluent ノードに要求を送信するアプリケーション クライアントとして機能します。</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent階層型ストレージ構成</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">階層化ストレージ構成には、Kafka で次のパラメータが必要です。</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">検証には、HTTP プロトコルを使用したStorageGRIDを使用しましたが、HTTPS も機能します。アクセスキーと秘密鍵は、<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>パラメータ。</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetAppオブジェクトストレージ - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">検証のために、 StorageGRIDで単一サイト構成を構成しました。</block>
  <block id="dddbd2d03db81f9c6cb7d2dc1329df76" category="paragraph"><block ref="dddbd2d03db81f9c6cb7d2dc1329df76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">検証テスト</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">検証のために以下の 5 つのテストケースを完了しました。これらのテストは Trogdor フレームワークで実行されます。最初の 2 つは機能テストであり、残りの 3 つはパフォーマンス テストでした。</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">オブジェクトストアの正確性テスト</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">このテストでは、オブジェクト ストア API のすべての基本操作 (get/put/delete など) が階層化ストレージのニーズに応じて適切に機能するかどうかを判定します。これは、すべてのオブジェクト ストア サービスが次のテストに先立って合格することが期待される基本テストです。合格か不合格かを判断する断定的なテストです。</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">階層化機能の正確性テスト</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">このテストでは、合格または不合格のいずれかになるアサーション テストを使用して、エンドツーエンドの階層型ストレージ機能が適切に動作するかどうかを判断します。このテストでは、デフォルトで階層化が有効にされ、ホットセット サイズが大幅に削減されたテスト トピックが作成されます。新しく作成されたテスト トピックにイベント ストリームを生成し、ブローカーがセグメントをオブジェクト ストアにアーカイブするのを待機し、イベント ストリームを消費して、消費されたストリームが生成されたストリームと一致することを検証します。イベント ストリームに生成されるメッセージの数は構成可能であり、ユーザーはテストのニーズに応じて十分な大きさのワークロードを生成できます。ホットセットのサイズが縮小されたことで、アクティブ セグメント外のコンシューマー フェッチがオブジェクト ストアからのみ提供されるようになり、読み取りに対するオブジェクト ストアの正確性をテストするのに役立ちます。このテストは、オブジェクト ストア障害注入ありとなしの状態で実行しました。  StorageGRIDのノードの 1 つでサービス マネージャー サービスを停止し、エンドツーエンドの機能がオブジェクト ストレージで動作することを検証することで、ノード障害をシミュレートしました。</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">階層フェッチベンチマーク</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">このテストでは、階層化オブジェクト ストレージの読み取りパフォーマンスを検証し、ベンチマークによって生成されたセグメントからの高負荷状態での範囲フェッチ読み取り要求をチェックしました。このベンチマークでは、Confluent は階層フェッチ要求に対応するカスタム クライアントを開発しました。</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">生産・消費ワークロードベンチマーク</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">このテストでは、セグメントのアーカイブを通じてオブジェクト ストアへの書き込みワークロードを間接的に生成しました。読み取りワークロード (読み取られたセグメント) は、コンシューマー グループがセグメントを取得したときにオブジェクト ストレージから生成されました。このワークロードはテスト スクリプトによって生成されました。このテストでは、並列スレッドでのオブジェクト ストレージの読み取りと書き込みのパフォーマンスをチェックしました。階層化機能の正確性テストと同様に、オブジェクト ストア障害注入の有無でテストを行いました。</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">保持ワークロードベンチマーク</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">このテストでは、トピック保持の負荷が高い状態でのオブジェクト ストアの削除パフォーマンスをチェックしました。保持ワークロードは、テスト トピックに並行して多数のメッセージを生成するテスト スクリプトを使用して生成されました。テスト トピックでは、サイズ ベースおよび時間ベースの積極的な保持設定が構成されていたため、イベント ストリームがオブジェクト ストアから継続的に消去されていました。その後、セグメントはアーカイブされました。これにより、ブローカーによるオブジェクト ストレージ内の大量の削除と、オブジェクト ストア削除操作のパフォーマンスの収集が行われました。</block>
  <block id="996099c5b9fa96634feb727528db335e" category="list-text">Apache Kafka とは何ですか?</block>
  <block id="64512a184434b7e7734cf3c0a7283f2a" category="list-text">silly rename とは何ですか?</block>
  <block id="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link"><block ref="c4fe8f5f0b73bc80c0f8289fac9a6123" category="inline-link-rx"></block></block>
  <block id="0bf644a00aca415462aeb30f96e502cf" category="paragraph"><block ref="0bf644a00aca415462aeb30f96e502cf" category="inline-link-rx"></block></block>
  <block id="4a15e598cdac14bbb90bb0e4020f4a79" category="list-text">ONATP はストリーミング アプリケーション用に読み取られます。</block>
  <block id="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link"><block ref="90bd054ee4c47533d08a6c79bd89dc5a" category="inline-link-rx"></block></block>
  <block id="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="paragraph"><block ref="05c0a7e8a1aa7fd9f25faae2cfd814e9" category="inline-link-rx"></block></block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp製品ドキュメント</block>
  <block id="e861ab8ac55c9110672ee8b4ba3c5990" category="list-text">NFS とは何ですか?</block>
  <block id="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link"><block ref="bbdb25bd27a345174d3b4ea622b9ec26" category="inline-link-rx"></block></block>
  <block id="6b6d6a7e1bfbb25506c4af7f443a7b25" category="paragraph"><block ref="6b6d6a7e1bfbb25506c4af7f443a7b25" category="inline-link-rx"></block></block>
  <block id="9fee8c35c177577e85d941aa2c9dedc4" category="list-text">Kafka パーティションの再割り当てとは何ですか?</block>
  <block id="2363cdcf0f5fc9a387ed87b925979747" category="inline-link"><block ref="2363cdcf0f5fc9a387ed87b925979747" category="inline-link-rx"></block></block>
  <block id="12b4d09f121a118c1b63eba5f3523fa2" category="paragraph"><block ref="12b4d09f121a118c1b63eba5f3523fa2" category="inline-link-rx"></block></block>
  <block id="f06a814ac7d838a2d019219102377120" category="list-text">OpenMessaging ベンチマークとは何ですか?</block>
  <block id="9466397f90b4d13297982537f7f1f157" category="inline-link"><block ref="9466397f90b4d13297982537f7f1f157" category="inline-link-rx"></block></block>
  <block id="f42769fbe9abef93dd4da40d8f886c4a" category="paragraph"><block ref="f42769fbe9abef93dd4da40d8f886c4a" category="inline-link-rx"></block></block>
  <block id="bcc483eab76f7252a6d3060ae223f024" category="list-text">Kafka ブローカーを移行するにはどうすればよいですか?</block>
  <block id="7702dea2646d94249d97c22a4dcb6f96" category="inline-link"><block ref="7702dea2646d94249d97c22a4dcb6f96" category="inline-link-rx"></block></block>
  <block id="ebdd7bc6eaa2157f5f400c61c1826417" category="paragraph"><block ref="ebdd7bc6eaa2157f5f400c61c1826417" category="inline-link-rx"></block></block>
  <block id="3f7e227a8b3d0fc0cdcbf84e2bc565ac" category="list-text">Prometheus で Kafka ブローカーを監視するにはどうすればよいですか?</block>
  <block id="2d2cb8fe8b8d32b7fb984622e41036f1" category="paragraph"><block ref="2d2cb8fe8b8d32b7fb984622e41036f1" category="inline-link-rx"></block></block>
  <block id="c8219112931de58f84e7a14a0d24d1ce" category="list-text">Apache Kafka 向けマネージド プラットフォーム</block>
  <block id="a96e98488edf9123c2fb5281e71c6ec2" category="paragraph"><block ref="a96e98488edf9123c2fb5281e71c6ec2" category="inline-link-rx"></block></block>
  <block id="0cb1f340d12ba20e283d00e1e0823526" category="list-text">Apache Kafka のサポート</block>
  <block id="14bb5ca8b6287991417f8f43b4d9eb0c" category="paragraph"><block ref="14bb5ca8b6287991417f8f43b4d9eb0c" category="inline-link-rx"></block></block>
  <block id="9d5591555b2fbddd314212720dc97729" category="list-text">Apache Kafka のコンサルティングサービス</block>
  <block id="583ea5ea8c7ad81fed86a1925483124c" category="paragraph"><block ref="583ea5ea8c7ad81fed86a1925483124c" category="inline-link-rx"></block></block>
  <block id="bf06620c2cdf1b79a1673e62b409eae0" category="summary">厄介な名前変更問題に対するNetAppソリューションは、これまで NFS と互換性がなかったワークロードに対して、シンプルで安価な集中管理型のストレージ形式を提供します。</block>
  <block id="5fe141c77d102adcaccfa6da33564741" category="paragraph">この新しいパラダイムにより、顧客は災害復旧やデータ保護の目的で移行やミラーリングが容易な、管理しやすい Kafka クラスターを作成できるようになります。また、NFS には、CPU 使用率の低減、リカバリ時間の短縮、ストレージ効率の大幅な向上、 NetApp ONTAPによるパフォーマンスの向上など、さらなるメリットがあることもわかりました。</block>
  <block id="34ea6423c17a78bdf284132538078bac" category="summary">このドキュメントでは、silly-rename の問題と解決の検証、CPU 使用率の削減による I/O 待機時間の短縮、Kafka ブローカーの回復時間の高速化、クラウドとオンプレミスでのパフォーマンスについて説明します。</block>
  <block id="47e33b895b285760d0d1bcb64e42e5d0" category="doc">TR-4947: NetApp NFSストレージを使用したApache Kafkaワークロード - 機能検証とパフォーマンス</block>
  <block id="62233ad21bd81bbbff938616c0106477" category="paragraph">Shantanu Chakole、Karthikeyan Nagalingam、Joe Scott、 NetApp</block>
  <block id="8150fcf9bdcb89b4901e10f34571667e" category="paragraph">Kafka は、大量のメッセージ データを受け入れることができる堅牢なキューを備えた分散型のパブリッシュ/サブスクライブ メッセージング システムです。  Kafka を使用すると、アプリケーションはトピックに非常に高速にデータを書き込んだり読み取ったりできます。 Kafka は、そのフォールト トレランスとスケーラビリティにより、多数のデータ ストリームを非常に高速に取り込んで移動する信頼性の高い方法として、ビッグ データ分野でよく使用されます。ユースケースには、ストリーム処理、Web サイト アクティビティの追跡、メトリックの収集と監視、ログの集約、リアルタイム分析などがあります。</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">ここをクリックしてください。</block>
  <block id="e1304dc2c6d37619b73112fae0bd8411" category="paragraph">NFS 上の通常の Kafka 操作は正常に動作しますが、NFS 上で実行されている Kafka クラスターのサイズ変更または再パーティション化中に、名前変更の問題によりアプリケーションがクラッシュします。負荷分散やメンテナンスの目的で Kafka クラスターのサイズを変更したり、再パーティション化したりする必要があるため、これは重大な問題です。詳細は以下をご覧ください<block ref="eff8c14b44ddf611b2ff09607d7665a2" category="inline-link-rx"></block>。</block>
  <block id="229b214236b3c346dc9f6c75d096604b" category="paragraph">このドキュメントでは、次の内容について説明します。</block>
  <block id="995fd45f2f5174bc9a5d8029655c1b88" category="list-text">馬鹿げた名前変更問題と解決策の検証</block>
  <block id="7c9e8a4fdb767e60565e9c4b4d95eed2" category="list-text">CPU使用率を減らしてI/O待機時間を短縮する</block>
  <block id="915a1ce7d578786f5aa93e503452d2b9" category="list-text">Kafkaブローカーの回復時間の短縮</block>
  <block id="5810e3ce10e4e8edfee5f25cae3459c1" category="list-text">クラウドとオンプレミスでのパフォーマンス</block>
  <block id="7910f734d679965fb4e725f87dcb3c61" category="section-title">Kafka ワークロードに NFS ストレージを使用する理由は何ですか?</block>
  <block id="932e5edaa1f66c6b109d045d3c7ba0bc" category="paragraph">実稼働アプリケーションの Kafka ワークロードは、アプリケーション間で膨大な量のデータをストリーミングできます。このデータは、Kafka クラスター内の Kafka ブローカー ノードに保持され、保存されます。 Kafka は可用性と並列性でも知られており、トピックをパーティションに分割し、それらのパーティションをクラスター全体に複製することでこれを実現します。これは、最終的に、Kafka クラスターを流れる膨大な量のデータのサイズが通常倍増することを意味します。 NFS を使用すると、ブローカーの数の変化に応じてデータの再バランスが非常に迅速かつ簡単に行えます。大規模な環境では、ブローカーの数が変更されたときに DAS 間でデータを再調整するのは非常に時間がかかり、ほとんどの Kafka 環境ではブローカーの数は頻繁に変更されます。</block>
  <block id="a49afd0b2827b8f1d1b83a36f75d3efc" category="paragraph">その他の利点は次のとおりです。</block>
  <block id="889d2761ec65245a621931da633b8cfe" category="list-text">*成熟。*  NFS は成熟したプロトコルであり、その実装、セキュリティ保護、および使用のほとんどの側面が十分に理解されていることを意味します。</block>
  <block id="c231daeb716325a2bca62a5e30431c8d" category="list-text">*開ける。*  NFS はオープン プロトコルであり、その継続的な開発は、無料かつオープンなネットワーク プロトコルとしてインターネット仕様に文書化されています。</block>
  <block id="6526aeb62806bf842c7ab66949c2de0c" category="list-text">*コスト効率が良い。*  NFS は、既存のネットワーク インフラストラクチャを使用するためセットアップが簡単な、低コストのネットワーク ファイル共有ソリューションです。</block>
  <block id="8c70ad2ab84f33f7d462109fc8edc329" category="list-text">*集中管理*  NFS を集中管理することで、個々のユーザー システムに追加のソフトウェアやディスク領域が必要になることが減ります。</block>
  <block id="dbb4f7d4eb0147816ffd5d84e4a79e19" category="list-text">*配布済み*  NFS は分散ファイル システムとして使用できるため、リムーバブル メディア ストレージ デバイスの必要性が軽減されます。</block>
  <block id="37377984e38462f1628867b8e7a1e772" category="section-title">Kafka ワークロードにNetApp を選ぶ理由</block>
  <block id="300fdb82e8f9a8b6ebb6d42a92483544" category="paragraph">NetApp NFS 実装はプロトコルのゴールド スタンダードとみなされており、数え切れないほどのエンタープライズ NAS 環境で使用されています。NetAppの信頼性に加えて、次のような利点もあります。</block>
  <block id="f7e7d6aebe6163c0f639238b2e1a0333" category="list-text">信頼性と効率性</block>
  <block id="735980c2ea138788423c50ba2ef7c6c5" category="list-text">スケーラビリティとパフォーマンス</block>
  <block id="a8fbd78750bfdd72ecb8371fa5fa9648" category="list-text">高可用性（ NetApp ONTAPクラスタの HA パートナー）</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="list-text">データ保護</block>
  <block id="e005f1a13de2a01927e39ecb29ff1a7c" category="list-text">*災害復旧 (NetApp SnapMirror)*サイトがダウンした場合、または別のサイトで再開して中断したところから続行する必要がある場合。</block>
  <block id="81757222cee28779fe25327e8ef3f5a2" category="list-text">ストレージ システムの管理性 ( NetApp OnCommandを使用した管理)。</block>
  <block id="7d411cbcfa7cf122ac8423795b89a4b8" category="list-text">*負荷分散*クラスターを使用すると、異なるノードでホストされているデータ LIF から異なるボリュームにアクセスできます。</block>
  <block id="6c38013b179499c32ccf05a98b927de6" category="list-text">*中断のない運用。*  LIF またはボリュームの移動は NFS クライアントに対して透過的です。</block>
  <block id="d4baa2e552beefa00e93883ed51f3ba2" category="summary">オンプレミスでは、 ONTAP 9.12.1RC1 を搭載したNetApp AFF A900ストレージ コントローラを使用して、Kafka クラスターのパフォーマンスとスケーリングを検証しました。以前のONTAPおよびAFFを使用した階層型ストレージのベスト プラクティスと同じテストベッドを使用しました。</block>
  <block id="1e753c720a0b773dd9d69024ca734577" category="doc">AFF A900オンプレミスのパフォーマンス概要と検証</block>
  <block id="94391d4f56386aadb6f39e1a596f2427" category="paragraph">オンプレミスでは、 ONTAP 9.12.1RC1 を搭載したNetApp AFF A900ストレージ コントローラを使用して、Kafka クラスターのパフォーマンスとスケーリングを検証しました。以前のONTAPおよびAFFを使用した階層型ストレージのベスト プラクティスと同じテストベッドを使用しました。</block>
  <block id="b1e7584c9874b52caeb25c3646e8f273" category="paragraph">AFF A900 を評価するために、Confluent Kafka 6.2.0 を使用しました。クラスターには 8 つのブローカー ノードと 3 つの Zookeeper ノードが含まれます。パフォーマンス テストには、5 つの OMB ワーカー ノードを使用しました。</block>
  <block id="7d23a6a699d760fc27aa7ce39406c010" category="paragraph"><block ref="7d23a6a699d760fc27aa7ce39406c010" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">ストレージ構成</block>
  <block id="637d24b49cc32320a5e44ea905f65d10" category="paragraph">NetApp FlexGroups インスタンスを使用して、ログ ディレクトリに単一の名前空間を提供し、リカバリと構成を簡素化しました。ログ セグメント データへの直接パス アクセスを提供するために、NFSv4.1 と pNFS を使用しました。</block>
  <block id="50ff5e789ae0742f2485b5147c072643" category="section-title">クライアントのチューニング</block>
  <block id="fc3a7751877b7f4e9a71c82ad3da7e44" category="paragraph">各クライアントは、次のコマンドを使用してFlexGroupインスタンスをマウントしました。</block>
  <block id="a5b2794b174e20f0b6dd9350cba3df82" category="paragraph">さらに、<block ref="44d907b0e69e5aa31320f9e86a7ef440" prefix=" " category="inline-code"></block>デフォルトから<block ref="ea5d2f1c4608232e07d3aa3d998e5135" prefix=" " category="inline-code"></block>に<block ref="045117b0e0a11a242b9765e79cbf113f" prefix=" " category="inline-code"></block>。これは、 ONTAPのデフォルトのセッション スロット制限と一致します。</block>
  <block id="31305973da10c7b492918a2ad2b3deee" category="section-title">Kafkaブローカーのチューニング</block>
  <block id="4ed38f0369b8bb562a96594ca860ab81" category="paragraph">テスト対象システムのスループットを最大化するために、特定の主要なスレッド プールのデフォルト パラメータを大幅に増加しました。ほとんどの構成では、Confluent Kafka のベスト プラクティスに従うことをお勧めします。このチューニングは、ストレージへの未処理の I/O の同時実行性を最大化するために使用されました。これらのパラメータは、ブローカーのコンピューティング リソースとストレージ属性に合わせて調整できます。</block>
  <block id="0e80721091b1e58209e2877462ebbd21" category="section-title">ワークロードジェネレータのテスト方法論</block>
  <block id="9707ee58e22a2478985c56025e656cad" category="paragraph">スループット ドライバーとトピック構成には、クラウド テストと同じ OMB 構成を使用しました。</block>
  <block id="dbdfae7d08a693255815e0890397b78f" category="list-text">FlexGroupインスタンスは、 AFFクラスター上で Ansible を使用してプロビジョニングされました。</block>
  <block id="6c2577e00543c33096c33e1b2e79742d" category="list-text">ONTAP SVM で pNFS が有効になりました。</block>
  <block id="62313ead30e5ae09df5e2329bfe44784" category="list-text">ワークロードは、Cloud Volumes ONTAPと同じワークロード構成を使用して、スループット ドライバーによってトリガーされました。 「<block ref="f628eac6c1ff8c1b0462e81ea7b2efc1" category="inline-xref-macro-rx"></block> " 下に。ワークロードではレプリケーション係数 3 が使用され、ログ セグメントの 3 つのコピーが NFS に保持されました。</block>
  <block id="823002616491cde5a10847131e46b9a6" category="list-text">最後に、バックログを使用して、消費者が最新のメッセージに追いつく能力を測定するための測定を完了しました。 OMB は、測定の開始時にコンシューマーを一時停止することでバックログを構築します。これにより、バックログの作成 (プロデューサーのみのトラフィック)、バックログの排出 (トピック内の見逃されたイベントをコンシューマーが追いつくコンシューマー中心のフェーズ)、および定常状態の 3 つの異なるフェーズが生成されます。「<block ref="67d9096f7dc6dfc3943f178b4a30cff8" category="inline-xref-macro-rx"></block>詳細については、「」を参照してください。</block>
  <block id="158bb82f009332b2fe16aba7bebc0c15" category="section-title">定常状態のパフォーマンス</block>
  <block id="216824b7a5a0da585075bc35333402f6" category="paragraph">AWS のCloud Volumes ONTAPと AWS の DAS と同様の比較を行うために、OpenMessaging ベンチマークを使用してAFF A900 を評価しました。すべてのパフォーマンス値は、プロデューサー レベルとコンシューマー レベルでの Kafka クラスターのスループットを表します。</block>
  <block id="34121e3b81b5330bbb499603af5609e6" category="paragraph">Confluent Kafka とAFF A900 を使用した定常状態のパフォーマンスでは、プロデューサーとコンシューマーの両方で 3.4 GBps を超える平均スループットが達成されました。これは、Kafka クラスター全体で 340 万件を超えるメッセージです。  BrokerTopicMetrics の持続スループットをバイト/秒単位で視覚化することで、 AFF A900がサポートする優れた安定したパフォーマンスとトラフィックを確認できます。</block>
  <block id="c99b1e0f8a1447330448c8c7dc3df6b6" category="inline-image-macro">このグラフはブローカー ネットワーク スループットを示します。</block>
  <block id="7965f443cb0aaaa8c5c51bc5dec6bed3" category="paragraph"><block ref="7965f443cb0aaaa8c5c51bc5dec6bed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9877d3e22635e0b37f0b74ab2d832d05" category="paragraph">これは、トピックごとに配信されるメッセージのビューと一致します。次のグラフはトピックごとの内訳を示しています。テストした構成では、4 つのトピックにわたってトピックごとに約 90 万件のメッセージが確認されました。</block>
  <block id="a6f05b2032cdce5554a9058f33e2d728" category="paragraph"><block ref="a6f05b2032cdce5554a9058f33e2d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc35bf5a15bb7c42ab972c7038f773f5" category="section-title">究極のパフォーマンスとストレージの限界の探求</block>
  <block id="58b4fe8d21ee892b9633349960eaa7ab" category="paragraph">AFFについては、バックログ機能を使用して OMB でもテストしました。バックログ機能は、Kafka クラスターにイベントのバックログが蓄積されている間、コンシューマーのサブスクリプションを一時停止します。このフェーズでは、プロデューサー トラフィックのみが発生し、ログにコミットされるイベントが生成されます。これはバッチ処理またはオフライン分析ワークフローを最もよくエミュレートします。これらのワークフローでは、コンシューマー サブスクリプションが開始され、ブローカー キャッシュからすでに削除されている履歴データを読み取る必要があります。</block>
  <block id="2aeeb1b752e68f3fabc8026c34af1e23" category="paragraph">この構成におけるコンシューマー スループットのストレージ制限を理解するために、プロデューサーのみのフェーズを測定し、A900 が吸収できる書き込みトラフィックの量を把握しました。次のセクションを参照してください。<block ref="dbf93a9130703fe2432219c42c2bf311" category="inline-xref-macro-rx"></block>このデータをどのように活用するかを理解してください。</block>
  <block id="feec11a45c1fd079250c6f3603d708cd" category="paragraph">この測定のプロデューサーのみの部分では、A900 パフォーマンスの限界を押し上げる高いピーク スループットが確認されました (プロデューサーとコンシューマーのトラフィックを処理する他のブローカー リソースが飽和していない場合)。</block>
  <block id="bab88ff8b10be68a7d1ab6839852ce6b" category="paragraph"><block ref="bab88ff8b10be68a7d1ab6839852ce6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f237b36d09d10702066fb620cf352dcf" category="admonition">この測定では、メッセージごとのオーバーヘッドを制限し、NFS マウント ポイントへのストレージ スループットを最大化するために、メッセージ サイズを 16k に増やしました。</block>
  <block id="9e1dbe9319ed19b15341f3000f56398a" category="paragraph">Confluent Kafka クラスターは、ピーク時のプロデューサー スループット 4.03GBps を達成しました。</block>
  <block id="3355268f822f520fe03b272691c2e428" category="paragraph">OMB がイベントバックログの入力を完了すると、コンシューマー トラフィックが再開されました。バックログの排出による測定中に、すべてのトピックにわたって 20 GBps を超えるピーク消費者スループットが観測されました。  OMB ログ データを保存する NFS ボリュームへの合計スループットは、約 30 GBps に近づきました。</block>
  <block id="157a25969caf77d231e319ce70f0b637" category="section-title">サイズガイド</block>
  <block id="2e4bacad236b9e36d868b929042e2bad" category="inline-link">サイズガイド</block>
  <block id="eec877a6f9c2530996fae2423259c2c6" category="paragraph">Amazon Web Servicesは<block ref="e9ae0e8f89540055129f0fae422bdb9a" category="inline-link-rx"></block>Kafka クラスターのサイズ設定とスケーリング用。</block>
  <block id="cc4abcaa3ba3e4f795b82759d3dcd056" category="paragraph">このサイズ設定は、Kafka クラスターのストレージ スループット要件を決定するための便利な式を提供します。</block>
  <block id="f2fb73fb163775775c1145d28c68ad20" category="paragraph">レプリケーション係数 r を持つ tcluster のクラスターに生成される集約スループットの場合、ブローカー ストレージが受信するスループットは次のようになります。</block>
  <block id="0acbbdd0cc159664d8baab43c6d168bd" category="paragraph">これをさらに簡略化することができます。</block>
  <block id="28c949d6bdead032a1410c176cbf74cb" category="paragraph">この式を使用すると、Kafka ホット層のニーズに適したONTAPプラットフォームを選択できます。</block>
  <block id="df3f8ed04b35156def4360bb05a77cc1" category="paragraph">次の表は、さまざまなレプリケーション係数を持つ A900 の予測プロデューサー スループットを示しています。</block>
  <block id="329589e3ff014cb50ee2238aecc6a867" category="cell">複製係数</block>
  <block id="75ec49708cc8881a7762e3740e342ca3" category="cell">プロデューサースループット（GPps）</block>
  <block id="c2b3050f7fde2050bb86e4e9ef0f7567" category="cell">3（測定値）</block>
  <block id="31053ad0506e935470ca21b43cae98cf" category="cell">3.4</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="a9d9d1b0257dda96d595bd00149cccdb" category="cell">10.2</block>
  <block id="bc0316be7ba1d2f8b53c282f09f9b532" category="summary">NetApp NFS にマウントされたストレージ層を持つ Kafka クラスターのパフォーマンスを AWS クラウドでベンチマークしました。ベンチマークの例については、次のセクションで説明します。</block>
  <block id="bf57de8e029ea3108f102be3202cff5f" category="doc">AWS FSx ONTAPのパフォーマンスの概要と検証</block>
  <block id="71db594c48140b244b2b54ff2bdedb71" category="paragraph">NetApp NFS にマウントされたストレージ層を持つ Kafka クラスターのパフォーマンスを AWS FSx ONTAPでベンチマークしました。ベンチマークの例については、次のセクションで説明します。</block>
  <block id="1c036e91476215fff31a2c45fdf276f9" category="section-title">AWS FSx ONTAPでの Apache Kafka</block>
  <block id="29144a8d530212e5210d98eceae62106" category="paragraph">ネットワーク ファイル システム (NFS) は、大量のデータを保存するために広く使用されているネットワーク ファイル システムです。ほとんどの組織では、Apache Kafka などのストリーミング アプリケーションによってデータが生成されることが増えています。これらのワークロードには、スケーラビリティ、低レイテンシ、最新のストレージ機能を備えた堅牢なデータ取り込みアーキテクチャが必要です。リアルタイム分析を可能にし、実用的な洞察を提供するには、適切に設計された高性能なインフラストラクチャが必要です。</block>
  <block id="3c10ee4415fe854b95a1b3d124b0f0ea" category="paragraph">Kafka は設計上、POSIX 準拠のファイル システムで動作し、ファイル操作の処理にはファイル システムに依存しますが、NFSv3 ファイル システムにデータを保存する場合、Kafka ブローカー NFS クライアントは、XFS や Ext4 などのローカル ファイル システムとは異なる方法でファイル操作を解釈する場合があります。一般的な例としては、クラスターを拡張してパーティションを再割り当てするときに Kafka ブローカーが失敗する原因となった NFS Silly の名前変更が挙げられます。この課題に対処するため、 NetApp はオープンソースの Linux NFS クライアントを更新し、現在 RHEL8.7、RHEL9.1 で一般公開されており、現在の FSx ONTAPリリースであるONTAP 9.12.1 からサポートされている変更を加えました。</block>
  <block id="2c69958ee453c213417e415ee57b1690" category="paragraph">Amazon FSx ONTAP は、クラウド内で完全に管理され、スケーラブルで高性能な NFS ファイルシステムを提供します。  FSx ONTAP上の Kafka データは、大量のデータを処理し、フォールト トレランスを確保するために拡張できます。  NFS は、重要な機密データセットの集中ストレージ管理とデータ保護を提供します。</block>
  <block id="542c651fdfac42519bffb9b7ebf01539" category="paragraph">これらの機能強化により、AWS のお客様は、AWS コンピューティングサービスで Kafka ワークロードを実行するときに FSx ONTAPを活用できるようになります。これらの利点は次のとおりです。 * CPU 使用率を削減して I/O 待機時間を短縮します。 * Kafka ブローカーの回復時間が短縮されます。  * 信頼性と効率性。  * スケーラビリティとパフォーマンス。  * マルチアベイラビリティゾーンの可用性。  * データ保護。</block>
  <block id="cafd94f15e4ecd146a2af6ea620cc490" category="section-title">AWS FSx ONTAPでの Kafka</block>
  <block id="7e3b8d1a53f4bf4f127be8ea0fda504d" category="paragraph">AWS FSx ONTAPを搭載した Kafka クラスターの AWS クラウドでのパフォーマンスをベンチマークしました。このベンチマークについては、次のセクションで説明します。</block>
  <block id="029bc8dc2b20f11a166635df18b0a419" category="section-title">建築のセットアップ</block>
  <block id="6d14883a196c6b234f62d60a400fe708" category="paragraph">次の表は、AWS FSx ONTAPを使用した Kafka クラスターの環境構成を示しています。</block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">プラットフォームコンポーネント</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">環境設定</block>
  <block id="f874b8bfe50ce846d8156aabe96e5a34" category="cell">カフカ 3.2.3</block>
  <block id="e2322efe17a0927e7f855686b9597301" category="list-text">飼育員×3 – t2.small</block>
  <block id="ea55ea3b374458b5777457efaf0db679" category="list-text">ブローカーサーバー x 3 – i3en.2xlarge</block>
  <block id="d521f24278937c9ada520622e97168d8" category="list-text">1 x Grafana – c5n.2xlarge</block>
  <block id="747684069b5286f0282d40e544a04812" category="list-text">4 x プロデューサー/コンシューマー -- c5n.2xlarge *</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">すべてのノード上のオペレーティング システム</block>
  <block id="a0d574b61a80df70bd921b269853cc18" category="cell">RHEL8.6</block>
  <block id="9e813193a6755822d3c1628326e814e6" category="cell">4GB/秒のスループットと160000 IOPSを備えたマルチAZ</block>
  <block id="8eb6827eb8f798501ab14f58155a9982" category="section-title">NetApp FSx ONTAPセットアップ</block>
  <block id="eb1e12842ba64aa1b662a4e95a406d45" category="list-text">最初のテストでは、2TB の容量と 2GB/秒のスループットで 40000 IOP の FSx ONTAPファイルシステムを作成しました。</block>
  <block id="7ce8d5b94f98d9eb7023e64b4f92f5fd" category="paragraph">この例では、AWS CLI を介して FSx ONTAPをデプロイしています。必要に応じて、環境に合わせてコマンドをさらにカスタマイズする必要があります。さらに、FSx ONTAP はAWS コンソールから導入および管理できるため、コマンドライン入力が少なくなり、より簡単かつ合理化された導入エクスペリエンスを実現できます。</block>
  <block id="81656db36243146de24c60a68b7b395c" category="paragraph">ドキュメント FSx ONTAPでは、テスト リージョン (US-East-1) の 2GB/秒スループットのファイル システムで達成可能な最大 IOPS は 80,000 iops です。  FSx ONTAPファイルシステムの合計最大 IOPS は 160,000 IOPS であり、これを実現するには 4GB/秒のスループットの展開が必要です。これについては、このドキュメントの後半で説明します。</block>
  <block id="3c50ca3005ca0da0071db25317a45f47" category="paragraph">FSx ONTAP のパフォーマンス仕様の詳細については、AWS FSx ONTAP のドキュメントをご覧ください。<block ref="f270bb91d9718c264ef59ceaf9562990" category="inline-link-rx"></block> 。</block>
  <block id="ac3f15100beedf3665df00f75c6a126e" category="paragraph">FSx「create-file-system」の詳細なコマンドライン構文については、以下を参照してください。<block ref="6dfaa72a4db79e3cd69acb6bd09e3928" category="inline-link-rx"></block></block>
  <block id="4510c1fa7d54bc22137fc99fdee7ec14" category="paragraph">たとえば、KMS キーが指定されていない場合に使用されるデフォルトの AWS FSx マスターキーではなく、特定の KMS キーを指定できます。</block>
  <block id="b2d4bc4b14215051ed2eea3eff254d84" category="list-text">FSx ONTAPファイルシステムを作成するときに、次のようにファイルシステムを記述した後、JSON の戻り値で「LifeCycle」ステータスが「AVAILABLE」に変わるまで待機します。</block>
  <block id="fcd00639267fd24b3c25a30b3abcd5b0" category="list-text">fsxadmin ユーザーで FSx ONTAP SSH にログインして資格情報を検証します。Fsxadmin は、作成時の FSx ONTAPファイルシステムのデフォルトの管理者アカウントです。  fsxadmin のパスワードは、ステップ 1 で完了したように、AWS コンソールまたは AWS CLI を使用して最初にファイルシステムを作成したときに設定されたパスワードです。</block>
  <block id="89fd702da938a0842ce8bbbd1978c407" category="list-text">資格情報が検証されたら、FSx ONTAPファイルシステム上にストレージ仮想マシンを作成します。</block>
  <block id="52140a6ade484065f20232f9d150ea61" category="paragraph">ストレージ仮想マシン (SVM) は、FSx ONTAPボリューム内のデータを管理およびアクセスするための独自の管理資格情報とエンドポイントを備えた分離されたファイル サーバーであり、FSx ONTAPマルチテナント機能を提供します。</block>
  <block id="e05c7d2454cf3006c8871c25085ec858" category="list-text">プライマリ ストレージ仮想マシンを構成したら、新しく作成された FSx ONTAPファイルシステムに SSH で接続し、以下のサンプル コマンドを使用してストレージ仮想マシンにボリュームを作成します。同様に、この検証用に 6 つのボリュームを作成します。私たちの検証に基づいて、デフォルトの構成要素 (8) 以下を維持すると、Kafka のパフォーマンスが向上します。</block>
  <block id="f82c8c9ef7e5f94bfc60abe80b30a2c1" category="list-text">テストのためにボリュームに追加の容量が必要になります。ボリュームのサイズを 2TB に拡張し、ジャンクション パスにマウントします。</block>
  <block id="401223c85704727381abb64f33f1e700" category="paragraph">FSx ONTAPでは、ボリュームをシンプロビジョニングできます。この例では、拡張ボリュームの合計容量がファイルシステムの合計容量を超えているため、追加のプロビジョニング済みボリューム容量のロックを解除するには、ファイルシステムの合計容量を拡張する必要があります。これについては次の手順で説明します。</block>
  <block id="980bf78b74033a80493ead9ead18533e" category="list-text">次に、パフォーマンスと容量をさらに向上させるために、FSx ONTAPのスループット容量を2GB/秒から4GB/秒に、IOPSを160000に、容量を5TBに拡張しました。</block>
  <block id="cfd6d8adc21dc264014c117cc1a95fda" category="paragraph">FSx「update-file-system」の詳細なコマンドライン構文については、以下を参照してください。<block ref="f3196344ef0cf3de8d956a0736aba68b" category="inline-link-rx"></block></block>
  <block id="d067a587144a5c3f420cd628e1e5e9ae" category="list-text">FSx ONTAPボリュームは、Kafkaブローカーのnconnectおよびデフォルトオプションでマウントされます。</block>
  <block id="fe25ee0c1614b7db9e4a6cec9f2cd488" category="paragraph">次の図は、FSx ONTAPベースの Kafka クラスターの最終的なアーキテクチャを示しています。</block>
  <block id="a09d4eb20485c4e2d2f9ed81274d727a" category="inline-image-macro">この画像は、FSx ONTAPベースの Kafka クラスターのアーキテクチャを示しています。</block>
  <block id="f230dbbbd1d967f5675641bd1e9ff03e" category="paragraph"><block ref="f230dbbbd1d967f5675641bd1e9ff03e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a205c51d74e59d28030cda2886e41130" category="list-text">計算します。専用サーバーで実行される 3 ノードの Zookeeper アンサンブルを備えた 3 ノードの Kafka クラスターを使用しました。各ブローカーには、FSx ONTAPインスタンス上の 6 つのボリュームへの 6 つの NFS マウント ポイントがありました。</block>
  <block id="447931d0542671d1817df0b8bdc35ff4" category="list-text">監視。 Prometheus と Grafana の組み合わせには 2 つのノードを使用しました。ワークロードを生成するために、この Kafka クラスターに対して生成と消費が可能な別の 3 ノード クラスターを使用しました。</block>
  <block id="35f0ed4ee5bc59733f7cd41a36cf4721" category="list-text">ストレージ。 2TB ボリュームを 6 つマウントした FSx ONTAPを使用しました。その後、ボリュームは NFS マウントを使用して Kafka ブローカーにエクスポートされました。FSx ONTAPボリュームは、16 個の nconnect セッションと Kafka ブローカーのデフォルト オプションを使用してマウントされます。</block>
  <block id="c06018aab55e4fa9ef871b34b2cf7897" category="section-title">OpenMessage ベンチマーク構成。</block>
  <block id="9300a7a969a31b3c5371c03474456ec3" category="paragraph">NetApp Cloud Volumes ONTAPに使用したのと同じ構成を使用しました。詳細については、こちらを参照してください - link:kafka-nfs-performance-overview-and-validation-in-aws.html#architectural-setup</block>
  <block id="91c26176df142d17ab999313541632c5" category="section-title">テストの方法論</block>
  <block id="79f0e8e2c892a7ffb6c02f9be47fd6f5" category="list-text">Kafka クラスターは、Terraform と Ansible を使用して、上記の仕様に従ってプロビジョニングされました。  Terraform は、Kafka クラスターの AWS インスタンスを使用してインフラストラクチャを構築するために使用され、Ansible はそれら上に Kafka クラスターを構築します。</block>
  <block id="d9a3b4ca51b8378374ab25c3f90ec2a2" category="list-text">上記のワークロード構成と同期ドライバを使用して、OMB ワークロードがトリガーされました。</block>
  <block id="3f6a85702112dff5bcd0970b7ceb3f02" category="list-text">同じワークロード構成のスループット ドライバーで別のワークロードがトリガーされました。</block>
  <block id="c680d437163cc6bab4f9bdb35c3073d0" category="section-title">観察</block>
  <block id="5f2da6c069f19294c52f39a18639f0d2" category="paragraph">NFS 上で実行されている Kafka インスタンスのパフォーマンスをベンチマークするためのワークロードを生成するために、2 つの異なるタイプのドライバーが使用されました。ドライバー間の違いは、ログフラッシュプロパティです。</block>
  <block id="6e3e5905f95f1d3670a864fd2b1e1855" category="paragraph">Kafka レプリケーション係数 1 および FSx ONTAPの場合:</block>
  <block id="477397883986e4a6ef0944db3f171a9a" category="list-text">Sync ドライバーによって一貫して生成される合計スループット: 約 3218 MBps、ピーク パフォーマンス: 約 3652 MBps。</block>
  <block id="526cf61e40ed54cf3e36bc48e608fe6a" category="list-text">スループット ドライバーによって一貫して生成される合計スループット: 約 3679 MBps、ピーク パフォーマンス: 約 3908 MBps。</block>
  <block id="5c677e3834aab5345e650615a307b653" category="paragraph">レプリケーション係数 3 および FSx ONTAPを使用した Kafka の場合:</block>
  <block id="1d0957e5fc4340aeed631639b2076501" category="list-text">Sync ドライバーによって一貫して生成される合計スループット: 約 1252 MBps、ピーク パフォーマンス: 約 1382 MBps。</block>
  <block id="e18b6be6753e1c55e4474648e1073e75" category="list-text">スループット ドライバーによって一貫して生成される合計スループット: 約 1218 MBps、ピーク パフォーマンス: 約 1328 MBps。</block>
  <block id="9e99c55380b9b536ec73cd9bdfbad865" category="paragraph">Kafka レプリケーション ファクター 3 では、FSx ONTAPで読み取りおよび書き込み操作が 3 回発生しました。Kafka レプリケーション ファクター 1 では、FSx ONTAPで読み取りおよび書き込み操作が 1 回であるため、両方の検証で最大スループット 4GB/秒に到達できました。</block>
  <block id="4bb1ab47e2a029960970bd2e246f9a57" category="paragraph">Sync ドライバーは、ログがディスクに瞬時にフラッシュされるため一貫したスループットを生成できますが、Throughput ドライバーは、ログが一括してディスクにコミットされるためスループットのバーストを生成します。</block>
  <block id="920a7d00fe9032493a9a70c1e6c8972a" category="paragraph">これらのスループット数値は、指定された AWS 構成に対して生成されます。より高いパフォーマンス要件の場合、インスタンス タイプをスケールアップしてさらに調整し、スループット数値を向上させることができます。合計スループットまたは合計レートは、プロデューサー レートとコンシューマー レートの両方の組み合わせです。</block>
  <block id="5d4902b750979a6daa75a334daf3b4dd" category="inline-image-macro">この画像は、RF1とRF3を使用したkafkaのパフォーマンスを示しています。</block>
  <block id="67731dd79a61f656bfde458fade09eb2" category="paragraph"><block ref="67731dd79a61f656bfde458fade09eb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3293059261e00d42aa4678d1677be1b1" category="paragraph">以下のグラフは、Kafka レプリケーション ファクター 3 の 2GB/秒の FSx ONTAPと 4GB/秒のパフォーマンスを示しています。レプリケーション係数 3 は、FSx ONTAPストレージで読み取りおよび書き込み操作を 3 回実行します。スループット ドライバーの合計速度は 881 MB/秒で、2 GB/秒の FSx ONTAPファイルシステムで約 2.64 GB/秒の Kafka 操作の読み取りと書き込みを実行します。また、スループット ドライバーの合計速度は 1328 MB/秒で、約 3.98 GB/秒の Kafka 操作の読み取りと書き込みを実行します。  Kafka のパフォーマンスは、FSx ONTAPスループットに基づいて線形かつスケーラブルです。</block>
  <block id="a7ddac9765853f96e59270871b8a3925" category="inline-image-macro">この画像は、2GB/秒と4GB/秒のスケールアウト パフォーマンスを示しています。</block>
  <block id="94043e4666620e8e09ceedcb705c7951" category="paragraph"><block ref="94043e4666620e8e09ceedcb705c7951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61f2d83a3758c796ac8892836cada117" category="paragraph">以下のグラフは、EC2 インスタンスと FSx ONTAP (Kafka レプリケーション係数: 3) のパフォーマンスを示しています。</block>
  <block id="b891a78e120a481bc23346cb210b2fa2" category="inline-image-macro">この画像は、RF3 における EC2 と FSx ONTAPのパフォーマンス比較を示しています。</block>
  <block id="59b617ab46ce09f11c02ed94c18645e4" category="paragraph"><block ref="59b617ab46ce09f11c02ed94c18645e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b742a6a1f227191aecb81d8822d2ee" category="doc">AWS でのパフォーマンスの概要と検証</block>
  <block id="28e2dfa4242e2b504727dab8605d1432" category="section-title">NetApp Cloud Volumes ONTAPを使用した AWS クラウドでの Kafka (高可用性ペアと単一ノード)</block>
  <block id="1dc7a426b0cbf7d35c5edda73f68403d" category="paragraph">NetApp Cloud Volumes ONTAP (HA ペア) を搭載した Kafka クラスターのパフォーマンスを AWS クラウドでベンチマークしました。このベンチマークについては、次のセクションで説明します。</block>
  <block id="61c964c4267b0fa60eeaa1a7ccdf706e" category="paragraph">次の表は、NAS を使用した Kafka クラスターの環境構成を示しています。</block>
  <block id="4f04a8a7e04e79aafa7150a5ae2bab1b" category="cell">NetApp Cloud Volumes ONTAPインスタンス</block>
  <block id="462fed98d4e5a4d1be4d08b1fdd3f0df" category="cell">HAペアインスタンス - m5dn.12xLarge x 2ノード シングルノードインスタンス - m5dn.12xLarge x 1ノード</block>
  <block id="29e8b4fdf26266c94b184b76858f935e" category="section-title">NetAppクラスタボリュームONTAPセットアップ</block>
  <block id="febbbf2a22b781c8cb2d828a8cbf52d6" category="list-text">Cloud Volumes ONTAP HA ペアの場合、各ストレージ コントローラ上の各アグリゲートに 3 つのボリュームを持つ 2 つのアグリゲートを作成しました。単一のCloud Volumes ONTAPノードに対して、アグリゲート内に 6 つのボリュームを作成します。</block>
  <block id="72bcc37cf8850d4e74a6305d71727956" category="inline-image-macro">この画像は aggr3 と aggr22 の特性を示しています。</block>
  <block id="cc5972f21a1c1b3f25fd1c54ca580885" category="paragraph"><block ref="cc5972f21a1c1b3f25fd1c54ca580885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="518fcf406a83698c4ba5d2f41cafab41" category="inline-image-macro">この画像は aggr2 の特性を示しています。</block>
  <block id="7bf987d778dee1c98d1b0b2d5fb00a9c" category="paragraph"><block ref="7bf987d778dee1c98d1b0b2d5fb00a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a6501fcefae41cda9ecf425cdc1ef15" category="list-text">より優れたネットワーク パフォーマンスを実現するために、HA ペアと単一ノードの両方で高速ネットワークを有効にしました。</block>
  <block id="a4de9e1c332b656e2e19024cce28f939" category="inline-image-macro">この画像は高速ネットワークを有効にする方法を示しています。</block>
  <block id="49c32669e9d6be5a2b08ff5d8eb59127" category="paragraph"><block ref="49c32669e9d6be5a2b08ff5d8eb59127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678217b29dc6cbf917f08c79a1819f92" category="list-text">ONTAP NVRAM のIOPS が高いことに気づいたので、 Cloud Volumes ONTAPルート ボリュームの IOPS を 2350 に変更しました。 Cloud Volumes ONTAPのルート ボリューム ディスクのサイズは 47 GB でした。次のONTAPコマンドは HA ペア用ですが、同じ手順が単一ノードにも適用されます。</block>
  <block id="71ac6dbf3d671b6b9db5497aad37fc67" category="inline-image-macro">この画像はボリュームのプロパティを変更する方法を示しています。</block>
  <block id="044b1cecac787ba4da45dc749881f5a1" category="paragraph"><block ref="044b1cecac787ba4da45dc749881f5a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c2cacbcd5f4927358fee9d8a0b60252" category="paragraph">次の図は、NAS ベースの Kafka クラスターのアーキテクチャを示しています。</block>
  <block id="a5f2ebf87b5aa37d2e02d041ede98e4f" category="list-text">*計算します。*専用サーバーで実行される 3 ノードの Zookeeper アンサンブルを備えた 3 ノードの Kafka クラスターを使用しました。各ブローカーには、専用の LIF を介してCloud Volumes ONTAPインスタンス上の単一のボリュームへの 2 つの NFS マウント ポイントがありました。</block>
  <block id="493b3bd02a683f505d957bb27957e1b6" category="list-text">*監視。* Prometheus と Grafana の組み合わせには 2 つのノードを使用しました。ワークロードを生成するために、この Kafka クラスターに対して生成と消費が可能な別の 3 ノード クラスターを使用しました。</block>
  <block id="dcb39d8372b01f5eb051372b3d943fbd" category="list-text">*ストレージ。*インスタンスにマウントされた 6TB GP3 AWS-EBS ボリューム 1 つを備えた HA ペアの Cloud Volumes ONTAPインスタンスを使用しました。その後、ボリュームは NFS マウントを使用して Kafka ブローカーにエクスポートされました。</block>
  <block id="78f0f1d311c4aae35de324851ecea08a" category="inline-image-macro">この図は、NAS ベースの Kafka クラスターのアーキテクチャを示しています。</block>
  <block id="474d97e74219f2fc9511f3691ed0ae94" category="paragraph"><block ref="474d97e74219f2fc9511f3691ed0ae94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cce0ad6ab772599285bd32c539025c1f" category="section-title">OpenMessageベンチマーク構成</block>
  <block id="6a1fe63829e046313e1b3073459bf538" category="list-text">NFS のパフォーマンスを向上させるには、NFS サーバーと NFS クライアント間のネットワーク接続を増やす必要があります。これは、nconnect を使用して作成できます。次のコマンドを実行して、nconnect オプションを使用してブローカー ノードに NFS ボリュームをマウントします。</block>
  <block id="a973eefced896f4a698ed64af6dc0199" category="list-text">Cloud Volumes ONTAPでネットワーク接続を確認します。次のONTAPコマンドは、単一のCloud Volumes ONTAPノードから使用されます。同じ手順がCloud Volumes ONTAP HA ペアにも適用されます。</block>
  <block id="828ed34406e4dab30166070e0af1f142" category="list-text">以下のKafkaを使用します<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>Cloud Volumes ONTAP HA ペアのすべての Kafka ブローカーで。その<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>プロパティはブローカーごとに異なり、残りのプロパティはブローカーに共通です。ブローカー1の場合、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>値は次のとおりです。</block>
  <block id="66ddebf2d4ab98ff8682a008dc466ce6" category="list-text">ブローカー2の場合、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>プロパティ値は次のとおりです。</block>
  <block id="fcfc381980a9ed554f51cbfd5b77616a" category="list-text">ブローカー3の場合、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>プロパティ値は次のとおりです。</block>
  <block id="00d57462d7009374713be86d6c491d89" category="list-text">単一のCloud Volumes ONTAPノードの場合、Kafka<block ref="21d5034d4d99d6ca0da314367f1cccd6" prefix=" " category="inline-code"></block> Cloud Volumes ONTAP HAペアの場合と同じですが、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>財産。</block>
  <block id="cf168cce281f1eccdc9f9fb55c933d29" category="list-text">ブローカー1の場合、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>値は次のとおりです。</block>
  <block id="1692ac5191f19e15cf0e3a8af0820752" category="list-text">ブローカー2の場合、<block ref="b858cc142f1fc84a95bfd5a17ea09e1d" prefix=" " category="inline-code"></block>値は次のとおりです。</block>
  <block id="4b0728fa62359454465b3a26a608d83c" category="list-text">OMB 内のワークロードは、次のプロパティで構成されます。<block ref="9a97642a426510e31f49e0a98ed35e46" prefix=" " category="inline-code"></block> 。</block>
  <block id="433b44cf3e6084d97e5162a06d481873" category="paragraph">その<block ref="f21d26061df60c086aedb156e38f66b5" prefix=" " category="inline-code"></block>ユースケースごとに異なる場合があります。パフォーマンステストでは 3K を使用しました。</block>
  <block id="bd9348653b0cfa7f0962b694fa058428" category="paragraph">Kafka クラスターでワークロードを生成するために、OMB の Sync または Throughput という 2 つの異なるドライバーを使用しました。</block>
  <block id="50e5861dab89d00bf88787e044b2c24f" category="list-text">同期ドライバーのプロパティに使用される yaml ファイルは次のとおりです。<block ref="46c2adf6b9dc6e5883c47b1d76feb008" prefix=" " category="inline-code"></block> ：</block>
  <block id="9ae100f8fb1875133a485c355266af55" category="list-text">スループットドライバーのプロパティに使用される yaml ファイルは次のとおりです。<block ref="658e4b47fcd8812e9b0b2886af867717" prefix=" " category="inline-code"></block> ：</block>
  <block id="a887b430cb278fa8f52827a223308324" category="list-text">上記の仕様に従って、Terraform と Ansible を使用して Kafka クラスターがプロビジョニングされました。  Terraform は、Kafka クラスターの AWS インスタンスを使用してインフラストラクチャを構築するために使用され、Ansible はそれら上に Kafka クラスターを構築します。</block>
  <block id="59f70e2d523801f5ede7c9bb7b48cc76" category="paragraph">Cloud Volumes ONTAP HA ペアの場合:</block>
  <block id="ffb03fd768825b381d478b114716f8cf" category="list-text">Sync ドライバーによって一貫して生成される合計スループット: ~1236 MBps。</block>
  <block id="84c96e7c92d1f10aac5f3600c7df9299" category="list-text">スループット ドライバーに対して生成された合計スループット: ピーク時 ~1412 MBps。</block>
  <block id="5896e2cd1e01fb8ef69cdf280a9a38e3" category="paragraph">単一のCloud Volumes ONTAPノードの場合:</block>
  <block id="d3c9dedf3eb9fce5e9a983948c3cef0e" category="list-text">Sync ドライバーによって一貫して生成される合計スループット: ~ 1962MBps。</block>
  <block id="86acf2bdaf8de60bbc77d3dc8f0e1b12" category="list-text">スループットドライバーによって生成される合計スループット: ピーク時約 1660 MBps</block>
  <block id="c5616509b949bfcdee10d7e87918ec9d" category="inline-image-macro">ここでは 4 つの異なるグラフが示されています。  CVO-HA ペア スループット ドライバー。  CVO-HA ペア同期ドライバー。  CVO 単一ノード スループット ドライバー。  CVO 単一ノード同期ドライバー。</block>
  <block id="d2fc51602d60125ca82c279f8a8e03af" category="paragraph"><block ref="d2fc51602d60125ca82c279f8a8e03af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c6ad6fcb6db991d86273d33ed35d3c9" category="paragraph">スループットまたは同期ドライバーのベンチマークを実行するときは、必ずストレージのスループットを確認してください。</block>
  <block id="22156e4cc2df3388f0f9dfe0c178db37" category="inline-image-macro">このグラフは、レイテンシ、IOPS、スループットのパフォーマンスを示します。</block>
  <block id="e34c5c483b0b104d0cc1453f3be5f6b4" category="paragraph"><block ref="e34c5c483b0b104d0cc1453f3be5f6b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc2e9a005ff6b9d50a1fca9914e8eac0" category="summary">このセクションでは、不合理な名前変更の問題と、その問題に対処するために NFS サーバーと NFS クライアントに必要な変更について説明します。</block>
  <block id="0d5e61a5d0c056718a15d6df7037a50c" category="doc">NFS から Kafka へのワークロードの名前変更に関する問題に対するNetApp のソリューション</block>
  <block id="e5ee0fc73f4f4f38e75acb2c0b2343be" category="paragraph">Kafka は、基盤となるファイルシステムが POSIX 準拠 (たとえば、XFS または Ext4) であることを前提に構築されています。  Kafka リソースの再バランス調整により、アプリケーションがまだ使用しているファイルが削除されます。 POSIX 準拠のファイル システムでは、unlink を続行できます。ただし、ファイルへの参照がすべてなくなった後にのみファイルが削除されます。基礎となるファイルシステムがネットワークに接続されている場合、NFS クライアントはリンク解除呼び出しをインターセプトし、ワークフローを管理します。リンク解除されるファイルには保留中のオープンがあるため、NFS クライアントは NFS サーバーに名前変更要求を送信し、リンク解除されたファイルが最後に閉じられるときに、名前が変更されたファイルに対して削除操作を発行します。この動作は一般に NFS の奇妙な名前変更と呼ばれ、NFS クライアントによって調整されます。</block>
  <block id="f17efbdff90d69935a8d84a6215665a5" category="paragraph">この動作により、NFSv3 サーバーのストレージを使用する Kafka ブローカーで問題が発生します。ただし、NFSv4.x プロトコルには、開かれたリンクされていないファイルに対してサーバーが責任を持つようにすることで、この問題に対処する機能があります。このオプション機能をサポートする NFS サーバーは、ファイルを開くときに所有権機能を NFS クライアントに伝えます。  NFS クライアントは、保留中のオープンがある場合にリンク解除の管理を停止し、サーバーがフローを管理できるようにします。  NFSv4 仕様では実装のガイドラインが提供されていますが、これまでこのオプション機能をサポートする NFS サーバー実装は知られていませんでした。</block>
  <block id="219af746424bba4643138d0820ab40b5" category="paragraph">不合理な名前変更の問題を解決するには、NFS サーバーと NFS クライアントに次の変更が必要です。</block>
  <block id="36efd47a4ba95b58e3b2a0f2ed7420ad" category="list-text">*NFS クライアント (Linux) への変更。*ファイルが開かれるときに、NFS サーバーは開かれたファイルのリンク解除を処理できることを示すフラグで応答します。  NFS クライアント側の変更により、フラグが存在する場合に NFS サーバーがリンク解除を処理できるようになります。 NetApp は、これらの変更をオープンソースの Linux NFS クライアントに反映しました。更新された NFS クライアントは、RHEL8.7 および RHEL9.1 で一般公開されました。</block>
  <block id="f400588f268c9f90112ff6290a81575a" category="list-text">*NFS サーバーへの変更。* NFS サーバーはオープンを追跡します。既存の開いているファイルのリンク解除は、POSIX セマンティクスに合わせてサーバーによって管理されるようになりました。最後のオープンが閉じられると、NFS サーバーはファイルの実際の削除を開始し、無駄な名前変更プロセスを回避します。  ONTAP NFS サーバは、最新リリースのONTAP 9.12.1 でこの機能を実装しました。</block>
  <block id="21a87b96dd7bfc9863d6bca5fc12f005" category="paragraph">NFS クライアントとサーバーに上記の変更を加えることで、Kafka はネットワーク接続された NFS ストレージの利点をすべて安全に享受できるようになります。</block>
  <block id="8a1762b0db0285b0ca6661669e3a9aec" category="summary">機能検証では、ストレージに NFSv3 をマウントした Kafka クラスターはパーティションの再配分などの Kafka 操作を実行できないのに対し、修正を適用した NFSv4 にマウントされた別のクラスターは中断なく同じ操作を実行できることを示しました。</block>
  <block id="2b1635c7ae2a72d0b26454157a03e197" category="doc">機能検証 - ばかげた名前変更の修正</block>
  <block id="a8ead7a6a54d47ea0a38e64908ab321f" category="section-title">検証設定</block>
  <block id="e087dbbdc5792f1e574cdf41c135d858" category="paragraph">セットアップは AWS 上で実行されます。次の表は、検証に使用されたさまざまなプラットフォーム コンポーネントと環境構成を示しています。</block>
  <block id="cccdd75af54f32ac7f570bbcca39f516" category="cell">Confluent Platform バージョン 7.2.1</block>
  <block id="185b9d1a84206af090c5f70ac68f24ad" category="list-text">飼育員3人 – t3.xlarge</block>
  <block id="6677060ff0c6c4620e427121a576713c" category="list-text">4台のブローカーサーバー – r3.xlarge</block>
  <block id="61e62294effd3d2046982e7d5a22b824" category="list-text">1 x Grafana – t3.xlarge</block>
  <block id="1e2657a43dca2051e4684eb73c2a856c" category="list-text">コントロールセンター x 1 – t3.xlarge</block>
  <block id="2dcca349e332f9e312cebc29485dadf0" category="list-text">3 x 生産者/消費者</block>
  <block id="00ecb59dfdd1b1378b38c6b7bf8e91dc" category="cell">RHEL8.7以降</block>
  <block id="d09d15c71c68b596f76c57a87a19e0e5" category="cell">シングルノードインスタンス – M5.2xLarge</block>
  <block id="3ba4ec8d167c12be652d6829ce6e51d8" category="paragraph">次の図は、このソリューションのアーキテクチャ構成を示しています。</block>
  <block id="b3c6c8984f5671892932b2a7eacc5bf4" category="inline-image-macro">この画像は、プロデューサー スウォーム、Kafka クラスター、CVO インスタンスをそれぞれ含む 3 つのプライベート サブネットを含む VPC を含む AWS トポロジを示しています。</block>
  <block id="2046377162498de9fec810aafa41c2b3" category="paragraph"><block ref="2046377162498de9fec810aafa41c2b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d580bb4c55b441a712ec6c9dc12d38b" category="section-title">建築の流れ</block>
  <block id="82c8c0c94e152cc00496c6c5a1fa76b0" category="list-text">*計算します。*専用サーバーで実行される 3 ノードの Zookeeper アンサンブルを備えた 4 ノードの Kafka クラスターを使用しました。</block>
  <block id="e236bd14d5d59a952978645a606dd7f9" category="list-text">*監視。*  Prometheus と Grafana の組み合わせには 2 つのノードを使用しました。</block>
  <block id="c375f003dbf6b1accc45fd3811ce2b82" category="list-text">*作業量。*ワークロードを生成するために、この Kafka クラスターにデータを生成したり、この Kafka クラスターからデータを消費したりできる、別の 3 ノード クラスターを使用しました。</block>
  <block id="ada284cbb65ff7bad5814ecb0c6ecb2f" category="list-text">*ストレージ。*インスタンスに 2 つの 500 GB GP2 AWS-EBS ボリュームが接続された、単一ノードのNetApp Cloud Volumes ONTAPインスタンスを使用しました。これらのボリュームは、LIF を介して単一の NFSv4.1 ボリュームとして Kafka クラスターに公開されました。</block>
  <block id="e86dc7584f98dc172fd46661ef8b935a" category="paragraph">すべてのサーバーに対して、Kafka のデフォルトのプロパティが選択されました。動物園の飼育員の群れにも同じことを行いました。</block>
  <block id="c31fea06105fe5260bb879284c6181e0" category="list-text">アップデート<block ref="9733772c7c0780d4ef7a6a8d6a9dbd7d" prefix=" " category="inline-code"></block>kafka ボリュームに次のように追加します。</block>
  <block id="5ca41832794ba1f8118f718465d6ffe4" category="list-text">次の違いを持つ 2 つの類似した Kafka クラスターが作成されました。</block>
  <block id="fc1a46a26a283c18443e516b58cb0a58" category="list-text">*クラスター1*実稼働対応のONTAPバージョン 9.12.1 を実行するバックエンド NFS v4.1 サーバーは、 NetApp CVO インスタンスによってホストされていました。ブローカーに RHEL 8.7/RHEL 9.1 がインストールされました。</block>
  <block id="183a9a6c4f97a876554696844cf5cd19" category="list-text">*クラスター2*バックエンド NFS サーバーは、手動で作成された汎用 Linux NFSv3 サーバーでした。</block>
  <block id="8dac413f2b3b7fdfc73d642ae6e79a33" category="list-text">両方の Kafka クラスターにデモ トピックが作成されました。</block>
  <block id="dc30a10b7f3dac3bcce7b54e12502e89" category="paragraph">クラスター 1:</block>
  <block id="0cdb385ae4a7f7449cf10919962c71c8" category="inline-image-macro">このスクリーンショットは、クラスター 1 に作成されたデモ トピックを示しています。</block>
  <block id="23e2fb3a3a7caf11826a6ddc3650812b" category="paragraph"><block ref="23e2fb3a3a7caf11826a6ddc3650812b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="83655cf6beab33b344c9ae17bec532d0" category="paragraph">クラスター 2:</block>
  <block id="772ab3218dd37dea5c304575fe358498" category="inline-image-macro">このスクリーンショットは、クラスター 2 に作成されたデモ トピックを示しています。</block>
  <block id="2d82e26036412c43987356c7c8ca8fb3" category="paragraph"><block ref="2d82e26036412c43987356c7c8ca8fb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb392c27040a7eb25cfeb1d96323917e" category="list-text">両方のクラスターの新しく作成されたトピックにデータがロードされました。これは、デフォルトの Kafka パッケージに付属する produced-perf-test ツールキットを使用して実行されました。</block>
  <block id="bd5bb4c79c0fd5aea6e14277bbd9c5fe" category="list-text">Telnet を使用して、各クラスターのブローカー 1 のヘルス チェックが実行されました。</block>
  <block id="ec97e8f78ae99ff145018ede90a47c77" category="list-text">テルネット<block ref="da440d4c50d5bbb0ffa4021d6db8332c" prefix=" " category="inline-code"></block></block>
  <block id="a93dad1338160e3b828529ad6a585d13" category="list-text">テルネット<block ref="2a3da46f5894b7e15be0ea3be46975cc" prefix=" " category="inline-code"></block></block>
  <block id="a7892fb38856d45eb1f6cd89d3118830" category="paragraph">次のスクリーンショットは、両方のクラスター上のブローカーのヘルスチェックが成功したことを示しています。</block>
  <block id="855ba5b1fb4b822400c8e412d08df6e4" category="inline-image-macro">このスクリーンショットは、両方のブローカーでのヘルスチェックが成功した場合の読み取り結果を示しています。</block>
  <block id="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="paragraph"><block ref="abe3c89cfc6f09b3a5f31df9bcf7ac04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a63ad47b1692dcaccf39fb2a5c42e393" category="list-text">NFSv3 ストレージ ボリュームを使用する Kafka クラスターがクラッシュする障害状態をトリガーするために、両方のクラスターでパーティションの再割り当てプロセスを開始しました。パーティションの再割り当ては、<block ref="5cbd65bd2e4824bbb4876b792e513e10" prefix=" " category="inline-code"></block> 。詳細なプロセスは次のとおりです。</block>
  <block id="9ea6b7d5de4fbe3c468699ad3c8bb6ef" category="list-text">Kafka クラスター内のトピックのパーティションを再割り当てするために、提案された再割り当て構成 JSON を生成しました (これは両方のクラスターに対して実行されました)。</block>
  <block id="c4c8306a70b22c96715a3f79fe60eca9" category="list-text">生成された再割り当てJSONは、<block ref="d773b1c180323b61e54dc5acaa6fb66f" prefix=" " category="inline-code"></block> 。</block>
  <block id="05e65fb821eccc3b4cb26cc7285d75f8" category="list-text">実際のパーティションの再割り当てプロセスは、次のコマンドによって開始されました。</block>
  <block id="83c299e30316ef5659e9b3bbd34b40ad" category="list-text">再割り当てが完了してから数分後、ブローカーの別のヘルス チェックで、NFSv3 ストレージ ボリュームを使用しているクラスターが不合理な名前変更の問題に遭遇してクラッシュした一方で、修正が適用されNetApp ONTAP NFSv4.1 ストレージ ボリュームを使用しているクラスター 1 は中断することなく操作を継続していることが示されました。</block>
  <block id="197bc98012d3a74f45e086c86b7237bc" category="inline-image-macro">このスクリーンショットはクラッシュしたブローカーからの出力を示しています。</block>
  <block id="3a51f6a0340d9026c9fc6619a6584b83" category="paragraph"><block ref="3a51f6a0340d9026c9fc6619a6584b83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7796cd6b11de5af34093097d2db9b94f" category="list-text">Cluster1-Broker-1 は稼働しています。</block>
  <block id="fef78f6445fec5a3c0d0cb2008e6c34e" category="list-text">Cluster2-broker-1 は停止しています。</block>
  <block id="e413a6c934b14b11c478c905d8c0489b" category="list-text">Kafka のログ ディレクトリを確認すると、修正が適用されたNetApp ONTAP NFSv4.1 ストレージ ボリュームを使用する Cluster 1 ではパーティション割り当てが適切に行われていたのに対し、汎用 NFSv3 ストレージを使用する Cluster 2 では、名前変更の問題によってパーティション割り当てが適切に行われず、クラッシュが発生していたことが明らかになりました。次の図は、クラスター 2 のパーティションの再バランスを示しています。これにより、NFSv3 ストレージで名前変更の問題が発生しました。</block>
  <block id="1c2cca9f5ca8cce4b11ebdc970e4a78c" category="inline-image-macro">このスクリーンショットは、クラスター 2 がクラッシュした場合のログ出力を示しています。</block>
  <block id="587e107619187efb07b3bd05f8bcf7f9" category="paragraph"><block ref="587e107619187efb07b3bd05f8bcf7f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43fea21bb45bdea6ebc007efbf3c0053" category="paragraph">次の図は、 NetApp NFSv4.1 ストレージを使用したクラスター 1 のクリーン パーティションの再バランスを示しています。</block>
  <block id="1ac73d9186e013f2157d22422bc044ff" category="inline-image-macro">このスクリーンショットは、クラスタ1のクリーンなパーティション割り当てが成功した場合のログ出力を示しています。</block>
  <block id="f3d0f09c5b4a3c2f532881572a744b6c" category="paragraph"><block ref="f3d0f09c5b4a3c2f532881572a744b6c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8eac57fa6403d9c896c24cb94767e954" category="summary">Kafka を使用した NFS ストレージの無意味な名前変更の問題に対する解決策ができたので、Kafka ワークロードにNetApp ONTAPストレージを活用する堅牢なデプロイメントを作成できます。これにより、運用上のオーバーヘッドが大幅に削減されるだけでなく、Kafka クラスターに次の利点がもたらされます。</block>
  <block id="76827cff700415303c6b7420a1869192" category="doc">Kafka ワークロードにNetApp NFS を使用する理由</block>
  <block id="984b2b530f32710e640393a80677e426" category="paragraph">Kafka を使用した NFS ストレージの無意味な名前変更の問題に対する解決策ができたので、Kafka ワークロードにNetApp ONTAPストレージを活用する堅牢なデプロイメントを作成できます。これにより、運用上のオーバーヘッドが大幅に削減されるだけでなく、Kafka クラスターに次のような利点がもたらされます。</block>
  <block id="2dbec01439aed1c5b5fbe8a521623f2d" category="list-text">*Kafka ブローカーの CPU 使用率が削減されました。*分散型NetApp ONTAPストレージを使用すると、ディスク I/O 操作がブローカーから分離され、CPU フットプリントが削減されます。</block>
  <block id="24c6011da569f3cc3fede5c4eafff91e" category="list-text">*ブローカーの回復時間が短縮されます。*分散されたNetApp ONTAPストレージは Kafka ブローカー ノード間で共有されるため、従来の Kafka デプロイメントと比較して、データを再構築することなく、いつでも短時間で新しいコンピューティング インスタンスが不良ブローカーを置き換えることができます。</block>
  <block id="04615fed33ad7a5a209c685460f2c557" category="list-text">*ストレージ効率。*アプリケーションのストレージ層がNetApp ONTAPを通じてプロビジョニングされるようになったため、顧客はインライン データ圧縮、重複排除、圧縮など、 ONTAPに備わっているストレージ効率の利点をすべて活用できます。</block>
  <block id="c7444ea1ca211e0d3dd1b89c4f792d00" category="paragraph">これらの利点は、このセクションで詳しく説明するテスト ケースでテストおよび検証されています。</block>
  <block id="454cd026e1a6a7761ee25bf6682aeb2b" category="section-title">Kafka ブローカーの CPU 使用率の削減</block>
  <block id="70c59ac3ed6ee89fe977676b2dba2f05" category="paragraph">技術仕様は同一だが、ストレージ テクノロジが異なる 2 つの別々の Kafka クラスターで同様のワークロードを実行したところ、全体的な CPU 使用率が DAS よりも低いことがわかりました。  Kafka クラスターがONTAPストレージを使用している場合、全体的な CPU 使用率が低くなるだけでなく、CPU 使用率の増加は DAS ベースの Kafka クラスターよりも緩やかな勾配を示しました。</block>
  <block id="c9d177e7e6018d464567bf6a8f9773e7" category="paragraph">次の表は、CPU 使用率の削減を示すために使用された環境構成を示しています。</block>
  <block id="5ed4a4dbe122b39d7103642bff11de54" category="cell">Kafka 3.2.3 ベンチマークツール: OpenMessaging</block>
  <block id="3cb61b8b67329a8a20d9128458cf6633" category="list-text">4 x プロデューサー/コンシューマー -- c5n.2xlarge</block>
  <block id="d34010cfee0f2a6d774e450acd135088" category="cell">RHEL 8.7以降</block>
  <block id="bce5fbe7fa89f635a887c6af2f95a9be" category="cell">シングルノードインスタンス – M5.2xLarge</block>
  <block id="a27bb92a9fdd5b8b4c084b824b810232" category="section-title">ベンチマークツール</block>
  <block id="d483516be45a355eab4c7f9b129540c9" category="inline-link">オープンメッセージング</block>
  <block id="0a48e066bcee681066419fb01ccd9f16" category="paragraph">このテストケースで使用したベンチマークツールは<block ref="3990ab384d3299fd4c655b02444eb5d6" category="inline-link-rx"></block>フレームワーク。 OpenMessaging はベンダー中立かつ言語に依存しません。金融、電子商取引、IoT、ビッグデータに関する業界ガイドラインを提供し、異機種システムやプラットフォーム間でのメッセージングおよびストリーミング アプリケーションの開発に役立ちます。次の図は、OpenMessaging クライアントと Kafka クラスターの相互作用を示しています。</block>
  <block id="ac6d62ee86368b8c24366434f9b5d5a1" category="inline-image-macro">この画像は、OpenMessaging クライアントと Kafka クラスターの相互作用を示しています。</block>
  <block id="9cb3e560e852dc92918678c092a4105e" category="paragraph"><block ref="9cb3e560e852dc92918678c092a4105e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6250495e61aa2eb3c47f71d21f58c6f8" category="list-text">*計算します。*専用サーバーで実行される 3 ノードの Zookeeper アンサンブルを備えた 3 ノードの Kafka クラスターを使用しました。各ブローカーには、専用の LIF を介してNetApp CVO インスタンス上の単一ボリュームへの 2 つの NFSv4.1 マウント ポイントがありました。</block>
  <block id="f91ee5c5359f2260d72c50f2c8009925" category="list-text">*監視。* Prometheus と Grafana の組み合わせには 2 つのノードを使用しました。ワークロードを生成するために、この Kafka クラスターにワークロードを生成したり、この Kafka クラスターからワークロードを消費したりできる、独立した 3 ノード クラスターがあります。</block>
  <block id="e2b1493c4214be739b2c9349a2c481ef" category="list-text">*ストレージ。*インスタンスにマウントされた 6 つの 250 GB GP2 AWS-EBS ボリュームを備えた単一ノードのNetApp Cloud Volumes ONTAPインスタンスを使用しました。これらのボリュームは、専用の LIF を介して 6 つの NFSv4.1 ボリュームとして Kafka クラスターに公開されました。</block>
  <block id="ede634748bd4515e69245593cfc4478c" category="list-text">*構成。*このテスト ケースで構成可能な 2 つの要素は、Kafka ブローカーと OpenMessaging ワークロードでした。</block>
  <block id="b053d1656e3b9dcaa2b4834fbdc4fb86" category="list-text">*ブローカー設定* Kafka ブローカーには次の仕様が選択されました。以下で強調されているように、すべての測定に複製係数 3 を使用しました。</block>
  <block id="d5ee20b40da2061d10bff33a6f13467a" category="inline-image-macro">この画像は、Kafka ブローカー用に選択された仕様を示しています。</block>
  <block id="41b835894ba02ffb1ba3f3fdae71877c" category="paragraph"><block ref="41b835894ba02ffb1ba3f3fdae71877c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82f54619faeaa86063f362102c160601" category="list-text">*OpenMessaging ベンチマーク (OMB) ワークロード構成。*以下の仕様が提供されました。以下に強調表示されている目標生産者率を指定しました。</block>
  <block id="da43f96a4bfe17af8039df6b15f4f6da" category="inline-image-macro">この画像は、OpenMessaging ベンチマーク ワークロード構成用に選択された仕様を示しています。</block>
  <block id="41106ec7ad546fdd6a08b370c8093ab9" category="paragraph"><block ref="41106ec7ad546fdd6a08b370c8093ab9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6067cc387407f4d8dc9d623c770cfd" category="list-text">2 つの類似したクラスターが作成され、それぞれ独自のベンチマーク クラスター スウォームのセットを持ちました。</block>
  <block id="c85bb905404dda665035e21b11ab1a58" category="list-text">*クラスター1*  NFS ベースの Kafka クラスター。</block>
  <block id="9ed0b3eccef17299a0119b0f28568e78" category="list-text">*クラスター2*  DAS ベースの Kafka クラスター。</block>
  <block id="a38c46362b3feb9b3bb5f53b1957d50f" category="list-text">OpenMessaging コマンドを使用して、各クラスターで同様のワークロードがトリガーされました。</block>
  <block id="c18ed3feb8720fe4fc76d90a9fa6a6e3" category="list-text">生成率の設定は 4 回の反復で増加され、CPU 使用率は Grafana で記録されました。生産率は次のレベルに設定されました。</block>
  <block id="04207e7bb62b9b5d14bdb603f74e683c" category="list-text">10,000</block>
  <block id="e19784a5420512b2876c7b24680652b5" category="list-text">40,000</block>
  <block id="e57650a6c15f273334d41da58fa72111" category="list-text">80,000</block>
  <block id="ee70718f6a92d6c1b099a6942f594963" category="list-text">100,000</block>
  <block id="524fdb84d137ea63c19f5efab343f82b" category="paragraph">Kafka でNetApp NFS ストレージを使用すると、主に 2 つの利点があります。</block>
  <block id="612e27ad9fd383437f1445cf80d554b1" category="list-text">*CPU 使用率を約 3 分の 1 削減できます。*同様のワークロードでの全体的な CPU 使用率は、DAS SSD と比較して NFS の方が低く、節約幅は生成率が低い場合は 5%、生成率が高い場合は 32% です。</block>
  <block id="bc31b9852409e970a3a4659fef4b4f93" category="list-text">*生産率が高い場合の CPU 使用率のドリフトが 3 分の 1 に減少します。*予想どおり、生産率が上がるにつれて、CPU 使用率の増加は上向きに推移しました。ただし、DAS を使用する Kafka ブローカーの CPU 使用率は、低い生成率の場合の 31% から高い生成率の場合の 70% に上昇し、39% 増加しました。ただし、NFS ストレージ バックエンドでは、CPU 使用率は 26% から 38% に上昇し、12% 増加しました。</block>
  <block id="6299b9c8f7a14a0a0ca7407cbb9a187a" category="inline-image-macro">このグラフは、DAS ベースのクラスターの動作を示しています。</block>
  <block id="9630ee6aa29406a977bc5179849d2639" category="paragraph"><block ref="9630ee6aa29406a977bc5179849d2639" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60e393621d29424b529201d4bc48e3b4" category="inline-image-macro">このグラフは、NFS ベースのクラスターの動作を示しています。</block>
  <block id="74336896d4b61e55ed364028f046f35b" category="paragraph"><block ref="74336896d4b61e55ed364028f046f35b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03d4293a3bcf73010216e2f0399fd571" category="paragraph">また、100,000 件のメッセージでは、DAS は NFS クラスターよりも CPU 使用率が高くなります。</block>
  <block id="a0e6052c526d2d343fa217b609c943a6" category="inline-image-macro">このグラフは、100,000 件のメッセージにおける DAS ベースのクラスターの動作を示しています。</block>
  <block id="73c360518d32a693e133ab63604b2ab4" category="paragraph"><block ref="73c360518d32a693e133ab63604b2ab4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9d76c4aeb68cf4d7ef9bf3ce121bdd2" category="inline-image-macro">このグラフは、100,000 件のメッセージでの NFS ベースのクラスターの動作を示しています。</block>
  <block id="be31c668debc31c9573036c63b1b4f49" category="paragraph"><block ref="be31c668debc31c9573036c63b1b4f49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60a5caa55d79e52e0af298cf19b5c73d" category="section-title">ブローカーの回復が速い</block>
  <block id="bc0ed21388f4042414a88362de068e14" category="paragraph">共有NetApp NFS ストレージを使用すると、Kafka ブローカーの回復が速くなることがわかりました。 Kafka クラスターでブローカーがクラッシュした場合、このブローカーは同じブローカー ID を持つ正常なブローカーに置き換えられます。このテストケースを実行すると、DAS ベースの Kafka クラスターの場合、クラスターは新しく追加された正常なブローカー上でデータを再構築するため、時間がかかることがわかりました。  NetApp NFS ベースの Kafka クラスターの場合、置き換えたブローカーは以前のログ ディレクトリからデータを読み取り続けるため、回復がはるかに速くなります。</block>
  <block id="687972ccb765e5204fa2220ba3dff130" category="list-text">4 x プロデューサー/コンシューマー -- c5n.2xlarge</block>
  <block id="31638173210d76d464e93c8f3f53711c" category="list-text">1 x バックアップ Kafka ノード – i3en.2xlarge</block>
  <block id="5d27021addda02398c54d28a4ceee767" category="cell">RHEL8.7以降</block>
  <block id="477284b661c88fdd810eb7273729b5ed" category="paragraph"><block ref="477284b661c88fdd810eb7273729b5ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64898c42d1ced91d44ff2e383b066de3" category="list-text">*計算します。*専用サーバー上で実行される 3 ノードの Zookeeper アンサンブルを備えた 3 ノードの Kafka クラスター。各ブローカーには、専用 LIF を介してNetApp CVO インスタンス上の単一ボリュームへの 2 つの NFS マウント ポイントがあります。</block>
  <block id="06e870f499bc90bbe828323be8625621" category="list-text">*監視。* Prometheus と Grafana の組み合わせの 2 つのノード。ワークロードを生成するために、この Kafka クラスターに対して生成および消費できる別の 3 ノード クラスターを使用します。</block>
  <block id="1a5c8241b05feb71d0733c2cc2f073c2" category="list-text">*ストレージ。*インスタンスにマウントされた 6 つの 250 GB GP2 AWS-EBS ボリュームを持つ単一ノードのNetApp Cloud Volumes ONTAPインスタンス。これらのボリュームは、専用の LIF を介して 6 つの NFS ボリュームとして Kafka クラスターに公開されます。</block>
  <block id="7a4e5e874bf6fcf8217de7f8f0af5acb" category="list-text">*ブローカーの構成*このテスト ケースで構成可能な唯一の要素は Kafka ブローカーです。 Kafka ブローカーには次の仕様が選択されました。その<block ref="2aa7cd054835892b354c130576c17b61" prefix=" " category="inline-code"></block>特定のノードが ISR リストから削除される速度を決定するため、高い値に設定されます。不良ノードと正常なノードを切り替える場合、そのブローカー ID が ISR リストから除外されないようにする必要があります。</block>
  <block id="d6068b616491b51ff179d0138965bba4" category="inline-image-macro">この画像は、Kafka ブローカー用に選択された仕様を示しています。</block>
  <block id="ce565ed35fddb2c8191f4b8496e98245" category="paragraph"><block ref="ce565ed35fddb2c8191f4b8496e98245" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f6ea5961f5640ce4fa828022abc91c1" category="list-text">2 つの類似したクラスターが作成されました。</block>
  <block id="71754d8c640cd0a117a3c82af0bd3646" category="list-text">EC2 ベースの合流クラスター。</block>
  <block id="c4b4e0617e4a38a83a00fc9bd8083465" category="list-text">NetApp NFS ベースの合流クラスター。</block>
  <block id="fbbf8c78f6f01371b1caa7b79bfa91b9" category="list-text">元の Kafka クラスターのノードと同一の構成で、スタンバイ Kafka ノードが 1 つ作成されました。</block>
  <block id="b2d04ce59538c1ba125aa91697b3854f" category="list-text">各クラスターでサンプルトピックが作成され、ブローカーごとに約 110 GB のデータが入力されました。</block>
  <block id="25bb70a763a5456f70f68d98646ecbd6" category="list-text">*EC2 ベースのクラスター。*  Kafkaブローカーデータディレクトリは、<block ref="8463a3643fa4431218a88d6e1e85f064" prefix=" " category="inline-code"></block> (次の図では、cluster1 の Broker-1 [左端末])。</block>
  <block id="bbec1799f53d01620bdd78881b0f0310" category="list-text">* NetApp NFS ベースのクラスター。*  KafkaブローカーデータディレクトリはNFSポイントにマウントされます<block ref="ecabd55f704fe0f0dcc41be6e7e7ab83" prefix=" " category="inline-code"></block>(次の図では、cluster2 の Broker-1 [右端末])。</block>
  <block id="86f85a2a5eed8a784f9a06a8fe205c9a" category="inline-image-macro">この画像には 2 つの端末画面が表示されています。</block>
  <block id="3a534dc7ed1f2e8444c4b278dd70aa7e" category="paragraph"><block ref="3a534dc7ed1f2e8444c4b278dd70aa7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02296aafa9e3a6424418dd97a673e931" category="list-text">各クラスターで、Broker-1 が終了され、失敗したブローカーの回復プロセスがトリガーされました。</block>
  <block id="fe4c3f604a59eb786f64f0fc5a7cfa01" category="list-text">ブローカーが終了した後、ブローカーの IP アドレスがスタンバイ ブローカーのセカンダリ IP として割り当てられました。これは、Kafka クラスター内のブローカーが次のように識別されるため必要でした。</block>
  <block id="597bfb23e3e10c354a661882e4728565" category="list-text">*IPアドレス*障害が発生したブローカー IP をスタンバイ ブローカーに再割り当てすることによって割り当てられます。</block>
  <block id="d86a6ec6cd64cd7365ad5d46f7c32d85" category="list-text">*ブローカーID*これはスタンバイブローカーで設定されました<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>。</block>
  <block id="c71af5d75ff28fc80b8aa2c6c6832c39" category="list-text">IP が割り当てられると、スタンバイ ブローカーで Kafka サービスが開始されました。</block>
  <block id="e6f0e1804a85ff41f08342fa0cd0e8c5" category="list-text">しばらくして、サーバー ログを取得して、クラスター内の置換ノードでデータを構築するのにかかった時間をチェックしました。</block>
  <block id="b4e6de827ba8af76c3d7cf0e11dee63e" category="paragraph">Kafka ブローカーの回復はほぼ 9 倍高速になりました。障害が発生したブローカー ノードの回復にかかる時間は、Kafka クラスターで DAS SSD を使用する場合と比較して、 NetApp NFS 共有ストレージを使用する場合の方が大幅に短縮されることがわかりました。  1 TB のトピック データの場合、DAS ベースのクラスターのリカバリ時間は 48 分でしたが、 NetApp-NFS ベースの Kafka クラスターの場合は 5 分未満でした。</block>
  <block id="fcd5351f741ba27a03aeaa4aff141fde" category="paragraph">EC2 ベースのクラスターでは新しいブローカー ノードで 110 GB のデータを再構築するのに 10 分かかりましたが、NFS ベースのクラスターでは 3 分でリカバリを完了しました。また、ログでは、EC2 のパーティションのコンシューマー オフセットが 0 である一方、NFS クラスターではコンシューマー オフセットが以前のブローカーから取得されていることも確認しました。</block>
  <block id="01a0d5c558a836a74adf3dc3fe1de25d" category="section-title">DASベースのクラスター</block>
  <block id="542ac5d9dd4769eb5fb4a8a7da3aa594" category="list-text">バックアップ ノードは 08:55:53,730 に開始されました。</block>
  <block id="b5f0acf8be0dd329b7dae7c96c9b3dc8" category="inline-image-macro">この画像は、DAS ベースのクラスターのログ出力を示しています。</block>
  <block id="91569a3f4fee956cd801e625cc8eb34f" category="paragraph"><block ref="91569a3f4fee956cd801e625cc8eb34f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d48d1996a0b89fc5aa313e48f1c2c149" category="list-text">データ再構築プロセスは 09:05:24,860 に終了しました。  110GB のデータの処理には約 10 分かかりました。</block>
  <block id="d598dda290e226574121bf65a66222c1" category="paragraph"><block ref="d598dda290e226574121bf65a66222c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d10d1e0d7dc7546ca2ee585553c90f24" category="section-title">NFSベースのクラスタ</block>
  <block id="e163d6812be40c2618b43cc9d2ed21a1" category="list-text">バックアップ ノードは 09:39:17,213 に開始されました。開始ログエントリは以下に強調表示されています。</block>
  <block id="1af763f7fe72be73a16f6a9010023e1f" category="inline-image-macro">この画像は、NFS ベースのクラスターのログ出力を示しています。</block>
  <block id="bbb8038819966fa92b04b31dfe935e66" category="paragraph"><block ref="bbb8038819966fa92b04b31dfe935e66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459f0a82f7fc8505de6db94698f5e9c8" category="list-text">データ再構築プロセスは 09:42:29,115 に終了しました。  110GB のデータの処理には約 3 分かかりました。</block>
  <block id="bb69fdfb2a75f135682b3880999f8c2e" category="paragraph"><block ref="bb69fdfb2a75f135682b3880999f8c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24c9b21a2ca87ae467a56b044593521b" category="paragraph">約 1 TB のデータを含むブローカーに対してテストを繰り返しましたが、DAS の場合は約 48 分、NFS の場合は約 3 分かかりました。結果は次のグラフに示されています。</block>
  <block id="6994918ac91afbe69dd9a20ab257afa1" category="inline-image-macro">このグラフは、DAS ベースのクラスターまたは NFS ベースのクラスターのいずれかで、ブローカーにロードされたデータの量に応じてブローカーの回復にかかる時間を示します。</block>
  <block id="fcc7c3e745c4c2ba0f4fe48c8d589122" category="paragraph"><block ref="fcc7c3e745c4c2ba0f4fe48c8d589122" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd18465573ec21a6218982055981f6b1" category="section-title">ストレージ効率</block>
  <block id="f94ef2603834178da773ec5ccd97683b" category="paragraph">Kafka クラスターのストレージ層はNetApp ONTAPを通じてプロビジョニングされたため、 ONTAPのすべてのストレージ効率機能を利用できました。これは、Cloud Volumes ONTAPでプロビジョニングされた NFS ストレージを使用して Kafka クラスターで大量のデータを生成することによってテストされました。  ONTAP の機能により、スペースが大幅に削減されたことがわかりました。</block>
  <block id="d1030267f4090d953bd3cabbb565b51b" category="cell">単一ノードインスタンス – M5.2xLarge</block>
  <block id="717373873e977ccdc16d9a371e92b55b" category="list-text">*計算します。*専用サーバーで実行される 3 ノードの Zookeeper アンサンブルを備えた 3 ノードの Kafka クラスターを使用しました。各ブローカーには、専用 LIF を介してNetApp CVO インスタンス上の単一ボリュームへの 2 つの NFS マウント ポイントがありました。</block>
  <block id="cce21f164c30f5ce10f914c4542e252f" category="list-text">*ストレージ。*インスタンスにマウントされた 6 つの 250 GB GP2 AWS-EBS ボリュームを備えた単一ノードのNetApp Cloud Volumes ONTAPインスタンスを使用しました。これらのボリュームは、専用の LIF を介して 6 つの NFS ボリュームとして Kafka クラスターに公開されました。</block>
  <block id="68f29d01fbebb4ad998127522e13950b" category="list-text">*構成。*このテスト ケースで構成可能な要素は、Kafka ブローカーでした。</block>
  <block id="8e44bdd37fc66a06e9780582642d0c37" category="paragraph">圧縮はプロデューサー側でオフにされたため、プロデューサーは高いスループットを生成できるようになりました。代わりに、ストレージ効率はコンピューティング層によって処理されました。</block>
  <block id="7da10cbdbba2e826cd4954054b5c1843" category="list-text">上記の仕様で Kafka クラスターがプロビジョニングされました。</block>
  <block id="e857c1394ce43b04a9548d5a3dec0ee5" category="list-text">クラスターでは、OpenMessaging ベンチマーク ツールを使用して約 350 GB のデータが生成されました。</block>
  <block id="efc4a3d9bfed3a9a80b0caea9016ca6c" category="list-text">ワークロードが完了した後、 ONTAP System Manager と CLI を使用してストレージ効率統計が収集されました。</block>
  <block id="9c9850d81b369454a9610d48c5bfe8a0" category="paragraph">OMB ツールを使用して生成されたデータでは、ストレージ効率比が 1.70:1 で、スペースが約 33% 節約されました。次の図に示すように、生成されたデータによって使用された論理スペースは 420.3 GB で、データを保持するために使用された物理スペースは 281.7 GB でした。</block>
  <block id="f11c8594ca77ceb3e0ab124768dd061d" category="inline-image-macro">この画像は、VMDISK でのスペース節約を示しています。</block>
  <block id="565d9cbc0c15374b9bdebe62dd5efe32" category="paragraph"><block ref="565d9cbc0c15374b9bdebe62dd5efe32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3afbd9828e011526955ca93b48b57524" category="inline-image-macro">スクリーンショット</block>
  <block id="50abdfc5295b4aedbb53a46e0bd7512b" category="paragraph"><block ref="50abdfc5295b4aedbb53a46e0bd7512b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6c6f7c15f1d0324567be0828cb855f7" category="paragraph"><block ref="c6c6f7c15f1d0324567be0828cb855f7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">このドキュメントでは、階層型ストレージ ベンチマーク キットを使用したNetApp ONTAP上の Confluent プラットフォームのパフォーマンス ベンチマークの概要を説明します。</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: NetApp ONTAPストレージコントローラとの連携</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam、Joe Scott、 NetApp Rankesh Kumar、Confluent</block>
  <block id="30f774bc5050b82b9a42fe5d8f4bc99f" category="paragraph">Confluent Platform のスケーラビリティと弾力性を高めるには、ワークロードを迅速に拡張してバランスをとることができる必要があります。階層型ストレージにより、運用上の負担が軽減され、Confluent に大量のデータを保存しやすくなります。</block>
  <block id="981ac9f1443bdd13b0920d6ca1ee4eb3" category="paragraph">基本的な考え方は、データ ストレージとデータ処理を分離することです。これにより、それぞれを個別にスケーリングすることがはるかに簡単になります。</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">業界をリードする革新技術を搭載したNetApp ONTAPデータ管理ソフトウェアは、データがどこに保存されていても Confluent に多くの利点をもたらします。</block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">NetApp StorageGRIDセットアップを使用して、プロデュースおよびコンシューマー ワークロード用に 3 ～ 4 ノードの階層型ストレージ テストを実行しました。</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">スケーラビリティを考慮したパフォーマンステスト</block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">NetApp StorageGRIDセットアップを使用して、プロデューサー ワークロードとコンシューマー ワークロード用に 3 ～ 4 ノードの階層型ストレージ テストを実行しました。当社のテストによると、完了までの時間とパフォーマンス結果は、 StorageGRIDノードの数に正比例しました。  StorageGRID のセットアップには少なくとも 3 つのノードが必要でした。</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">ストレージ ノードの数が増加すると、生成と消費の操作を完了する時間は直線的に減少しました。</block>
  <block id="5393f806598ea16510805a4ab3b20623" category="paragraph"><block ref="5393f806598ea16510805a4ab3b20623" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">s3 取得操作のパフォーマンスは、 StorageGRIDノードの数に基づいて直線的に増加しました。  StorageGRID は最大 200 個の StorageGRID ノードをサポートします。</block>
  <block id="d73d827635c7a6fcfa52120cc6f3b96d" category="paragraph"><block ref="d73d827635c7a6fcfa52120cc6f3b96d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">このテストは、クラスター トポロジの変更や不均一な負荷に基づいて再バランス調整を自動化する自己バランス クラスター機能に基づいています。</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">合流型自己バランスクラスター</block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">これまでに Kafka クラスターを管理したことがある場合は、クラスター全体でワークロードのバランスをとるためにパーティションを別のブローカーに手動で再割り当てする際の課題をよくご存知でしょう。大規模な Kafka を導入している組織では、特にミッションクリティカルなアプリケーションがクラスター上に構築されている場合、大量のデータの再シャッフルは困難で面倒でリスクを伴う可能性があります。ただし、Kafka の使用例が最小であっても、プロセスには時間がかかり、人為的エラーが発生しやすくなります。</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">私たちのラボでは、クラスター トポロジの変更や負荷の不均一性に基づいて再バランス調整を自動化する Confluent の自己バランス調整クラスター機能をテストしました。 Confluent の再バランス テストは、ノード障害が発生したとき、またはスケーリング ノードでブローカー間でデータの再バランス調整が必要になったときに、新しいブローカーを追加する時間を測定するのに役立ちます。従来の Kafka 構成では、クラスターの拡大に伴って再バランス調整するデータの量も増加しますが、階層型ストレージでは再バランス調整は少量のデータに制限されます。当社の検証によると、階層型ストレージの再バランス調整は、従来の Kafka アーキテクチャでは数秒または数分かかり、クラスターの拡大に伴って直線的に増加します。</block>
  <block id="829c663686b68c76ea97bd7a23d534b6" category="paragraph">自己バランス型クラスターでは、パーティションの再バランスが完全に自動化され、Kafka のスループットが最適化され、ブローカーのスケーリングが加速され、大規模なクラスターを実行する際の運用上の負担が軽減されます。定常状態では、自己バランス型クラスターがブローカー間のデータの偏りを監視し、パーティションを継続的に再割り当てしてクラスターのパフォーマンスを最適化します。プラットフォームを拡大または縮小する場合、自己バランス型クラスターは新しいブローカーの存在または古いブローカーの削除を自動的に認識し、後続のパーティションの再割り当てをトリガーします。これにより、ブローカーを簡単に追加および廃止できるようになり、Kafka クラスターの弾力性が根本的に向上します。これらの利点は、手動による介入、複雑な計算、またはパーティションの再割り当てに通常伴う人的エラーのリスクを必要とせずに得られます。その結果、データの再バランス調整ははるかに短い時間で完了し、クラスターを常に監視する必要がなくなり、より価値の高いイベント ストリーミング プロジェクトに集中できるようになります。</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">このセットアップでは、Kafka s3 シンク コネクタを使用して、Kafka からオブジェクト ストレージ内のトピックを直接読み書きする方法を示します。このテストではスタンドアロンの Confluent クラスターを使用しましたが、このセットアップは分散クラスターにも適用できます。</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3コネクタ</block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 Sink コネクタは、Apache Kafka トピックから S3 オブジェクトに Avro、JSON、または Bytes 形式でデータをエクスポートします。 Amazon S3 シンクコネクタは、Kafka からデータを定期的にポーリングし、それを S3 にアップロードします。パーティショナーは、すべての Kafka パーティションのデータをチャンクに分割するために使用されます。各データ チャンクは S3 オブジェクトとして表されます。キー名は、トピック、Kafka パーティション、およびこのデータ チャンクの開始オフセットをエンコードします。</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Confluent Web サイトから Confluent Kafka をダウンロードします。</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">パッケージをサーバー上のフォルダーに解凍します。</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">2 つの変数をエクスポートします。</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">スタンドアロンのConfluent Kafkaセットアップの場合、クラスタは一時的なルートフォルダを作成します。<block ref="d42b9c57d24cf5db3bd8d332dc35437f" prefix=" " category="inline-code"></block>また、Zookeeper、Kafka、スキーマレジストリ、connect、ksql-server、control-centerフォルダを作成し、それぞれの設定ファイルをコピーします。<block ref="5f8dd6e4b96ae5c78585ed0293d4338d" prefix=" " category="inline-code"></block> 。次の例を参照してください。</block>
  <block id="ed529b17b192b6bcfa1fb220aa0f37e4" category="list-text">Zookeeper を設定します。デフォルトのパラメータを使用する場合は、何も変更する必要はありません。</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">上記の構成では、<block ref="2f11dbffae155119df4dc4d60229477e" prefix=" " category="inline-code"></block>財産。デフォルトでは、Kafka リーダーの選択には 3 つの Zookeeper が必要です。</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">myidファイルを作成した<block ref="417022983f4126687b04c2a16a36183c" prefix=" " category="inline-code"></block>一意のIDを持つ:</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">myid ファイルには、最後の IP アドレス番号を使用しました。  Kafka、connect、control-center、Kafka、Kafka-rest、ksql-server、および schema-registry 構成にはデフォルト値を使用しました。</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Kafka サービスを開始します。</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">各構成にはログ フォルダーがあり、問題のトラブルシューティングに役立ちます。場合によっては、サービスの起動に時間がかかることがあります。すべてのサービスが稼働していることを確認してください。</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">Kafka connectをインストールするには<block ref="dcd3bd9446852f6dec3cf416e98154dc" prefix=" " category="inline-code"></block>。</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">特定のバージョンをインストールするには、<block ref="edb107f75d4831212ad61dd615bc468f" prefix=" " category="inline-code"></block> 。</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">デフォルトでは、<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>インストールされている<block ref="6ae652b878f3c54eeaed9d623a1a8c82" prefix=" " category="inline-code"></block>。</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">プラグインのパスを新しいものに更新します<block ref="4ccf7940f1e125b6b7fb994629fe7c02" prefix=" " category="inline-code"></block>。</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Confluent サービスを停止して再起動します。</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">アクセスIDと秘密鍵を<block ref="40f203cedcd08f7589920d1a469a96d9" prefix=" " category="inline-code"></block>ファイル。</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">バケットにアクセスできることを確認します。</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">s3 およびバケット構成用に s3-sink プロパティ ファイルを構成します。</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">いくつかのレコードを s3 バケットにインポートします。</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">s3-sink コネクタをロードします。</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">s3-sink のステータスを確認します。</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">ログをチェックして、s3-sink がトピックを受け入れる準備ができていることを確認します。</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Kafka のトピックを確認します。</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">s3 バケット内のオブジェクトを確認します。</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">内容を確認するには、次のコマンドを実行して、各ファイルを S3 からローカルファイルシステムにコピーします。</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">Apacheアーカイブ</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">レコードを印刷するには、avro-tools-1.11.0.1.jar（<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block> ）。</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">このページでは、このソリューションのパフォーマンスを向上させるためのベスト プラクティスについて説明します。</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">パフォーマンスのベストプラクティスガイドライン</block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">ONTAPの場合、可能な場合は 1 MB 以上の GET サイズを使用します。</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">増加<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>そして<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>で<block ref="05cc8f97f27bba0114c55d20c80d4fe7" prefix=" " category="inline-code"></block>ブローカーノードでは、増加した階層化アクティビティを S3 層にプッシュできます。これらの結果は<block ref="0a6a261ab97b8f0aa88765065fded320" prefix=" " category="inline-code"></block>そして<block ref="f05155cb2203ab2a3da64642aea51bd0" prefix=" " category="inline-code"></block>32 に設定します。</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3 バケットは、メンバー集約ごとに 8 つの構成要素をターゲットにする必要があります。</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">S3 トラフィックを駆動するイーサネット リンクでは、ストレージとクライアントの両方で可能な場合は 9k の MTU を使用する必要があります。</block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">この検証テストでは、 NetApp ONTAPストレージ コントローラを搭載した Confluent で 31.74 GBps の階層化スループットを達成しました。</block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">この検証テストでは、 NetApp ONTAPストレージ コントローラを搭載した Confluent で 31.74 GBps の階層化スループットを達成しました。</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Confluent とは何ですか?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">ONTAPのベストプラクティスにおける S3</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3 オブジェクトストレージ管理</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">このページでは、このソリューションのパラメータ内での Confluent のパフォーマンス検証について説明します。</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent パフォーマンス検証</block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">NetApp ONTAP上の階層化ストレージについて、Confluent Platform を使用して検証を実施しました。  NetAppチームと Confluent チームは協力してこの検証に取り組み、必要なテスト ケースを実行しました。</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">合流セットアップ</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">セットアップには、3 つの動物園管理人、5 つのブローカー、および 256 GB の RAM と 16 個の CPU を備えた 5 つのテスト サーバーを使用しました。 NetAppストレージには、 AFF A900 HA ペアを備えたONTAP を使用しました。ストレージとブローカーは 100GbE 接続を介して接続されました。</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">次の図は、階層型ストレージの検証に使用される構成のネットワーク トポロジを示しています。</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">この図は、階層型ストレージの検証に使用される構成のネットワーク トポロジを示しています。</block>
  <block id="b460294b1898fd26dfbb545338caacee" category="paragraph"><block ref="b460294b1898fd26dfbb545338caacee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">ツール サーバーは、Confluent ノードとの間でイベントを送受信するアプリケーション クライアントとして機能します。</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">次のテストパラメータを使用しました。</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">検証には、HTTP プロトコルを使用したONTAPを使用しましたが、HTTPS も機能しました。アクセスキーと秘密鍵は、<block ref="f5bafadf6000aaed6c910fea0a85f4f3" prefix=" " category="inline-code"></block>パラメータ。</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetAppストレージ コントローラ – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">検証のために、 ONTAPで単一の HA ペア構成を構成しました。</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">この図は、検証のために環境が単一の HA ペアとしてどのように構成されたかを示しています。</block>
  <block id="267b459a69088e0dc82f7fe972205f92" category="paragraph"><block ref="267b459a69088e0dc82f7fe972205f92" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">検証結果</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">検証のために以下の 5 つのテストケースを完了しました。最初の 2 つは機能テストであり、残りの 3 つはパフォーマンス テストでした。</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">このテストでは、API 呼び出しを使用して、階層化ストレージに使用されるオブジェクト ストアに対して get、put、delete などの基本操作を実行します。</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">このテストでは、オブジェクト ストレージのエンドツーエンドの機能をチェックします。トピックを作成し、新しく作成されたトピックへのイベント ストリームを生成し、ブローカーがセグメントをオブジェクト ストレージにアーカイブするのを待機し、イベント ストリームを消費し、消費されたストリームが生成されたストリームと一致することを検証します。このテストは、オブジェクト ストア障害注入ありとなしの状態で実行しました。  ONTAPのノードの 1 つでサービス マネージャ サービスを停止し、エンドツーエンドの機能がオブジェクト ストレージで動作することを検証することで、ノード障害をシミュレートしました。</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">生産・消費ワークロードジェネレータ</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">このテストは、セグメントのアーカイブを通じてオブジェクト ストアへの書き込みワークロードを間接的に生成します。読み取りワークロード (読み取られたセグメント) は、コンシューマー グループがセグメントを取得したときにオブジェクト ストレージから生成されました。このワークロードは TOCC スクリプトによって生成されました。このテストでは、並列スレッドでのオブジェクト ストレージの読み取りと書き込みのパフォーマンスをチェックしました。階層化機能の正確性テストと同様に、オブジェクト ストア障害注入の有無でテストを行いました。</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">保持ワークロードジェネレータ</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">このテストでは、トピック保持のワークロードが大きい場合のオブジェクト ストレージの削除パフォーマンスをチェックしました。保持ワークロードは、テスト トピックと並行して多数のメッセージを生成する TOCC スクリプトを使用して生成されました。テスト トピックでは、サイズ ベースおよび時間ベースの積極的な保持設定が構成されていたため、イベント ストリームがオブジェクト ストアから継続的に消去されていました。その後、セグメントはアーカイブされました。これにより、ブローカーによるオブジェクト ストレージ内の多数の削除と、オブジェクト ストア削除操作のパフォーマンスの収集が行われました。</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="inline-link">合流</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">検証の詳細については、<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> Webサイト。</block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">1 つのAFF A900 HA ペアのNetAppストレージ コントローラを使用して、生成/消費ワークロード中に 5 つまたは 8 つのブローカー ノードで階層化ストレージ テストを実行しました。当社のテストによると、 AFF A900 のリソース使用率が 100% に達するまで、完了までの時間とパフォーマンス結果はブローカー ノードの数に応じて変化しました。  ONTAPストレージ コントローラのセットアップには、少なくとも 1 つの HA ペアが必要でした。</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">生成・消費ワークロードジェネレータによるパフォーマンステスト</block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3 取得操作のパフォーマンスは、Confluent ブローカー ノードの数に基づいて直線的に増加しました。  ONTAPストレージ コントローラは、単一の展開で最大 12 個の HA ペアをサポートします。</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">次のグラフは、5 つまたは 8 つのブローカー ノードによる S3 階層化トラフィックの組み合わせを示しています。  AFF A900の単一 HA ペアのパフォーマンスを最大化しました。</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">このデータ グラフは、5 つまたは 8 つのブローカー ノードによる S3 階層化トラフィックの組み合わせを示しています。</block>
  <block id="d1912fadda4ef80cc1a01c7f3f919602" category="paragraph"><block ref="d1912fadda4ef80cc1a01c7f3f919602" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">次のグラフは、Kafka のスループットが約 31.74 GBps であることを示しています。</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">このデータ グラフは、Kafka のスループットが約 31.74 GBps であることを示しています。</block>
  <block id="a9504735d0b0cbb3b424919bb1328a7d" category="paragraph"><block ref="a9504735d0b0cbb3b424919bb1328a7d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">ONTAPストレージコントローラでも同様のスループットが観測されました。<block ref="d40e53103e181690f77a04eadc8aa6cc" prefix=" " category="inline-code"></block>報告。</block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">このセクションでは、階層化ストレージ用のNetApp ONTAPを使用した Confluent Platform 展開のパフォーマンス検証に使用されるハードウェアとソフトウェアについて説明します。次の表は、ソリューションのアーキテクチャと基本コンポーネントを示しています。</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">Confluent およびONTAP搭載のNetApp AFF A900ストレージ コントローラは、データ ストリーム用に設計された分散システムです。どちらも水平スケーラブルでフォールト トレランスを備え、負荷がかかった状態でも優れたパフォーマンスを提供します。これらは、データフットプリントを最小限に抑えるデータ削減テクノロジーにより、ストレージコストを削減しながら、分散データストリーミングとストリーム処理において相互に補完します。 AFF A900ストレージ コントローラは、コンピューティング リソースとデータ ストレージ リソースを分離しながら優れたパフォーマンスを提供します。これによりシステム管理が簡素化され、リソースを個別に拡張できるようになります。</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">ソリューションの概要を示す画像。</block>
  <block id="c7c06ecce0e6f1e46fab6853d4d45058" category="paragraph"><block ref="c7c06ecce0e6f1e46fab6853d4d45058" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent Platform バージョン 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">動物園飼育員3人</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">ブローカーサーバー x 8</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">5台のツールサーバー</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">グラファナ x 1</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">コントロールセンター x 1</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">ウォームバケット用のNetApp ONTAP</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">1 x AFF A900高可用性（HA）ペア</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">2つのCPU、合計16個の物理コア</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">インテル Xeon</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GBの物理メモリ</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbEデュアルポート</block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">このページでは、このソリューションで使用されるテクノロジについて説明します。</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">技術概要</block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAPストレージ コントローラ</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAPは、高性能なエンタープライズ グレードのストレージ オペレーティング システムです。</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8 では、Amazon Simple Storage Service (S3) API のサポートが導入されました。  ONTAP は、Amazon Web Services (AWS) S3 API アクションのサブセットをサポートし、クラウド プロバイダー (AWS、Azure、GCP) およびオンプレミス全体のONTAPベースのシステムでデータをオブジェクトとして表現できるようにします。</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRIDソフトウェアは、オブジェクト ストレージ向けのNetApp の主力ソリューションです。  ONTAP は、エッジでの取り込みおよび前処理ポイントを提供することでStorageGRID を補完し、オブジェクト データ用にNetAppが提供するデータ ファブリックを拡張し、 NetApp製品ポートフォリオの価値を高めます。</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">S3 バケットへのアクセスは、承認されたユーザーとクライアント アプリケーションを通じて提供されます。次の図は、アプリケーションが S3 バケットにアクセスする様子を示しています。</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">この図は、アプリケーションが S3 バケットにアクセスしている様子を示しています。</block>
  <block id="185bab9f8946071e86896c051a520617" category="paragraph"><block ref="185bab9f8946071e86896c051a520617" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">主な使用例</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">S3 API をサポートする主な目的は、 ONTAP上のオブジェクト アクセスを提供することです。  ONTAP統合ストレージ アーキテクチャは、ファイル (NFS および SMB)、ブロック (FC および iSCSI)、およびオブジェクト (S3) をサポートするようになりました。</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">ネイティブS3アプリケーション</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">S3 を使用したオブジェクト アクセスにONTAPサポートを活用できるアプリケーションが増えています。大容量のアーカイブ ワークロードに適していますが、ネイティブ S3 アプリケーションにおける高パフォーマンスのニーズは急速に高まっており、次のようなメリットがあります。</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">Analytics</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">人工知能</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">エッジツーコアの取り込み</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">お客様は、 ONTAP System Manager などの使い慣れた管理ツールを使用して、 ONTAPでの開発および運用用の高性能オブジェクト ストレージを迅速にプロビジョニングし、 ONTAPストレージの効率性とセキュリティを活用できるようになりました。</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPoolエンドポイント</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">ONTAP 9.8 以降、 FabricPool はONTAP内のバケットへの階層化をサポートし、 ONTAP間の階層化が可能になります。これは、既存のFASインフラストラクチャをオブジェクト ストア エンドポイントとして再利用したいお客様にとって最適なオプションです。</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool は、次の 2 つの方法でONTAPへの階層化をサポートします。</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">*ローカル クラスターの階層化*非アクティブなデータは、クラスタ LIF を使用してローカル クラスタにあるバケットに階層化されます。</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">*リモート クラスター階層化*非アクティブなデータは、 FabricPoolクライアント上の IC LIF とONTAPオブジェクト ストア上のデータ LIF を使用して、従来のFabricPoolクラウド階層と同様の方法で、リモート クラスタにあるバケットに階層化されます。</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">既存のクラスタで追加のハードウェアや管理の負担なしでS3の機能を利用する場合は、ONTAP S3が適しています。300 TB を超える規模の導入では、 NetApp StorageGRIDソフトウェアが引き続きオブジェクト ストレージ向けの主力NetAppソリューションとなります。  ONTAPまたはStorageGRID をクラウド層として使用する場合、 FabricPoolライセンスは必要ありません。</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">Confluent 階層型ストレージ向けNetApp ONTAP</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">すべてのデータ センターでは、ビジネスに不可欠なアプリケーションを稼働させ、重要なデータを利用可能かつ安全に維持する必要があります。新しいNetApp AFF A900システムは、 ONTAP Enterprise Edition ソフトウェアと高耐障害性設計を採用しています。当社の新しい超高速 NVMe ストレージ システムは、ミッション クリティカルな業務の中断を排除し、パフォーマンス チューニングを最小限に抑え、ランサムウェア攻撃からデータを保護します。</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">Confluent クラスターの初期導入から拡張まで、ビジネス クリティカルなアプリケーションを中断することなく、環境の変化に迅速に適応することが求められます。  ONTAP のエンタープライズ データ管理、サービス品質 (QoS)、およびパフォーマンスにより、環境に合わせて計画を立て、適応することができます。</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">NetApp ONTAPと Confluent Tiered Storage を併用すると、 ONTAP をスケールアウト ストレージ ターゲットとして活用することで Apache Kafka クラスターの管理が簡素化され、Confluent のコンピューティング リソースとストレージ リソースを個別にスケーリングできるようになります。</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3 サーバーは、 ONTAPの成熟したスケールアウト ストレージ機能に基づいて構築されています。  S3 バケットを拡張して ONTAP クラスターに新しく追加されたノードを使用することで、 ONTAPクラスターのスケーリングをシームレスに実行できます。</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">ONTAP System Managerによるシンプルな管理</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager は、ブラウザベースのグラフィカル インターフェイスであり、世界中に分散した場所にあるONTAPストレージ コントローラを単一の画面で構成、管理、監視できます。</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">この図は、 ONTAP System Manager のワークスペースを示しています。</block>
  <block id="db8cf11125f7909f889c4894d1b8c042" category="paragraph"><block ref="db8cf11125f7909f889c4894d1b8c042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">ONTAP S3は、System ManagerおよびONTAP CLIを使用して設定および管理できます。System Manager を使用して S3 を有効にし、バケットを作成すると、 ONTAP は簡素化された構成のためのベストプラクティスのデフォルトを提供します。  S3 サーバーとバケットを CLI から構成した場合でも、必要に応じて System Manager を使用して管理できます。その逆も可能です。</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">System Managerを使用してS3バケットを作成すると、デフォルトのパフォーマンス サービス レベルが設定されます。これは、システムで使用できる最も高いレベルです。たとえば、 AFFシステムでは、デフォルト設定は Extreme になります。パフォーマンス サービス レベルは、事前定義された適応型 QoS ポリシー グループです。デフォルトのストレージ サービス レベルを使用する代わりに、カスタムのQoSポリシー グループを指定するか、ポリシー グループをなしにすることもできます。</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">定義済みの適応型 QoS ポリシー グループには次のものが含まれます。</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">*過激。*最も低いレイテンシと最高のパフォーマンスを必要とするアプリケーションに使用されます。</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">*パフォーマンス。*適度なパフォーマンスとレイテンシが求められるアプリケーションに使用します。</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">*価値。*レイテンシよりもスループットと容量を重視するアプリケーションに使用します。</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">*カスタム。*カスタムのQoSポリシーまたはQoSポリシーなしを指定します。</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">*階層化に使用* を選択した場合、パフォーマンス サービス レベルは選択されず、システムは階層化されたデータに最適なパフォーマンスを持つ低コストのメディアを選択しようとします。</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAPは、選択したサービス レベルを満たす、最も適切なディスクを含むローカル階層にバケットをプロビジョニングします。ただし、バケットに含めるディスクを指定する必要がある場合は、CLIでローカル階層（アグリゲート）を指定してS3オブジェクト ストレージを設定する方法もあります。CLIでS3サーバを設定した場合も、必要に応じてSystem Managerで管理できます。</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">バケットに使用するアグリゲートはCLIでしか指定できません。</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform は、継続的なリアルタイム ストリームとしてデータに簡単にアクセス、保存、管理できる本格的なデータ ストリーミング プラットフォームです。 Apache Kafka のオリジナル作成者によって構築された Confluent は、エンタープライズ グレードの機能によって Kafka の利点を拡大するとともに、Kafka の管理や監視の負担を軽減します。現在、Fortune 100 企業の 80% 以上がデータ ストリーミング テクノロジーを活用しており、そのほとんどが Confluent を使用しています。</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">Confluentを選ぶ理由</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Confluent は、履歴データとリアルタイム データを単一の信頼できる中央ソースに統合することで、まったく新しいカテゴリの最新のイベント駆動型アプリケーションを簡単に構築し、ユニバーサル データ パイプラインを実現し、完全なスケーラビリティ、パフォーマンス、信頼性を備えた強力な新しいユースケースを実現します。</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Confluent は何に使用されますか?</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform を使用すると、異なるシステム間でデータがどのように転送されるか、または統合されるかといった基礎となる仕組みを心配するのではなく、データからビジネス価値を引き出す方法に集中できます。具体的には、Confluent Platform は、データ ソースを Kafka に接続し、ストリーミング アプリケーションを構築するだけでなく、Kafka インフラストラクチャのセキュリティ保護、監視、管理も簡素化します。現在、Confluent Platform は、金融サービス、オムニチャネル小売、自律走行車から不正検出、マイクロサービス、IoT まで、さまざまな業界の幅広いユースケースで使用されています。</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">次の図は、Confluent Platform のコンポーネントを示しています。</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">この図は、Confluent Platform のコンポーネントを示しています。</block>
  <block id="e21a51ac4ed645780def5d56f85ac9a8" category="paragraph"><block ref="e21a51ac4ed645780def5d56f85ac9a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent イベント ストリーミング テクノロジーの概要</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">カフカ</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent Platformの中核は<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>最も人気のあるオープンソース分散ストリーミング プラットフォームです。  Kafka の主な機能は次のとおりです。</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">レコードのストリームを公開およびサブスクライブします。</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">フォールト トレラントな方法でレコードのストリームを保存します。</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">レコードのストリームを処理します。</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">Confluent Platform には、すぐに使用できる Schema Registry、REST Proxy、合計 100 個以上の構築済み Kafka コネクタ、ksqlDB も含まれています。</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent プラットフォームのエンタープライズ機能の概要</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">*Confluent コントロール センター*  Kafka を管理および監視するための UI ベースのシステム。  Kafka Connect を簡単に管理し、他のシステムへの接続を作成、編集、管理できるようになります。</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">*Kubernetes 用の Confluent。*  Confluent for Kubernetes は Kubernetes オペレーターです。  Kubernetes オペレーターは、特定のプラットフォーム アプリケーションに固有の機能と要件を提供することで、Kubernetes のオーケストレーション機能を拡張します。  Confluent Platform の場合、これには Kubernetes 上の Kafka のデプロイメント プロセスを大幅に簡素化し、一般的なインフラストラクチャ ライフサイクル タスクを自動化することが含まれます。</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">*Kafka Connect コネクタ。*コネクタは Kafka Connect API を使用して、Kafka をデータベース、キー値ストア、検索インデックス、ファイルシステムなどの他のシステムに接続します。 Confluent Hub には、最も人気のあるデータ ソースとシンク用のダウンロード可能なコネクタがあり、Confluent Platform で完全にテストされサポートされているバージョンのコネクタも含まれています。詳細は以下をご覧ください<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">*自己バランス型クラスター。*自動化された負荷分散、障害検出、自己修復を提供します。また、手動で調整することなく、必要に応じてブローカーを追加または廃止するためのサポートも提供します。</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">*合流クラスターのリンク。*クラスターを直接接続し、リンク ブリッジを介して 1 つのクラスターから別のクラスターにトピックをミラーリングします。クラスター リンクにより、マルチデータセンター、マルチクラスター、ハイブリッド クラウドの展開のセットアップが簡素化されます。</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">*Confluent 自動データバランサー*クラスター内のブローカーの数、パーティションのサイズ、パーティションの数、およびリーダーの数を監視します。これにより、データをシフトしてクラスター全体で均一なワークロードを作成しながら、再バランスのトラフィックを調整して、再バランス中の本番ワークロードへの影響を最小限に抑えることができます。</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">*合流型複製子。*複数のデータ センターで複数の Kafka クラスターを管理することがこれまで以上に簡単になります。</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">*階層型ストレージ*お気に入りのクラウド プロバイダーを使用して大量の Kafka データを保存するオプションを提供し、運用上の負担とコストを削減します。階層型ストレージを使用すると、コスト効率の高いオブジェクト ストレージにデータを保存し、コンピューティング リソースが必要な場合にのみブローカーを拡張できます。</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">*Confluent JMS クライアント。* Confluent Platform には、Kafka 用の JMS 互換クライアントが含まれています。この Kafka クライアントは、バックエンドとして Kafka ブローカーを使用して、JMS 1.1 標準 API を実装します。これは、JMS を使用するレガシー アプリケーションがあり、既存の JMS メッセージ ブローカーを Kafka に置き換えたい場合に役立ちます。</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">*Confluent MQTT プロキシ。*中間に MQTT ブローカーを必要とせずに、MQTT デバイスおよびゲートウェイから Kafka に直接データを公開する方法を提供します。</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">*Confluent セキュリティ プラグイン* Confluent セキュリティ プラグインは、さまざまな Confluent Platform ツールおよび製品にセキュリティ機能を追加するために使用されます。現在、Confluent REST プロキシには、受信リクエストを認証し、認証されたプリンシパルを Kafka へのリクエストに伝播するのに役立つプラグインが用意されています。これにより、Confluent REST プロキシ クライアントは Kafka ブローカーのマルチテナント セキュリティ機能を利用できるようになります。</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetAppStorageGRID</block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRIDは、高性能でコスト効率に優れたオブジェクト ストレージ プラットフォームです。階層型ストレージを使用すると、ローカル ストレージまたはブローカーの SAN ストレージに保存されている Confluent Kafka 上のデータの大部分が、リモート オブジェクト ストアにオフロードされます。この構成により、クラスターの再調整、拡張、縮小、または障害が発生したブローカーの交換にかかる時間とコストが削減され、運用が大幅に改善されます。オブジェクト ストレージは、オブジェクト ストア層に存在するデータの管理において重要な役割を果たすため、適切なオブジェクト ストレージを選択することが重要です。</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID は、分散型のノードベースのグリッド アーキテクチャを使用して、インテリジェントなポリシー主導のグローバル データ管理を提供します。ユビキタスなグローバル オブジェクト名前空間と洗練されたデータ管理機能を組み合わせることで、ペタバイト単位の非構造化データと数十億個のオブジェクトの管理を簡素化します。シングルコールのオブジェクト アクセスはサイト全体に拡張され、高可用性アーキテクチャを簡素化するとともに、サイトまたはインフラストラクチャの停止に関係なく継続的なオブジェクト アクセスを保証します。</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">マルチテナンシーにより、複数の非構造化クラウドおよびエンタープライズ データ アプリケーションを同じグリッド内で安全に処理できるようになり、 NetApp StorageGRIDの ROI と使用事例が増加します。メタデータ駆動型のオブジェクト ライフサイクル ポリシーを使用して複数のサービス レベルを作成し、複数の地域にわたって耐久性、保護、パフォーマンス、および局所性を最適化できます。ユーザーは、常に変化する IT 環境で要件が変わったときに、データ管理ポリシーを調整し、トラフィック制限を監視および適用して、中断なくデータ ランドスケープに再調整することができます。</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">グリッドマネージャーによるシンプルな管理</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID Grid Manager は、ブラウザベースのグラフィカル インターフェイスであり、世界中に分散された場所にあるStorageGRIDシステムを単一の画面で構成、管理、監視できます。</block>
  <block id="772a64d9b71789d3f7910c440c370541" category="paragraph"><block ref="772a64d9b71789d3f7910c440c370541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID Grid Manager インターフェイスを使用して、次のタスクを実行できます。</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">画像、ビデオ、レコードなどのオブジェクトの、グローバルに分散されたペタバイト規模のリポジトリを管理します。</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">オブジェクトの可用性を確保するためにグリッド ノードとサービスを監視します。</block>
  <block id="e21286be18c417a3042cb53e1dd1e8da" category="list-text">情報ライフサイクル管理 (ILM) ルールを使用して、時間の経過に伴うオブジェクト データの配置を管理します。これらのルールは、オブジェクトのデータが取り込まれた後に何が起こるか、どのように損失から保護されるか、オブジェクト データがどこに保存されるか、どのくらいの期間保存されるかを制御します。</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">システム内のトランザクション、パフォーマンス、および操作を監視します。</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">情報ライフサイクル管理ポリシー</block>
  <block id="0550f1f7df7311673165b9915b4d10b2" category="paragraph">StorageGRIDには、特定のパフォーマンスとデータ保護の要件に応じて、オブジェクトのレプリカ コピーを保持したり、2+1 や 4+2 などの EC (消去コーディング) スキームを使用してオブジェクトを保存したりするなど、柔軟なデータ管理ポリシーがあります。ワークロードと要件は時間の経過とともに変化するため、ILM ポリシーも時間の経過とともに変更する必要があるのが一般的です。  ILM ポリシーの変更は中核機能であり、これによりStorageGRID のお客様は変化し続ける環境に迅速かつ簡単に適応できます。</block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">パフォーマンス</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712、SG5760、SG6060、またはSGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRIDは、VM、ベアメタル、または専用アプライアンスなどのストレージノードを追加することでパフォーマンスを拡張します。<block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block> 。当社のテストでは、SGF6024 アプライアンスを使用した最小サイズの 3 ノード グリッドで Apache Kafka の主要なパフォーマンス要件を超えました。顧客が追加のブローカーを使用して Kafka クラスターを拡張すると、ストレージ ノードを追加してパフォーマンスと容量を向上させることができます。</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">ロードバランサとエンドポイントの構成</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRIDの管理ノードは、 StorageGRIDシステムを表示、構成、管理するための Grid Manager UI (ユーザー インターフェイス) と REST API エンドポイント、およびシステム アクティビティを追跡するための監査ログを提供します。 Confluent Kafka 階層型ストレージに高可用性の S3 エンドポイントを提供するために、管理ノードとゲートウェイ ノードでサービスとして実行されるStorageGRIDロード バランサーを実装しました。さらに、ロード バランサはローカル トラフィックも管理し、GSLB (グローバル サーバー負荷分散) と通信して災害復旧を支援します。</block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">エンドポイント構成をさらに強化するために、 StorageGRID は管理ノードに組み込まれたトラフィック分類ポリシーを提供し、ワークロード トラフィックを監視し、ワークロードにさまざまなサービス品質 (QoS) 制限を適用できるようにします。トラフィック分類ポリシーは、ゲートウェイ ノードと管理ノードのStorageGRIDロード バランサ サービスのエンドポイントに適用されます。これらのポリシーは、トラフィックのシェーピングと監視に役立ちます。</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRIDにおけるトラフィック分類</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRIDには QoS 機能が組み込まれています。トラフィック分類ポリシーは、クライアント アプリケーションから送信されるさまざまな種類の S3 トラフィックを監視するのに役立ちます。次に、入力/出力帯域幅、読み取り/書き込み同時要求の数、または読み取り/書き込み要求レートに基づいてこのトラフィックに制限を設定するポリシーを作成して適用できます。</block>
  <block id="75dab812558989436263375877a82fb6" category="paragraph">Apache Kafka は、Java と Scala で記述されたストリーム処理を使用したソフトウェア バスのフレームワーク実装です。リアルタイムのデータフィードを処理するための、統合された高スループット、低レイテンシのプラットフォームを提供することを目的としています。  Kafka は、Kafka Connect を介してデータのエクスポートとインポートのために外部システムに接続でき、Java ストリーム処理ライブラリである Kafka ストリームを提供します。 Kafka は、効率性を重視して最適化されたバイナリ TCP ベースのプロトコルを使用し、メッセージを自然にグループ化してネットワーク ラウンドトリップのオーバーヘッドを削減する「メッセージ セット」抽象化に依存しています。これにより、大規模な順次ディスク操作、大規模なネットワーク パケット、連続したメモリ ブロックが可能になり、Kafka はランダム メッセージ書き込みのバースト ストリームを線形書き込みに変換できるようになります。次の図は、Apache Kafka の基本的なデータ フローを示しています。</block>
  <block id="3c061e9fbf92872063da256279195fbb" category="paragraph"><block ref="3c061e9fbf92872063da256279195fbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka は、プロデューサーと呼ばれる任意の数のプロセスから送信されるキーと値のメッセージを保存します。データは、異なるトピック内の異なるパーティションに分割できます。パーティション内では、メッセージはオフセット (パーティション内のメッセージの位置) によって厳密に順序付けられ、タイムスタンプとともにインデックスが付けられて保存されます。コンシューマーと呼ばれる他のプロセスは、パーティションからメッセージを読み取ることができます。ストリーム処理の場合、Kafka は、Kafka からデータを消費し、結果を Kafka に書き戻す Java アプリケーションを作成できる Streams API を提供します。  Apache Kafka は、Apache Apex、Apache Flink、Apache Spark、Apache Storm、Apache NiFi などの外部ストリーム処理システムとも連携します。</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka は 1 つ以上のサーバー (ブローカーと呼ばれる) のクラスター上で実行され、すべてのトピックのパーティションはクラスター ノード全体に分散されます。さらに、パーティションは複数のブローカーに複製されます。このアーキテクチャにより、Kafka はフォールト トレラントな方法で大量のメッセージ ストリームを配信できるようになり、Java Message Service (JMS)、Advanced Message Queuing Protocol (AMQP) などの従来のメッセージング システムの一部を置き換えることが可能になりました。  0.11.0.0 リリース以降、Kafka は、Streams API を使用して 1 回だけのストリーム処理を提供するトランザクション書き込みを提供します。</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka は、通常のトピックと圧縮されたトピックの 2 種類のトピックをサポートしています。通常のトピックは、保持時間またはスペースの制限付きで構成できます。指定された保持期間よりも古いレコードがある場合、またはパーティションのスペース制限を超えた場合、Kafka は古いデータを削除してストレージスペースを解放できます。デフォルトでは、トピックの保持期間は 7 日間に設定されていますが、データを無期限に保存することもできます。圧縮されたトピックの場合、レコードは時間または領域の境界に基づいて期限切れになることはありません。代わりに、Kafka は後続のメッセージを同じキーを持つ古いメッセージの更新として扱い、キーごとに最新のメッセージを削除しないことを保証します。ユーザーは、特定のキーに null 値を設定したいわゆるトゥームストーン メッセージを書き込むことで、メッセージを完全に削除できます。</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka には 5 つの主要な API があります。</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">*プロデューサー API。*アプリケーションがレコードのストリームを公開することを許可します。</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">*コンシューマー API*アプリケーションがトピックをサブスクライブし、レコードのストリームを処理することを許可します。</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">*コネクタ API。*トピックを既存のアプリケーションにリンクできる再利用可能なプロデューサー API とコンシューマー API を実行します。</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">*ストリーム API。*この API は入力ストリームを出力に変換し、結果を生成します。</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">*管理 API。*  Kafka トピック、ブローカー、およびその他の Kafka オブジェクトを管理するために使用されます。</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">コンシューマー API とプロデューサー API は、Kafka メッセージング プロトコルの上に構築され、Java での Kafka コンシューマー クライアントとプロデューサー クライアントのリファレンス実装を提供します。基礎となるメッセージング プロトコルはバイナリ プロトコルであり、開発者はこれを使用して任意のプログラミング言語で独自のコンシューマー クライアントまたはプロデューサー クライアントを作成できます。これにより、Kafka は Java 仮想マシン (JVM) エコシステムから解放されます。利用可能な非 Java クライアントのリストは、Apache Kafka wiki で管理されています。</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka のユースケース</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka は、メッセージング、Web サイトのアクティビティ追跡、メトリック、ログ集約、ストリーム処理、イベント ソーシング、コミット ログで最も人気があります。</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka はスループット、組み込みのパーティショニング、レプリケーション、フォールト トレランスが向上しており、大規模なメッセージ処理アプリケーションに適したソリューションとなっています。</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka は、追跡パイプライン内のユーザーのアクティビティ (ページ ビュー、検索) を、リアルタイムのパブリッシュ/サブスクライブ フィードのセットとして再構築できます。</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka は運用監視データによく使用されます。これには、分散アプリケーションからの統計を集約して、運用データの集中フィードを生成することが含まれます。</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">多くの人が、ログ集約ソリューションの代わりとして Kafka を使用しています。ログ集約では通常、サーバーから物理ログ ファイルが収集され、処理のために中央の場所 (ファイル サーバーや HDFS など) に配置されます。 Kafka はファイルの詳細を抽象化し、ログまたはイベント データをメッセージ ストリームとしてよりクリーンに抽象化します。これにより、処理のレイテンシが低減され、複数のデータ ソースと分散データ消費のサポートが容易になります。</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka の多くのユーザーは、複数のステージで構成される処理パイプラインでデータを処理します。このパイプラインでは、生の入力データが Kafka トピックから消費され、その後、さらなる消費や後続処理のために、集約、拡充、またはその他の方法で新しいトピックに変換されます。たとえば、ニュース記事を推奨するための処理パイプラインでは、RSS フィードから記事のコンテンツをクロールし、「記事」トピックに公開する場合があります。さらに処理を進めると、このコンテンツが正規化または重複排除され、クリーンアップされた記事コンテンツが新しいトピックに公開され、最終処理段階でこのコンテンツをユーザーに推奨しようとする可能性があります。このような処理パイプラインは、個々のトピックに基づいてリアルタイムのデータフローのグラフを作成します。</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">イベント サウシングは、状態の変化が時間順のレコードのシーケンスとして記録されるアプリケーション設計のスタイルです。  Kafka は非常に大きなログ データの保存をサポートしているため、このスタイルで構築されたアプリケーションにとって優れたバックエンドになります。</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka は、分散システムの一種の外部コミット ログとして機能します。ログはノード間でデータを複製するのに役立ち、障害が発生したノードがデータを復元するための再同期メカニズムとして機能します。  Kafka のログ圧縮機能は、このユースケースのサポートに役立ちます。</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform は、アプリケーション開発と接続の高速化、ストリーム処理による変換の実現、大規模なエンタープライズ運用の簡素化、厳格なアーキテクチャ要件への対応を支援するように設計された高度な機能で Kafka を補完する、エンタープライズ対応のプラットフォームです。 Apache Kafka のオリジナル作成者によって構築された Confluent は、エンタープライズ グレードの機能によって Kafka の利点を拡大するとともに、Kafka の管理や監視の負担を軽減します。現在、Fortune 100 企業の 80% 以上がデータ ストリーミング テクノロジーを活用しており、そのほとんどが Confluent を使用しています。</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform を使用すると、異なるシステム間でデータがどのように転送されるか、または統合されるかといった基礎となる仕組みを心配するのではなく、データからビジネス価値を引き出す方法に集中できます。具体的には、Confluent Platform は、データ ソースを Kafka に接続し、ストリーミング アプリケーションを構築するだけでなく、Kafka インフラストラクチャのセキュリティ保護、監視、管理も簡素化します。現在、Confluent Platform は、金融サービス、オムニチャネル小売、自律走行車から不正検出、マイクロサービス、IoT まで、さまざまな業界の幅広いユースケースに使用されています。</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">次の図は、Confluent Kafka プラットフォームのコンポーネントを示しています。</block>
  <block id="4f93c36b7d83350cef38a27356c0d5c9" category="paragraph"><block ref="4f93c36b7d83350cef38a27356c0d5c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95577831087dbd899deb60b296f64a9c" category="section-title">Confluentのイベントストリーミングテクノロジーの概要</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent Platformの中核は<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>最も人気のあるオープンソースの分散ストリーミング プラットフォームです。  Kafka の主な機能は次のとおりです。</block>
  <block id="8da3f3354457b244e53f1423a77e8944" category="section-title">Confluent プラットフォームのエンタープライズ機能の概要</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">*Confluent コントロール センター*  Kafka を管理および監視するための GUI ベースのシステム。  Kafka Connect を簡単に管理し、他のシステムへの接続を作成、編集、管理できるようになります。</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">*Kafka への Confluent コネクタ。*コネクタは Kafka Connect API を使用して、Kafka をデータベース、キー値ストア、検索インデックス、ファイルシステムなどの他のシステムに接続します。 Confluent Hub には、最も人気のあるデータ ソースとシンク用のダウンロード可能なコネクタがあり、Confluent Platform で完全にテストされサポートされているバージョンのコネクタも含まれています。詳細は以下をご覧ください<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>。</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">*自己バランス型クラスター。*自動化された負荷分散、障害検出、自己修復を提供します。手動で調整することなく、必要に応じてブローカーを追加または廃止するためのサポートを提供します。</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">*Confluent 自動データバランサー*クラスター内のブローカーの数、パーティションのサイズ、パーティションの数、およびリーダーの数を監視します。これにより、データをシフトしてクラスター全体で均一なワークロードを作成しながら、再バランスのトラフィックを調整して、再バランス中の本番ワークロードへの影響を最小限に抑えることができます。</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157-DEPLOY: NetAppストレージ ソリューションを使用した Apache Spark ワークロード</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-DEPLOY では、NetApp NFS AFFストレージ システム上の Apache Spark SQL のパフォーマンスと機能の検証について説明します。さまざまなシナリオに基づいた構成、アーキテクチャ、パフォーマンス テスト、およびNetApp ONTAPデータ管理ソフトウェアで Spark を使用する際の推奨事項について説明します。また、JBOD (Just Bunch Of Disks) とNetApp AFF A800ストレージ コントローラに基づくテスト結果も説明します。</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">最新のデータ分析 - さまざまな分析戦略に合わせたさまざまなソリューション</block>
  <block id="139dc952e7e6df2bb7d8000f47a42232" category="paragraph">このホワイト ペーパーでは、 NetApp の最新データ分析ソリューション戦略について説明します。これには、ビジネス成果、顧客の課題、テクノロジのトレンド、競合のレガシー アーキテクチャ、最新のワークフロー、ユース ケース、業界、クラウド、テクノロジ パートナー、データ ムーバー、 NetApp Active IQ Digital Advisor ( Digital Advisorとも呼ばれます)、 NetApp DataOps Toolkit、Hadoop to Spark、 NetApp Trident Protect を使用したソフトウェア定義ストレージ、コンテナ、エンタープライズ データ管理、アーカイブ、および AI と分析の目標を達成するための階層化に関する詳細と、 NetAppと顧客が協力してデータ アーキテクチャを最新化する方法が含まれています。</block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">このTRでは次の資料を参照しています。</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark のアーキテクチャとコンポーネント</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Sparkのユースケース</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="list-text">バート</block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">広告クリック予測のためのディープネットワークとクロスネットワーク</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="list-text">FlexGroup</block>
  <block id="63e6562f5c9bc7c86f115b960762e586" category="paragraph"><block ref="63e6562f5c9bc7c86f115b960762e586" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">ストリーミングETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Hadoop向けNetApp Eシリーズソリューション</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="list-text">NetApp の最新データ分析ソリューション</block>
  <block id="105db1e1e5e90ed75dc22390638d6b74" category="inline-link-macro">データ分析ソリューション</block>
  <block id="a1acc25bb8d463a22c069a9ae3d7a581" category="paragraph"><block ref="a1acc25bb8d463a22c069a9ae3d7a581" category="inline-link-macro-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">XCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="1ae50adfec05c416d0398e26bea5fc01" category="list-text">BlueXPコピーと同期</block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">データオプスツールキット</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">このページでは、主要な AI、ML、DL のユースケースとアーキテクチャについて詳しく説明します。</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">主要なAI、ML、DLのユースケースとアーキテクチャ</block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">主要な AI、ML、DL のユースケースと方法論は、次のセクションに分けられます。</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">Spark NLPパイプラインとTensorFlow分散推論</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">次のリストには、さまざまな開発レベルでデータ サイエンス コミュニティに採用されている最も人気のあるオープン ソース NLP ライブラリが含まれています。</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">自然言語ツールキット（NLTK）</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block> 。すべての NLP テクニックに対応する完全なツールキット。  2000年代初頭から維持されてきました。</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">テキストブロブ</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block> 。NLTK と Pattern をベースに構築された、使いやすい NLP ツール Python API。</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">スタンフォード・コアNLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block> 。スタンフォード NLP グループによって開発された Java の NLP サービスとパッケージ。</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">ゲンシム</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block> 。Topic Modelling for Humans は、チェコデジタル数学ライブラリ プロジェクト用の Python スクリプトのコレクションとして始まりました。</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">スパシー</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block> 。トランスフォーマー向け GPU アクセラレーションを備えた Python と Cython を使用したエンドツーエンドの産業用 NLP ワークフロー。</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">ファストテキスト</block>
  <block id="c3ad48f357ddb1f4eb538b483e904fbe" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block> 。Facebook の AI 研究 (FAIR) ラボによって作成された、単語埋め込みの学習と文分類のための無料の軽量オープンソース NLP ライブラリです。</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">スパークML</block>
  <block id="16cbab2d9cd08ef0822a3f68f3792982" category="paragraph">Spark NLP は、すべての NLP タスクと要件に対応する単一の統合ソリューションであり、実際の運用ユースケースでスケーラブルで高性能、かつ高精度な NLP ベースのソフトウェアを実現します。転移学習を活用し、研究や業界全体で最新の最先端のアルゴリズムとモデルを実装します。 Sparkは上記のライブラリを完全にサポートしていないため、Spark NLPは<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block>ミッションクリティカルな本番ワークフロー向けのエンタープライズグレードの NLP ライブラリとして、Spark の汎用インメモリ分散データ処理エンジンを活用します。そのアノテーターは、ルールベースのアルゴリズム、機械学習、TensorFlow を活用して、ディープラーニングの実装を強化します。これには、トークン化、レマタイズ化、ステミング、品詞タグ付け、固有表現認識、スペルチェック、感情分析などを含む一般的な NLP タスクが含まれます。</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">BERT (Bidirectional Encoder Representations from Transformers) は、NLP 用のトランスフォーマー ベースの機械学習手法です。事前トレーニングと微調整の概念を普及させました。 BERT のトランスフォーマー アーキテクチャは機械翻訳から生まれたもので、リカレント ニューラル ネットワーク (RNN) ベースの言語モデルよりも長期的な依存関係をより適切にモデル化します。また、すべてのトークンのランダムな 15% がマスクされ、モデルがそれを予測することで真の双方向性を実現するマスク言語モデリング (MLM) タスクも導入されました。</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">ロイターTRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">金融フレーズバンク</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">説明文書DL</block>
  <block id="75396b8f8501a234110f5c2b41e8f2c1" category="paragraph">金融感情分析は、専門的な言語とその分野のラベル付きデータが不足しているため、困難です。 FinBERTは、事前学習済みのBERTに基づく言語モデルであり、ドメイン適応された。<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block> 、金融コーパス、ラベル付きデータで微調整された（<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block> ）を使用して金融センチメントを分類します。研究者らはニュース記事から金融用語を含む4,500の文を抽出した。その後、金融のバックグラウンドを持つ 16 人の専門家と修士課程の学生が、その文章を肯定的、中立的、否定的と分類しました。  FinBERTと他の2つの事前学習済みパイプラインを使用して、2016年から2020年までのNASDAQ上場企業トップ10社の決算説明会の記録の感情を分析するためのエンドツーエンドのSparkワークフローを構築しました。<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block> ) を Spark NLP から取得します。</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLP の基盤となるディープラーニング エンジンは TensorFlow です。これは、モデルの構築を容易にし、どこでも堅牢な ML を生成でき、研究のための強力な実験を可能にする、エンドツーエンドのオープンソース 機械学習プラットフォームです。したがって、Sparkでパイプラインを実行する場合<block ref="cbfea9758df7100c6471e30d3f36d3e1" prefix=" " category="inline-code"></block>モードでは、基本的に、1 つのマスター ノードと複数のワーカー ノード、およびクラスターにマウントされたネットワーク接続ストレージにわたって、データとモデルの並列化を伴う分散 TensorFlow を実行していました。</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod分散トレーニング</block>
  <block id="7a2c7ce5896a9e74083af4e2048bb5a8" category="inline-link">Hadoop向けNetApp Eシリーズソリューション</block>
  <block id="bd3eac2bb98f840c3e8ec0d92eb9a66f" category="paragraph">MapReduce 関連のパフォーマンスに関するコア Hadoop 検証は、TeraGen、TeraSort、TeraValidate、および DFSIO (読み取りと書き込み) を使用して実行されます。  TeraGenとTeraSortの検証結果は、<block ref="c276ecb51e19896948b1464a39a504e4" category="inline-link-rx"></block> AFFの「ストレージ階層化」セクションを参照してください。</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">SparkのHovorod</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">お客様のご要望に基づき、Spark を使用した分散トレーニングは、さまざまなユースケースの中でも最も重要なものの 1 つであると考えています。この文書では、<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> NetApp All Flash FAS (AFF) ストレージ コントローラー、 Azure NetApp Files、 StorageGRIDを使用して、 NetApp のオンプレミス、クラウド ネイティブ、ハイブリッド クラウド ソリューションで Spark のパフォーマンスを検証します。</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Spark パッケージは、Horovod の便利なラッパーを提供します。これにより、Spark クラスターでの分散トレーニング ワークロードの実行が簡単になり、データ処理、モデル トレーニング、モデル評価がすべてトレーニング データと推論データが存在する Spark で実行される、緊密なモデル設計ループが可能になります。</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann ストア売上</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Spark で Horovod を実行するための API には、高レベルの Estimator API と低レベルの Run API の 2 つがあります。どちらも Spark 実行プログラムで Horovod を起動するために同じ基本メカニズムを使用しますが、Estimator API はデータ処理、モデル トレーニング ループ、モデル チェックポイント、メトリック収集、分散トレーニングを抽象化します。  Horovod Spark Estimators、TensorFlow、Kerasを使用して、エンドツーエンドのデータ準備と分散トレーニングワークフローを構築しました。<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block>競争。</block>
  <block id="85cbe9ee50d80a624a5aacb533195f44" category="paragraph">脚本<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>セクションをご覧ください<block ref="b6cb6fe53e443d0379ed59c804a7a30d" category="inline-link-macro-rx"></block>3 つの部分から構成されます。</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">最初の部分では、Kaggle によって提供され、コミュニティによって収集された CSV ファイルの初期セットに対してさまざまなデータ前処理手順を実行します。入力データは、<block ref="13148717f8faa9037f37d28971dfc219" prefix=" " category="inline-code"></block>サブセットとテストデータセット。</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">2 番目の部分では、対数シグモイド活性化関数と Adam オプティマイザーを備えた Keras ディープ ニューラル ネットワーク (DNN) モデルを定義し、Spark 上の Horovod を使用してモデルの分散トレーニングを実行します。</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">3 番目の部分では、検証セット全体の平均絶対誤差を最小化する最適なモデルを使用して、テスト データセットの予測を実行します。次に、出力 CSV ファイルを作成します。</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="inline-link-macro">機械学習</block>
  <block id="4f57ef43a107778b9d34e7c8fabafb09" category="paragraph">セクションを参照<block ref="c54562cdac0f1ff9f8a09a53f27a34da" category="inline-link-macro-rx"></block>さまざまな実行時間の比較結果。</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">Keras を使用したマルチワーカー ディープラーニングによる CTR 予測</block>
  <block id="d003b4f5bf1fc42082f5817cb6e961dc" category="paragraph">ML プラットフォームとアプリケーションの最近の進歩により、大規模な学習に多くの注目が集まっています。クリックスルー率 (CTR) は、オンライン広告の表示回数 100 回あたりの平均クリックスルー数 (パーセントで表されます) として定義されます。これは、デジタル マーケティング、小売、電子商取引、サービス プロバイダーなど、さまざまな業界の垂直分野やユース ケースで重要な指標として広く採用されています。  CTRと分散トレーニングのパフォーマンス結果の適用の詳細については、<block ref="7cd04747490b9545ba139688b057ed31" category="inline-link-macro-rx"></block>セクション。</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo テラバイトクリックログデータセット</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">この技術レポートでは、<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (TR-4904 を参照) Keras を使用してマルチワーカー分散ディープラーニングを実施し、Deep and Cross Network (DCN) モデルを含む Spark ワークフローを構築し、ログ損失エラー関数の観点からそのパフォーマンスをベースライン Spark ML ロジスティック回帰モデルと比較します。  DCN は、制限された次数の有効な特徴相互作用を効率的にキャプチャし、高度に非線形な相互作用を学習し、手動の特徴エンジニアリングや徹底的な検索を必要とせず、計算コストが低くなります。</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">Web 規模の推奨システムのデータは大部分が離散的かつカテゴリ化されているため、特徴空間が大きくまばらになり、特徴の探索が困難になります。このため、ほとんどの大規模システムはロジスティック回帰などの線形モデルに制限されています。ただし、頻繁に予測される特徴を識別し、同時に目に見えない、またはまれなクロス特徴を探索することが、適切な予測を行うための鍵となります。線形モデルはシンプルで解釈しやすく、拡張も容易ですが、表現力には限界があります。</block>
  <block id="b5353aa08a1306ca5da9e3faacc66b15" category="paragraph">一方、クロス特徴はモデルの表現力の向上に重要であることが示されています。残念ながら、このような特徴を識別するには、多くの場合、手動の特徴エンジニアリングや徹底的な検索が必要になります。目に見えない機能の相互作用を一般化することは、多くの場合困難です。 DCN のようなクロスニューラルネットワークを使用すると、特徴の交差を明示的に自動的に適用することで、タスク固有の特徴エンジニアリングを回避できます。クロス ネットワークは複数のレイヤーで構成されており、相互作用の最高度はレイヤーの深さによって決定されると考えられます。各レイヤーは、既存の相互作用に基づいて高次の相互作用を生成し、前のレイヤーからの相互作用を維持します。</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">ディープ ニューラル ネットワーク (DNN) は、機能間の非常に複雑な相互作用をキャプチャできる可能性を秘めています。ただし、DCN と比較すると、ほぼ 1 桁多くのパラメータが必要となり、クロス フィーチャを明示的に形成できず、一部の種類のフィーチャの相互作用を効率的に学習できない可能性があります。クロスネットワークはメモリ効率が高く、実装が簡単です。クロスコンポーネントと DNN コンポーネントを共同でトレーニングすることで、予測機能のインタラクションを効率的にキャプチャし、Criteo CTR データセットで最先端のパフォーマンスを実現します。</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">ディープクリック率</block>
  <block id="c024a57f5a6b531b69123f5c78627fb9" category="paragraph">DCN モデルは、埋め込みおよびスタッキング レイヤーから始まり、クロス ネットワークとディープ ネットワークが並列に続きます。次に、2 つのネットワークからの出力を結合する最終結合レイヤーが続きます。入力データは、スパースな特徴と密な特徴を持つベクトルにすることができます。 Sparkでは、ライブラリには次のような型が含まれています<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>。したがって、ユーザーはこれら 2 つを区別し、それぞれの関数やメソッドを呼び出すときに注意することが重要です。 CTR予測のようなWebスケールのレコメンデーションシステムでは、入力は主にカテゴリ特徴であり、例えば<block ref="f296a99dd35f7e3e83183f98a62982bf" prefix=" " category="inline-code"></block>。このような特徴は、多くの場合、ワンホットベクトルとしてエンコードされます。たとえば、<block ref="05b38799fb2e84c83a72d68e1cb6ff67" prefix=" " category="inline-code"></block> 。ワンホットエンコーディング（OHE）<block ref="4fe0a291146b8f5681b4e75f2031c1b1" prefix=" " category="inline-code"></block>常に変化し、増え続ける語彙を持つ現実世界のデータセットを扱うときに役立ちます。例を修正しました<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block>大規模な語彙を処理し、DCN の埋め込みおよびスタッキング層に埋め込みベクトルを作成します。</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo ディスプレイ広告データセット</block>
  <block id="75253ebc28edb897ef33f95dd995dd58" category="paragraph">その<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block>広告のクリック率を予測します。 13 個の整数特徴と 26 個のカテゴリ特徴があり、各カテゴリは高いカーディナリティを持っています。このデータセットでは、入力サイズが大きいため、logloss の 0.001 の改善は実質的に重要です。大規模なユーザーベースに対する予測精度のわずかな向上は、企業の収益の大幅な増加につながる可能性があります。データセットには、7 日間の 11 GB のユーザー ログが含まれており、これは約 4,100 万件のレコードに相当します。  Sparkを使用しました<block ref="26ef62452ce5167b94d9bf8e4552df44" prefix=" " category="inline-code"></block>データをランダムに分割し、トレーニング用（80%）、クロス検証用（10%）、残りの10%をテスト用にします。</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN は、Keras を使用して TensorFlow に実装されました。  DCN を使用してモデル トレーニング プロセスを実装する場合、主なコンポーネントは 4 つあります。</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">*データの処理と埋め込み。*実数値の特徴は、対数変換を適用することによって正規化されます。カテゴリ特徴量の場合、特徴量を6×(カテゴリカーディナリティ)1/4次元の稠密ベクトルに埋め込みます。すべての埋め込みを連結すると、次元 1026 のベクトルが生成されます。</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">*最適化。* Adam オプティマイザーを使用してミニバッチ確率最適化を適用しました。バッチサイズは 512 に設定されました。ディープ ネットワークにバッチ正規化が適用され、勾配クリップ ノルムは 100 に設定されました。</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">*正規化。*  L2 正則化またはドロップアウトは効果的ではないことが判明したため、早期停止を使用しました。</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">*ハイパーパラメータ*隠し層の数、隠し層のサイズ、初期学習率、およびクロス層の数に対するグリッド検索に基づいて結果を報告します。隠し層の数は 2 ～ 5 で、隠し層のサイズは 32 ～ 1024 でした。 DCN の場合、クロス レイヤーの数は 1 ～ 6 でした。初期学習率は 0.0001 から 0.001 まで 0.0001 ずつ増分して調整されました。すべての実験では、トレーニング ステップ 150,000 で早期停止が適用され、それを超えるとオーバーフィッティングが発生し始めました。</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">ディープFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">自動挿入</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="edddedbe12bade5d0d47c6600aa7fc40" category="paragraph">DCNに加えて、CTR予測のための他の一般的なディープラーニングモデルもテストしました。<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block> 、<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block> 、 そして<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>。</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">検証に使用されるアーキテクチャ</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">この検証では、 AFF-A800 HA ペアを持つ 4 つのワーカー ノードと 1 つのマスター ノードを使用しました。すべてのクラスター メンバーは 10GbE ネットワーク スイッチを介して接続されていました。</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">このNetApp Spark ソリューションの検証では、E5760、E5724、 AFF-A800 という 3 つの異なるストレージ コントローラを使用しました。  E シリーズ ストレージ コントローラは、12Gbps SAS 接続で 5 つのデータ ノードに接続されていました。  AFF HA ペア ストレージ コントローラは、10GbE 接続を介してエクスポートされた NFS ボリュームを Hadoop ワーカー ノードに提供します。  Hadoop クラスター メンバーは、E シリーズ、 AFF、およびStorageGRID Hadoop ソリューション内の 10GbE 接続を介して接続されていました。</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">検証に使用されるアーキテクチャ。</block>
  <block id="dbb9fda021247ba28b40c95fcf20d529" category="paragraph"><block ref="dbb9fda021247ba28b40c95fcf20d529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">最新のエンタープライズ データ センターは、オンプレミスや複数のパブリック クラウドで、一貫した運用モデルを備えた継続的なデータ管理プレーンを通じて複数の分散インフラストラクチャ環境を接続するハイブリッド クラウドです。ハイブリッド クラウドを最大限に活用するには、データ変換やアプリケーションのリファクタリングを行わずに、オンプレミス環境とマルチクラウド環境間でデータをシームレスに移動できる必要があります。</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">ハイブリッドクラウドソリューション</block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">顧客は、データ保護などのユースケースのためにセカンダリ ストレージをクラウドに移行するか、アプリケーション開発や DevOps などのビジネス クリティカル度の低いワークロードをクラウドに移行するかのいずれかの方法でハイブリッド クラウドの取り組みを開始すると述べています。その後、より重要なワークロードに移行します。最も人気のあるハイブリッド クラウド ワークロードには、Web およびコンテンツのホスティング、DevOps およびアプリケーション開発、データベース、分析、コンテナ化されたアプリなどがあります。これまで、企業の AI プロジェクトの複雑さ、コスト、リスクは、実験段階から実稼働段階までの AI 導入を妨げてきました。</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">NetApp のハイブリッド クラウド ソリューションを利用すると、お客様は、分散環境全体のデータとワークフロー管理を単一のコントロール パネルで統合されたセキュリティ、データ ガバナンス、コンプライアンス ツールから恩恵を受けられると同時に、消費量に基づいて総所有コストを最適化できます。次の図は、顧客のビッグデータ分析データにマルチクラウド接続を提供する役割を担うクラウド サービス パートナーのソリューション例です。</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">クラウド サービス パートナーのソリューション例。</block>
  <block id="f6eb8b15960b6dcbfd7e927644b45d94" category="paragraph"><block ref="f6eb8b15960b6dcbfd7e927644b45d94" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">このシナリオでは、さまざまなソースから AWS に受信された IoT データは、 NetApp Private Storage (NPS) の中央の場所に保存されます。 NPS ストレージは、AWS および Azure にある Spark または Hadoop クラスターに接続され、複数のクラウドで実行されるビッグ データ分析アプリケーションが同じデータにアクセスできるようになります。このユースケースの主な要件と課題は次のとおりです。</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">データは、さまざまなセンサーやハブを介して、オンプレミスやクラウド環境などのさまざまなソースから受信する必要があります。</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">ソリューションは効率的かつ費用対効果の高いものでなければなりません。</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">主な課題は、さまざまなオンプレミス環境とクラウド環境間でハイブリッド分析サービスを提供する、コスト効率が高く効率的なソリューションを構築することです。</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">当社のデータ保護およびマルチクラウド接続ソリューションは、複数のハイパースケーラーにクラウド分析アプリケーションを導入する際の問題点を解決します。上の図に示すように、センサーからのデータは Kafka を介してストリーミングされ、AWS Spark クラスターに取り込まれます。データは、Equinix データセンター内のクラウド プロバイダーの外部にある NPS にある NFS 共有に保存されます。</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">NetApp NPS は、それぞれ Direct Connect 接続と Express Route 接続を介して Amazon AWS と Microsoft Azure に接続されているため、お客様は In-Place Analytics モジュールを活用して、Amazon と AWS の両方の分析クラスターからデータにアクセスできます。その結果、オンプレミスとNPSストレージの両方でONTAPソフトウェアが実行されるため、<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> NPS データをオンプレミス クラスターにミラーリングし、オンプレミスと複数のクラウドにわたるハイブリッド クラウド分析を提供できます。</block>
  <block id="bc35f58684dbedfb73dd7ff64a4bd5a8" category="paragraph">最高のパフォーマンスを得るために、 NetAppでは通常、複数のネットワーク インターフェイスと直接接続または高速ルートを使用してクラウド インスタンスからデータにアクセスすることを推奨しています。弊社には他にもデータムーバーソリューションがあります。<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block>そして<block ref="079cab06c3947ff50532e4e825fc7b2c" category="inline-link-rx"></block>顧客がアプリケーション対応型で安全かつコスト効率に優れたハイブリッド クラウド Spark クラスターを構築できるように支援します。</block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">次の 3 つの Python スクリプトは、テストされた 3 つの主要なユース ケースに対応しています。まず<block ref="b01d528ada3b5a6e0e9094642b727562" prefix=" " category="inline-code"></block>。</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">2番目のスクリプトは<block ref="b502aa50c7ae6d7ea7adaf15de40ffe5" prefix=" " category="inline-code"></block>。</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">3番目のスクリプトは<block ref="5e1386bf4aaea9725a3cc5bc8e2bc9f4" prefix=" " category="inline-code"></block>。</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp には、 FAS/ AFF、E シリーズ、 Cloud Volumes ONTAP の3 つのストレージ ポートフォリオがあります。当社では、Apache Spark を使用した Hadoop ソリューション向けに、 AFFおよび E シリーズをONTAPストレージ システムで検証しました。  NetAppが提供するデータ ファブリックは、データ アクセス、制御、保護、セキュリティのためのデータ管理サービスとアプリケーション (ビルディング ブロック) を統合します。</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark ソリューションの概要</block>
  <block id="c7516072fbed3396e6f4c39a5f2356a6" category="paragraph">NetApp には、 FAS/ AFF、E シリーズ、 Cloud Volumes ONTAP の3 つのストレージ ポートフォリオがあります。当社では、Apache Spark を使用した Hadoop ソリューション向けに、 AFFおよび E シリーズをONTAPストレージ システムで検証しました。</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">データ ファブリックは、データ管理サービスとアプリケーションを提供します。</block>
  <block id="6370a459d17d7eda9502b6008ad71b4a" category="paragraph"><block ref="6370a459d17d7eda9502b6008ad71b4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS ダイレクト アクセス。*追加のソフトウェアやドライバーを必要とせずに、最新の Hadoop および Spark クラスターにNetApp NFS ボリュームへの直接アクセスを提供します。</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirrorテクノロジー。*オンプレミスとONTAP Cloud または NPS インスタンス間のデータ保護機能を提供します。</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">次の図は、 NetAppストレージを使用した Spark ソリューションを示しています。</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">NetAppストレージを使用した Spark ソリューション。</block>
  <block id="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="paragraph"><block ref="2c73cc344c9ea7b4fbe0e5179bb17d5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58a24b49fbb76272d712aaabf465bf7" category="paragraph">ONTAP Spark ソリューションは、既存の本番データへのアクセスを使用して、インプレース分析と AI、ML、DL ワークフローにNetApp NFS 直接アクセス プロトコルを使用します。  Hadoop ノードで利用可能な本番データは、インプレース分析および AI、ML、DL ジョブを実行するためにエクスポートされます。  Hadoop ノードで処理するデータには、 NetApp NFS 直接アクセスを使用しても使用しなくてもアクセスできます。 Sparkではスタンドアロンまたは<block ref="bb3462b62cd8db3f9ba007d86f8d1c6d" prefix=" " category="inline-code"></block>クラスタマネージャでは、NFSボリュームを次のように設定できます。<block ref="806400a5eefaa4811c63e2b45a736984" prefix=" " category="inline-code"></block> 。異なるデータセットを使用して 3 つのユースケースを検証しました。これらの検証の詳細は、「テスト結果」のセクションに記載されています。  （外部参照）</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">次の図は、 NetApp Apache Spark/Hadoop ストレージの位置付けを示しています。</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop ストレージの位置付け。</block>
  <block id="8e32cf48ce4f12a61f456b3ec41a7e21" category="paragraph"><block ref="8e32cf48ce4f12a61f456b3ec41a7e21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">E シリーズ Spark ソリューション、 AFF/ FAS ONTAP Spark ソリューション、 StorageGRID Spark ソリューションの独自の機能を特定し、詳細な検証とテストを実施しました。当社の観察に基づき、 NetApp は、グリーンフィールド インストールと新しいスケーラブルな導入には E シリーズ ソリューションを推奨し、既存の NFS データを使用したインプレース分析、AI、ML、DL ワークロードにはAFF/ FASソリューションを推奨し、オブジェクト ストレージが必要な場合の AI、ML、DL および最新のデータ分析にはStorageGRID を推奨しています。</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Spark に推奨されるNetAppソリューション。</block>
  <block id="32530ebcaeef5cc30a605229e26ea933" category="paragraph"><block ref="32530ebcaeef5cc30a605229e26ea933" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">データ レイクは、分析、AI、ML、DL ジョブに使用できるネイティブ形式の大規模なデータセットのストレージ リポジトリです。  E シリーズ、 AFF/ FAS、 StorageGRID SG6060 Spark ソリューション用のデータ レイク リポジトリを構築しました。 E シリーズ システムは Hadoop Spark クラスターへの HDFS アクセスを提供しますが、既存の運用データは Hadoop クラスターへの NFS 直接アクセス プロトコルを通じてアクセスされます。オブジェクト ストレージに存在するデータセットに対して、 NetApp StorageGRID はS3 および S3a の安全なアクセスを提供します。</block>
  <block id="881214767967db331c99550277ceb793" category="summary">このページでは、主要な定義、Splunk 分散デプロイメント、Splunk SmartStore、データ フロー、ハードウェアとソフトウェアの要件、単一サイトとマルチサイトの要件など、Splunk アーキテクチャについて説明します。</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunkアーキテクチャ</block>
  <block id="3924240363e47a4a292119abc4a993a1" category="paragraph">このセクションでは、主要な定義、Splunk 分散デプロイメント、Splunk SmartStore、データ フロー、ハードウェアおよびソフトウェアの要件、単一サイトおよびマルチサイトの要件などを含む Splunk アーキテクチャについて説明します。</block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">主な定義</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">次の 2 つの表には、分散 Splunk 展開で使用される Splunk およびNetAppコンポーネントがリストされています。</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">この表には、分散型 Splunk Enterprise 構成の Splunk ハードウェア コンポーネントがリストされています。</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunkコンポーネント</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">Task</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">インデクサー</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise データのリポジトリ</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">ユニバーサルフォワーダー</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">データの取り込みとインデクサーへのデータ転送を担当</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">検索ヘッド</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">インデクサー内のデータを検索するために使用するユーザーフロントエンド</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">クラスターマスター</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">Splunkのインデクサーと検索ヘッドのインストールを管理します</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">監視コンソール</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">展開全体で使用される集中監視ツール</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">ライセンスマスター</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">ライセンスマスターはSplunk Enterpriseのライセンスを管理します</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">デプロイメントサーバー</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">構成を更新し、処理コンポーネントにアプリを配布します</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">ストレージコンポーネント</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">ホット層データを管理するために使用されるオールフラッシュ ストレージ。ローカル ストレージとも呼ばれます。</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">ウォーム層データを管理するために使用される S3 オブジェクト ストレージ。 SmartStore によって、ホット層とウォーム層の間でデータを移動するために使用されます。リモート ストレージとも呼ばれます。</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">この表には、Splunk ストレージ アーキテクチャのコンポーネントがリストされています。</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">責任あるコンポーネント</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">スマートストア</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">インデクサーに、ローカル ストレージからオブジェクト ストレージにデータを階層化する機能を提供します。</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">スプランク</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">ホット</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">ユニバーサル フォワーダーが新しく書き込まれたデータを配置する着陸地点。ストレージは書き込み可能で、データは検索可能です。このデータ層は通常、SSD または高速 HDD で構成されます。</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">キャッシュマネージャー</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">インデックス付けされたデータのローカル キャッシュを管理し、検索が発生したときにリモート ストレージからウォーム データを取得し、最も使用頻度の低いデータをキャッシュから削除します。</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">暖かい</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">データは論理的にバケットにロールされ、最初にホット層からウォーム層に名前が変更されます。この層内のデータは保護されており、ホット層と同様に、より大容量の SSD または HDD で構成できます。一般的なデータ保護ソリューションを使用して、増分バックアップと完全バックアップの両方がサポートされます。</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk 分散デプロイメント</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">多数のマシンでデータが生成される大規模な環境をサポートするには、大量のデータを処理する必要があります。多くのユーザーがデータを検索する必要がある場合は、Splunk Enterprise インスタンスを複数のマシンに分散することで、展開を拡張できます。これは分散展開と呼ばれます。</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">一般的な分散展開では、各 Splunk Enterprise インスタンスは特殊なタスクを実行し、主要な処理機能に対応する 3 つの処理層のいずれかに存在します。</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">次の表は、Splunk Enterprise の処理層を示しています。</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">階層</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">コンポーネント</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">説明</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">データ入力</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">フォワーダー</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">フォワーダーはデータを消費し、そのデータをインデクサーのグループに転送します。</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">インデックス作成</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">インデクサーは、通常、フォワーダーのグループから受信する着信データをインデックス化します。インデクサーはデータをイベントに変換し、イベントをインデックスに保存します。インデクサーは、検索ヘッドからの検索要求に応じて、インデックス付けされたデータも検索します。</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">検索管理</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">検索ヘッドは、検索の中心的なリソースとして機能します。クラスター内の検索ヘッドは交換可能であり、検索ヘッド クラスターのどのメンバーからでも同じ検索、ダッシュボード、ナレッジ オブジェクトなどにアクセスできます。</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">次の表は、分散型 Splunk Enterprise 環境で使用される重要なコンポーネントを示しています。</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">責任</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">インデックスクラスタマスター</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">インデクサー クラスターのアクティビティと更新を調整します</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">インデックス管理</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">インデックスクラスター</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">相互にデータを複製するように構成された Splunk Enterprise インデクサーのグループ</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">検索ヘッドデプロイヤー</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">クラスタ マスターへの展開と更新を処理します</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">検索ヘッド管理</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">検索ヘッドクラスター</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">検索の中心となるリソースとして機能する検索ヘッドのグループ</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">ロードバランサー</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">クラスター化されたコンポーネントによって使用され、検索ヘッド、インデクサー、および S3 ターゲットによる増加する需要を処理し、クラスター化されたコンポーネント全体に負荷を分散します。</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">クラスタ化されたコンポーネントの負荷管理</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Splunk Enterprise 分散デプロイメントの次の利点をご覧ください。</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">多様なデータソースや分散したデータソースにアクセスする</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">あらゆる規模や複雑さの企業のデータニーズに対応する機能を提供します</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">データレプリケーションとマルチサイト展開により、高可用性を実現し、災害復旧を確実に実現します。</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk スマートストア</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore は、Amazon S3 などのリモート オブジェクト ストアにインデックス付きデータを保存できるようにするインデクサー機能です。展開のデータ量が増加すると、通常、ストレージの需要がコンピューティング リソースの需要を上回ります。  SmartStore を使用すると、インデクサー ストレージとコンピューティング リソースを個別にスケーリングすることで、コスト効率よく管理できます。</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore は、リモート ストレージ層とキャッシュ マネージャーを導入します。これらの機能により、データをインデクサー上のローカルまたはリモート ストレージ層に保存できます。キャッシュ マネージャーは、インデクサーと、インデクサー上に構成されているリモート ストレージ層間のデータの移動を管理します。</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">SmartStore を使用すると、インデクサーのストレージフットプリントを最小限に抑え、I/O が最適化されたコンピューティング リソースを選択できます。ほとんどのデータはリモート ストレージに保存されます。インデクサーは、ホット バケット、アクティブまたは最近の検索に参加しているウォーム バケットのコピー、およびバケット メタデータという最小限のデータを含むローカル キャッシュを維持します。</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStoreのデータフロー</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">さまざまなソースから受信したデータがインデクサーに到達すると、データはインデックス化され、ホット バケットにローカルに保存されます。インデクサーは、ホット バケット データをターゲット インデクサーに複製します。これまでのところ、データ フローは、SmartStore 以外のインデックスのデータ フローと同一です。</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">ホット バケットがウォームに移行すると、データ フローが分岐します。検索は最近インデックスが作成されたデータに対して実行される傾向があるため、ソース インデクサーは、既存のコピーをキャッシュに残したまま、ウォーム バケットをリモート オブジェクト ストア (リモート ストレージ層) にコピーします。ただし、リモート ストアは複数のローカル コピーを保持せずに高可用性を提供するため、ターゲット インデクサーはコピーを削除します。バケットのマスター コピーはリモート ストアに保存されるようになりました。</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">次の図は、Splunk SmartStore のデータ フローを示しています。</block>
  <block id="d7a63eb40866a66e8bb1fc64387b113e" category="paragraph"><block ref="d7a63eb40866a66e8bb1fc64387b113e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">インデクサー上のキャッシュ マネージャーは、SmartStore データ フローの中心となります。検索リクエストを処理するために必要に応じてリモート ストアからバケットのコピーを取得します。また、時間の経過とともに検索に使用される可能性が低くなるため、古いバケットのコピーやあまり検索されていないバケットのコピーをキャッシュから削除します。</block>
  <block id="b36837abd403dcb47f93edcd619c14de" category="paragraph">キャッシュ マネージャーの役割は、利用可能なキャッシュの使用を最適化しながら、検索が必要なバケットにすぐにアクセスできるようにすることです。</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">以下の表は、ソリューションを実装するために必要なソフトウェア コンポーネントを示しています。ソリューションの実装で使用されるソフトウェア コンポーネントは、顧客の要件に応じて異なる場合があります。</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">製品ファミリー</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">製品名</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">製品バージョン</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="cell">オペレーティング システム</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRIDオブジェクトストレージ</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">N/A</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunkエンタープライズ</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise と SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">単一サイトおよび複数サイトの要件</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">データが多数のマシンから生成され、多くのユーザーがデータを検索する必要があるエンタープライズ Splunk 環境 (中規模および大規模の展開) では、Splunk Enterprise インスタンスを単一サイトおよび複数のサイトに分散することで、展開を拡張できます。</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">次の表は、分散型 Splunk Enterprise 環境で使用されるコンポーネントを示しています。</block>
  <block id="ee5ff25e83985cc8f46c04780442d06b" category="cell">互いのデータを複製するように構成された Splunk Enterprise インデクサーのグループ</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">ロードバランサー</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">クラスタ化されたコンポーネントの負荷管理</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">この図は、単一サイトの分散展開の例を示しています。</block>
  <block id="d929fa57a2db2b79fca2a0c134995344" category="paragraph"><block ref="d929fa57a2db2b79fca2a0c134995344" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">この図は、マルチサイト分散展開の例を示しています。</block>
  <block id="aa56e29281a1be8656361637c931faec" category="paragraph"><block ref="aa56e29281a1be8656361637c931faec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">次の表は、ソリューションを実装するために必要なハードウェア コンポーネントの最小数を示しています。ソリューションの特定の実装で使用されるハードウェア コンポーネントは、顧客の要件によって異なる場合があります。</block>
  <block id="f690a37fe0f7a5932c9eee9dc887f7c7" category="admonition">Splunk SmartStore とStorageGRID を単一のサイトに導入したか複数のサイトに導入したかに関係なく、すべてのシステムはStorageGRID GRID Manager から単一の管理パネルで管理されます。詳細については、「Grid Manager による簡単な管理」セクションを参照してください。</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">この表には、単一のサイトに使用されるハードウェアがリストされています。</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">ディスク</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">使用可能な容量</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">メモ</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRIDSG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">管理ノードとロードバランサ</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRIDSG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">x48、8TB（NL-SAS HDD）</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">リモート ストレージ</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">この表には、マルチサイト構成 (サイトごと) に使用されるハードウェアがリストされています。</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">管理ノードとロードバランサ</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRIDロードバランサー: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">オブジェクト ストレージでは、クラウド ストレージの名前空間を提供するためにロード バランサーを使用する必要があります。  StorageGRID は、F5 や Citrix などの主要ベンダーのサードパーティ ロード バランサーをサポートしていますが、多くのお客様は、シンプルさ、回復力、高パフォーマンスを求めて、エンタープライズ グレードのStorageGRIDバランサーを選択しています。  StorageGRIDロード バランサは、VM、コンテナ、または専用アプライアンスとして利用できます。</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000 は、S3 データパス接続の高可用性 (HA) グループとインテリジェントな負荷分散の使用を容易にします。他のオンプレミス オブジェクト ストレージ システムでは、カスタマイズされたロード バランサーは提供されません。</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000 アプライアンスは次の機能を提供します。</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">StorageGRIDシステムのロードバランサと、オプションで管理ノード機能</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">ノードの導入と構成を簡素化するStorageGRIDアプライアンスインストーラ</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">S3エンドポイントとSSLの簡素化された構成</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">専用帯域幅（サードパーティのロードバランサーを他のアプリケーションと共有するのとは対照的）</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">最大4 x 100Gbpsの集約イーサネット帯域幅</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">次の画像は、SG1000 ゲートウェイ サービス アプライアンスを示しています。</block>
  <block id="605bc0a01cfe9da48adf3da49367bbdc" category="paragraph"><block ref="605bc0a01cfe9da48adf3da49367bbdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060 アプライアンスには、コンピューティング コントローラ (SG6060) と、2 つのストレージ コントローラと 60 台のドライブを含むストレージ コントローラ シェルフ (E シリーズ E2860) が含まれています。このアプライアンスは次の機能を提供します。</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">単一の名前空間で最大 400 PB までスケールします。</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">最大 4x 25Gbps の集約イーサネット帯域幅。</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">ノードの展開と構成を簡素化するStorageGRIDアプライアンス インストーラが含まれています。</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">各 SG6060 アプライアンスには、1 つまたは 2 つの追加拡張シェルフを搭載でき、合計 180 台のドライブを搭載できます。</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">ストレージ コントローラのフェイルオーバー サポートを提供する 2 つの E シリーズ E2800 コントローラ (デュプレックス構成)。</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">60 台の 3.5 インチ ドライブ (2 台のソリッド ステート ドライブと 58 台の NL-SAS ドライブ) を収容する 5 つの引き出し付きドライブ シェルフ。</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">次の画像は SG6060 アプライアンスを示しています。</block>
  <block id="cf84ce9e448fb9e498568b901279526a" category="paragraph"><block ref="cf84ce9e448fb9e498568b901279526a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunkの設計</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">次の表は、単一サイトの Splunk 構成を示しています。</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">コア</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16コア</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32GBのRAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">セントOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">ユーザーデータを管理します</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">ユーザーフロントエンドはインデクサー内のデータを検索します</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">検索ヘッドクラスタの更新を処理します</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Splunkのインストールとインデクサーを管理します</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">監視コンソールとライセンスマスター</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">Splunk の導入全体を集中的に監視し、Splunk ライセンスを管理します。</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">次の表は、マルチサイト構成の Splunk 構成について説明しています。</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">この表は、マルチサイト構成 (サイト A) の Splunk 構成を示しています。</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">データの取り込みとインデクサーへのデータの転送を担当します。</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">Splunk 展開全体の集中監視を実行し、Splunk ライセンスを管理します。</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">この表は、マルチサイト構成 (サイト B) の Splunk 構成を示しています。</block>
  <block id="89586ffe0445b81e878d1032f66f2e12" category="summary">Splunk Enterprise は、セキュリティ、IT、DevOps チーム全体の成果を促進する、市場をリードする SIEM ソリューションです。</block>
  <block id="4d39837f3e2d893412540b1652c97cbe" category="paragraph">Splunk Enterprise は、セキュリティ、IT、DevOps チーム全体の成果を促進する、市場をリードする SIEM ソリューションです。お客様の組織全体で Splunk の使用が大幅に増加しました。したがって、データをより長期間保持しながら、より多くのデータ ソースを追加する必要があり、Splunk インフラストラクチャに負荷がかかります。</block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore とNetApp StorageGRIDの組み合わせは、SmartStore とStorageGRIDオブジェクト ストレージによる取り込みパフォーマンスの向上と、複数の地理的領域にわたる Splunk 環境のスケーラビリティの向上を組織が実現できる、スケーラブルなアーキテクチャを提供するように設計されています。</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="inline-link">NetApp StorageGRIDドキュメント リソース</block>
  <block id="a246b965362984dc941c948da019cebe" category="list-text"><block ref="a246b965362984dc941c948da019cebe" category="inline-link-rx"></block></block>
  <block id="1deabb4a384507a50ad75f7c30954fe6" category="list-text"><block ref="1deabb4a384507a50ad75f7c30954fe6" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="inline-link">Splunk Enterprise ドキュメント</block>
  <block id="04e37c317ba66f65142c3479329cc2e3" category="list-text"><block ref="04e37c317ba66f65142c3479329cc2e3" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="inline-link">Splunk Enterprise SmartStoreについて</block>
  <block id="fefd29a254418e70038ff08010d7066e" category="list-text"><block ref="fefd29a254418e70038ff08010d7066e" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="inline-link">Splunk Enterprise 分散デプロイメントマニュアル</block>
  <block id="12c4d056a98e583e653fc125f9f3338d" category="list-text"><block ref="12c4d056a98e583e653fc125f9f3338d" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="inline-link">Splunk Enterprise インデクサーとインデクサーのクラスターの管理</block>
  <block id="634ac9166526f20af850f5021155d4c5" category="list-text"><block ref="634ac9166526f20af850f5021155d4c5" category="inline-link-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">この技術レポートでは、 NetAppが Splunk SmartStore ソリューションに提供するメリットの概要を示しながら、お客様の環境で Splunk SmartStore を設計およびサイズ設定するためのフレームワークを示します。その結果、魅力的な TCO を実現するシンプルでスケーラブル、かつ回復力のあるソリューションが実現します。</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: Splunk SmartStore を搭載したNetApp StorageGRID</block>
  <block id="fa4442e299e1aa350a002220ee278abc" category="paragraph">Splunk Enterprise は、セキュリティ、IT、DevOps チーム全体の成果を促進する、市場をリードするセキュリティ情報およびイベント管理 (SIEM) ソリューションです。</block>
  <block id="3b878279a04dc47d60932cb294d96259" category="section-title">概要</block>
  <block id="78298f39c2d5411f080a61b3abeb845f" category="paragraph">データ量は指数関数的に増加し続けており、この膨大なリソースを活用できる企業には大きなチャンスが生まれています。 Splunk Enterprise は、より幅広いユースケースで採用され続けています。ユースケースが拡大するにつれて、Splunk Enterprise が取り込んで処理するデータの量も増加します。 Splunk Enterprise の従来のアーキテクチャは、優れたデータ アクセスと可用性を提供する分散スケールアウト設計です。しかし、このアーキテクチャを使用している企業は、急増するデータ量に対応するために拡張することに伴うコストの増加に直面しています。</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">Splunk SmartStore とNetApp StorageGRID は、コンピューティングとストレージが分離された新しい導入モデルを提供することで、この課題を解決します。このソリューションは、コンピューティングとストレージを個別に拡張し、コスト効率の高いクラウドベースの S3 オブジェクト ストレージにインテリジェントな階層化を追加することでコストを削減しながら、単一サイトおよび複数サイトにまたがる拡張を可能にすることで、Splunk Enterprise 環境に比類のないスケールと弾力性をもたらします。</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">このソリューションは、検索パフォーマンスを維持しながらローカル ストレージ内のデータ量を最適化し、コンピューティングとストレージをオンデマンドで拡張できるようにします。  SmartStore は、データ アクセス パターンを自動的に評価して、リアルタイム分析のためにアクセスする必要があるデータと、低コストの S3 オブジェクト ストレージに保存する必要があるデータを決定します。</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">この技術レポートでは、 NetAppが Splunk SmartStore ソリューションに提供するメリットの概要を示しながら、お客様の環境で Splunk SmartStore を設計およびサイズ設定するためのフレームワークを示します。その結果、魅力的な TCO を実現するシンプルでスケーラブル、かつ回復力のあるソリューションが実現します。  StorageGRID は、スケーラブルでコスト効率に優れた S3 プロトコル/API ベースのオブジェクト ストレージ (リモート ストレージとも呼ばれます) を提供し、組織が Splunk ソリューションをより低コストで拡張しながら、回復力を高めることを可能にします。</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore では、オブジェクト ストレージをリモート ストアまたはリモート ストレージ層と呼びます。</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">NetApp StorageGRIDについて</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRIDは、大規模なアーカイブ、メディア リポジトリ、Web データ ストア向けのソフトウェア定義のオブジェクト ストレージ ソリューションです。  NetApp は、 StorageGRIDを通じて、業界をリードするイノベーションとデータ管理ソリューションの提供における 20 年の経験を活用し、組織がオンプレミス、パブリック、プライベート、ハイブリッド クラウドの展開の両方で情報を管理し、その価値を最大化できるよう支援します。</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID は、大規模な非構造化データに対して安全で耐久性のあるストレージを提供します。統合されたメタデータ駆動型のライフサイクル管理ポリシーにより、データの存続期間全体にわたってデータが存在する場所が最適化されます。コンテンツは適切な場所、適切な時間、適切なストレージ層に配置され、コストが削減されます。単一の名前空間により、 StorageGRIDストレージの地理的な場所に関係なく、単一の呼び出しでデータにアクセスできます。顧客は、データセンター間およびクラウド インフラストラクチャ内で複数のStorageGRIDインスタンスを展開および管理できます。</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRIDシステムは、既存のクライアント アプリケーションと次世代のクライアント アプリケーションの両方と統合できる、グローバルに分散された冗長な異機種ノードで構成されています。</block>
  <block id="a8bc435c89c3235d62a12e0fb3c5c909" category="paragraph"><block ref="a8bc435c89c3235d62a12e0fb3c5c909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape は最近、最新のレポート「IDC MarketScape: Worldwide Object-Based Storage 2019 Vendor Assessment」でNetApp をリーダーに選出しました。  StorageGRID は、最も要求の厳しい業界で 20 年近く実稼働環境で導入されており、非構造化データの分野ではリーダーとして認められています。</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">StorageGRIDを使用すると、次のことを実現できます。</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">複数のStorageGRIDインスタンスを展開して、数百ペタバイトまで簡単に拡張できる単一の名前空間を通じて、データセンターとクラウド間の任意の場所からデータにアクセスします。</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">インフラストラクチャ全体にわたって展開および集中管理できる柔軟性を提供します。</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">階層化された Erasure Coding (EC) を活用し、15 ナインの耐久性で比類のない耐久性を実現します。</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Amazon S3 Glacier および Azure Blob への検証済みの統合により、より多くのハイブリッド マルチクラウド機能を有効にします。</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">独自の API やベンダー ロックインなしで、改ざん防止のデータ保持を通じて規制義務を満たし、コンプライアンスを促進します。</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRIDホームページ</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">StorageGRIDが最も複雑な非構造化データ管理の問題を解決する方法の詳細については、<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block> 。</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Splunk Enterpriseについて</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise は、データを行動に変えるためのプラットフォームです。ログ ファイル、Web サイト、デバイス、センサー、アプリケーションなどのさまざまなソースによって生成されたデータは、Splunk Indexers に送信され、解析されるため、データから豊富な分析情報を得ることができます。データ侵害を特定したり、顧客や製品の傾向を指摘したり、インフラストラクチャを最適化する機会を見つけたり、さまざまなユースケースにわたって実用的な洞察を作成したりすることができます。</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Splunk SmartStoreについて</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore は、Splunk アーキテクチャの利点を拡張するとともに、コスト効率の高い拡張性を簡素化します。コンピューティング リソースとストレージ リソースを分離すると、インデクサー ノードはデータのサブセットのみをキャッシュとして保存するため、I/O に最適化され、ストレージのニーズが大幅に削減されます。必要なリソースが 1 つだけであれば、追加のコンピューティング リソースやストレージ リソースを追加する必要がないため、大幅なコスト削減を実現できます。コスト効率が高く、簡単に拡張できる S3 ベースのオブジェクト ストレージを使用することで、環境がさらに簡素化され、コストが削減され、より大規模なデータ セットを維持できるようになります。</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore は、次のような大きな価値を組織に提供します。</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">ウォームデータをコスト最適化された S3 オブジェクトストレージに移動することでストレージコストを削減</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">ストレージとコンピューティングを分離してシームレスにスケーリング</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">耐障害性に優れたクラウドネイティブストレージを活用してビジネス継続性を簡素化</block>
  <block id="bdcc72fc1bad1a939182ad2bde321f1e" category="summary">このページでは、 NetApp StorageGRIDコントローラ上の Splunk SmartStore のパフォーマンスについて説明します。</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">単一サイトのSmartStoreパフォーマンス</block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">このセクションでは、 NetApp StorageGRIDコントローラ上の Splunk SmartStore のパフォーマンスについて説明します。  Splunk SmartStore は、ウォーム データをリモート ストレージ (この場合はパフォーマンス検証のStorageGRIDオブジェクト ストレージ) に移動します。</block>
  <block id="dd1e8d1bd57ca578a4ba44e789957d0f" category="paragraph"><block ref="dd1e8d1bd57ca578a4ba44e789957d0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">ホット/キャッシュ ストレージには EF600 を使用し、リモート ストレージにはStorageGRID 6060 を使用しました。パフォーマンス検証には次のアーキテクチャを使用しました。検索ヘッドを 2 つ、データをインデクサーに転送するヘビー フォワーダーを 4 つ、リアルタイム データを生成する Splunk イベント ジェネレーター (Eventgens) を 7 つ、データを保存するためのインデクサーを 18 個使用しました。</block>
  <block id="b127bd17913b4ab46912efd5b9a74269" category="paragraph"><block ref="b127bd17913b4ab46912efd5b9a74269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="section-title">構成</block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">この表には、SmartStorage パフォーマンス検証に使用されるハードウェアがリストされています。</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">重量物輸送業者</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">スレッド 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">ユーザーのフロントエンドはインデクサー内のデータを検索します</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStoreリモートストアのパフォーマンス検証</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">このパフォーマンス検証では、10 日分のデータに対して、すべてのインデクサーのローカル ストレージに SmartStore キャッシュを構成しました。私たちは、<block ref="6255199182bd8af7ba33e8a06e144dc4" prefix=" " category="inline-code"></block> (バケット サイズ 750 MB) を Splunk クラスター マネージャーで作成し、変更をすべてのインデクサーにプッシュしました。アップロード パフォーマンスを測定するために、10 日間にわたって 1 日あたり 10 TB を取り込み、すべてのホット バケットを同時にウォームにロールオーバーし、SmartStore モニタリング コンソール ダッシュボードからインスタンスごとおよびデプロイメント全体のピークおよび平均スループットをキャプチャしました。</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">この画像は 1 日に取り込まれたデータを示しています。</block>
  <block id="1c106a39adeca49606809938222599d3" category="paragraph"><block ref="1c106a39adeca49606809938222599d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">クラスタマスターから次のコマンドを実行しました（インデックス名は<block ref="b6f5a7e4d9c3de59289306e2636a7438" prefix=" " category="inline-code"></block>）。次に、SmartStore モニタリング コンソールのダッシュボードを使用して、インスタンスごとおよび展開全体のピークおよび平均アップロード スループットをキャプチャしました。</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">クラスター マスターは、すべてのインデクサー (rtp-idx0001…rtp-idx0018) に対してパスワードなしの認証を行います。</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">ダウンロードのパフォーマンスを測定するために、次のコマンドを使用して evict CLI を 2 回実行し、キャッシュからすべてのデータを削除しました。</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">クラスター マスターから次のコマンドを実行し、 StorageGRIDのリモート ストアの 10 日間のデータに対して検索ヘッドから検索を実行しました。次に、SmartStore モニタリング コンソールのダッシュボードを使用して、インスタンスごとおよび展開全体のピークおよび平均アップロード スループットをキャプチャしました。</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">インデクサー構成は SmartStore クラスター マスターからプッシュされました。クラスター マスターには、インデクサーに対して次の構成がありました。</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">パフォーマンス マトリックスを収集するために、検索ヘッドで次の検索クエリを実行しました。</block>
  <block id="71e6150ea19aef0f2e67a79bd131fca8" category="paragraph"><block ref="71e6150ea19aef0f2e67a79bd131fca8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">クラスター マスターからパフォーマンス情報を収集しました。ピークパフォーマンスは61.34GBpsでした。</block>
  <block id="c5e60940f195879f09af22af10f55027" category="paragraph"><block ref="c5e60940f195879f09af22af10f55027" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">平均パフォーマンスは約 29GBps でした。</block>
  <block id="a8eebaef6e6889ddddfe09cfa523009c" category="paragraph"><block ref="a8eebaef6e6889ddddfe09cfa523009c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRIDのパフォーマンス</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">イベントジェン</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore のパフォーマンスは、大量のデータから特定のパターンと文字列を検索することに基盤を置いています。この検証では、イベントは以下を使用して生成されます。<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block>検索ヘッドを介して特定の Splunk インデックス (eventgen-test) に対して実行され、ほとんどのクエリの要求はStorageGRIDに送られます。次の画像は、クエリ データのヒットとミスを示しています。ヒット データはローカル ディスクから取得され、ミス データはStorageGRIDコントローラから取得されます。</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">緑色はヒットデータ、オレンジ色はミスデータを示します。</block>
  <block id="5776938ffab0b4f2730d8923c004d57e" category="paragraph"><block ref="5776938ffab0b4f2730d8923c004d57e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">StorageGRIDで検索クエリを実行すると、 StorageGRIDからの S3 取得速度の時間が次の画像に表示されます。</block>
  <block id="7393ba7bdc5067b2c80450122c8a2f0d" category="paragraph"><block ref="7393ba7bdc5067b2c80450122c8a2f0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRIDハードウェアの使用</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRIDインスタンスには、1 つのロード バランサーと 3 つのStorageGRIDコントローラーがあります。  3 つのコントローラーすべての CPU 使用率は 75% ～ 100% です。</block>
  <block id="69851341d968a4444c52d6c167608079" category="paragraph"><block ref="69851341d968a4444c52d6c167608079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">NetAppストレージコントローラ搭載SmartStore - 顧客にとってのメリット</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">*コンピューティングとストレージの分離。*  Splunk SmartStore はコンピューティングとストレージを分離し、それらを個別に拡張できるようにします。</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">*オンデマンドのデータ。*  SmartStore は、オンデマンドでデータをコンピューティングに近づけ、コンピューティングとストレージの弾力性とコスト効率を提供して、大規模なデータ保持期間の延長を実現します。</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">*AWS S3 API に準拠しています。*  SmartStore は、AWS S3 API を使用して、 StorageGRIDなどの AWS S3 および S3 API 準拠のオブジェクト ストアである復元ストレージと通信します。</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">*ストレージ要件とコストを削減します。*  SmartStore は、古いデータ (ウォーム/コールド) のストレージ要件を削減します。  NetAppストレージはデータ保護を提供し、障害と高可用性に対応するため、必要なのはデータのコピーが 1 つだけです。</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">*ハードウェア障害。*  SmartStore 展開でノード障害が発生しても、データにアクセスできなくなることはなく、ハードウェア障害やデータの不均衡からのインデクサーの回復が大幅に高速化されます。</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">アプリケーションとデータに対応したキャッシュ。</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">インデクサーの追加と削除、およびクラスターのセットアップと解体をオンデマンドで実行します。</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">ストレージ層はハードウェアに縛られなくなりました。</block>
  <block id="c1d2fce5798cdc81a1393206b0332f8a" category="summary">このソリューションにより、コンピューティング、ホット ストレージ、または S3 リソースを追加して、単一サイトおよび複数サイトの展開全体でのユーザー数や取り込み速度に関する需要の増大に対応できます。</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="doc">このソリューションの利点</block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">*パフォーマンス。*  Splunk SmartStore とNetApp StorageGRID を組み合わせることで、オブジェクト ストレージを使用してホット バケットとウォーム バケット間でのデータの高速移行が可能になります。  StorageGRID は、大規模なオブジェクト ワークロードに高速なパフォーマンスを提供することで、移行プロセスを強化します。</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">*マルチサイト対応。*  StorageGRID分散アーキテクチャにより、Splunk SmartStore は、データがどこに存在するかに関係なく、どのサイトからでもデータにアクセスできる単一のグローバル名前空間を通じて、単一サイトおよび複数サイトにわたる展開を拡張できます。</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">*スケーラビリティが向上しました。*  Splunk 環境における変化するニーズと要求を満たすために、コンピューティング リソースとは独立してストレージ リソースを拡張し、TCO を改善します。</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">*容量。*  StorageGRIDを使用すると、単一の名前空間を 560 PB 以上に拡張して、Splunk 展開で急速に増加するボリュームに対応できます。</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">*データの可用性*データのビジネス価値の変化に応じて動的に調整できるメタデータ主導のポリシーを使用して、データの可用性、パフォーマンス、地理的分散、保持、保護、およびストレージ コストを最適化します。</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunkが提供するガイドライン</block>
  <block id="3c5d06925a5d5bceedd74c82d3d38c04" category="paragraph">ローカル (ホット) ストレージとリモート (ウォーム) ストレージ間のバケット コピーの転送を処理するインデクサーのコンポーネントである SmartStore キャッシュを使用してパフォーマンスを向上します。このソリューションのSplunkのサイズは、<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block> 。このソリューションにより、コンピューティング、ホット ストレージ、または S3 リソースを追加して、単一サイトおよび複数サイトの展開全体でのユーザー数や取り込み速度に関する需要の増大に対応できます。</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">このページでは、 NetApp StorageGRID、Splunk Enterprise、Splunk SmartStore など、このソリューションを完成させるために使用されるコンポーネントについて説明します。</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">ソリューションの概要</block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRIDは、高性能でコスト効率に優れたオブジェクト ストレージ プラットフォームです。分散型のノードベースのグリッド アーキテクチャを使用して、インテリジェントでポリシー主導のグローバル データ管理を提供します。ユビキタスなグローバル オブジェクト名前空間と洗練されたデータ管理機能を組み合わせることで、ペタバイト単位の非構造化データと数十億個のオブジェクトの管理を簡素化します。シングルコールのオブジェクト アクセスはサイト全体に拡張され、高可用性アーキテクチャを簡素化するとともに、サイトまたはインフラストラクチャの停止に関係なく継続的なオブジェクト アクセスを保証します。</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">マルチテナンシーにより、複数のクラウドおよびエンタープライズ非構造化データ アプリケーションを同じグリッド内で安全に処理できるようになり、 StorageGRIDの ROI と使用事例が増加します。メタデータ駆動型のオブジェクト ライフサイクル ポリシーを使用して複数のサービス レベルを作成し、複数の地域にわたって耐久性、保護、パフォーマンス、および局所性を最適化できます。ユーザーは、要件の変化に応じてポリシーを調整し、中断なくデータ環境を再調整できます。</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore は、 StorageGRID をリモート ストレージ層として活用し、単一のオブジェクト名前空間として提供される、地理的に分散した複数のサイトを展開して堅牢な可用性と耐久性を実現します。これにより、Splunk SmartStore は、 StorageGRIDの高パフォーマンス、高密度容量、および単一の URL を使用して複数の物理サイトにわたって数百のノードに拡張する機能を活用して、オブジェクトと対話できるようになります。この単一の URL により、単一のサイトを超えてもストレージの拡張、アップグレード、修復を中断なく実行できるようになります。  StorageGRID独自のデータ管理ポリシー エンジンは、最適化されたレベルのパフォーマンスと耐久性を提供し、データの局所性要件に準拠します。</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">機械生成データの収集と分析のリーダーである Splunk は、運用分析機能を通じて IT の簡素化と近代化を支援します。また、ビジネス分析、セキュリティ、IoT のユースケースにも拡張されます。ストレージは、Splunk ソフトウェアの導入を成功させる上で重要な要素です。</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">機械生成データは、最も急速に成長しているタイプのビッグデータです。フォーマットは予測不可能であり、さまざまなソースから高レートかつ大量に提供されることがよくあります。これらのワークロード特性は、多くの場合、デジタル排気と呼ばれます。  Splunk SmartStore は、このデータを理解し、最もコスト効率の高いストレージ層にホット データとウォーム データを最適に配置するためのスマート データ階層化を提供します。</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore は、 StorageGRIDなどのオブジェクト ストレージ (リモート ストレージまたはリモート ストレージ層とも呼ばれます) を使用して、S3 プロトコルでウォーム データを保存するインデクサー機能です。</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">展開のデータ量が増加すると、通常、ストレージの需要がコンピュータ リソースの需要を上回ります。  SmartStore を使用すると、コンピューティングとストレージを個別に拡張することで、インデクサー ストレージとコンピューティング リソースをコスト効率よく管理できます。</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore は、S3 プロトコルとキャッシュ マネージャーを使用したリモート ストレージ層を導入します。これらの機能により、データをインデクサー上のローカルまたはリモート ストレージに保存できます。インデクサー上に存在するキャッシュ マネージャーは、インデクサーとリモート ストレージ層間のデータの移動を管理します。データは、バケット メタデータとともにバケット (ホット バケットとウォーム バケット) に保存されます。</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">SmartStore を使用すると、ほとんどのデータがリモート ストレージ層に存在するため、インデクサーのストレージ フットプリントを最小限に抑え、I/O が最適化されたコンピューティング リソースを選択できます。インデクサーは、要求され予測された結果を返すために必要な最小限のデータ量を表すローカル キャッシュを維持します。ローカル キャッシュには、ホット バケット、アクティブまたは最近の検索に参加しているウォーム バケットのコピー、およびバケットのメタデータが含まれます。</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">Splunk SmartStore とStorageGRID を組み合わせることで、顧客は、高性能でコスト効率の高いリモート ストレージを使用して環境を段階的に拡張しながら、ソリューション全体に高度な弾力性を提供できます。これにより、お客様は、より多くのインデクサーが必要な場合、データ保持期間を変更する場合、または中断なく取り込み速度を上げる場合など、いつでも任意の数量のコンポーネント (ホット ストレージおよび/またはウォーム S3 ストレージ) を追加できます。</block>
  <block id="d919f51e7020fabd237372f4c163a60e" category="summary">StorageGRID には、ユーザーが常に変化する環境に合わせて活用し、カスタマイズできるさまざまな機能があります。</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Splunk SmartStore 向けの柔軟なStorageGRID機能</block>
  <block id="d7ec4db6b0e9313773163a8a2404946e" category="paragraph">StorageGRID には、ユーザーが常に変化する環境に合わせて活用し、カスタマイズできるさまざまな機能があります。  Splunk SmartStore の導入から拡張まで、環境は変更に迅速に対応することが求められ、Splunk に支障をきたさないものでなければなりません。  StorageGRID の柔軟なデータ管理ポリシー (ILM) とトラフィック分類子 (QoS) を使用すると、環境に合わせて計画を立て、適応することができます。</block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager は、次の図に示すように、単一の画面で世界中に分散された場所にあるStorageGRIDシステムを構成、管理、監視できるブラウザベースのグラフィカル インターフェイスです。</block>
  <block id="b426e35a4f24b1452cf4688598a7429c" category="paragraph"><block ref="b426e35a4f24b1452cf4688598a7429c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Grid Manager インターフェイスを使用して、次のタスクを実行します。</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Splunk 向けNetApp StorageGRIDアプリ</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">NetApp StorageGRID App for Splunk は、Splunk Enterprise 専用のアプリケーションです。このアプリは、Splunk 用のNetApp StorageGRIDアドオンと連携して動作します。  StorageGRID の健全性、アカウントの使用状況情報、セキュリティ監査の詳細、リソースの使用状況と監視などの可視性を提供します。</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">次の画像は、Splunk 用のStorageGRIDアプリを示しています。</block>
  <block id="33e8e06b4bbde24cf3f439a1bd66cf19" category="paragraph"><block ref="33e8e06b4bbde24cf3f439a1bd66cf19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILMポリシー</block>
  <block id="2121ccc9450b2df939a6752c3559486a" category="paragraph">StorageGRID には柔軟なデータ管理ポリシーがあり、オブジェクトの複数のコピーを保持したり、特定のパフォーマンスとデータ保護の要件に応じて 2+1 や 4+2 などの EC (消去コーディング) スキーム (およびその他多数) を使用してオブジェクトを保存したりできます。ワークロードと要件は時間の経過とともに変化するため、ILM ポリシーも時間の経過とともに変更する必要があるのが一般的です。  ILM ポリシーの変更は中核機能であり、これによりStorageGRID のお客様は変化し続ける環境に迅速かつ簡単に適応できます。</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID は、VM またはベアメタル、あるいは SG5712、SG5760、SG6060、SGF6024 などの専用アプライアンスなどのノードを追加することでパフォーマンスを拡張します。当社のテストでは、SG6060 アプライアンスを使用した最小サイズの 3 ノード グリッドで SmartStore の主要なパフォーマンス要件を超えました。顧客が追加のインデクサーを使用して Splunk インフラストラクチャを拡張すると、ストレージ ノードを追加してパフォーマンスと容量を向上させることができます。</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">ロードバランサとエンドポイントの構成</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRIDの管理ノードは、 StorageGRIDシステムを表示、構成、管理するための Grid Manager UI (ユーザー インターフェイス) と REST API エンドポイント、およびシステム アクティビティを追跡するための監査ログを提供します。 Splunk SmartStore リモート ストレージに高可用性の S3 エンドポイントを提供するために、管理ノードとゲートウェイ ノードでサービスとして実行されるStorageGRIDロード バランサーを実装しました。さらに、ロード バランサはローカル トラフィックも管理し、GSLB (グローバル サーバー負荷分散) と通信して災害復旧を支援します。</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">エンドポイント構成をさらに強化するために、 StorageGRID は管理ノードに組み込まれたトラフィック分類ポリシーを提供し、ワークロード トラフィックを監視し、ワークロードにさまざまなサービス品質 (QoS) 制限を適用できるようにします。トラフィック分類ポリシーは、ゲートウェイ ノードと管理ノードのStorageGRIDロード バランサ サービスのエンドポイントに適用されます。これらのポリシーは、トラフィックの制限と監視に役立ちます。</block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">顧客が Splunk データ分析の威力と使いやすさを認識するにつれて、当然のことながら、増え続けるデータのインデックス作成を望むようになります。データ量が増加すると、それを処理するために必要なコンピューティングおよびストレージ インフラストラクチャも増加します。</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">インテリジェントな階層化とコスト削減</block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">顧客が Splunk データ分析の威力と使いやすさを認識するにつれて、当然のことながら、増え続けるデータのインデックス作成を望むようになります。データ量が増加すると、それを処理するために必要なコンピューティングおよびストレージ インフラストラクチャも増加します。古いデータは参照される頻度が低いため、同じ量のコンピューティング リソースをコミットして高価なプライマリ ストレージを消費することはますます非効率になります。大規模に運用するには、ウォーム データをよりコスト効率の高い層に移動し、コンピューティングとプライマリ ストレージをホット データ用に解放することで、顧客はメリットを得られます。</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">Splunk SmartStore とStorageGRID は、スケーラブルでパフォーマンスが高く、コスト効率に優れたソリューションを組織に提供します。  SmartStore はデータ対応であるため、データ アクセス パターンを自動的に評価し、リアルタイム分析のためにアクセスする必要があるデータ (ホット データ) と、低コストの長期ストレージに保存する必要があるデータ (ウォーム データ) を判断します。  SmartStore は業界標準の AWS S3 API を動的かつインテリジェントに使用し、 StorageGRIDが提供する S3 ストレージにデータを配置します。  StorageGRIDの柔軟なスケールアウト アーキテクチャにより、ウォーム データ層を必要に応じてコスト効率よく拡張できます。  StorageGRIDのノードベースのアーキテクチャにより、パフォーマンスとコストの要件が最適に満たされます。</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">次の図は、Splunk とStorageGRID の階層化を示しています。</block>
  <block id="f710071dfe9306034297e2bbb442d8bc" category="paragraph"><block ref="f710071dfe9306034297e2bbb442d8bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">業界をリードする Splunk SmartStore とNetApp StorageGRIDの組み合わせにより、フルスタック ソリューションを通じて分離アーキテクチャの利点が実現します。</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp Eシリーズ E5700とSplunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn、NetApp</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623 では、 NetApp E シリーズと Splunk 設計の統合アーキテクチャについて説明します。ノード ストレージのバランス、信頼性、パフォーマンス、ストレージ容量、密度が最適化されたこの設計では、スケーラビリティが高く TCO が低い Splunk クラスター化インデックス ノード モデルが採用されています。ストレージをコンピューティングから分離すると、それぞれを個別に拡張できるようになり、どちらかを過剰にプロビジョニングするコストを節約できます。さらに、このドキュメントでは、Splunk マシン ログ イベント シミュレーション ツールから取得したパフォーマンス テストの結果をまとめています。</block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="f1739b1d5d1c44e562a8500d3b80579f" category="summary">NetApp AI 機能により、AI パイプライン全体でシームレスなデータ管理とデータ移動が可能になり、生成 AI モデルのトレーニング、再トレーニング、微調整、推論、監視が可能になります。</block>
  <block id="36cc0281ec7abcd20091f5d39b995cc4" category="doc">ジェネレーティブAIとNetAppの価値</block>
  <block id="6dbc3469d4924aa631238769172515d8" category="paragraph">生成型人工知能 (AI) の需要は業界全体に混乱をもたらし、ビジネスの創造性と製品のイノベーションを促進しています。</block>
  <block id="40ed4c797a14998a489b495cd8c9a5e0" category="paragraph">多くの組織が生成 AI を使用して、新しい製品機能を構築し、エンジニアリングの生産性を向上させ、より優れた結果と消費者エクスペリエンスを提供する AI 搭載アプリケーションのプロトタイプを作成しています。 Generative Pre-trained Transformers (GPT) などの生成 AI は、ニューラル ネットワークを使用して、テキスト、オーディオ、ビデオなど多様な新しいコンテンツを作成します。大規模言語モデル (LLM) には極めて大きな規模と膨大なデータセットが関係するため、企業が AI ソリューションを設計する前に、オンプレミス、ハイブリッド、マルチクラウドの導入オプションの魅力的なデータ ストレージ機能を活用し、データのモビリティ、データ保護、ガバナンスに関連するリスクを軽減する堅牢な AI インフラストラクチャを設計することが重要です。このホワイト ペーパーでは、これらの考慮事項と、生成 AI モデルのトレーニング、再トレーニング、微調整、推論のための AI データ パイプライン全体でシームレスなデータ管理とデータ移動を可能にする対応するNetApp AI 機能について説明します。</block>
  <block id="a573d92b77d430af7e424879baf78e94" category="section-title">概要</block>
  <block id="3fed37bedb6b36d52c0c5b3aa0089bfe" category="paragraph">最近では、2022 年 11 月に GPT-3 のスピンオフである ChatGPT がリリースされて以来、ユーザーのプロンプトに応じてテキスト、コード、画像、さらには治療用タンパク質を生成するために使用される新しい AI ツールが大きな注目を集めています。これは、ユーザーが自然言語を使用してリクエストを行うことができ、AI がユーザーのリクエストを反映したニュース記事や製品の説明などのテキストを解釈して生成したり、既存のデータでトレーニングされたアルゴリズムを使用してコード、音楽、音声、視覚効果、3D アセットを生成したりすることを意味します。その結果、安定的な拡散、幻覚、プロンプトエンジニアリング、価値の調整などのフレーズが AI システムの設計で急速に登場しています。これらの自己教師型または半教師型の機械学習 (ML) モデルは、クラウド サービス プロバイダーやその他の AI 企業ベンダーを通じて、事前トレーニング済みの基礎モデル (FM) として広く利用できるようになり、さまざまな業界のさまざまな企業で、幅広い下流の NLP (自然言語処理) タスクに採用されています。マッキンゼーなどの調査アナリスト企業は、「生成 AI が生産性に与える影響は、世界経済に数兆ドルの価値をもたらす可能性がある」と主張しています。企業が AI を人間の思考パートナーとして再考するとともに、FM が同時に企業や機関が生成 AI で何ができるかまで範囲を広げるなか、膨大な量のデータを管理する機会は今後も増え続けるでしょう。このドキュメントでは、オンプレミス、ハイブリッド、またはマルチクラウド環境の両方でNetApp の顧客に価値をもたらすNetApp の機能に関連する生成 AI と設計コンセプトの概要を説明します。</block>
  <block id="8bcfe22a3d7c5edf904444893704a8de" category="paragraph">*では、顧客が AI 環境でNetAppを使用するとどのようなメリットがあるのでしょうか?*  NetApp は、データとクラウドの急速な増加、マルチクラウド管理、AI などの次世代テクノロジーの導入によって生じる複雑さに組織が対応できるよう支援します。  NetApp は、AI ワークロードに最適化された高性能とバランスの取れたインテリジェントなデータ管理ソフトウェアとストレージ インフラストラクチャにさまざまな機能を統合しました。  LLM のような生成 AI ソリューションでは、インテリジェンスを強化するために、ソース データセットをストレージからメモリに何度も読み取って処理する必要があります。  NetApp は、エッジからコア、クラウドまでのエコシステム全体にわたるデータ モビリティ、データ ガバナンス、データ セキュリティ テクノロジーのリーダーであり、大規模な AI ソリューションを構築するエンタープライズ顧客にサービスを提供しています。 NetApp は、強力なパートナー ネットワークを活用して、最高データ責任者、AI エンジニア、エンタープライズ アーキテクト、データ サイエンティストを支援し、AI モデルのトレーニングと推論におけるデータ準備、データ保護、戦略的データ管理の責任を果たすための自由に流れるデータ パイプラインを設計し、AI/ML ライフサイクルのパフォーマンスと拡張性を最適化しています。ディープラーニング データ パイプライン用のNetApp ONTAP AI、ストレージ エンドポイント間でデータをシームレスかつ効率的に転送するためのNetApp SnapMirror 、データ フローがバッチからリアルタイムに移行し、データ エンジニアリングが適切なタイミングでNetAppれる場合にリアルタイム レンダリングを実現するNetApp FlexCacheなどの NetApp のデータ テクノロジーと機能は、リアルタイム生成 AI モデルの導入に価値をもたらします。あらゆるタイプの企業が新しい AI ツールを導入するにつれ、エッジからデータ センター、クラウドに至るまで、拡張可能で責任ある説明可能な AI ソリューションが求められるデータの課題に直面しています。ハイブリッドおよびマルチクラウドのデータ オーソリティとして、 NetAppは、生成 AI モデルのトレーニング (事前トレーニング)、微調整、コンテキストベースの推論、LLM のモデル減衰モニタリングのためのデータ パイプラインとデータ レイクの構築のあらゆる側面を支援するパートナー ネットワークと共同ソリューションの構築に取り組んでいます。</block>
  <block id="ba4c46fa4f06702b4667d0b3a6b2bdfe" category="section-title">生成 AI とは何ですか?</block>
  <block id="11703c9edbc2bf714a8c4be38891fc77" category="paragraph">生成 AI は、コンテンツの作成方法、新しいデザイン コンセプトの生成方法、斬新な構成の探索方法を変えています。これは、テキスト、コード、画像、オーディオ、ビデオ、合成データなどの新しいコンテンツを生成できる、Generative Adversarial Network (GAN)、Variational Autoencoders (VAE)、Generative Pre-Trained Transformers (GPT) などのニューラル ネットワーク フレームワークを示しています。 OpenAI の Chat-GPT、Google の Bard、Hugging Face の BLOOM、Meta の LLaMA などのトランスフォーマーベースのモデルは、大規模言語モデルの多くの進歩を支える基盤技術として登場しました。同様に、OpenAI の Dall-E、Meta の CM3leon、Google の Imagen は、テキストから画像への拡散モデルの例であり、顧客に前例のないレベルのフォトリアリズムを提供して、新しい複雑な画像をゼロから作成したり、データセットの拡張と、テキストと視覚のセマンティクスをリンクするテキストから画像への合成を使用して既存の画像を編集して高品質のコンテキスト認識画像を生成したりします。デジタル アーティストは、NeRF (Neural Radiance Field) などのレンダリング テクノロジと生成 AI を組み合わせて、静的な 2D 画像を没入型の 3D シーンに変換し始めています。一般に、LLMは次の4つのパラメータによって特徴付けられます: (1) モデルのサイズ（通常は数十億のパラメータ単位）; (2) トレーニングデータセットのサイズ; (3) トレーニングのコスト、および (4) トレーニング後のモデルパフォーマンス。  LLM も主に 3 つのトランスフォーマー アーキテクチャに分類されます。 (i) エンコーダーのみのモデル。例：BERT（Google、2018）、（ii）エンコーダー・デコーダー例：BART（Meta、2020）、および（iii）デコーダーのみのモデル。例：LLaMA（Meta、2023）、PaLM-E（Google、2023）。ビジネス要件に応じて、企業がどのアーキテクチャを選択するかに関係なく、トレーニング データセット内のモデル パラメータの数 (N) とトークンの数 (D) によって、通常、トレーニング (事前トレーニング) または LLM の微調整のベースライン コストが決まります。</block>
  <block id="d1ddcb04dcb447b3f05fa54e9ab492d0" category="section-title">エンタープライズユースケースと下流のNLPタスク</block>
  <block id="a4a7c510156562fb9841dd055348b753" category="paragraph">さまざまな業界の企業は、ビジネス運営、販売、マーケティング、法務サービスのために、AI が既存のデータから新しい形の価値を抽出して生み出す可能性をますます発見しています。 IDC (International Data Corporation) の世界規模の生成 AI の使用事例と投資に関する市場情報によると、ソフトウェア開発と製品設計における知識管理が最も大きな影響を受け、次いでマーケティングのストーリーライン作成と開発者向けのコード生成が影響を受けます。ヘルスケア分野では、臨床研究組織が医学の新たな境地を開拓しています。 ProteinBERT のような事前トレーニング済みモデルには、遺伝子オントロジー (GO) アノテーションが組み込まれており、医薬品のタンパク質構造を迅速に設計できます。これは、創薬、バイオインフォマティクス、分子生物学における重要なマイルストーンとなります。バイオテクノロジー企業は、肺組織に不可逆的な瘢痕化を引き起こす肺疾患である肺線維症（IPF）などの疾患の治療を目的とした、AIが発見した生成薬のヒト臨床試験を開始した。</block>
  <block id="8e5aaca094938e3b1a2e08f48f3db558" category="paragraph">図1: 生成AIを推進するユースケース</block>
  <block id="8d04a6a1813e89b5849d40e5113b0902" category="paragraph"><block ref="8d04a6a1813e89b5849d40e5113b0902" category="inline-image-macro-rx" type="image"></block></block>
  <block id="605e4f6997ac64a7de35f4e8a02721e9" category="paragraph">生成 AI によって促進される自動化の導入の増加は、多くの職業における仕事の需要と供給にも変化をもたらしています。マッキンゼーによれば、米国の労働市場（下の図）は急速な変化を遂げており、AIの影響を考慮するとこの傾向は今後も続く可能性がある。</block>
  <block id="844d4a4d01e4441540857f7a302f6239" category="paragraph">出典：マッキンゼー・アンド・カンパニー</block>
  <block id="14509aeb117a81412dfa4dc27107f735" category="inline-image-macro">図2：出典：マッキンゼー・アンド・カンパニー</block>
  <block id="f86a1cf79787f9ca7a0bc2698a14baa8" category="paragraph"><block ref="1cdd0679074896d7373f66c66dc8dda4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="072f966c176c14e4a8ac1b32dff891bc" category="section-title">生成AIにおけるストレージの役割</block>
  <block id="6a352eac97ff84fb6680bea0e3f1582b" category="inline-link-macro">512 MB</block>
  <block id="23f951a15f217f2ce467c5d52e3a74a2" category="paragraph">LLM は主にディープラーニング、GPU、コンピューティングに依存しています。ただし、GPU バッファがいっぱいになると、データをストレージにすぐに書き込む必要があります。一部の AI モデルはメモリ内で実行できるほど小さいですが、特に数十億のトークンや数百万の画像が含まれる場合、LLM では大規模なデータセットへの高速アクセスを提供するために高い IOPS と高スループットのストレージが必要です。 LLM の一般的な GPU メモリ要件では、10 億のパラメータを持つモデルをトレーニングするために必要なメモリは、32 ビットの完全精度で最大 80 GB になる可能性があります。その場合、70 億から 700 億のパラメータの規模に及ぶ LLM ファミリである Meta の LLaMA 2 では、70x80、約 5600 GB または 5.6 TB の GPU RAM が必要になる可能性があります。さらに、必要なメモリの量は、生成するトークンの最大数に正比例します。例えば、最大512トークン（約380語）の出力を生成したい場合は、<block ref="8b6a924b2b2c8b02d5e56762d0384bc1" category="inline-link-macro-rx"></block> 。重要ではないと思われるかもしれませんが、より大きなバッチを実行したい場合は、その分が加算されていきます。そのため、メモリ内で LLM をトレーニングまたは微調整する組織にとっては非常にコストがかかり、ストレージが生成 AI の基礎となります。</block>
  <block id="b0b4b15d26d559735ca79c547ebcf9b6" category="section-title">LLMへの3つの主なアプローチ</block>
  <block id="29ff458fbe275b29aaf5e7dbd636eed4" category="inline-link-macro">ハーバード・ビジネス・レビュー</block>
  <block id="b026e17fa592b49ccc86f0f9b718b03b" category="paragraph">ほとんどの企業にとって、現在の傾向に基づくと、LLM を導入するアプローチは 3 つの基本シナリオに要約できます。最近の<block ref="9b642d86ef84545807d431905b86239d" category="inline-link-macro-rx"></block>記事: (1) LLM をゼロからトレーニング (事前トレーニング) する – コストがかかり、専門的な AI/ML スキルが必要。(2) 企業データを使用して基礎モデルを微調整する – 複雑だが可能。(3) 検索拡張生成 (RAG) を使用して、企業データを含むドキュメントリポジトリ、API、ベクターデータベースを照会する。これらはそれぞれ、さまざまな種類の問題を解決するために使用される実装において、労力、反復速度、コスト効率、およびモデルの精度の間でトレードオフがあります (下の図)。</block>
  <block id="c35884049dd0467b68f884a60d4920ea" category="paragraph">図3: 問題の種類</block>
  <block id="2ee3234ece3d669efe95dc1a84c67a06" category="paragraph"><block ref="2ee3234ece3d669efe95dc1a84c67a06" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff76a02d3da4ad3236fe1704ce7b2a4c" category="section-title">基礎モデル</block>
  <block id="212ec66e09b7b19d2e397c5c04e8543d" category="paragraph">基礎モデル (FM) はベースモデルとも呼ばれ、大規模な自己監督を使用して大量のラベルなしデータでトレーニングされた大規模な AI モデル (LLM) であり、通常は幅広い下流の NLP タスクに適応します。トレーニング データは人間によってラベル付けされていないため、モデルは明示的にエンコードされるのではなく、自動的に生成されます。これは、モデルが明示的にプログラムされなくても、独自のストーリーや物語を生成できることを意味します。したがって、FM の重要な特徴は均質化であり、これは多くの領域で同じ方法が使用されることを意味します。しかし、パーソナライゼーションと微調整のテクニックにより、最近登場した製品に統合された FM は、テキストの生成、テキストから画像への変換、テキストからコードへの変換が優れているだけでなく、ドメイン固有のタスクの説明やコードのデバッグにも役立ちます。たとえば、OpenAI の Codex や Meta の Code Llama などの FM は、プログラミング タスクの自然言語による記述に基づいて、複数のプログラミング言語でコードを生成できます。これらのモデルは、Python、C#、JavaScript、Perl、Ruby、SQL など 12 を超えるプログラミング言語に精通しています。ユーザーの意図を理解し、ソフトウェア開発、コードの最適化、プログラミング タスクの自動化に役立つ、目的のタスクを実行する特定のコードを生成します。</block>
  <block id="09505640cb74de4ed6c0043b4fd83b62" category="section-title">微調整、ドメイン特異性、再トレーニング</block>
  <block id="d70061bb0ac24d99b6a01f537dfc5836" category="inline-link-macro">メタのラマ2</block>
  <block id="3983fea9bc2f220141201994aa6cf9de" category="paragraph">データの準備とデータの前処理に続く LLM 展開における一般的な方法の 1 つは、大規模で多様なデータセットでトレーニングされた事前トレーニング済みモデルを選択することです。微調整の文脈では、これはオープンソースの大規模言語モデル、例えば<block ref="40c631914d673c775e5813606a4c652a" category="inline-link-macro-rx"></block>700億のパラメータと2兆個のトークンでトレーニングされました。事前トレーニング済みのモデルを選択したら、次のステップはドメイン固有のデータでそれを微調整することです。これには、モデルのパラメータを調整し、特定のドメインとタスクに適応するために新しいデータでトレーニングすることが含まれます。たとえば、金融業界に役立つ幅広い金融データについてトレーニングされた独自の LLM である BloombergGPT などです。特定のタスク向けに設計およびトレーニングされたドメイン固有のモデルは、通常、その範囲内では高い精度とパフォーマンスを備えていますが、他のタスクまたはドメイン間での転送性は低くなります。ビジネス環境とデータが一定期間にわたって変化すると、テスト時のパフォーマンスと比較して、FM の予測精度が低下し始める可能性があります。このとき、モデルの再トレーニングまたは微調整が重要になります。従来の AI/ML におけるモデルの再トレーニングとは、展開された ML モデルを新しいデータで更新することを指し、通常は発生する 2 種類のドリフトを排除するために実行されます。  （１）概念のドリフト - 入力変数と目標変数の関係が時間の経過とともに変化すると、予測したい内容の記述が変化するため、モデルは不正確な予測を生成する可能性があります。 （2）データドリフト - 入力データの特性が変化したときに発生します。たとえば、顧客の習慣や行動が時間の経過とともに変化し、モデルがそのような変化に対応できなくなります。同様に、再トレーニングは FM/LLM にも適用されますが、コストが非常に高くなる可能性がある (数百万ドル単位) ため、ほとんどの組織では検討できない可能性があります。これは現在活発に研究されており、LLMOps の分野ではまだ発展途上です。そのため、再トレーニングの代わりに、微調整された FM でモデルの減衰が発生した場合、企業は新しいデータセットを使用して再度微調整すること (はるかに安価) を選択できます。コストの観点から、Azure-OpenAI Services のモデル価格表の例を以下に示します。各タスク カテゴリごとに、顧客は特定のデータセットでモデルを微調整および評価できます。</block>
  <block id="95d06c21390dc25827c0fd489dc141e4" category="paragraph">出典: Microsoft Azure</block>
  <block id="56307bc010f6f11cf695a4f4a8868ec2" category="paragraph"><block ref="56307bc010f6f11cf695a4f4a8868ec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157d80dbb8ad88a26dfd59594b88e11c" category="section-title">迅速なエンジニアリングと推論</block>
  <block id="e48b39374db0f3e4c1479cb81f7ebd58" category="paragraph">プロンプト エンジニアリングとは、モデルの重みを更新せずに LLM と通信して目的のタスクを実行するための効果的な方法を指します。 AI モデルのトレーニングと微調整が NLP アプリケーションにとって重要であるのと同様に、トレーニングされたモデルがユーザーのプロンプトに応答する推論も同様に重要です。推論のシステム要件は、一般的に、LLM から GPU にデータを供給する AI ストレージ システムの読み取りパフォーマンスに大きく依存します。これは、最適な応答を生成するために、保存されている数十億のモデル パラメータを適用する必要があるためです。</block>
  <block id="71451daa1205b079e03924f700485fb7" category="section-title">LLMOps、モデル監視、Vectorstores</block>
  <block id="37dc13dd8c23bd5e417bad0376cb8642" category="paragraph">従来の機械学習オペレーション (MLOps) と同様に、大規模言語モデルオペレーション (LLMOps) でも、運用環境での LLM の管理のためのツールとベスト プラクティスを備えたデータ サイエンティストと DevOps エンジニアのコラボレーションが必要です。ただし、LLM のワークフローと技術スタックはいくつかの点で異なる可能性があります。たとえば、LangChain などのフレームワークを使用して構築された LLM パイプラインは、ベクターストアやベクター データベースなどの外部埋め込みエンドポイントへの複数の LLM API 呼び出しを連結します。ダウンストリーム コネクタ (ベクター データベースなど) に埋め込みエンドポイントとベクターストアを使用することで、データの保存方法とアクセス方法が大きく進歩しました。ゼロから開発される従来の ML モデルとは対照的に、LLM は、より具体的なドメインでのパフォーマンスを向上させるために新しいデータで微調整された FM から始まるため、転移学習に依存することがよくあります。したがって、LLMOps がリスク管理とモデル減衰監視の機能を提供することが重要です。</block>
  <block id="e1e7449571fe3b65d3a1e689bc700cbc" category="section-title">生成AI時代のリスクと倫理</block>
  <block id="c12a37efb07149af3ee94636c74b80c5" category="paragraph">「ChatGPT – 洗練されているが、それでも意味不明な情報を吐き出す。」– MIT Tech Review。ゴミを入れればゴミしか出てこないというのは、コンピューティングにおいて常に難しい問題です。生成型 AI との唯一の違いは、ゴミを非常に信頼できるものにして、不正確な結果をもたらすことに優れていることです。 LLM は、構築している物語に合うように事実を捏造する傾向があります。したがって、生成 AI を AI と同等のコストを削減する絶好の機会と捉えている企業は、ディープフェイクを効率的に検出し、バイアスを減らし、リスクを低減して、システムの誠実性と倫理性を維持する必要があります。エンドツーエンドの暗号化と AI ガードレールによるデータ モビリティ、データ品質、データ ガバナンス、データ保護をサポートする堅牢な AI インフラストラクチャを備えた自由に流れるデータ パイプラインは、責任ある説明可能な生成 AI モデルの設計において重要です。</block>
  <block id="b1c01c916bfeda43bbe010599a3756ef" category="section-title">顧客シナリオとNetApp</block>
  <block id="d475afb6eaf5d8966136580d55f5a688" category="paragraph">図3: 機械学習/大規模言語モデルのワークフロー</block>
  <block id="1d5b6314b7c490b3ba00c157c5d73c98" category="paragraph"><block ref="1d5b6314b7c490b3ba00c157c5d73c98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9dd90f4ead88ee59ec52f11bac2d164b" category="paragraph">*トレーニングですか、それとも微調整ですか?* (a) LLM モデルを最初からトレーニングするか、事前トレーニング済みの FM を微調整するか、RAG を使用して基盤モデル外のドキュメント リポジトリからデータを取得してプロンプトを拡張するか、(b) オープンソースの LLM (例: Llama 2) または独自の FM (例: ChatGPT、Bard、AWS Bedrock) を活用するかという問題は、組織にとって戦略的な決定です。それぞれのアプローチには、コスト効率、データ重力、運用、モデルの精度、LLM の管理の間でトレードオフがあります。</block>
  <block id="8c8696e5c9dd013fefe41f5a257ecba6" category="paragraph">NetAppは企業として、社内の業務文化や製品の設計およびエンジニアリングへの取り組みに AI を取り入れています。たとえば、NetApp の自律型ランサムウェア保護は、AI と機械学習を使用して構築されています。ファイル システムの異常を早期に検出し、脅威が運用に影響する前に特定できるようにします。  2 番目に、 NetApp は売上や在庫の予測などのビジネス オペレーションに予測 AI を使用し、チャットボットを使用してコール センターの製品サポート サービス、技術仕様、保証、サービス マニュアルなどで顧客を支援します。  3 番目に、 NetApp は、NetApp ONTAP AI、NetApp SnapMirror、NetApp FlexCache などの NetApp 製品と機能を使用して、需要予測、医療用画像処理、感情分析などの予測 AI ソリューションや、製造業における産業用画像異常検出用の GAN や銀行および金融サービスにおけるマネー ロンダリング防止および詐欺検出などの生成 AI ソリューションを構築NetAppにサービスを提供する製品とソリューションを通じて、AINetAppSnapMirrorONTAPとNetApp /NetAppFlexCacheに顧客価値をもたらします。</block>
  <block id="1e79e12b94e448f7c2f614e8ab2794ba" category="section-title">NetAppの機能</block>
  <block id="14560cdfa11223c1b6b5ae41321de6d4" category="paragraph">チャットボット、コード生成、画像生成、ゲノムモデル表現などの生成 AI アプリケーションにおけるデータの移動と管理は、エッジ、プライベート データ センター、ハイブリッド マルチクラウド エコシステムにまたがって行われます。たとえば、ChatGPT などの事前トレーニング済みモデルの API を介して公開されるエンドユーザー アプリから、乗客が航空券をビジネス クラスにアップグレードするのを支援するリアルタイム AI ボットは、乗客情報がインターネット上で公開されていないため、単独ではそのタスクを達成できません。 API は、ハイブリッドまたはマルチクラウド エコシステム内に存在する可能性のある航空会社からの乗客の個人情報とチケット情報にアクセスする必要があります。同様のシナリオは、1 対多の生物医学研究機関が関与する創薬全体にわたって臨床試験を実行するために LLM を使用するエンドユーザー アプリケーションを介して薬剤分子と患者データを共有する科学者にも当てはまる可能性があります。 FM または LLM に渡される機密データには、PII、財務情報、健康情報、生体認証データ、位置データ、通信データ、オンライン行動、法的情報などが含まれる場合があります。このようなリアルタイム レンダリング、プロンプト実行、エッジ推論のイベントでは、エンド ユーザー アプリからオープン ソースまたは独自の LLM モデルを経由してストレージ エンドポイントにデータが移動され、さらにオンプレミスまたはパブリック クラウド プラットフォーム上のデータ センターにデータが移動されます。このようなすべてのシナリオにおいて、大規模なトレーニング データセットとそのようなデータの移動に依存する LLM を伴う AI 操作にとって、データのモビリティとデータ保護は非常に重要です。</block>
  <block id="2bf2b67b54f29152ea5e8649dd4b7327" category="paragraph">図4: 生成AI - LLMデータパイプライン</block>
  <block id="206f6329180f9a8251d5f78b853663ab" category="inline-image-macro">図4: 生成AI-LLMデータパイプライン</block>
  <block id="47b42e2c6c693df656a00ec63e39dde3" category="paragraph"><block ref="47b42e2c6c693df656a00ec63e39dde3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc004144b88d4fadbbf7623c57d2c805" category="paragraph">NetApp のストレージ インフラストラクチャ、データ、クラウド サービスのポートフォリオは、インテリジェントなデータ管理ソフトウェアによって強化されています。</block>
  <block id="7d5e80d61d854ee2e646efedf9f5e72d" category="paragraph">*データ準備*: LLM 技術スタックの最初の柱は、従来の ML スタックからほとんど変更されていません。 AI パイプラインでのデータ前処理は、トレーニングや微調整の前にデータを正規化およびクレンジングするために必要です。このステップには、Amazon S3 層の形式、またはファイル ストアやNetApp StorageGRIDなどのオブジェクト ストアなどのオンプレミスのストレージ システムの形式で存在する場所に関係なくデータを取り込むためのコネクタが含まれます。</block>
  <block id="b63aea4b58eede8ed8da27c8b36c34dc" category="paragraph">* NetApp ONTAP* は、データセンターとクラウドにおける NetApp の重要なストレージ ソリューションを支える基盤テクノロジーです。  ONTAPには、サイバー攻撃に対する自動ランサムウェア保護、組み込みデータ転送機能、オンプレミス、ハイブリッド、NAS、SAN、オブジェクト、ソフトウェア定義ストレージ (SDS) の LLM 展開におけるマルチクラウドのさまざまなアーキテクチャに対応するストレージ効率機能など、さまざまなデータ管理および保護機能が含まれています。</block>
  <block id="77b83e7426a1ca8eea17df3ff3a421f7" category="paragraph">* ディープラーニング モデルのトレーニング用NetApp ONTAP AI*。 NetApp ONTAP は、 ONTAPストレージ クラスタとNVIDIA DGX コンピューティング ノードを使用するNetApp顧客向けに、NFS over RDMA を使用したNVIDIA GPU Direct Storage をサポートします。コスト効率の高いパフォーマンスを提供し、ソース データセットをストレージからメモリに何度も読み取って処理することでインテリジェンスを促進し、組織が LLM へのアクセスをトレーニング、微調整、スケーリングできるようにします。</block>
  <block id="420e9d37fdcde42065e69c7f6d925ab3" category="paragraph">* NetApp FlexCache* は、ファイルの配布を簡素化し、アクティブに読み取られたデータのみをキャッシュするリモート キャッシュ機能です。これは、LLM のトレーニング、再トレーニング、微調整に役立ち、リアルタイム レンダリングや LLM 推論などのビジネス要件を持つ顧客に価値をもたらします。</block>
  <block id="0aef0293018a6f953acd79d5d6fb52ae" category="paragraph">* NetApp SnapMirror * は、任意の 2 つのONTAPシステム間でボリューム スナップショットを複製するONTAP機能です。この機能は、エッジのデータをオンプレミスのデータセンターまたはクラウドに最適に転送します。 SnapMirror は、顧客がエンタープライズ データを含む RAG を使用してクラウドで生成 AI を開発する場合に、オンプレミス クラウドとハイパースケーラー クラウド間でデータを安全かつ効率的に移動するために使用できます。変更のみを効率的に転送することで、帯域幅を節約し、レプリケーションを高速化します。これにより、FM または LLM のトレーニング、再トレーニング、微調整の操作中に重要なデータ移動機能が提供されます。</block>
  <block id="67e47ad6c891ade32e226f1b046d1168" category="paragraph">* NetApp SnapLock* は、データセットのバージョン管理のために、 ONTAPベースのストレージ システムに不変のディスク機能をもたらします。マイクロコア アーキテクチャは、FPolicy Zero Trust エンジンを使用して顧客データを保護するように設計されています。  NetApp は、攻撃者が特にリソースを消費する方法で LLM と対話する場合に、サービス拒否 (DoS) 攻撃に抵抗することで、顧客データの可用性を確保します。</block>
  <block id="6fb00f321c345f8a92148aec8d1359f9" category="paragraph">* NetApp Cloud Data Sense* は、企業のデータセット内に存在する個人情報を識別、マッピング、分類し、ポリシーを制定し、オンプレミスまたはクラウドでのプライバシー要件を満たし、セキュリティ体制を改善して規制に準拠するのに役立ちます。</block>
  <block id="8bca7c4074d7b3156f8b66e3ad7a5be8" category="paragraph">* NetApp BlueXP* Cloud Data Sense を活用した分類。顧客は、データ資産全体のデータを自動的にスキャン、分析、分類、操作し、セキュリティ リスクを検出し、ストレージを最適化し、クラウドの導入を加速できます。統合コントロール プレーンを介してストレージ サービスとデータ サービスを組み合わせ、顧客は計算に GPU インスタンスを使用し、コールド ストレージ階層化とアーカイブおよびバックアップにハイブリッド マルチクラウド環境を使用できます。</block>
  <block id="528fb7334ec5453cef67bca12d29f735" category="paragraph">* NetAppファイルとオブジェクトの二重性*。 NetApp ONTAP は、NFS と S3 のデュアルプロトコル アクセスを可能にします。このソリューションにより、顧客はNetApp Cloud Volumes ONTAPの S3 バケットを介して Amazon AWS SageMaker ノートブックの NFS データにアクセスできるようになります。これにより、NFS と S3 の両方からデータを共有し、異種データ ソースに簡単にアクセスする必要がある顧客に柔軟性が提供されます。たとえば、ファイル オブジェクト バケットにアクセスして、SageMaker 上の Meta の Llama 2 テキスト生成モデルなどの FM を微調整します。</block>
  <block id="a2e08866ca50b890089d6b77f640d7b5" category="paragraph">* NetApp Cloud Sync* サービスは、クラウドまたはオンプレミスの任意のターゲットにデータを移行するためのシンプルで安全な方法を提供します。  Cloud Sync は、オンプレミスまたはクラウド ストレージ、NAS、オブジェクト ストア間でデータをシームレスに転送および同期します。</block>
  <block id="e53b3c8e83c8d94be048ce5801830a49" category="paragraph">* NetApp XCP* は、あらゆるデバイスからNetAppへ、またNetAppからNetAppへのデータ移行を高速かつ確実に実行できるクライアント ソフトウェアです。  XCP は、Hadoop HDFS ファイル システムからONTAP NFS、S3、またはStorageGRIDに大量のデータを効率的に移動する機能も提供し、XCP ファイル分析はファイル システムの可視性を提供します。</block>
  <block id="d0d48e5a8fe903e906882461b57dcfd3" category="paragraph">* NetApp DataOps Toolkit* は、データ サイエンティスト、DevOps、データ エンジニアが、高性能スケールアウト NetApp ストレージを基盤とするデータ ボリュームや JupyterLab ワークスペースのプロビジョニング、クローン作成、スナップショット作成などのさまざまなデータ管理タスクをほぼ瞬時に実行できるようにするNetAppライブラリです。</block>
  <block id="97d451a12ea524d66984cc35758777b4" category="paragraph">*NetApp の製品セキュリティ*。  LLM は応答の中で機密データを誤って公開する可能性があるため、LLM を活用した AI アプリケーションに関連する脆弱性を研究する CISO にとっては懸念事項となります。 OWASP (Open Worldwide Application Security Project) で概説されているように、LLM 内のデータ ポイズニング、データ漏洩、サービス拒否、プロンプト インジェクションなどのセキュリティ問題は、データの露出から攻撃者による不正アクセスまで、企業に影響を及ぼす可能性があります。データ ストレージ要件には、構造化データ、半構造化データ、非構造化データの整合性チェックと不変のスナップショットが含まれる必要があります。データセットのバージョン管理には、 NetAppスナップショットおよびSnapLock が使用されています。厳格なロールベースのアクセス制御 (RBAC)、安全なプロトコル、業界標準の暗号化を導入し、保存中のデータと転送中のデータの両方を保護できます。  Cloud Insightsと Cloud Data Sense を組み合わせることで、脅威の原因をフォレンジック的に特定し、復元するデータの優先順位を決定するのに役立つ機能が提供されます。</block>
  <block id="0364ee2a32c23b9f35e29f68c79d63e1" category="section-title">* DGX BasePOD を搭載したONTAP AI*</block>
  <block id="c6f1dc673303b79fafb5e05f0c7a97cb" category="paragraph">NVIDIA DGX BasePOD を搭載したNetApp ONTAP AI リファレンス アーキテクチャは、機械学習 (ML) および人工知能 (AI) ワークロード向けのスケーラブルなアーキテクチャです。 LLM の重要なトレーニング フェーズでは、通常、データはデータ ストレージからトレーニング クラスターに定期的にコピーされます。このフェーズで使用されるサーバーは、GPU を使用して計算を並列化し、膨大な量のデータを必要とします。生の I/O 帯域幅のニーズを満たすことは、高い GPU 使用率を維持するために非常に重要です。</block>
  <block id="9a05494b8b259619e21e3e78c47f4dc5" category="section-title">* NVIDIA AI Enterprise を搭載したONTAP AI*</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise は、 NVIDIA認定システムを搭載した VMware vSphere で実行できるようにNVIDIAによって最適化、認定、サポートされている、エンドツーエンドのクラウド ネイティブな AI およびデータ分析ソフトウェア スイートです。このソフトウェアは、最新のハイブリッド クラウド環境での AI ワークロードのシンプルかつ迅速な導入、管理、スケーリングを可能にします。  NetAppと VMware を搭載したNVIDIA AI Enterprise は、シンプルで使い慣れたパッケージでエンタープライズ クラスの AI ワークロードとデータ管理を提供します。</block>
  <block id="1ad177c0b9d841f941eb7d5322dc9b52" category="section-title">*1Pクラウドプラットフォーム*</block>
  <block id="0e877c6cfb49f5bbdc17c6d204b4b7cb" category="paragraph">完全に管理されたクラウド ストレージ オファリングは、Microsoft Azure ではAzure NetApp Files (ANF) として、AWS ではAmazon FSx for NetApp ONTAP (FSx ONTAP) として、Google ではGoogle Cloud NetApp Volumes (GNCV) としてネイティブに利用できます。  1P は、パブリッククラウドでデータセキュリティを強化し、可用性の高い AI ワークロードを実行できるようにする、マネージド型の高性能ファイルシステムです。AWS SageMaker、Azure-OpenAI サービス、Google の Vertex AI などのクラウドネイティブ ML プラットフォームを使用して LLM/FM を微調整できます。</block>
  <block id="64992f0c01704aa99d3bd851b7673bf7" category="section-title">NetAppパートナー ソリューション スイート</block>
  <block id="0e3151175898c0a6687552a854a08b00" category="paragraph">NetApp は、コアとなるデータ製品、テクノロジー、機能に加え、強力な AI パートナー ネットワークとも緊密に連携し、顧客に付加価値を提供しています。</block>
  <block id="5c682f526a6d29391ad4d45cd7c7cae9" category="paragraph">* AI システムのNVIDIA Guardrails* は、AI テクノロジーの倫理的かつ責任ある使用を保証するための安全策として機能します。 AI 開発者は、特定のトピックに関する LLM 対応アプリケーションの動作を定義し、不要なトピックに関するディスカッションに参加できないようにすることができます。オープンソース ツールキットである Guardrails は、信頼性が高く、安全で、セキュリティ保護された LLM 会話システムを構築するために、LLM を他のサービスにシームレスかつ安全に接続する機能を提供します。</block>
  <block id="0b46f95333d136197f1bb757634ebae2" category="paragraph">*Domino Data Lab* は、AI 導入のどの段階であっても、高速、安全、かつ経済的な Generative AI の構築と製品化のための多用途のエンタープライズ グレードのツールを提供します。  Domino のエンタープライズ MLOps プラットフォームを使用すると、データ サイエンティストは好みのツールとすべてのデータを使用し、どこからでも簡単にモデルをトレーニングおよび展開し、リスクとコストを効果的に管理できます。これらはすべて 1 つのコントロール センターから実行できます。</block>
  <block id="20350fb42ff163b07d9d4a2636b4a555" category="paragraph">*エッジ AI 向け Modzy*。  NetAppと Modzy は提携して、画像、音声、テキスト、表など、あらゆる種類のデータに大規模な AI を提供しています。  Modzy は、AI モデルを展開、統合、実行するための MLOps プラットフォームであり、データ サイエンティストにモデル監視、ドリフト検出、説明可能性の機能を提供し、シームレスな LLM 推論のための統合ソリューションを提供します。</block>
  <block id="50841f507614d3540c25e7671dc0cdc0" category="paragraph">*Run:AI* とNetAppは提携して、AI ワークロードのオーケストレーションを簡素化する Run:AI クラスタ管理プラットフォームを使用したNetApp ONTAP AI ソリューションの独自の機能を実証しました。  GPU リソースを自動的に分割および結合し、Spark、Ray、Dask、Rapids の統合フレームワークが組み込まれているため、データ処理パイプラインを数百台のマシンに拡張できるように設計されています。</block>
  <block id="7f8ef2f7d9a73eb64e35d815049ddd46" category="paragraph">生成 AI は、モデルが大量の高品質データでトレーニングされた場合にのみ効果的な結果を生成できます。  LLM は目覚ましい成果を達成してきましたが、その限界、設計上の課題、およびデータのモビリティとデータ品質に関連するリスクを認識することが重要です。 LLM は、異種のデータ ソースからの大規模かつ多様なトレーニング データセットに依存します。モデルによって生成された不正確な結果や偏った結果は、企業と消費者の両方を危険にさらす可能性があります。これらのリスクは、データ品質、データ セキュリティ、およびデータ モビリティに関連するデータ管理の課題から潜在的に生じる LLM の制約に対応する可能性があります。 NetApp は、急速なデータ増加、データ モビリティ、マルチクラウド管理、AI の導入によって生じる複雑さに組織が対応できるよう支援します。大規模な AI インフラストラクチャと効率的なデータ管理は、生成 AI などの AI アプリケーションの成功を定義する上で非常に重要です。コスト効率、データ ガバナンス、倫理的な AI プラクティスを管理しながら、企業のニーズに応じて拡張する能力を損なうことなく、すべての展開シナリオをカバーすることが、お客様にとって重要です。  NetApp は、お客様の AI 導入を簡素化し、加速させるために常に取り組んでいます。</block>
  <block id="cea78864209b835e9b37cbe0a2cb862e" category="doc">NVA-1172-DESIGN: NVIDIA OVX 対応のNetApp AIPodと Lenovo</block>
  <block id="cd270e0e169361bb079873f1cb21e6b5" category="paragraph">ボビー・ウーメン、アビナフ・シン、ロニー・ダニエル、 NetApp</block>
  <block id="999a2bd7b329bd7fe4178352281b558b" category="paragraph">このリファレンス アーキテクチャは、 NVIDIA L40S GPU を搭載したNVIDIA認定 OVX Lenovo ThinkSystem サーバーとNVIDIA Spectrum ネットワークを組み合わせて、LLM (大規模言語モデル) を最適化して展開するための最適なインフラストラクチャ ソリューションを提供します。このドキュメントの目的は、OVX 構成のストレージに関するガイダンスを提供することです。このプラットフォームは、RAG (Retrieval Augmented Generation)、微調整、軽量モデルトレーニングなど、さまざまな Generative AI ワークロードに適しています。</block>
  <block id="688a655aa25fa96dbcd977348cc95acc" category="inline-link-macro">NVA-1172-DESIGN: NetApp AIPod with Lenovo for NVIDIA OVX 設計ガイド</block>
  <block id="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="paragraph"><block ref="07ba0b8aab1e2887d9dc0f7f9d5dad4f" category="inline-link-macro-rx"></block></block>
  <block id="82b67ae3d50932b0d818b7c3a23b3428" category="summary">NetApp AIPodとNVIDIA DGX システム - アーキテクチャ</block>
  <block id="92527686d5dc11342676e296e31b0b51" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX H100 システム - ソリューション アーキテクチャ</block>
  <block id="34fc6f8c7d10337be1b911dd98627e40" category="paragraph">このセクションでは、 NVIDIA DGX システムを搭載したNetApp AIPodのアーキテクチャに焦点を当てます。</block>
  <block id="b10a3a95ab83cbad7acc457e6bc13a1b" category="section-title">DGX システムを搭載したNetApp AIPod</block>
  <block id="990e00b86cef2bb25d2e346df6e7adfe" category="paragraph">このリファレンス アーキテクチャは、コンピューティング ノード間の 400Gb/s InfiniBand (IB) 接続を使用して、コンピューティング クラスター相互接続とストレージ アクセスに個別のファブリックを活用します。下の図は、DGX H100 システムを使用したNetApp AIPodの全体的なソリューション トポロジを示しています。</block>
  <block id="5d065d1080de5349462d7a342f622bf3" category="paragraph">_NetApp AIpodソリューションのトポロジ_</block>
  <block id="552dcf63ade7f6a706107c5da1f5a2a6" category="paragraph"><block ref="552dcf63ade7f6a706107c5da1f5a2a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">ネットワーク設計</block>
  <block id="57f55a30c80dbf621eb119c782a8b3c5" category="paragraph">この構成では、コンピューティング クラスター ファブリックは、高可用性を実現するために相互に接続された 1 組の QM9700 400Gb/s IB スイッチを使用します。各 DGX H100 システムは 8 つの接続を使用してスイッチに接続され、偶数番号のポートが 1 つのスイッチに接続され、奇数番号のポートが他のスイッチに接続されます。</block>
  <block id="8ee4ef799026973266981f7c555ea058" category="paragraph">ストレージ システム アクセス、インバンド管理、およびクライアント アクセスには、SN4600 イーサネット スイッチのペアが使用されます。スイッチはスイッチ間リンクで接続され、さまざまなトラフィック タイプを分離するために複数の VLAN が構成されています。特定の VLAN 間で基本的な L3 ルーティングが有効になり、同じスイッチ上のクライアントとストレージ インターフェイス間、およびスイッチ間で複数のパスが有効になり、高可用性が実現します。より大規模な導入の場合、必要に応じてスパイン スイッチ用のスイッチ ペアと追加のリーフを追加することで、イーサネット ネットワークをリーフ スパイン構成に拡張できます。</block>
  <block id="082b01f67d64181611dc998408a2b121" category="inline-link-macro">展開の詳細</block>
  <block id="41b55cdcb36636c126a5ef6c6e873a08" category="paragraph">コンピューティング相互接続と高速イーサネット ネットワークに加えて、すべての物理デバイスは、帯域外管理のために 1 つ以上の SN2201 イーサネット スイッチにも接続されます。詳しくは<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>ネットワーク構成の詳細については、ページをご覧ください。</block>
  <block id="9eaf2c6f65cf6ad700b387972ddc345e" category="section-title">DGX H100 システムのストレージ アクセスの概要</block>
  <block id="b1cdc2ac23891a1bf0e697359ffeeef6" category="paragraph">各 DGX H100 システムには、管理およびストレージ トラフィック用の 2 つのデュアル ポート ConnectX-7 アダプタがプロビジョニングされており、このソリューションでは各カードの両方のポートが同じスイッチに接続されます。次に、各カードの 1 つのポートが LACP MLAG ボンドに設定され、各スイッチに 1 つのポートが接続されます。このボンドでは、インバンド管理、クライアント アクセス、およびユーザー レベルのストレージ アクセス用の VLAN がホストされます。</block>
  <block id="891c72a31ed1199769c3f62cab11e7b4" category="paragraph">各カードのもう 1 つのポートは、 AFF A90ストレージ システムへの接続に使用され、ワークロードの要件に応じて複数の構成で使用できます。  NVIDIA Magnum IO GPUDirect ストレージをサポートするために RDMA 経由の NFS を使用する構成の場合、ポートは個別の VLAN 内の IP アドレスで個別に使用されます。  RDMA を必要としない展開の場合、ストレージ インターフェイスを LACP ボンディングで構成して、高可用性と追加の帯域幅を実現することもできます。 RDMA の有無にかかわらず、クライアントは NFS v4.1 pNFS とセッション トランキングを使用してストレージ システムをマウントし、クラスター内のすべてのストレージ ノードへの並列アクセスを有効にできます。詳しくは<block ref="11e89a956fe8616ed611e595e22cdb97" category="inline-link-macro-rx"></block>クライアント構成の詳細については、ページをご覧ください。</block>
  <block id="c95998835114a4e50f348f8c5e5686ed" category="inline-link-macro">NVIDIA BasePOD ドキュメント</block>
  <block id="8660b0a825d671d8855117ae496d3af6" category="paragraph">DGX H100システムの接続の詳細については、<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> 。</block>
  <block id="42dc99c097c1b9b9af75ba060788e1f1" category="section-title">ストレージシステムの設計</block>
  <block id="61b2fad5f824784462363e1b366833fa" category="paragraph">各AFF A90ストレージ システムは、各コントローラからの 6 つの 200 GbE ポートを使用して接続されます。各コントローラの 4 つのポートは DGX システムからのワークロード データ アクセスに使用され、各コントローラの 2 つのポートは LACP インターフェイス グループとして構成され、クラスタ管理アーティファクトとユーザー ホーム ディレクトリの管理プレーン サーバーからのアクセスをサポートします。ストレージ システムからのすべてのデータ アクセスは NFS を介して提供され、AI ワークロード アクセス専用のストレージ仮想マシン (SVM) と、クラスター管理専用の別の SVM が用意されています。</block>
  <block id="6c9aef89eae0fd771909b15623e452df" category="paragraph">管理 SVM には、各コントローラに設定された 2 ポート インターフェイス グループでホストされる単一の LIF のみが必要です。その他のFlexGroupボリュームは、クラスタ ノード イメージ、システム監視履歴データ、エンド ユーザーのホーム ディレクトリなどのクラスタ管理アーティファクトを格納するために管理 SVM 上にプロビジョニングされます。下の図は、ストレージ システムの論理構成を示しています。</block>
  <block id="995db3e6bdfdd81bd5e1b6a98b33e5b7" category="paragraph">_NetApp A90 ストレージ クラスタの論理構成_</block>
  <block id="1e7a613d4d1ae838806eb303b8f25492" category="paragraph"><block ref="1e7a613d4d1ae838806eb303b8f25492" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6420553f17ebdab39fa9a1825d57651" category="section-title">管理プレーンサーバー</block>
  <block id="e6391a8600a62f5346ec27d437d43626" category="paragraph">このリファレンス アーキテクチャには、管理プレーンで使用するための 5 台の CPU ベースのサーバーも含まれています。これらのシステムのうち 2 つは、クラスターの展開と管理のためのNVIDIA Base Command Manager のヘッド ノードとして使用されます。他の 3 つのシステムは、ジョブ スケジューリングに Slurm を利用したデプロイメント用の Kubernetes マスター ノードやログイン ノードなどの追加のクラスター サービスを提供するために使用されます。  Kubernetes を活用した導入では、 NetApp Trident CSI ドライバーを活用して、 AFF A900ストレージ システム上の管理ワークロードと AI ワークロードの両方に永続ストレージを備えた自動プロビジョニングとデータ サービスを提供できます。</block>
  <block id="108f9bbf932c304dff7d03edbf186c18" category="paragraph">各サーバーは、クラスターの展開と管理を可能にするために IB スイッチと Ethernet スイッチの両方に物理的に接続されており、前述のようにクラスター管理アーティファクトを保存するために管理 SVM を介してストレージ システムへの NFS マウントが設定されています。</block>
  <block id="19a97f58216292f6ce34aa1a3ad9e96e" category="summary">NetApp AIPodとNVIDIA DGX システム - 詳細情報の入手先</block>
  <block id="43e1c1d93ec30f643ac7004cd6fafc47" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX システム - まとめと追加情報</block>
  <block id="7c3d91801a54614f755a9f2897ee42f3" category="paragraph">このセクションには、 NVIDIA DGX システムを搭載したNetApp AIPodに関する追加情報の参照が含まれています。</block>
  <block id="bcde7144e6a13836183bd03e403987ef" category="paragraph">DGX BasePOD アーキテクチャは、同様に高度なストレージとデータ管理機能を必要とする次世代のディープラーニング プラットフォームです。  DGX BasePOD とNetApp AFFシステムを組み合わせることで、 NetApp AIPodと DGX システムのアーキテクチャをほぼあらゆる規模で実装できます。  AFF は、 NetApp ONTAPの優れたクラウド統合とソフトウェア定義機能と組み合わせることで、エッジ、コア、クラウドにわたる包括的なデータ パイプラインを実現し、DL プロジェクトを成功させます。</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="section-title">追加情報</block>
  <block id="68e34599e7058d633da08de84c55032d" category="paragraph">このドキュメントに記載されている情報の詳細については、次のドキュメントや Web サイトを参照してください。</block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAPデータ管理ソフトウェア — ONTAP情報ライブラリ</block>
  <block id="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link"><block ref="5f60faf04d2b972aa0cf8c369cfc6a26" category="inline-link-rx"></block></block>
  <block id="d99ede023f079413a479e349dcb54616" category="paragraph"><block ref="d99ede023f079413a479e349dcb54616" category="inline-link-rx"></block></block>
  <block id="b8667e5a766c0335e106bdd9b4ea825f" category="list-text">NetApp AFF A90ストレージシステム -</block>
  <block id="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link"><block ref="8a5df1408a92dc0ef3181cd15cbc989e" category="inline-link-rx"></block></block>
  <block id="22ef65e375f266c2889509f939e1ac83" category="paragraph"><block ref="22ef65e375f266c2889509f939e1ac83" category="inline-link-rx"></block></block>
  <block id="29b91fda4bb7baae0176d0ca5870634a" category="list-text">NetApp ONTAP RDMA情報 -</block>
  <block id="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-macro"><block ref="0f4b138acdd63a2f36e4aeb66ce027c5" category="inline-link-rx"></block></block>
  <block id="c08c09703d9322a16ef4a93b82ff897e" category="paragraph"><block ref="c08c09703d9322a16ef4a93b82ff897e" category="inline-link-macro-rx"></block></block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="list-text">NetAppTrident</block>
  <block id="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="paragraph"><block ref="3daf8b3b7ee9b11922ef3d82e81e3a2c" category="inline-link-macro-rx"></block></block>
  <block id="4613e07c94020e7ba8189d048f9d61c1" category="list-text">NetApp GPUDirect ストレージブログ -</block>
  <block id="cf8832fa60205a911c1036fb274f649e" category="inline-link"><block ref="cf8832fa60205a911c1036fb274f649e" category="inline-link-rx"></block></block>
  <block id="0f1f9907ba0a6f040f1fa28d77e74fb8" category="paragraph"><block ref="0f1f9907ba0a6f040f1fa28d77e74fb8" category="inline-link-rx"></block></block>
  <block id="64dc43320ec1a44c390fafb5e2408f4b" category="list-text">NVIDIA DGX BasePOD</block>
  <block id="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link"><block ref="6ff1278864800ae134fcd2dda1a5e0e9" category="inline-link-rx"></block></block>
  <block id="0c2cd58ffa7f091c420ae61854a0a8db" category="paragraph"><block ref="0c2cd58ffa7f091c420ae61854a0a8db" category="inline-link-rx"></block></block>
  <block id="e3d6e4bdd7281f2c5d652f6f01825970" category="list-text">NVIDIA DGX H100 システム</block>
  <block id="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link"><block ref="f3d1cd3a647a52b1157c812ae2d90248" category="inline-link-rx"></block></block>
  <block id="f4e11a54d0110771220fa05425235763" category="paragraph"><block ref="f4e11a54d0110771220fa05425235763" category="inline-link-rx"></block></block>
  <block id="d90238071267e4279a25de2c6945b227" category="list-text">NVIDIAネットワーク</block>
  <block id="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link"><block ref="51c8257f6c8ba308b83f9f13b405dad0" category="inline-link-rx"></block></block>
  <block id="a19d7568aa9c7e4c1f3bf3e831367115" category="paragraph"><block ref="a19d7568aa9c7e4c1f3bf3e831367115" category="inline-link-rx"></block></block>
  <block id="a96fecd8b3666b7b60c0bc0a24db79b2" category="list-text">NVIDIA Magnum IO™ GPUDirect™ ストレージ</block>
  <block id="74079d06fd0015403a15f89699e6bcba" category="inline-link"><block ref="74079d06fd0015403a15f89699e6bcba" category="inline-link-rx"></block></block>
  <block id="110c88150ddcbc728071b2fcd7848bd2" category="paragraph"><block ref="110c88150ddcbc728071b2fcd7848bd2" category="inline-link-rx"></block></block>
  <block id="c7bef72157cc39b6eb7c391a393a20d2" category="list-text">NVIDIAベースコマンド</block>
  <block id="bbae10fb46fb1d3604fe601d556f4187" category="inline-link"><block ref="bbae10fb46fb1d3604fe601d556f4187" category="inline-link-rx"></block></block>
  <block id="936c47b696a994feb0ad33a2addb1168" category="paragraph"><block ref="936c47b696a994feb0ad33a2addb1168" category="inline-link-rx"></block></block>
  <block id="b4675c30af15f661c8112c2853f97970" category="list-text">NVIDIAベースコマンドマネージャー</block>
  <block id="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link"><block ref="5cb8e16a3e555ee938b528aaeb45b703" category="inline-link-rx"></block></block>
  <block id="6b36fdb81918af4b96afe2ba587a8ae1" category="paragraph"><block ref="6b36fdb81918af4b96afe2ba587a8ae1" category="inline-link-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="list-text">NVIDIA AIエンタープライズ</block>
  <block id="42c9b161f86365b647172182503d9520" category="inline-link"><block ref="42c9b161f86365b647172182503d9520" category="inline-link-rx"></block></block>
  <block id="f5802e2c53799babc0ac27f6cb392604" category="paragraph"><block ref="f5802e2c53799babc0ac27f6cb392604" category="inline-link-rx"></block></block>
  <block id="9132ee4ebfc1bcccf9be22b87e818413" category="paragraph">このドキュメントは、 NetAppソリューションおよびONTAPエンジニアリング チーム (David Arnette、Olga Kornievskaia、Dustin Fischer、Srikanth Kaligotla、Mohit Kumar、および Raghuram Sudhaakar) によって作成されました。著者らは、継続的なサポートをいただいたNVIDIAおよびNVIDIA DGX BasePODエンジニアリング チームにも感謝の意を表します。</block>
  <block id="7c4d674fe3a4532c3ffe553151378a3f" category="summary">NetApp AIPodとNVIDIA DGX システム - 導入</block>
  <block id="302db59f0ad2458d76aedcc8a6fdd7be" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX システム - 導入の詳細</block>
  <block id="c584dd3e1383c7899a434fb7b8e1a341" category="paragraph">このセクションでは、このソリューションの検証中に使用される展開の詳細について説明します。使用される IP アドレスは例であり、展開環境に基づいて変更する必要があります。この構成の実装に使用される特定のコマンドの詳細については、適切な製品ドキュメントを参照してください。</block>
  <block id="b5f0a1ca7b5559b93159bcc11b7b99e9" category="paragraph">下の図は、1 つの DGX H100 システムと 1 つの HA ペアのAFF A90コントローラの詳細なネットワークおよび接続情報を示しています。次のセクションの展開ガイダンスは、この図の詳細に基づいています。</block>
  <block id="a1ce9904a2cc7e8a6e1267980553c732" category="paragraph">_NetApp AIpod ネットワーク構成_</block>
  <block id="c4e9bce0ddaf289da0094c0a0560c136" category="paragraph"><block ref="c4e9bce0ddaf289da0094c0a0560c136" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea12591fa7a8663c28086764fc393d35" category="paragraph">次の表は、最大 16 個の DGX システムと 2 個のAFF A90 HA ペアのケーブル割り当ての例を示しています。</block>
  <block id="4919e7d6c7a8481619e206520f937aaf" category="cell">スイッチとポート</block>
  <block id="e0ac20adce6ffee48c7151b070aa5737" category="cell">デバイス</block>
  <block id="e85450f6454a8b84aa3dd8ab4cfe658c" category="cell">デバイスポート</block>
  <block id="bdbd5451b62f5c0739cd0300b29d0db1" category="cell">スイッチ1ポート1～16</block>
  <block id="b6bf51e15f6d9d931c3ef52dcf7c2e74" category="cell">DGX-H100-01から-16</block>
  <block id="4d866d6d7dc3628895dbedb26f1bdf96" category="cell">enp170s0f0np0、スロット1ポート1</block>
  <block id="6438dabe67e09d4e0ec2e3d17d7074f9" category="cell">スイッチ1ポート17-32</block>
  <block id="744d517d131df3b9ae1b4bdbdf70b282" category="cell">enp170s0f1np1、スロット1ポート2</block>
  <block id="2914cd4a87277c08ac1f71cafd311de5" category="cell">スイッチ1ポート33-36</block>
  <block id="b08a34f62ae5d3df1c59356cb996a50a" category="cell">AFF-A90-01から-04</block>
  <block id="3d163afca230cdca293d07b9bce1004f" category="cell">ポートe6a</block>
  <block id="09a5a99bfdac461078765cf577fa36c1" category="cell">スイッチ1ポート37-40</block>
  <block id="67d1565f0da7861ffc787acf0cc159af" category="cell">ポートe11a</block>
  <block id="d350694943ec1acbb17fb85d69fd2aa9" category="cell">スイッチ1ポート41-44</block>
  <block id="44b26214a7c3f5ffe5ec1db0aa3e4f98" category="cell">ポートe2a</block>
  <block id="9e444fba13b3dd8f65bd7deb1b742747" category="cell">スイッチ1ポート57-64</block>
  <block id="7a744922ca20208077a50d69271d15fd" category="cell">ISLからスイッチ2へ</block>
  <block id="68813ae3b3a11b5b786ffe4305c5d542" category="cell">ポート57～64</block>
  <block id="9b878f628cccd99408682b50785b3598" category="cell">スイッチ2ポート1-16</block>
  <block id="3cdeea9afe6ab2952bd32f14b371d0c3" category="cell">enp41s0f0np0、スロット2ポート1</block>
  <block id="6a11ad764d8b60d242c533b565b99142" category="cell">スイッチ2ポート17-32</block>
  <block id="e26d3524de049d551125c01b1d65729e" category="cell">enp41s0f1np1、スロット2ポート2</block>
  <block id="59ba8265a302f2fb97997075c8f27f6d" category="cell">スイッチ2ポート33-36</block>
  <block id="9df3af84859046bac07e13013fce0466" category="cell">ポートe6b</block>
  <block id="d9a9acdd71cb92eb03299a9702a84577" category="cell">スイッチ2ポート37-40</block>
  <block id="0b9b24c59934606f5e10f1c15b3a86cb" category="cell">ポートe11b</block>
  <block id="2f4b59b7b40dec7ee6362e6017960380" category="cell">スイッチ2ポート41-44</block>
  <block id="2c635d05e781d03137efe254ee8f86a1" category="cell">ポートe2b</block>
  <block id="67a367a7d31cdd640df71104820055c4" category="cell">スイッチ2ポート57-64</block>
  <block id="ed38d5a59568aa5dd0a40c94574cf056" category="cell">ISLからスイッチ1へ</block>
  <block id="c470336f17afce51494a7db95c91de92" category="paragraph">次の表は、この検証で使用されたさまざまなコンポーネントのソフトウェア バージョンを示しています。</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">ソフトウェア バージョン</block>
  <block id="b1c079bf2940033fab8f8dffbf4a5ff2" category="cell">NVIDIA SN4600スイッチ</block>
  <block id="90db213df8a0c782abe8388881fce336" category="cell">キュムラス Linux v5.9.1</block>
  <block id="18cf8e6ece8a122dba390f844981b900" category="cell">NVIDIA DGX システム</block>
  <block id="cfba00e4a4b4df8f6a7ebf83cfd81c4c" category="cell">DGX OS v6.2.1 (Ubuntu 22.04 LTS)</block>
  <block id="857ecbf3846b57d505e2a1b49da67f65" category="cell">メラノックスOFED</block>
  <block id="38aa87e1c845f13e459d6a71f7049cac" category="cell">24.01</block>
  <block id="3eb4233634d4c27ee1a1ddf72619b98d" category="cell">NetApp AFF A90</block>
  <block id="6944cefb93932417ed3a50959c66a9c5" category="cell">NetApp ONTAP 9.14.1</block>
  <block id="93fb68f81a2ad999b6aae02d586c4ef4" category="section-title">ストレージネットワーク構成</block>
  <block id="84814a12bbb8397e0a8f1357446c94e5" category="inline-link-macro">NVIDIA Cumulus Linux ドキュメント</block>
  <block id="5d27fc003227b21f0392098a85eb18c2" category="paragraph">このセクションでは、イーサネット ストレージ ネットワークの構成に関する重要な詳細について説明します。 InfiniBandコンピューティングネットワークの設定については、<block ref="784f66b69fd9a6fd2983e969e5202b40" category="inline-link-macro-rx"></block> 。スイッチの設定の詳細については、<block ref="5e4d481e02111d80d9871bbc3802a082" category="inline-link-macro-rx"></block> 。</block>
  <block id="57719be20908b73e68d37637555b97d6" category="paragraph">SN4600 スイッチを構成するために使用される基本的な手順を以下に概説します。このプロセスでは、ケーブル配線と基本的なスイッチ設定 (管理 IP アドレス、ライセンスなど) が完了していることを前提としています。</block>
  <block id="e55cea47183e18fc2e2e86a5dcee8ec7" category="list-text">スイッチ間のISLボンドを構成して、マルチリンクアグリゲーション（MLAG）とフェイルオーバートラフィックを有効にします。</block>
  <block id="72a998485758ede34cc727692eda3bd2" category="list-text">この検証では、テスト対象のストレージ構成に十分すぎるほどの帯域幅を提供するために8つのリンクを使用しました。</block>
  <block id="3051c0af523b2627a57ce2bf1e587655" category="list-text">MLAG を有効にする具体的な手順については、Cumulus Linux のドキュメントを参照してください。</block>
  <block id="8ae9a0f6054b5fb4a974e1f0d735ff8d" category="list-text">両方のスイッチのクライアントポートとストレージポートの各ペアにLACP MLAGを設定します。</block>
  <block id="3c81bce81a92df032d58d66eb88265b0" category="list-text">DGX-H100-01 の場合は各スイッチのポート swp17 (enp170s0f1np1 および enp41s0f1np1)、DGX-H100-02 の場合はポート swp18 (bond1-16)</block>
  <block id="563a9dfd999aa71e1b86c22188243c2b" category="list-text">各スイッチのポート swp41 はAFF-A90-01 (e2a および e2b)、ポート swp42 はAFF-A90-02 など (bond17-20)</block>
  <block id="44f6b0b1ffb3c7d26ff370ef2db934bb" category="list-text">nv set interfacebondX 結合メンバー swpX</block>
  <block id="e88a9fc1fac9e835ce4f94863fa6c017" category="list-text">nv set interface ボンドx ボンド mlag id X</block>
  <block id="53e5d1cb8672703c6d9c6468088afa1a" category="list-text">すべてのポートとMLAGボンドをデフォルトのブリッジドメインに追加します</block>
  <block id="e196c3365de079c5ab9127511e0dd99c" category="list-text">nv set int swp1-16,33-40 ブリッジドメイン br_default</block>
  <block id="807ec963a7ac91bb05d484cf2aedb28c" category="list-text">nv set int Bond1-20 ブリッジドメイン br_default</block>
  <block id="812bc6c1e22132212f3bd611d2be624b" category="list-text">各スイッチでRoCEを有効にする</block>
  <block id="5b474542c656a524ee80214d547f357f" category="list-text">nv roceモードロスレス設定</block>
  <block id="e1ddeeabdb3c578a39e7f7457c83adcb" category="list-text">VLAN を構成する - クライアントポート用に 2 つ、ストレージポート用に 2 つ、管理用に 1 つ、L3 スイッチ間用に 1 つ</block>
  <block id="e8c935d4b4d1ac2ba8e60a311d4dd3e3" category="list-text">スイッチ1-</block>
  <block id="d0dbd46c5b3822649194130f76e47a74" category="list-text">クライアント NIC 障害発生時の L3 スイッチからスイッチへのルーティング用の VLAN 3</block>
  <block id="4d0ddcd703c2db59dd2b93a0864f348e" category="list-text">各 DGX システムのストレージ ポート 1 の VLAN 101 (enp170s0f0np0、スロット 1 ポート 1)</block>
  <block id="988d3fe9d9a9c24bdfaf0d1e8c04c718" category="list-text">各AFF A90ストレージコントローラのポートe6aとe11aのVLAN 102</block>
  <block id="8534bf29bf68cf0b3a4ef8fc1c8367ef" category="list-text">各 DGX システムおよびストレージ コントローラへの MLAG インターフェイスを使用した管理用の VLAN 301</block>
  <block id="decdf257b13a488f92fa3c1f3c758e26" category="list-text">スイッチ2-</block>
  <block id="9d406d38f0c9d262294560c3ffe601e6" category="list-text">各 DGX システムのストレージ ポート 2 の VLAN 201 (enp41s0f0np0、スロット 2 ポート 1)</block>
  <block id="ad80d15b1164d5cda913549da61e6aa3" category="list-text">各AFF A90ストレージコントローラのポートe6bとe11bのVLAN 202</block>
  <block id="09417c9a09b9c4ceb39f1b21b0c805ce" category="list-text">各VLANに物理ポートを適切に割り当てます（例：クライアントVLANにはクライアントポート、ストレージVLANにはストレージポート）。</block>
  <block id="30add6fef18e27847f71d245bce4adf2" category="list-text">nv set int &lt;swpX&gt; ブリッジドメイン br_default アクセス &lt;vlan id&gt;</block>
  <block id="8c088863d87c4744d16775f50bd22826" category="list-text">必要に応じてボンディングされたインターフェース上で複数の VLAN を有効にするには、MLAG ポートをトランク ポートとして残しておく必要があります。</block>
  <block id="dc7dbdf7949b0253d64542d3a6648b53" category="list-text">各VLANのスイッチ仮想インターフェース（SVI）をゲートウェイとして設定し、L3ルーティングを有効にする</block>
  <block id="bbc11fb8434953cf5f8a56090594c94e" category="list-text">nv set int vlan3 ip address 100.127.0.0/31</block>
  <block id="56a4338a8bbb720e395dea767276043e" category="list-text">nv set int vlan101 ip address 100.127.101.1/24</block>
  <block id="c88e27e83683371775c79ed4db025a42" category="list-text">nv set int vlan102 ip address 100.127.102.1/24</block>
  <block id="c8e18763efa8332ade09b61ec6c43e79" category="list-text">nv set int vlan3 ip address 100.127.0.1/31</block>
  <block id="d39015045c0b670844a63ea89a0558e1" category="list-text">nv set int vlan201 ip address 100.127.201.1/24</block>
  <block id="72caedfc84ea977b468f72cc81db5b0f" category="list-text">nv set int vlan202 ip address 100.127.202.1/24</block>
  <block id="4d86d7ad33785bddc3f3227d7cfe8c00" category="list-text">静的ルートを作成する</block>
  <block id="957e71bdd90bad3e445176749a6e839a" category="list-text">同じスイッチ上のサブネットに対して静的ルートが自動的に作成される</block>
  <block id="ba77f5caf647fd0155f2edd382f4c005" category="list-text">クライアントリンク障害が発生した場合にスイッチ間のルーティングを行うために追加の静的ルートが必要です。</block>
  <block id="cb6543cc4fa221dc0cadbcce30a3d708" category="list-text">nv set vrf デフォルトルータ static 100.127.128.0/17 via 100.127.0.1</block>
  <block id="3616a5e3448d387e297a217363fcd491" category="list-text">nv set vrf default router static 100.127.0.0/17 via 100.127.0.0</block>
  <block id="2139fe384d5ae165545994dff01961d9" category="section-title">ストレージシステムの構成</block>
  <block id="eb75aeb3b4b2b9734ba3e52f5483f0b2" category="inline-link-macro">ONTAPのドキュメント</block>
  <block id="6c077f840844078f56944a0699577ff6" category="paragraph">このセクションでは、このソリューションの A90 ストレージ システムの構成に関する重要な詳細について説明します。 ONTAPシステムの構成の詳細については、<block ref="c9be69f343f12523b36264fad0c62551" category="inline-link-macro-rx"></block> 。以下の図は、ストレージ システムの論理構成を示しています。</block>
  <block id="a2720bc0a2d05de970087a0c7fad9311" category="paragraph">ストレージ システムを構成するために使用される基本的な手順を以下に概説します。このプロセスでは、基本的なストレージ クラスターのインストールが完了していることを前提としています。</block>
  <block id="a65ed1368170b15ddddd6ee0b2408084" category="list-text">各コントローラに、スペア1つを除いたすべての使用可能なパーティションを含む1つのアグリゲートを構成する</block>
  <block id="104afbbbf990a88bdaee0bb7222c4b8e" category="list-text">aggr create -node &lt;ノード&gt; -aggregate &lt;ノード&gt;_data01 -diskcount &lt;47&gt;</block>
  <block id="40531cd604f58d3ba347b865243c7e48" category="list-text">各コントローラでifgrpsを構成する</block>
  <block id="f72dfa57e15677b92e70b5a144e0b5f9" category="list-text">net port ifgrp create -node &lt;ノード&gt; -ifgrp a1a -mode multimode_lacp -distr-function port</block>
  <block id="55be7178bd14f4153f1b019457ede4a9" category="list-text">net port ifgrp add-port -node &lt;ノード&gt; -ifgrp &lt;ifgrp&gt; -ports &lt;ノード&gt;:e2a,&lt;ノード&gt;:e2b</block>
  <block id="b13faeadb39006cbcc1d3c2e50344bf1" category="list-text">各コントローラのifgrpでmgmt vlanポートを設定する</block>
  <block id="e6e28ccd055fb443d6dd14a9a6eb7d1a" category="list-text">ネットポートVLAN作成 -ノードaff-a90-01 -ポートa1a -VLAN-ID 31</block>
  <block id="f740c9ebcb9caacb0b5d819655c488ed" category="list-text">ネットポートVLAN作成 -ノードaff-a90-02 -ポートa1a -VLAN-ID 31</block>
  <block id="5d71abf584a26ed36de342533bc6b11f" category="list-text">ネットポートVLAN作成 -ノードaff-a90-03 -ポートa1a -VLAN-ID 31</block>
  <block id="21e3a0fbbbf79005355b371bbcdd44e6" category="list-text">ネットポートVLAN作成 -ノードaff-a90-04 -ポートa1a -VLAN-ID 31</block>
  <block id="cd002818e71e3e15ea7d845a92b82053" category="list-text">ブロードキャスト ドメインの作成</block>
  <block id="060c8e724635c9585153496e36c5fe64" category="list-text">ブロードキャストドメイン作成 -ブロードキャストドメイン vlan21 -mtu 9000 -ポート aff-a90-01:e6a、aff-a90-01:e11a、aff-a90-02:e6a、aff-a90-02:e11a、aff-a90-03:e6a、aff-a90-03:e11a、aff-a90-04:e6a、aff-a90-04:e11a</block>
  <block id="f0375c78fd286627e0ea2e893298127b" category="list-text">ブロードキャストドメインを作成 -ブロードキャストドメイン vlan22 -mtu 9000 -ポート aaff-a90-01:e6b、aff-a90-01:e11b、aff-a90-02:e6b、aff-a90-02:e11b、aff-a90-03:e6b、aff-a90-03:e11b、aff-a90-04:e6b、aff-a90-04:e11b</block>
  <block id="46bd5a85171233df8aad89e1ea34eca2" category="list-text">ブロードキャストドメイン作成 -ブロードキャストドメイン vlan31 -mtu 9000 -ポート aff-a90-01:a1a-31,aff-a90-02:a1a-31,aff-a90-03:a1a-31,aff-a90-04:a1a-31</block>
  <block id="623ea6b05fb05729ffd64b3aecd6e969" category="list-text">管理SVMの作成 *</block>
  <block id="5619023db11b9124790191d573fd6c9a" category="list-text">管理SVMを構成する</block>
  <block id="a085de8c20c0316efb0b620d42f96f5d" category="list-text">LIFを作成する</block>
  <block id="f2a8aff28094374e836aba88837e4ecd" category="list-text">net int create -vserver basepod-mgmt -lif vlan31-01 -home-node aff-a90-01 -home-port a1a-31 -address 192.168.31.X -netmask 255.255.255.0</block>
  <block id="025643e2f4f3d8255f6a74703e817f10" category="list-text">FlexGroupボリュームを作成する -</block>
  <block id="ff251de7d10dfd4d224adb00c9771d80" category="list-text">ボリューム作成 -vserver basepod-mgmt -ボリューム ホーム -サイズ 10T -自動プロビジョニング -フレックスグループ -ジャンクション パス /home</block>
  <block id="7eadd281ac9fa05f29dd10931c800b73" category="list-text">ボリューム作成 -vserver basepod-mgmt -ボリューム cm -サイズ 10T -自動プロビジョニング -フレックスグループ -ジャンクションパス /cm</block>
  <block id="4daa96de5bcd998457adea84b3b0d3f2" category="list-text">輸出ポリシーを作成する</block>
  <block id="0224cbf10aded53062d1c33a00ed3f00" category="list-text">エクスポートポリシールール作成 -vserver basepod-mgmt -policy default -client-match 192.168.31.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="d5c522a3ee4c4fb65fcbe94d031d0a08" category="list-text">データSVMの作成 *</block>
  <block id="6310e0b69ca3cd6447bec629307180b7" category="list-text">データSVMを構成する</block>
  <block id="8aa04063c0eff21564b4943f7c5bd0af" category="list-text">RDMAサポート用にSVMを構成する</block>
  <block id="f67ee8861066661a87085502a485f642" category="list-text">vserver nfs modify -vserver basepod-data -rdma が有効</block>
  <block id="f29cc71670e3362a894e54ea9924917c" category="list-text">LIFを作成する</block>
  <block id="3df4cfdffe24b83cba807ded784fb107" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif1 -home-node aff-a90-01 -home-port e6a -address 100.127.102.101 -netmask 255.255.255.0</block>
  <block id="26a6d29a1530006b710e49ad940bc64a" category="list-text">net int create -vserver basepod-data -lif c1-6a-lif2 -home-node aff-a90-01 -home-port e6a -address 100.127.102.102 -netmask 255.255.255.0</block>
  <block id="985d0d4d212dc0238d9f101fee0a3418" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif1 -home-node aff-a90-01 -home-port e6b -address 100.127.202.101 -netmask 255.255.255.0</block>
  <block id="07f93d0815d9e298cb8b02049c677706" category="list-text">net int create -vserver basepod-data -lif c1-6b-lif2 -home-node aff-a90-01 -home-port e6b -address 100.127.202.102 -netmask 255.255.255.0</block>
  <block id="2d977106413211171eefeeb51af2bdf7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif1 -ホームノード aff-a90-01 -ホームポート e11a -アドレス 100.127.102.103 -ネットマスク 255.255.255.0</block>
  <block id="10d75b950d2d9634a2804a1ed92f0df7" category="list-text">net int create -vserver basepod-data -lif c1-11a-lif2 -home-node aff-a90-01 -home-port e11a -address 100.127.102.104 -netmask 255.255.255.0</block>
  <block id="7e3ec60a178738ba9ac6680a6bf6340d" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif1 -home-node aff-a90-01 -home-port e11b -address 100.127.202.103 -netmask 255.255.255.0</block>
  <block id="b14efeaf4c17d63f2e6011dc35f5722c" category="list-text">net int create -vserver basepod-data -lif c1-11b-lif2 -home-node aff-a90-01 -home-port e11b -address 100.127.202.104 -netmask 255.255.255.0</block>
  <block id="74c24c93e98c023e9fe31988005f6735" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif1 -home-node aff-a90-02 -home-port e6a -address 100.127.102.105 -netmask 255.255.255.0</block>
  <block id="d00b578414c1bb9f219c72ef1262d701" category="list-text">net int create -vserver basepod-data -lif c2-6a-lif2 -home-node aff-a90-02 -home-port e6a -address 100.127.102.106 -netmask 255.255.255.0</block>
  <block id="c49b52997695ebd048410b0b8f9f19f2" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif1 -home-node aff-a90-02 -home-port e6b -address 100.127.202.105 -netmask 255.255.255.0</block>
  <block id="912c10c91d670dee279852756245a063" category="list-text">net int create -vserver basepod-data -lif c2-6b-lif2 -home-node aff-a90-02 -home-port e6b -address 100.127.202.106 -netmask 255.255.255.0</block>
  <block id="031724ef6867c2ff3771e70c8520b1d0" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif1 -home-node aff-a90-02 -home-port e11a -address 100.127.102.107 -netmask 255.255.255.0</block>
  <block id="8b417c98283cde9dc265541e2455e2f5" category="list-text">net int create -vserver basepod-data -lif c2-11a-lif2 -home-node aff-a90-02 -home-port e11a -address 100.127.102.108 -netmask 255.255.255.0</block>
  <block id="f129b43cd7a26c7049c4340ac4ef86e1" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif1 -ホームノード aff-a90-02 -ホームポート e11b -アドレス 100.127.202.107 -ネットマスク 255.255.255.0</block>
  <block id="5a6d6f4dbbb1d6f8f5558b1c36f5e671" category="list-text">net int create -vserver basepod-data -lif c2-11b-lif2 -home-node aff-a90-02 -home-port e11b -address 100.127.202.108 -netmask 255.255.255.0</block>
  <block id="057f5c63653dacba830db83ad6ad78ee" category="list-text">RDMAアクセス用にLIFを構成する</block>
  <block id="ea7a0f026442b56683f1e50cb21a0d06" category="list-text">ONTAP 9.15.1 を使用した導入では、物理情報の RoCE QoS 設定には、 ONTAP CLI では使用できない OS レベルのコマンドが必要です。  RoCE サポート用のポートの構成については、 NetAppサポートにお問い合わせください。  NFS over RDMA は問題なく機能します</block>
  <block id="2e94a4ea05164067f4cb6f27639c8b7a" category="list-text">ONTAP 9.16.1 以降では、エンドツーエンドの RoCE サポートに適した設定で物理インターフェイスが自動的に構成されるようになります。</block>
  <block id="95f5fd496607048d9a2d17c6c6577aa2" category="list-text">net int edit -vserverbasepod-data -lif * -rdma-protocols roce</block>
  <block id="29789a25d415e0f3b5d8cef38626fadc" category="list-text">データSVMでNFSパラメータを設定する</block>
  <block id="37013073e580c7f2ed500849958f49cd" category="list-text">nfs modify -vserver basepod-data -v4.1 有効 -v4.1-pnfs 有効 -v4.1-trunking 有効 -tcp-max-transfer-size 262144</block>
  <block id="8f7c2b974d2b68275b99738f2db92da7" category="list-text">FlexGroupボリュームを作成する -</block>
  <block id="375a2038f90b0da452502ee281313fdd" category="list-text">ボリューム作成 -vserver ベースポッドデータ -ボリュームデータ -サイズ 100T -自動プロビジョニング -フレックスグループ -ジャンクションパス /データ</block>
  <block id="48e79d83943623a53289accfc05a7108" category="list-text">エクスポート ポリシーの作成</block>
  <block id="f36c67518ab2b84b8b81ef59c8d30976" category="list-text">エクスポートポリシールール作成 -vserver basepod-data -policy default -client-match 100.127.101.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="738b25d5c96222859fa0d9f34e585e1d" category="list-text">エクスポートポリシールール作成 -vserver basepod-data -policy default -client-match 100.127.201.0/24 -rorule sys -rwrule sys -superuser sys</block>
  <block id="14f424e270715fb6e8bf7277cb075650" category="list-text">ルートを作成する</block>
  <block id="086c700f168ee8ad618b80e189d3ab75" category="list-text">ルートを追加 -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.102.1 metric 20</block>
  <block id="e6bf4bcbe9f12d429928fe014e660008" category="list-text">ルートを追加 -vserver basepod_data -destination 100.127.0.0/17 -gateway 100.127.202.1 metric 30</block>
  <block id="35dc59e7fce425d44a0f407fcd227c43" category="list-text">ルートを追加 -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.202.1 metric 20</block>
  <block id="50a387548848ab61afe342aa18b992c7" category="list-text">ルートを追加 -vserver basepod_data -destination 100.127.128.0/17 -gateway 100.127.102.1 metric 30</block>
  <block id="dc8a99ae9ee0b79d432c8eac1124edb5" category="section-title">RoCE ストレージ アクセス用の DGX H100 構成</block>
  <block id="206274d0712987318a4f897f7e6ae75c" category="inline-link-macro">BCMのドキュメント</block>
  <block id="0448e5984ca30c8aeeb162534801fe92" category="paragraph">このセクションでは、DGX H100 システムの構成に関する重要な詳細について説明します。これらの構成項目の多くは、DGX システムに展開された OS イメージに含めることも、起動時に Base Command Manager によって実装することもできます。これらは参考のためにここにリストされています。BCMでのノードとソフトウェアイメージの構成の詳細については、<block ref="21b53d84e45529faee31545df8020d3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="12211cca460b22741ca0d08e3f60fb0c" category="list-text">追加パッケージをインストールする</block>
  <block id="0df162aa5e7703fc2c2a77a7d1d5a1fe" category="list-text">ipmitool</block>
  <block id="e08cb560fa0fac340ce6e958daaf5e4d" category="list-text">python3-pip</block>
  <block id="8cd5d0cdb86cde9f0dc88352811817ec" category="list-text">Pythonパッケージをインストールする</block>
  <block id="32760a760ea625ddb856e92f3b089802" category="list-text">パラミコ</block>
  <block id="f02113237a5a5fff03e34c9eeeb46640" category="list-text">マットプロットライブラリ</block>
  <block id="9b162ba267ba83b0a5f5cb6cdbe972dd" category="list-text">パッケージのインストール後にdpkgを再設定する</block>
  <block id="a8bc68a93f8c901b4a33e27af2f21da0" category="list-text">dpkg --configure -a</block>
  <block id="0243e3d81be4d79f622d517c103c3ae0" category="list-text">MOFEDをインストールする</block>
  <block id="08c24ffe86544b752cd2764895595237" category="list-text">パフォーマンスチューニングのためのmst値を設定する</block>
  <block id="d5bedef65a3750cb3c0a2b86f80a11e4" category="list-text">mstconfig -y -d &lt;aa:00.0,29:00.0&gt; ADVANCED_PCI_SETTINGS=1 NUM_OF_VFS=0 MAX_ACC_OUT_READ=44 を設定します</block>
  <block id="bdacbd6c214d3cc42e1d1f8305ef92c9" category="list-text">設定を変更した後はアダプタをリセットしてください</block>
  <block id="9af48ffdb9436775e220fda80ded47ad" category="list-text">mlxfwreset -d &lt;aa:00.0,29:00.0&gt; -y リセット</block>
  <block id="c7cb0d4934d36b9bb0816b3a5c49f0b1" category="list-text">PCIデバイスにMaxReadReqを設定する</block>
  <block id="1a252b6a7629ccb0f15527f8ca5f627c" category="list-text">setpci -s &lt;aa:00.0,29:00.0&gt; 68.W=5957</block>
  <block id="29aaf92306610006fe7ce7d8c90411ca" category="list-text">RXおよびTXリングバッファサイズを設定する</block>
  <block id="3d789bdc86cf1d51f9b23d11b808ddd5" category="list-text">ethtool -G &lt;enp170s0f0np0,enp41s0f0np0&gt; 受信ポート数 8192 送信ポート数 8192</block>
  <block id="a0340fb71fb195f79ce47dabe6242f8e" category="list-text">mlnx_qos を使用して PFC と DSCP を設定する</block>
  <block id="6537005ab5e42cbee146ce9b17d892d8" category="list-text">mlnx_qos -i &lt;enp170s0f0np0,enp41s0f0np0&gt; --pfc 0,0,0,1,0,0,0,0 --trust=dscp --cable_len=3</block>
  <block id="a277efb29c974f8ae6d1925383335b05" category="list-text">ネットワークポート上の RoCE トラフィックの ToS を設定する</block>
  <block id="8c1e8c1481d777723e305f147f16012d" category="list-text">エコー 106 &gt; /sys/class/infiniband/&lt;mlx5_7,mlx5_1&gt;/tc/1/traffic_class</block>
  <block id="05dae9ad2cfb95dc1f78bc696aa0d6a4" category="list-text">各ストレージNICを適切なサブネット上のIPアドレスで構成します。</block>
  <block id="fa2bddc64b24b8cd13f0be734ce934ca" category="list-text">ストレージ NIC 1 の 100.127.101.0/24</block>
  <block id="945382c87aa13867b8b36da66c8ae8fc" category="list-text">ストレージ NIC 2 の 100.127.201.0/24</block>
  <block id="ed769c091c9112ad2d1a5c89de5c0c65" category="list-text">LACPボンディング用のインバンドネットワークポートを構成する（enp170s0f1np1、enp41s0f1np1）</block>
  <block id="af487da74a6eeea9aa52d90c5c8cd04d" category="list-text">各ストレージサブネットへのプライマリパスとセカンダリパスの静的ルートを構成する</block>
  <block id="593c13037333a6722527c42d1d0b156c" category="list-text">ルート追加 –net 100.127.0.0/17 gw 100.127.101.1 メトリック20</block>
  <block id="8656e83d4d88a713f09d848f3cc09702" category="list-text">ルート追加 –net 100.127.0.0/17 gw 100.127.201.1 メトリック30</block>
  <block id="85f6d08b3d54f8d8785ef6f36f7c61c3" category="list-text">ルート追加 –net 100.127.128.0/17 gw 100.127.201.1 メトリック20</block>
  <block id="d70120de1b67fd20affa2557aca990ef" category="list-text">ルート追加 –net 100.127.128.0/17 gw 100.127.101.1 メトリック30</block>
  <block id="7fc2f78e0bd34dcefec071f2a70514c2" category="list-text">/homeボリュームをマウントする</block>
  <block id="9ff7402ee00f4969ccc4395a7241c47c" category="list-text">マウント -o vers=3,nconnect=16,rsize=262144,wsize=262144 192.168.31.X:/home /home</block>
  <block id="152cd866abad6e43429948eb4715b973" category="list-text">マウント/データボリューム</block>
  <block id="1cd39f0089800bb9511317cc53d73557" category="list-text">データボリュームをマウントする際に、次のマウントオプションが使用されました。</block>
  <block id="bcd39ebb3417a185678d6de2189af4b9" category="list-text">vers=4.1 # 複数のストレージノードへの並列アクセスのために pNFS を有効にします</block>
  <block id="5cd472c72f4b3a3c75cbdb77edc30528" category="list-text">proto=rdma # 転送プロトコルをデフォルトのTCPではなくRDMAに設定します</block>
  <block id="f8553c0c0cde0245d779c37090c093a7" category="list-text">max_connect=16 # NFSセッショントランキングを有効にしてストレージポートの帯域幅を集約する</block>
  <block id="f8a3438d5712d48a22100c8109ea556e" category="list-text">write=eager # バッファリングされた書き込みの書き込みパフォーマンスが向上します</block>
  <block id="42fdb382646439a01d661ce9d2127a1c" category="list-text">rsize=262144,wsize=262144 # I/O転送サイズを256kに設定します</block>
  <block id="7f86b6f2a05fc6e5c5931f73e9af29fd" category="summary">NetApp AIPodとNVIDIA DGX システム - ハードウェア コンポーネント</block>
  <block id="7c451f18f811f88a48907bf86377cdd8" category="doc">NVA-1173 NetApp AIPod with NVIDIA DGX Systems - ハードウェアコンポーネント</block>
  <block id="bd6e083031bf15817a67b63cc58a211c" category="paragraph">このセクションでは、 NVIDIA DGX システムを搭載したNetApp AIPodのハードウェア コンポーネントに焦点を当てます。</block>
  <block id="68674fa5fbd6fb83969183d07d48b8cd" category="section-title">NetApp AFFストレージシステム</block>
  <block id="3b6d33ce139758ecf9b0b83f9ecce001" category="paragraph">NetApp AFF の最先端ストレージ システムにより、IT 部門は業界をリードするパフォーマンス、優れた柔軟性、クラウド統合、クラス最高のデータ管理により、エンタープライズ ストレージの要件を満たすことができます。フラッシュ専用に設計されたAFFシステムは、ビジネスクリティカルなデータの高速化、管理、保護に役立ちます。</block>
  <block id="d1d40f451fb75b4e7160785e64a75da3" category="section-title">AFF A90ストレージシステム</block>
  <block id="df7df1dd54ea101ca8a417ee258e2693" category="paragraph">NetApp ONTAPデータ管理ソフトウェアを搭載したNetApp AFF A90は、組み込みのデータ保護機能、オプションのランサムウェア対策機能、そして最も重要なビジネス ワークロードをサポートするために必要な高いパフォーマンスと復元力を提供します。ミッションクリティカルな業務の中断を排除し、パフォーマンス チューニングを最小限に抑え、ランサムウェア攻撃からデータを保護します。以下のメリットを提供します: • 業界をリードするパフォーマンス • 妥協のないデータセキュリティ • 簡素化された無停止アップグレード</block>
  <block id="6bd43dd4b56bb5bfe362d48a0d5219e0" category="paragraph">_NetApp AFF A90ストレージシステム_</block>
  <block id="df3fd00dc667f05e52f1e05b8dedfd55" category="paragraph"><block ref="df3fd00dc667f05e52f1e05b8dedfd55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1863aa82dcf92831635aa05e975d399d" category="section-title">業界をリードするパフォーマンス</block>
  <block id="a261fc6acbe5e140d750bc3f1dd8c7a7" category="paragraph">AFF A90 は、ディープラーニング、AI、高速分析などの次世代ワークロードだけでなく、Oracle、SAP HANA、Microsoft SQL Server、仮想化アプリケーションなどの従来のエンタープライズ データベースも簡単に管理します。  HA ペアあたり最大 2.4M IOPS と 100µs という低レイテンシで、ビジネスクリティカルなアプリケーションを最高速度で実行し続けるとともに、以前のNetAppモデルと比べてパフォーマンスが最大 50% 向上します。 NFS over RDMA、pNFS、セッション トランキングを使用すると、顧客は既存のデータ センター ネットワーク インフラストラクチャを使用して、次世代アプリケーションに必要な高レベルのネットワーク パフォーマンスを実現できます。また、SAN、NAS、オブジェクト ストレージの統合マルチプロトコル サポートにより拡張と成長が可能になり、オンプレミスまたはクラウドのデータに対して、統合された単一のONTAPデータ管理ソフトウェアで最大限の柔軟性を実現できます。さらに、 Active IQとCloud Insightsが提供する AI ベースの予測分析により、システムの健全性を最適化することもできます。</block>
  <block id="773efff7a0bbe1582ceff936530b5ae3" category="section-title">妥協のないデータセキュリティ</block>
  <block id="b867e6aa9b3e46766f55ab250eb69715" category="paragraph">AFF A90システムには、 NetAppの統合型およびアプリケーション整合性のあるデータ保護ソフトウェアの完全なスイートが含まれています。事前の対策と攻撃後の回復のために、組み込みのデータ保護と最先端のランサムウェア対策ソリューションを提供します。悪意のあるファイルがディスクに書き込まれるのをブロックし、ストレージの異常を簡単に監視して洞察を得ることができます。</block>
  <block id="f6353452ddd71a9ef0e4d8578d7dc7e3" category="section-title">簡素化された無停止アップグレード</block>
  <block id="4015e152c676ca730da1d797ef1e9993" category="paragraph">AFF A90 は、既存の A800 のお客様向けに、中断のないシャーシ内アップグレードとしてご利用いただけます。 NetApp は、高度な信頼性、可用性、保守性、管理性 (RASM) 機能を通じて、ミッションクリティカルな運用の更新と中断の排除を容易にします。さらに、 NetApp はONTAPソフトウェアがすべてのシステム コンポーネントのファームウェア更新を自動的に適用するため、運用効率をさらに向上させ、IT チームの日常業務を簡素化します。</block>
  <block id="13ab18b8510a80a65aefbf9a56e3b3d3" category="paragraph">最大規模の導入の場合、 AFF A1Kシステムは最高のパフォーマンスと容量のオプションを提供しますが、 AFF A70やAFF C800などの他のNetAppストレージ システムは、より低コストで小規模な導入のオプションを提供します。</block>
  <block id="3ebd416d1b3232ef4125025ab8f437a9" category="paragraph">NVIDIA DGX BasePOD は、 NVIDIA のハードウェアおよびソフトウェア コンポーネント、MLOps ソリューション、サードパーティのストレージで構成される統合ソリューションです。 NVIDIA製品と検証済みのパートナー ソリューションによるスケールアウト システム設計のベスト プラクティスを活用することで、顧客は AI 開発のための効率的で管理しやすいプラットフォームを実装できます。図 1 は、 NVIDIA DGX BasePODのさまざまなコンポーネントを示しています。</block>
  <block id="76d810a9cb0440f2de2c7104493e266f" category="paragraph">_NVIDIA DGX BasePOD ソリューション_</block>
  <block id="559d10ed60e21f546209442a6aade09d" category="paragraph"><block ref="559d10ed60e21f546209442a6aade09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a5f31a2eea3b274409614f4eb63433c" category="section-title">NVIDIA DGX H100 システム</block>
  <block id="2cdfa62855978fa129d36e4602f41e0b" category="paragraph">NVIDIA DGX H100™ システムは、 NVIDIA H100 Tensor Core GPU の画期的なパフォーマンスによって加速される AI の原動力です。</block>
  <block id="4a8da04b1b7a51ad2e9c77e221e0d9d9" category="paragraph">_NVIDIA DGX H100 システム_</block>
  <block id="b9ab32cd1976da02bb3c074578d491c3" category="paragraph"><block ref="b9ab32cd1976da02bb3c074578d491c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93b775e18b65e433d85d83ad863c1797" category="paragraph">DGX H100 システムの主な仕様は次のとおりです。 • 8 個のNVIDIA H100 GPU。  • GPU あたり 80 GB の GPU メモリ、合計 640 GB。  • NVIDIA NVSwitch チップ 4 個。  • PCIe 5.0 をサポートするデュアル 56 コア Intel Xeon Platinum 8480 プロセッサー。  • 2 TB の DDR5 システム メモリ。  • 8 つのシングルポートNVIDIA ConnectX-7 (InfiniBand/Ethernet) アダプタと 2 つのデュアルポートNVIDIA ConnectX-7 (InfiniBand/Ethernet) アダプタに対応する 4 つの OSFP ポート。  • DGX OS 用に 1.92 TB M.2 NVMe ドライブ 2 台、ストレージ/キャッシュ用に 3.84 TB U.2 NVMe ドライブ 8 台。  • 最大出力 10.2 kW。  DGX H100 CPU トレイの背面ポートを以下に示します。 4 つの OSFP ポートは、InfiniBand コンピューティング ファブリック用の 8 つの ConnectX-7 アダプタとして機能します。デュアル ポート ConnectX-7 アダプタの各ペアは、ストレージ ファブリックと管理ファブリックへの並列パスを提供します。アウトオブバンド ポートはBMCアクセスに使用されます。</block>
  <block id="1811b955f76e78d806cc9f89eca9365d" category="paragraph">_NVIDIA DGX H100 背面パネル_</block>
  <block id="7d94d25261d22723cf1dcbc550472562" category="paragraph"><block ref="7d94d25261d22723cf1dcbc550472562" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e64325a640583a5afbe8ce27e88608e" category="section-title">NVIDIA Quantum-2 QM9700 スイッチ</block>
  <block id="96e834f144fffd019191dee8b2e3fa9e" category="paragraph">_NVIDIA Quantum-2 QM9700 InfiniBand スイッチ_</block>
  <block id="02e6cd41035da9c303b4223fcb954c57" category="paragraph"><block ref="02e6cd41035da9c303b4223fcb954c57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58e83b10341e2ec3a48b164715b6ba34" category="paragraph">400Gb/s InfiniBand 接続を備えたNVIDIA Quantum-2 QM9700 スイッチは、 NVIDIA Quantum-2 InfiniBand BasePOD 構成のコンピューティング ファブリックを強化します。 ConnectX-7 シングルポート アダプタは、InfiniBand コンピューティング ファブリックに使用されます。各NVIDIA DGX システムには各 QM9700 スイッチへのデュアル接続があり、システム間に複数の高帯域幅、低遅延パスを提供します。</block>
  <block id="88f086b3f05858ad120601108f0821a7" category="section-title">NVIDIA Spectrum-3 SN4600 スイッチ</block>
  <block id="69dc0a65b1f9cc56bf9d1b38913e279e" category="paragraph">_NVIDIA Spectrum-3 SN4600 スイッチ_</block>
  <block id="a5317e31cdc481b4371010e9f47b541d" category="paragraph"><block ref="a5317e31cdc481b4371010e9f47b541d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df2b71117642b0bdbf87a4e9d643c47e" category="paragraph">NVIDIA Spectrum™-3 SN4600 スイッチは、合計 128 個のポート (スイッチあたり 64 個) を備え、DGX BasePOD のインバンド管理に冗長接続を提供します。 NVIDIA SN4600 スイッチは、1 GbE から 200 GbE までの速度を提供できます。イーサネット経由で接続されるストレージ アプライアンスでは、 NVIDIA SN4600 スイッチも使用されます。  NVIDIA DGX デュアルポート ConnectX-7 アダプタのポートは、インバンド管理とストレージ接続の両方に使用されます。</block>
  <block id="9bc83d36ebb307eef9521860d72d6a83" category="section-title">NVIDIA Spectrum SN2201 スイッチ</block>
  <block id="0a58d2e4f07c9b74c7b9f0f643df366e" category="paragraph">_NVIDIA Spectrum SN2201 スイッチ_</block>
  <block id="63573ea3854985f600f8cc8c44aa5bea" category="paragraph"><block ref="63573ea3854985f600f8cc8c44aa5bea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6714f3120a26d6eb7222fbbd52715a6c" category="paragraph">NVIDIA Spectrum SN2201 スイッチは、アウトオブバンド管理用の接続を提供する 48 個のポートを備えています。アウトオブバンド管理は、DGX BasePOD 内のすべてのコンポーネントに対して統合された管理接続を提供します。</block>
  <block id="82e5da407cc33e26189f053503aa2bf6" category="section-title">NVIDIA ConnectX-7 アダプター</block>
  <block id="74baf984365e15a6f92345e68021621a" category="paragraph">_NVIDIA ConnectX-7 アダプター_</block>
  <block id="062446821e85b6d2c053705d69b2c037" category="paragraph"><block ref="062446821e85b6d2c053705d69b2c037" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f31835004684d86091e359c9a240e92" category="paragraph">NVIDIA ConnectX-7 アダプターは、25/50/100/200/400G のスループットを提供できます。  NVIDIA DGX システムは、シングル ポートとデュアル ポートの両方の ConnectX-7 アダプタを使用して、400Gb/s InfiniBand と Ethernet による DGX BasePOD 展開の柔軟性を実現します。</block>
  <block id="9f68b039fbd3ecc8729ee9a4be7903ea" category="summary">NetApp AIPod with NVIDIA DGX Systems は、 NetApp ONTAP AFFストレージ システムとNVIDIAネットワークおよび DGX システムを使用したディープラーニングと人工知能向けのNVIDIA BasePOD に基づく、エンタープライズ対応のリファレンス アーキテクチャです。</block>
  <block id="9b07efa8439fb4859742ace8bb15c070" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX システム - 概要</block>
  <block id="03a5dba0ba7f06a853319a59ab10f1db" category="inline-image-macro">200,200,エラー: グラフィック イメージがありません</block>
  <block id="540456658a35dff79ec59aa1338d398e" category="paragraph"><block ref="540456658a35dff79ec59aa1338d398e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="217432d0ec5a422d97fdd8082983c438" category="paragraph">NetAppソリューションエンジニアリング</block>
  <block id="617f17b8f2c8c0557ec9f79c918464eb" category="paragraph">NVIDIA DGX™ システムとNetAppクラウド接続ストレージ システムを搭載した NetApp AIPod は、設計の複雑さと推測作業を排除することで、機械学習 (ML) および人工知能 (AI) ワークロードのインフラストラクチャ導入を簡素化します。次世代のワークロードに卓越したコンピューティング パフォーマンスを提供するNVIDIA DGX BasePOD™ 設計を基盤とするAIPodとNVIDIA DGX システムにより、 NetApp AFFストレージ システムが追加され、顧客は小規模から始めて中断なく拡張しながら、エッジからコア、クラウド、そしてその逆に至るまでデータをインテリジェントに管理できるようになります。  NetApp AIPod は、下の図に示すように、 NetApp AI ソリューションのより大規模なポートフォリオの一部です。</block>
  <block id="194ff09c8e869017b4ffe91887dde829" category="paragraph">_NetApp AI ソリューション ポートフォリオ_</block>
  <block id="629225e0ba0d0325f35ee6fcfd7ebf4e" category="paragraph"><block ref="629225e0ba0d0325f35ee6fcfd7ebf4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff9a398ccda9f0fc1e44521cf40ca977" category="paragraph">このドキュメントでは、 AIPodリファレンス アーキテクチャの主要コンポーネント、システム接続と構成情報、検証テストの結果、ソリューションのサイズ設定ガイダンスについて説明します。このドキュメントは、ML/DL および分析ワークロード向けの高性能インフラストラクチャの導入に関心のあるNetAppおよびパートナー ソリューション エンジニアと顧客の戦略的意思決定者を対象としています。</block>
  <block id="77f2324c2483df30f029d522599f882e" category="summary">NetApp AIPodとNVIDIA DGX システム - ソフトウェア コンポーネント</block>
  <block id="751547b5efb176a435e672a4015bb7e9" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX システム - ソフトウェア コンポーネント</block>
  <block id="c3d68fb38e0db372152f5a3a84fed148" category="paragraph">このセクションでは、 NetApp AIPod with NVIDIA DGX システムのソフトウェア コンポーネントに焦点を当てます。</block>
  <block id="5475410ded0787143601d2206a245532" category="section-title">NVIDIAソフトウェア</block>
  <block id="96a0475a5e6d02d46b5b8d7f1327a530" category="paragraph">NVIDIA Base Command™ はすべての DGX BasePOD に搭載されており、組織はNVIDIAソフトウェア イノベーションのメリットを最大限に活用できます。企業は、エンタープライズ グレードのオーケストレーションとクラスター管理、コンピューティング、ストレージ、ネットワーク インフラストラクチャを高速化するライブラリ、AI ワークロード向けに最適化されたオペレーティング システム (OS) を含む実績のあるプラットフォームを使用して、投資の可能性を最大限に引き出すことができます。</block>
  <block id="f30878d7bf93bf61a8d0a25e397a8583" category="paragraph">_NVIDIA BaseCommand ソリューション_</block>
  <block id="26997aefe36f4fb8a168ede0ec7189e1" category="paragraph"><block ref="26997aefe36f4fb8a168ede0ec7189e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="section-title">NVIDIA GPU クラウド (NGC)</block>
  <block id="5cbbb9592d14a268aacbc5ecd838a166" category="paragraph">NVIDIA NGC は、さまざまなレベルの AI 専門知識を持つデータ サイエンティスト、開発者、研究者のニーズを満たすソフトウェアを提供します。 NGC でホストされているソフトウェアは、共通の脆弱性と露出 (CVE)、暗号、および秘密鍵の集約されたセットに対してスキャンされます。複数の GPU、多くの場合はマルチノードに拡張できるようにテストおよび設計されており、ユーザーが DGX システムへの投資を最大限に活用できるようにします。</block>
  <block id="d19c3b09db45ed579ed1aa2895637b7d" category="paragraph">_NVIDIA GPU クラウド_</block>
  <block id="c46997ba8e7fdf0cb96f12b451129203" category="paragraph"><block ref="c46997ba8e7fdf0cb96f12b451129203" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b4d69ee10ecec0ac3d21aba6691dc53" category="paragraph">NVIDIA AI Enterprise は、あらゆる企業が生成 AI を利用できるようにするためのエンドツーエンドのソフトウェア プラットフォームであり、 NVIDIA DGX プラットフォームで実行するように最適化された生成 AI 基盤モデルに最速かつ最も効率的なランタイムを提供します。実稼働レベルのセキュリティ、安定性、管理性を備え、生成 AI ソリューションの開発を効率化します。  NVIDIA AI Enterprise は DGX BasePOD に含まれており、エンタープライズ開発者は、事前トレーニング済みのモデル、最適化されたフレームワーク、マイクロサービス、高速化されたライブラリ、エンタープライズ サポートにアクセスできます。</block>
  <block id="9aeccfb63defa46cb78ffa3611d362c6" category="section-title">NetAppのソフトウェア</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">NetAppの最新世代のストレージ管理ソフトウェアであるONTAP 9 により、企業はインフラストラクチャを最新化し、クラウド対応のデータセンターに移行できるようになります。 ONTAP は業界をリードするデータ管理機能を活用し、データの保存場所に関係なく、単一のツール セットでデータの管理と保護を可能にします。また、エッジ、コア、クラウドなど、必要な場所にデータを自由に移動することもできます。  ONTAP 9 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッド クラウド アーキテクチャ全体で次世代のインフラストラクチャ機能を実現する多数の機能が含まれています。</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">データの高速化と保護</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP は優れたレベルのパフォーマンスとデータ保護を提供し、これらの機能を次のように拡張します。</block>
  <block id="7c282a19ff405710e49738f9d0a03a85" category="list-text">パフォーマンスと低レイテンシ。  ONTAP は、NFS over RDMA、パラレル NFS (pNFS)、NFS セッション トランキングを使用したNVIDIA GPUDirect Storage (GDS) のサポートを含め、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="b2d0aaf645ff5747fbe1e0aec0cf528c" category="list-text">データ保護：ONTAP は、すべてのプラットフォームにわたる共通管理により、組み込みのデータ保護機能と業界最強のランサムウェア対策保証を提供します。</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NetAppボリューム暗号化 (NVE)。  ONTAP は、オンボードと外部キー管理の両方をサポートするネイティブのボリューム レベルの暗号化を提供します。</block>
  <block id="651928f77d87184265ec1be1ab0b8aff" category="list-text">ストレージのマルチテナントと多要素認証。  ONTAP は、最高レベルのセキュリティでインフラストラクチャ リソースを共有できるようにします。</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">データ管理を簡素化</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">データ管理は、AI アプリケーションと AI/ML データセットのトレーニングに適切なリソースが使用されるように、企業の IT 運用とデータ サイエンティストにとって非常に重要です。  NetAppテクノロジーに関する次の追加情報は、この検証の範囲外ですが、導入によっては関連する可能性があります。</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAPデータ管理ソフトウェアには、運用を合理化および簡素化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="621721e0b0144695aabce4090fa40eed" category="list-text">スナップショットとクローンにより、ML/DL ワークフローのコラボレーション、並列実験、強化されたデータ ガバナンスが可能になります。</block>
  <block id="b1932ff070760d4f32c0a3701982558d" category="list-text">SnapMirror は、ハイブリッド クラウドおよびマルチサイト環境でシームレスなデータ移動を可能にし、必要な場所に必要なときにデータを配信します。</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">インライン データ圧縮と拡張重複排除。データ圧縮によりストレージ ブロック内の無駄なスペースが削減され、重複排除により実効容量が大幅に増加します。これは、ローカルに保存されたデータとクラウドに階層化されたデータに適用されます。</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">最小、最大、および適応型サービス品質 (AQoS)。きめ細かなサービス品質 (QoS) 制御により、高度に共有された環境における重要なアプリケーションのパフォーマンス レベルを維持できます。</block>
  <block id="74959a361bdb223dafbb94226dd84e3e" category="list-text">NetApp FlexGroups を使用すると、ストレージ クラスター内のすべてのノードにデータを分散できるため、非常に大規模なデータセットに対して膨大な容量と高いパフォーマンスを実現できます。</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: FabricPool のベストプラクティス</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetAppFabricPool。  Amazon Web Services (AWS)、Azure、 NetApp StorageGRIDストレージ ソリューションなどのパブリックおよびプライベート クラウド ストレージ オプションへのコールド データの自動階層化を提供します。  FabricPoolの詳細については、以下を参照してください。<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block> 。</block>
  <block id="eec4aeb85db42cd9055b9aba24052c7e" category="list-text">NetApp FlexCache。ファイル配布を簡素化し、WAN の遅延を減らし、WAN 帯域幅のコストを削減するリモート ボリューム キャッシュ機能を提供します。  FlexCache、複数のサイトに分散した製品開発が可能になり、遠隔地から企業のデータセットに高速にアクセスできるようになります。</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">将来を見据えたインフラ</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP は、次の機能により、要求が厳しく常に変化するビジネス ニーズへの対応に役立ちます。</block>
  <block id="483e92f76323d9d7b2d7f2ec6d4c0590" category="list-text">シームレスなスケーリングと中断のない運用。 ONTAP は、既存のコントローラおよびスケールアウト クラスタへの容量のオンライン追加をサポートします。お客様は、コストのかかるデータ移行や停止なしで、NVMe や 32Gb FC などの最新テクノロジーにアップグレードできます。</block>
  <block id="96cf8f94fadb527d958ae5373082d6d7" category="list-text">クラウド接続。  ONTAP は、すべてのパブリック クラウドでソフトウェア定義ストレージ (ONTAP Select) とクラウド ネイティブ インスタンス (Google Cloud NetApp Volumes) のオプションを備えた、最もクラウドに接続されたストレージ管理ソフトウェアです。</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">新しいアプリケーションとの統合。  ONTAP は、既存のエンタープライズ アプリケーションをサポートするのと同じインフラストラクチャを使用して、自律走行車、スマート シティ、インダストリー 4.0 などの次世代プラットフォームとアプリケーション向けにエンタープライズ グレードのデータ サービスを提供します。</block>
  <block id="2c7194a99a4f7de8ffbf3ba400a92df8" category="paragraph">NetApp DataOps Toolkit は、高性能なスケールアウトNetAppストレージを基盤とする開発/トレーニング ワークスペースと推論サーバーの管理を簡素化する Python ベースのツールです。 DataOps Toolkit はスタンドアロン ユーティリティとして動作し、 NetApp Tridentを活用してストレージ操作を自動化する Kubernetes 環境ではさらに効果的です。主な機能は次のとおりです。</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">高性能のスケールアウトNetAppストレージを活用した新しい大容量の JupyterLab ワークスペースを迅速にプロビジョニングします。</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">エンタープライズ クラスのNetAppストレージを活用した新しいNVIDIA Triton Inference Server インスタンスを迅速にプロビジョニングします。</block>
  <block id="44ce48cceac53b351ab54ca5685fcf55" category="list-text">実験や迅速な反復を可能にするために、大容量の JupyterLab ワークスペースをほぼ瞬時に複製します。</block>
  <block id="b47bad7e2a479b14e613be5ba1af90a0" category="list-text">バックアップやトレーサビリティ/ベースライン作成のための大容量 JupyterLab ワークスペースのほぼ瞬時のスナップショット。</block>
  <block id="afe9b022bbe49ebc232dc11679a61bb4" category="list-text">大容量、高パフォーマンスのデータ ボリュームのプロビジョニング、クローン作成、スナップショットをほぼ瞬時に実行します。</block>
  <block id="b242f57e51b5f507797a088899c22df7" category="paragraph">Trident は、Anthos を含むコンテナと Kubernetes ディストリビューション向けの、完全にサポートされているオープンソースのストレージ オーケストレーターです。Trident は、 NetApp ONTAPを含むNetAppストレージ ポートフォリオ全体と連携し、NFS、NVMe/TCP、iSCSI 接続もサポートします。Trident は、ストレージ管理者の介入を必要とせずに、エンドユーザーがNetAppストレージ システムからストレージをプロビジョニングおよび管理できるようにすることで、DevOps ワークフローを加速します。</block>
  <block id="1efc1a71dad2451e243efa783d9aaba0" category="summary">NetApp AIPodとNVIDIA DGX システム - ソリューション検証とサイジングのガイダンス</block>
  <block id="1baf67b0ad3fef1cc60370bda6ebc7f9" category="doc">NVA-1173 NetApp AIPodとNVIDIA DGX システム - ソリューション検証およびサイジング ガイダンス</block>
  <block id="d2fb9fca0fa09d949a54ae42e337c891" category="paragraph">このセクションでは、 NetApp AIPodとNVIDIA DGX システムのソリューション検証とサイズ設定のガイダンスに焦点を当てます。</block>
  <block id="773a9689ba6682deeabffa6746d64105" category="section-title">ソリューション検証</block>
  <block id="364bed9cbf28e51b3a87b1cece482054" category="paragraph">このソリューションのストレージ構成は、オープンソース ツール FIO を使用した一連の合成ワークロードを使用して検証されました。これらのテストには、ディープラーニング トレーニング ジョブを実行する DGX システムによって生成されるストレージ ワークロードをシミュレートすることを目的とした読み取りおよび書き込み I/O パターンが含まれます。ストレージ構成は、DGX システムのクラスターをシミュレートするために、FIO ワークロードを同時に実行する 2 ソケット CPU サーバーのクラスターを使用して検証されました。各クライアントは、前述のものと同じネットワーク構成で構成され、次の詳細が追加されました。</block>
  <block id="5c553fedff3f40a2af76bb0c410b404f" category="paragraph">この検証には次のマウント オプションが使用されました。</block>
  <block id="cb8472643b1176f8340370ce5a0b204d" category="cell">バージョン=4.1</block>
  <block id="893b3a13ba8b6b5a60094306461bc370" category="cell">複数のストレージノードへの並列アクセスを可能にするpNFS</block>
  <block id="1df213ce94ed5cdef706c9350768f0c2" category="cell">プロトコル=rdma</block>
  <block id="42cc89ba8e1299f3640ad771a94abfaa" category="cell">転送プロトコルをデフォルトのTCPではなくRDMAに設定します</block>
  <block id="9b7b56ffe75ec2daff44ba8923725d27" category="cell">ポート=20049</block>
  <block id="52c223170500f2f347a266328f0c4216" category="cell">RDMA NFSサービスに正しいポートを指定する</block>
  <block id="5b75616cf8bcd004a7fb0c78bcf4cb1e" category="cell">最大接続数=16</block>
  <block id="82264615e17e10dec975d19de56f7e01" category="cell">NFSセッショントランキングを有効にしてストレージポートの帯域幅を集約します</block>
  <block id="b0b79785aa490d51befbe60046fe59a6" category="cell">書き込み=熱心</block>
  <block id="27d6ebb9c804f9228e43f1362d2ad502" category="cell">バッファ書き込みの書き込みパフォーマンスを向上</block>
  <block id="df2285a23b7de4affb43985a03a9b955" category="cell">rsize=262144、wsize=262144</block>
  <block id="226cf9c18b16f30e1381d76500dcd2c3" category="cell">I/O転送サイズを256kに設定する</block>
  <block id="1275e87e965ab2e83ee1a3d508393bb1" category="paragraph">さらに、クライアントは NFS max_session_slots 値が 1024 に設定されました。このソリューションは RDMA 経由の NFS を使用してテストされたため、ストレージ ネットワーク ポートはアクティブ/パッシブ ボンドで構成されました。この検証には次の結合パラメータが使用されました。</block>
  <block id="dc2f1400a2999b58888391b52366d42d" category="cell">モード=アクティブバックアップ</block>
  <block id="ceafe9fbea6d2853c0ef101fde263114" category="cell">ボンドをアクティブ/パッシブモードに設定する</block>
  <block id="0772e25cb688aaddbfcafe9a95042ae0" category="cell">primary=&lt;インターフェース名&gt;</block>
  <block id="126d68b093e92a0eeafa0ea632b5dee2" category="cell">すべてのクライアントのプライマリインターフェースはスイッチに分散されていました</block>
  <block id="cbfd831ae9cd4bbc2c5955b278fc1464" category="cell">miiモニター間隔=100</block>
  <block id="ef530a18c3e08c2e1454d98413c8995a" category="cell">監視間隔を100msに指定</block>
  <block id="4a7a0a399fdd09cc77725d4bca22c5d2" category="cell">フェイルオーバーMACポリシー=アクティブ</block>
  <block id="1cddea1ebc0f8a54ddb9d1b5d3701199" category="cell">アクティブ リンクの MAC アドレスがボンドの MAC であることを指定します。これは、結合されたインターフェース上での RDMA の適切な操作に必要です。</block>
  <block id="13e766ae456cff38288a10e042da1460" category="paragraph">ストレージ システムは、説明どおり、2 つの A900 HA ペア (4 つのコントローラ) と、各 HA ペアに接続された 24 個の 1.9 TB NVMe ディスク ドライブを備えた 2 つの NS224 ディスク シェルフで構成されました。アーキテクチャのセクションで説明したように、すべてのコントローラのストレージ容量はFlexGroupボリュームを使用して結合され、すべてのクライアントのデータはクラスタ内のすべてのコントローラに分散されました。</block>
  <block id="4534545218c3df22ad30ec5ab0466128" category="section-title">ストレージシステムのサイズ決定ガイダンス</block>
  <block id="e58e8ec46be51c65fb6895529b19620c" category="paragraph">NetApp はDGX BasePOD 認定を正常に完了しており、テストされた 2 つの A90 HA ペアは 16 個の DGX H100 システムのクラスターを簡単にサポートできます。より高いストレージ パフォーマンス要件を持つ大規模な導入の場合、 NetApp ONTAPクラスタにAFFシステムを追加して、単一クラスタで最大 12 個の HA ペア (24 ノード) まで構成できます。このソリューションで説明されているFlexGroupテクノロジーを使用すると、24 ノードのクラスターは単一の名前空間で 79 PB 以上、最大 552 GBps のスループットを提供できます。  AFF A400 、A250、C800 などのその他のNetAppストレージ システムは、より低コストで小規模な導入向けに、より低いパフォーマンスと/またはより高い容量のオプションを提供します。 ONTAP 9 は混合モデルのクラスタをサポートしているため、お客様は小さな初期フットプリントから始めて、容量とパフォーマンスの要件の拡大に応じて、より多くのストレージ システムまたはより大きなストレージ システムをクラスタに追加することができます。以下の表は、各AFFモデルでサポートされる A100 および H100 GPU の数の概算を示しています。</block>
  <block id="d151e6348ab5291d10caeda2db802b75" category="paragraph">_NetApp ストレージ システムのサイズ設定ガイダンス_</block>
  <block id="c61d72d95f504983715ce76fcfdfb864" category="paragraph"><block ref="c61d72d95f504983715ce76fcfdfb864" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28e8b3e83af233fe7085ba954fc6fd36" category="doc">Eシリーズストレージを搭載したNetApp上のBeeGFS</block>
  <block id="e8afe31a21b6aae9717484d865743dae" category="paragraph">E シリーズ ストレージを搭載したNetApp上の BeeGFS は、最も過酷なワークロードにも対応できる、シンプルで信頼性が高く、拡張性に優れ、コスト効率に優れた HPC インフラストラクチャを備えた、実績のある統合ソリューションです。</block>
  <block id="d18d454d6ae7128c6b49bf41c9ea2cf4" category="paragraph"><block ref="d18d454d6ae7128c6b49bf41c9ea2cf4" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-DEPLOY: NetApp Eシリーズ システム搭載 Quantum StorNext 導入ガイド</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">ライアン・ロディン、NetApp</block>
  <block id="25dbf1b5193ae9eff63687c18c19e6f5" category="paragraph">このドキュメントでは、 NetApp E シリーズ ストレージ システムを使用して StorNext 並列ファイル システム ソリューションを展開する方法について詳しく説明します。このソリューションは、 NetApp EF280 オールフラッシュ アレイ、 NetApp EF300 オールフラッシュ NVMe アレイ、 NetApp EF600 オールフラッシュ NVMe アレイ、およびNetApp E5760 ハイブリッド システムを対象としています。メディアおよびエンターテイメント業界でテストに広く使用されているツールである Frametest ベンチマークに基づいて、パフォーマンス特性を提供します。</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-DESIGN: NetApp Eシリーズ システムを搭載したQuantum StorNextの設計ガイド</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">このドキュメントでは、 NetApp E シリーズ ストレージ システムを使用して StorNext 並列ファイル システム ソリューションを設計する方法について詳しく説明します。このソリューションは、 NetApp EF280 オールフラッシュ アレイ、 NetApp EF300 オールフラッシュ NVMe アレイ、EF600 オールフラッシュ NVMe アレイ、およびNetApp E5760 ハイブリッド システムを対象としています。メディアおよびエンターテイメント業界でテストに広く使用されているツールである Frametest ベンチマークに基づいて、パフォーマンス特性を提供します。</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: NetApp Eシリーズストレージを使用したIBM Spectrum Scaleの導入 - インストールと検証</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">クリス・セイラー、NetApp</block>
  <block id="06bd55c4b576fd1f13eb5e25a1415bba" category="paragraph">TR-4859 では、IBM の Spectrum Scale ソフトウェア スタックに基づく完全な並列ファイル システム ソリューションを展開するプロセスについて説明します。  TR-4859 は、Spectrum Scale のインストール方法、インフラストラクチャの検証方法、および構成の管理方法の詳細を提供するように設計されています。</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="3026654be6be955b54735554371ee5a0" category="summary">このNetApp Verified Architecture では、 NetApp BeeGFS ビルディング ブロックを使用したNVIDIA DGX SuperPODの設計について説明します。このソリューションは、 NVIDIAの専用承認クラスターで検証されたフルスタック データセンター プラットフォームです。</block>
  <block id="85505186d8e84ecff8e7e71596423747" category="doc">NVIDIA DGX SuperPODとNetApp - 設計ガイド</block>
  <block id="49ba6c0ee9149acc4bdb6fac5165b7b0" category="paragraph">このNetApp Verified Architecture では、 NetApp BeeGFS ビルディング ブロックを使用したNVIDIA DGX SuperPODの設計について説明します。このソリューションは、 NVIDIAの専用受け入れクラスターで検証されたフルスタック データセンター プラットフォームです。</block>
  <block id="adb0b7d6a9d5c0af32d1c6fe9a103229" category="inline-image-macro">200,200</block>
  <block id="0a8dfa4d72d5f9b29ce5ac529286b37f" category="paragraph"><block ref="0a8dfa4d72d5f9b29ce5ac529286b37f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0a7225e9429ab905378b45f3aa288040" category="paragraph">アミン・ベナニ、クリスチャン・ホワイトサイド、デビッド・アーネット、サティッシュ・ティヤガラジャン（NetApp）</block>
  <block id="7919e821dc18f3e88c0201e01bf6a240" category="section-title">エグゼクティブサマリー</block>
  <block id="d83b5adf97fe549e1dc83bb95e6f2cdf" category="paragraph">急速に進化する今日のテクノロジー環境において、AI は消費者体験に革命をもたらし、あらゆる業界でイノベーションを推進しています。しかし、これは、AI ワークロードの厳しい要求に対応できる高性能コンピューティング (HPC) ソリューションを導入するというプレッシャーにさらされている IT 部門にとっても大きな課題となります。組織が AI の力を活用するために競争するにつれて、導入、拡張、管理が容易なソリューションの必要性が高まっています。</block>
  <block id="2e93342ec6458064edd50d209383c787" category="paragraph">NVIDIA DGX SuperPODは、今日の企業が直面する最も複雑な AI ワークロードをサポートするために IT 向けのターンキー ソリューションとして提供される AI データ センター インフラストラクチャ プラットフォームです。あらゆる正確なディープラーニング (DL) モデルの中核は大量のデータであり、このデータを効率的に提供および再提供できる高スループットのストレージ ソリューションが必要です。  NetApp BeeGFS ソリューションは、BeeGFS 並列ファイルシステムを備えたNetApp EF600 ストレージ アレイで構成されており、 NVIDIA DGX SuperPOD の能力を最大限に発揮できるようにします。 NetApp BeeGFS ソリューションは、SuperPOD アーキテクチャとの統合および拡張がNVIDIAによって検証されています。その結果、AI データ センターの導入と管理が簡素化され、パフォーマンスと容量の拡張性がほぼ無制限に実現します。</block>
  <block id="77e585eeb67a682a6445c0154fd9a028" category="paragraph">NetApp BeeGFS ソリューションは、高性能なNetApp EF600 NVMe ストレージ システムとスケーラブルな BeeGFS 並列ファイル システムを搭載しており、要求の厳しい AI ワークロードに対応する堅牢で効率的なストレージ基盤を提供します。共有ディスク アーキテクチャにより、高い可用性が保証され、システム上の課題に直面しても一貫したパフォーマンスとアクセス性が維持されます。このソリューションは、多様なストレージ要件に合わせてカスタマイズできる、スケーラブルで柔軟なアーキテクチャを提供します。顧客は、追加のストレージ ビルディング ブロックを統合することで、ストレージのパフォーマンスと容量を簡単に拡張し、最も要求の厳しいワークロードにも対応できます。</block>
  <block id="1ad3f73d04f7a3d0b225d62bf707c034" category="list-text">NVIDIA DGX SuperPOD は、検証済みの外部接続共有ストレージを備えた DGX H100 および H200 システムを活用します。</block>
  <block id="8dc89fa0c821b38b2ab07d3f5dd4385f" category="list-text">各 DGX SuperPOD スケーラブル ユニット (SU) は 32 個の DGX システムで構成され、FP8 精度で 640 ペタフロップスの AI パフォーマンスを実現します。  NetApp、単一の DGX SuperPOD 構成に対して少なくとも 2 つのビルディング ブロックを使用してNetApp BeeGFS ストレージ ソリューションのサイズを設定することを推奨しています。</block>
  <block id="0aa799745475dedefbc0785863494b75" category="paragraph">_ソリューションの概要_</block>
  <block id="0e06b8493198d6e7d8d53d9201ddd9bc" category="inline-image-macro">NVIDIA DGX SuperPODを使用したNetApp BeeGFS ソリューションの概要を示す図。</block>
  <block id="6bfc1196652f29c394bdbe8e2807a4a0" category="paragraph"><block ref="6bfc1196652f29c394bdbe8e2807a4a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="949e06b94ff43763386683593267b5d3" category="list-text">NetApp BeeGFS の構成要素は、2 つのNetApp EF600 アレイと 2 つの x86 サーバーで構成されています。</block>
  <block id="53a59094fc8cf61c8ceb5488c68798f9" category="list-text">NVIDIA DGX SuperPODの基盤にNetApp EF600 オールフラッシュ アレイを採用することで、お客様は 99.999% の稼働率を誇る信頼性の高いストレージ基盤を手に入れることができます。</block>
  <block id="23830778b135794055062035d895d122" category="list-text">NetApp EF600 とNVIDIA DGX システム間のファイル システム層は、BeeGFS 並列ファイル システムです。 BeeGFS は、従来の並列ファイルシステムの問題点を解決するために、ドイツの Fraunhofer 高性能コンピューティング センターによって作成されました。その結果、ThinkParQ によって開発および提供され、多くのスーパーコンピューティング環境で使用されている、最新のユーザー スペース アーキテクチャを備えたファイル システムが誕生しました。</block>
  <block id="d6dbc9a4d449d8584f1bc7766a233055" category="list-text">NetAppの BeeGFS サポートは、NetApp の優れたサポート組織と、パフォーマンスと稼働時間に関する顧客の要件を一致させます。お客様は、優れたサポート リソース、BeeGFS リリースへの早期アクセス、クォータ強制や高可用性 (HA) などの一部の BeeGFS エンタープライズ機能にアクセスできます。</block>
  <block id="06723075d010c851032e77543613704f" category="list-text">NVIDIA SuperPOD SU とNetApp BeeGFS ビルディング ブロックを組み合わせることで、コンピューティングやストレージを簡単かつシームレスに拡張できる俊敏な AI ソリューションが実現します。</block>
  <block id="e0d00c6a1325f01dc14822163a1d43fe" category="paragraph">_NetApp BeeGFS ビルディングブロック_</block>
  <block id="f2ccf42799ed738590ee8a95c9a2e5c9" category="inline-image-macro">単一のNetApp BeeGFS ビルディング ブロックを示す図。</block>
  <block id="9390da63574f67fe268b45392cf0ec3e" category="paragraph"><block ref="9390da63574f67fe268b45392cf0ec3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df07b47923825d5392c14e80cea2d72a" category="section-title">ユースケースの概要</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">このソリューションは、次のユースケースに適用されます。</block>
  <block id="30e31e5dc6388c3434cea1711261b743" category="list-text">機械学習 (ML)、ディープラーニング (DL)、自然言語処理 (NLP)、自然言語理解 (NLU)、生成 AI (GenAI) を含む人工知能 (AI)。</block>
  <block id="c21f50752fbbe8f54e46848c0f9ce70a" category="list-text">中規模から大規模のAIトレーニング</block>
  <block id="137c3bef49af695737b7c23000204b5c" category="list-text">コンピュータービジョン、音声、オーディオ、言語モデル</block>
  <block id="15ed9179636b107f0a88e83f782e6cec" category="list-text">メッセージ パッシング インターフェース (MPI) やその他の分散コンピューティング技術によって加速されるアプリケーションを含む HPC</block>
  <block id="90b7289b464ec4d544bf5a9eacbaf7f0" category="list-text">アプリケーション ワークロードの特徴は次のとおりです。</block>
  <block id="c9ccfce7935790c9fd0d9ccf98da5177" category="list-text">1GBを超えるファイルの読み取りまたは書き込み</block>
  <block id="680e47afa4860ce2ac4a078a0d466121" category="list-text">複数のクライアント（数十、数百、数千）による同じファイルの読み取りまたは書き込み</block>
  <block id="af7aa0607b7f1d728a529edd21a52763" category="list-text">マルチテラバイトまたはマルチペタバイトのデータセット</block>
  <block id="efc155766b6000aefdf459d6ff3ecd75" category="list-text">大規模なファイルと小規模なファイルの混在に最適化できる単一のストレージ名前空間を必要とする環境</block>
  <block id="dcbd8f687e2ef904380c2b6c942c989e" category="paragraph">このセクションでは、 NetAppソリューションを使用したNVIDIA DGX SuperPODの技術要件について説明します。</block>
  <block id="b95d6ba22cd7d0fb6a3c655d4c24d180" category="inline-link">NVIDIA DGX H100 SuperPOD リファレンス アーキテクチャ</block>
  <block id="02399dc2f4ffe6e6772456736a8522d7" category="inline-link">NVA-1164-DESIGN: NetApp NVA 設計上の BeeGFS</block>
  <block id="5425be0e2232456057166446265f9a88" category="paragraph">以下の表 1 に、単一の SU のソリューションを実装するために必要なハードウェア コンポーネントを示します。ソリューションのサイズは、32 台のNVIDIA DGX H100 システムと 2 台または 3 台のNetApp BeeGFS ビルディング ブロックから始まります。単一のNetApp BeeGFS ビルディング ブロックは、2 つのNetApp EF600 アレイと 2 つの x86 サーバーで構成されます。顧客は、展開サイズの拡大に応じて追加のビルディング ブロックを追加できます。詳細については、<block ref="55ded0354bf42e7e117b50dda2359a8a" category="inline-link-rx"></block>そして<block ref="de7b61948f391c0bb69985cc0357d2a5" category="inline-link-rx"></block>。</block>
  <block id="5aa595c84818428979f9fa2d99bb6f83" category="cell">NVIDIA DGX H100 または H200</block>
  <block id="6364d3f0f495b6ab9dcf8d3b5c6e0b01" category="cell">32</block>
  <block id="eef6c1a81c81a43f02e2b7749d260ef5" category="cell">NVIDIA Quantum QM9700スイッチ</block>
  <block id="34a2c495ed1b62db3e0fffd75420aca5" category="cell">8枚の葉、4本の背骨</block>
  <block id="be3accc5713b4d53186215779c2deeed" category="cell">NetApp BeeGFS の構成要素</block>
  <block id="0dbcb15fd014d19061fb2910f0a1ab0e" category="paragraph">以下の表 2 に、ソリューションを実装するために必要なソフトウェア コンポーネントを示します。ソリューションの特定の実装で使用されるソフトウェア コンポーネントは、顧客の要件に応じて異なる場合があります。</block>
  <block id="b9e807b01f3ef86c9dfed350c8c3d49f" category="cell">NVIDIA DGX ソフトウェア スタック</block>
  <block id="32ac4a04c126e4e450b2f93ae6cfd3a7" category="cell">ThinkParQ BeeGFS 並列ファイルシステム</block>
  <block id="dc140913e754c7554bc598a02951fa66" category="section-title">ソリューション検証</block>
  <block id="f95f7879d178879af0b5a728259ce9a3" category="inline-link">NVIDIA DGX SuperPOD: NetApp EF600 と BeeGFS リファレンス アーキテクチャ</block>
  <block id="24e45924f52e38078756fd5fb1d83668" category="paragraph">NetApp搭載NVIDIA DGX SuperPOD は、 NetApp BeeGFS ビルディング ブロックを使用してNVIDIAの専用承認クラスターで検証されました。受け入れ基準は、 NVIDIAが実行した一連のアプリケーション、パフォーマンス、ストレス テストに基づいています。詳細については、<block ref="2ffc6657f5234f1aed913433d4ce09f3" category="inline-link-rx"></block> 。</block>
  <block id="b7f81445ff8908f0aa2a3356e8231f05" category="paragraph">NetAppとNVIDIA は、AI ソリューションのポートフォリオを市場に提供するために長年にわたって協力してきました。 NetApp EF600 オールフラッシュ アレイを搭載したNVIDIA DGX SuperPOD は、顧客が安心して導入できる実証済みの検証済みソリューションです。この完全に統合されたターンキー アーキテクチャにより、導入のリスクがなくなり、誰もが AI リーダーシップの競争に勝つための道を歩むことができます。</block>
  <block id="dcd86a18e8aa77675f1b2f792cb6ba5c" category="inline-link-macro">NVIDIA DGX SuperPODリファレンス アーキテクチャ</block>
  <block id="98d56828382118fe5dcd8ef673b93afb" category="list-text"><block ref="98d56828382118fe5dcd8ef673b93afb" category="inline-link-macro-rx"></block></block>
  <block id="4fafe9ef5c2efce123913e9ac744f4d6" category="inline-link-macro">NVIDIA DGX SuperPODデータセンター設計リファレンスガイド</block>
  <block id="473bfb82bbec433a8f08fa15c67e0c08" category="list-text"><block ref="473bfb82bbec433a8f08fa15c67e0c08" category="inline-link-macro-rx"></block></block>
  <block id="6f698ddb1773933b8e41b2ed16297ce7" category="inline-link-macro">NVIDIA DGX SuperPOD: NetApp EF600 と BeeGFS</block>
  <block id="a552f45479fc3484a4356ed78090fa76" category="list-text"><block ref="7f25f2868948e2fffc54c32cf9c33644" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI を活用した自動化とエッジ コンピューティングは、ビジネス組織がデジタル変革を実現し、運用の効率と安全性を最大限に高めるのに役立つ主要なアプローチです。エッジ コンピューティングでは、データをデータセンターとの間で移動する必要がないため、データの処理速度が大幅に向上します。したがって、データセンターやクラウドとの間でデータを送受信する際に発生するコストが削減されます。</block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI を活用した自動化とエッジ コンピューティングは、ビジネス組織がデジタル変革を実現し、運用の効率と安全性を最大限に高めるのに役立つ主要なアプローチです。エッジ コンピューティングでは、データをデータセンターとの間で移動する必要がないため、データの処理速度が大幅に向上します。したがって、データセンターやクラウドとの間でデータを送受信する際に発生するコストが削減されます。企業がエッジに展開された AI 推論モデルを使用してほぼリアルタイムで意思決定を行う必要がある場合、レイテンシの低減と速度の向上が有益となります。</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetAppストレージ システムは、ローカル SSD ストレージと同等以上のパフォーマンスを提供し、データ サイエンティスト、データ エンジニア、AI/ML 開発者、ビジネスまたは IT の意思決定者に次のメリットをもたらします。</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI システム、分析、その他の重要なビジネス システム間でデータを簡単に共有できます。このデータ共有により、インフラストラクチャのオーバーヘッドが削減され、パフォーマンスが向上し、企業全体のデータ管理が合理化されます。</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">コストを最小限に抑え、リソースの使用率を向上させるために、コンピューティングとストレージを独立して拡張できます。</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">統合されたスナップショット コピーとクローンを使用して合理化された開発および展開ワークフローにより、瞬時にスペース効率の高いユーザー ワークスペース、統合バージョン管理、および自動展開が実現します。</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">災害復旧と事業継続性のためのエンタープライズ グレードのデータ保護。このドキュメントで紹介されているNetAppと Lenovo のソリューションは、エッジでのエンタープライズ グレードの AI 推論の展開に最適な、柔軟なスケールアウト アーキテクチャです。</block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="section-title">謝辞</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">JJ  Lenovo、HPC および AI ソリューション担当シニア マネージャー、ファルカンガー氏</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette、 NetAppテクニカル マーケティング エンジニア</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell、 NetApp EシリーズAIソリューション担当テクニカルリード</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman、 NetAppの QA エンジニア</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">このドキュメントに記載されている情報の詳細については、次のドキュメントや Web サイトを参照してください。</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF Aシリーズアレイ製品ページ</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAPデータ管理ソフトウェア - ONTAP 9 情報ライブラリ</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: NetApp EFシリーズの紹介</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp EシリーズSANtricityソフトウェア データシート</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">NetAppコンテナ向け永続ストレージ - NetApp Trident</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="list-text">MLPerf</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlowベンチマーク</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="list-text">Lenovo ThinkSystem SE350 エッジサーバー</block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F 統合フラッシュストレージアレイ</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="a4113bc79b3920d11274d7bf9cfafe10" category="paragraph"><block ref="a4113bc79b3920d11274d7bf9cfafe10" category="inline-link-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">このセクションでは、テストされた構成、ネットワーク インフラストラクチャ、SE350 サーバー、およびストレージ プロビジョニングの詳細について説明します。</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">テスト構成</block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">次の図はテスト構成を示しています。 NetApp AFF C190ストレージ システムと 2 台の Lenovo ThinkSystem SE350 サーバー (それぞれ 1 つのNVIDIA T4 アクセラレータを搭載) を使用しました。これらのコンポーネントは、10GbE ネットワーク スイッチを介して接続されます。ネットワーク ストレージには、検証/テスト データセットと事前トレーニング済みモデルが保存されます。サーバーは計算機能を提供し、ストレージは NFS プロトコルを介してアクセスされます。</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">このセクションでは、テストされた構成、ネットワーク インフラストラクチャ、SE350 サーバー、およびストレージ プロビジョニングの詳細について説明します。次の表は、ソリューション アーキテクチャの基本コンポーネントを示しています。</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="cell">Lenovo ThinkSystem サーバー</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">NVIDIA T4 GPU カード 1 枚を搭載した SE350 サーバー 2 台</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">各サーバーには、2.20GHzで動作する4つの物理コアと128GBのRAMを備えたIntel Xeon D-2123IT CPUが1つ搭載されています。</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">エントリーレベルのNetApp AFFストレージシステム（HAペア）</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 ソフトウェア</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24x 960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFSプロトコル</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">コントローラごとに1つのインターフェースグループ、マウントポイントに4つの論理IPアドレス</block>
  <block id="e2921b0ff5efef521f662303c467e27f" category="paragraph"><block ref="e2921b0ff5efef521f662303c467e27f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">次の表は、ストレージ構成を示しています：2RU、24 ドライブ スロットを備えたAFF C190 。</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">コントローラ</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">Aggregate</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroupボリューム</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">集約サイズ</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">ボリュームサイズ</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">オペレーティングシステムマウントポイント</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">コントローラ1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">攻撃1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_fg</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15 TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/netapp_lenovo_fg</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">コントローラー2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">攻撃2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_fg フォルダーには、モデル検証に使用されるデータセットが含まれています。</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">下の図はテスト構成を示しています。 NetApp EF280 ストレージ システムと 2 台の Lenovo ThinkSystem SE350 サーバー (それぞれ 1 つのNVIDIA T4 アクセラレータを搭載) を使用しました。これらのコンポーネントは、10GbE ネットワーク スイッチを介して接続されます。ネットワーク ストレージには、検証/テスト データセットと事前トレーニング済みモデルが保存されます。サーバーは計算機能を提供し、ストレージは NFS プロトコルを介してアクセスされます。</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">次の表は、EF280 のストレージ構成を示しています。</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">ボリューム グループ</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">Volume</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPサイズ</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">接続方法</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">第1巻</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16 TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1からiSCSI LUN 0へ</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">第2巻</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2からiSCSI LUN 1へ</block>
  <block id="7192b14affaba8b38680e0cd3749622e" category="paragraph"><block ref="7192b14affaba8b38680e0cd3749622e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">このドキュメントでは、新たなアプリケーション シナリオに対応するエッジ環境のNetAppストレージ コントローラと Lenovo ThinkSystem サーバーに GPU ベースの人工知能 (AI) 推論を展開するためのコンピューティングおよびストレージ アーキテクチャについて説明します。</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: エッジAI推論 - NetAppとLenovo ThinkSystem - ソリューション設計</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan、 NetApp Miroslav Hodak、Lenovo</block>
  <block id="290612199861c31d1036b185b4e69b75" category="section-title">まとめ</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">先進運転支援システム (ADAS)、インダストリー 4.0、スマート シティ、モノのインターネット (IoT) などのいくつかの新しいアプリケーション シナリオでは、ほぼゼロの遅延で継続的なデータ ストリームを処理する必要があります。このドキュメントでは、これらの要件を満たすエッジ環境のNetAppストレージ コントローラと Lenovo ThinkSystem サーバーに GPU ベースの人工知能 (AI) 推論を展開するためのコンピューティングおよびストレージ アーキテクチャについて説明します。このドキュメントでは、 NVIDIA T4 GPU を搭載したエッジ サーバー上のさまざまな推論タスクを評価する、業界標準の MLPerf 推論ベンチマークのパフォーマンス データも提供します。オフライン、シングル ストリーム、マルチストリームの推論シナリオのパフォーマンスを調査し、コスト効率の高い共有ネットワーク ストレージ システムを備えたアーキテクチャが非常に高性能であり、複数のエッジ サーバーのデータとモデルの管理の中心点となることを示します。</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">企業はネットワーク エッジで膨大な量のデータを生成するようになっています。スマート センサーと IoT データから最大限の価値を引き出すために、組織はエッジ コンピューティングを可能にするリアルタイム イベント ストリーミング ソリューションを求めています。そのため、計算負荷の高いジョブは、データセンター外のエッジで実行されることが増えています。 AI 推論はこのトレンドを推進する要因の 1 つです。エッジ サーバーは、特にアクセラレータを使用する場合、これらのワークロードに十分な計算能力を提供しますが、特にマルチサーバー環境では、ストレージの制限が問題になることがよくあります。このドキュメントでは、エッジ環境に共有ストレージ システムを導入する方法と、パフォーマンスを低下させることなく AI 推論ワークロードにどのようなメリットをもたらすかについて説明します。</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">このドキュメントでは、エッジでの AI 推論のリファレンス アーキテクチャについて説明します。複数の Lenovo ThinkSystem エッジ サーバーとNetAppストレージ システムを組み合わせて、導入と管理が容易なソリューションを作成します。これは、複数のカメラと産業用センサーを備えた工場現場、小売取引における販売時点管理 (POS) システム、自律走行車の視覚異常を識別する完全自動運転 (FSD) システムなど、さまざまな状況での実際の展開のためのベースライン ガイドとなることを目的としています。</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">このドキュメントでは、Lenovo ThinkSystem SE350 Edge Server とエントリーレベルのNetApp AFFおよび EF シリーズ ストレージ システムで構成されるコンピューティングおよびストレージ構成のテストと検証について説明します。リファレンス アーキテクチャは、AI 導入のための効率的でコスト効率の高いソリューションを提供するとともに、 NetApp ONTAPおよびNetApp SANtricityデータ管理ソフトウェアによる包括的なデータ サービス、統合データ保護、シームレスなスケーラビリティ、クラウド接続データ ストレージも提供します。</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">このドキュメントは次の読者を対象としています。</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">エッジでの AI の製品化を希望するビジネス リーダーおよびエンタープライズ アーキテクト。</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">データ サイエンティスト、データ エンジニア、AI/機械学習 (ML) 研究者、AI システムの開発者。</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI/ML モデルとアプリケーションの開発のためのソリューションを設計するエンタープライズ アーキテクト。</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">ディープラーニング (DL) および ML モデルを効率的に展開する方法を探しているデータ サイエンティストおよび AI エンジニア。</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">エッジ推論モデルの展開と管理を担当するエッジ デバイス マネージャーとエッジ サーバー管理者。</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">ソリューションアーキテクチャ</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">この Lenovo ThinkSystem サーバーとNetApp ONTAPまたはNetApp SANtricityストレージ ソリューションは、従来の CPU と並んで GPU の処理能力を使用して、大規模なデータセットでの AI 推論を処理するように設計されています。この検証では、次の 2 つの図に示すように、単一のNetApp AFFストレージ システムと相互接続された単一または複数の Lenovo SR350 エッジ サーバーを使用するアーキテクチャによる、高いパフォーマンスと最適なデータ管理が実証されています。</block>
  <block id="f21cce3e60a01cff1e8e221c6536fe78" category="paragraph"><block ref="f21cce3e60a01cff1e8e221c6536fe78" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94aa1b43a547a9dd2c4d023dbc98322b" category="paragraph"><block ref="94aa1b43a547a9dd2c4d023dbc98322b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">次の図の論理アーキテクチャの概要は、このアーキテクチャにおけるコンピューティング要素とストレージ要素の役割を示しています。具体的には、次の内容が表示されます。</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">カメラやセンサーなどから受信したデータに対して推論を実行するエッジ コンピューティング デバイス。</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">複数の目的を果たす共有ストレージ要素:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">推論モデルと推論の実行に必要なその他のデータを一元的に保存する場所を提供します。コンピューティング サーバーはストレージに直接アクセスし、推論モデルをローカルにコピーする必要なく、ネットワーク経由で推論モデルを使用します。</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">更新されたモデルはここにプッシュされます。</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">エッジ サーバーが受信した入力データをアーカイブし、後で分析できるようにします。たとえば、エッジ デバイスがカメラに接続されている場合、ストレージ要素はカメラでキャプチャされたビデオを保存します。</block>
  <block id="3c5974fb92ca4b40257a58c213d0f137" category="paragraph"><block ref="3c5974fb92ca4b40257a58c213d0f137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">赤</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">青</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">レノボのコンピューティングシステム</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFFストレージシステム</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">カメラやセンサーなどからの入力に基づいて推論を実行するエッジ デバイス。</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">後で分析するために、エッジ デバイスからの推論モデルとデータを保持する共有ストレージ。</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">このNetAppと Lenovo のソリューションは、主に次の利点を提供します。</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">エッジでの GPU アクセラレーション コンピューティング。</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">共有ストレージからバックアップおよび管理される複数のエッジ サーバーの展開。</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">データ損失なしで低い復旧ポイント目標 (RPO) と復旧時間目標 (RTO) を満たす強力なデータ保護。</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetAppスナップショット コピーとクローンを使用してデータ管理を最適化し、開発ワークフローを効率化します。</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">このアーキテクチャの使い方</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">このドキュメントでは、提案されたアーキテクチャの設計とパフォーマンスを検証します。ただし、コンテナー、ワークロード、モデル管理、クラウドまたはオンプレミスのデータセンターとのデータ同期など、特定のソフトウェア レベルの部分は、展開シナリオに固有のものであるため、テストしていません。ここでは複数の選択肢が存在します。</block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="inline-link-macro">NetApp AI コントロール プレーン</block>
  <block id="bfbeeaf5d09672568692829ade4ca556" category="paragraph">コンテナ管理レベルでは、Kubernetes コンテナ管理は適切な選択肢であり、完全なアップストリーム バージョン (Canonical) またはエンタープライズ展開に適した修正バージョン (Red Hat) のいずれかで適切にサポートされています。その<block ref="cba35aa1f9d4aeed351c50bd57559a4d" category="inline-link-macro-rx"></block>NetApp Tridentと新たに追加された<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block>データ サイエンティストやデータ エンジニアがNetAppストレージと統合するための組み込みのトレーサビリティ、データ管理機能、インターフェイス、およびツールを提供します。 Kubernetes 用の ML ツールキットである Kubeflow は、TensorFlow Serving やNVIDIA Triton Inference Server などの複数のプラットフォームでのモデルのバージョン管理と KFServing のサポートに加えて、追加の AI 機能を提供します。もう 1 つのオプションは、GPU 対応 AI 推論コンテナーのカタログへのアクセスとともにワークロード管理を提供するNVIDIA EGX プラットフォームです。ただし、これらのオプションを本番環境に導入するには多大な労力と専門知識が必要になる可能性があり、サードパーティの独立系ソフトウェア ベンダー (ISV) またはコンサルタントの支援が必要になる場合もあります。</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">ソリューション領域</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 推論とエッジ コンピューティングの主な利点は、デバイスが遅延なく高品質のデータを計算、処理、分析できることです。エッジ コンピューティングの使用例は非常に多く、このドキュメントですべてを説明することはできませんが、ここでは代表的なものをいくつか紹介します。</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">自動車：自動運転車</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">エッジ コンピューティングの典型的な例は、自律走行車 (AV) の先進運転支援システム (ADAS) です。無人運転車の AI は、安全な運転を実現するために、カメラやセンサーからの大量のデータを迅速に処理する必要があります。物体と人間の間の解釈に時間がかかりすぎると生死に関わる可能性があるため、そのデータをできるだけ車両の近くで処理できることが重要です。この場合、1 つ以上のエッジ コンピューティング サーバーがカメラ、RADAR、LiDAR、その他のセンサーからの入力を処理し、共有ストレージが推論モデルを保持し、センサーからの入力データを保存します。</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">ヘルスケア：患者モニタリング</block>
  <block id="bace962401fe7f588dcfdc4444fa9cfd" category="paragraph">AI とエッジ コンピューティングの最大の影響の 1 つは、在宅ケアと集中治療室 (ICU) の両方で慢性疾患の患者の継続的なモニタリングを強化できることです。インスリンレベル、呼吸、神経活動、心拍リズム、胃腸機能を監視するエッジデバイスから得られるデータは、人の命を救うために行動できる時間が限られているため、即座に行動を起こさなければならない即時のデータの分析が必要です。</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">小売：レジなし決済</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">エッジ コンピューティングは AI と ML を強化して、小売業者がチェックアウト時間を短縮し、客足を増やすのに役立ちます。レジなしシステムは、次のようなさまざまなコンポーネントをサポートします。</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">認証とアクセス。実店舗の買い物客を検証済みのアカウントに接続し、小売スペースへのアクセスを許可します。</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">在庫監視。センサー、RFID タグ、コンピューター ビジョン システムを使用して、買い物客によるアイテムの選択または選択解除を確認します。</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">ここでは、各エッジ サーバーが各チェックアウト カウンターを処理し、共有ストレージ システムが中央の同期ポイントとして機能します。</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">金融サービス：キオスクにおける人間の安全と詐欺防止</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">銀行組織は AI とエッジ コンピューティングを使用して革新を起こし、パーソナライズされた銀行エクスペリエンスを生み出しています。リアルタイムのデータ分析と AI 推論を使用するインタラクティブ キオスクにより、ATM は顧客の現金引き出しをサポートするだけでなく、カメラで撮影した画像を通じてキオスクを積極的に監視し、人間の安全に対するリスクや不正行為を特定できるようになりました。このシナリオでは、エッジ コンピューティング サーバーと共有ストレージ システムがインタラクティブ キオスクやカメラに接続され、銀行が AI 推論モデルを使用してデータを収集および処理できるようになります。</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">製造業：インダストリー4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">スマートファクトリーや 3D プリンティングなどの新たなトレンドとともに、第 4 次産業革命 (インダストリー 4.0) が始まりました。データ主導の未来に備えるために、大規模なマシンツーマシン (M2M) 通信と IoT を統合し、人間の介入を必要とせずに自動化を強化します。製造業はすでに高度に自動化されており、AI 機能の追加は長期的なトレンドの自然な流れです。 AI により、コンピューター ビジョンやその他の AI 機能を利用して自動化できる操作を自動化できます。品質管理や、人間の視覚や意思決定に依存するタスクを自動化して、工場現場の組立ラインで材料の分析を高速化し、製造工場が必要な ISO 規格と品質管理基準を満たすのに役立ちます。ここで、各コンピューティング エッジ サーバーは、製造プロセスを監視するセンサーの配列に接続され、更新された推論モデルが必要に応じて共有ストレージにプッシュされます。</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">通信：錆検出、鉄塔検査、ネットワーク最適化</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">通信業界では、コンピューター ビジョンと AI 技術を使用して画像を処理することで、錆を自動的に検出し、腐食が発生しているためさらに検査が必要な携帯電話基地局を特定します。近年、ドローン画像と AI モデルを使用して塔の特定の領域を特定し、錆、表面のひび割れ、腐食を分析するケースが増加しています。通信インフラや携帯電話基地局を効率的に点検し、定期的に劣化状況を評価して、必要に応じて速やかに修理することを可能にする AI 技術の需要は高まり続けています。</block>
  <block id="d88e40cd850f8bd6b5e737761a1786fd" category="paragraph">さらに、通信分野で新たに出現しているユースケースとして、AI および ML アルゴリズムを使用してデータ トラフィック パターンを予測し、5G 対応デバイスを検出し、MIMO (複数入力複数出力) エネルギー管理を自動化および拡張するというものがあります。 MIMO ハードウェアは、ネットワーク容量を増やすために無線塔で使用されますが、これには追加のエネルギー コストがかかります。セル サイトに展開された「MIMO スリープ モード」の ML モデルは、無線の効率的な使用を予測し、モバイル ネットワーク オペレーター (MNO) のエネルギー消費コストの削減に役立ちます。  AI 推論およびエッジ コンピューティング ソリューションは、MNO がデータセンターとの間で送受信されるデータの量を削減し、TCO を下げ、ネットワーク運用を最適化し、エンドユーザーの全体的なパフォーマンスを向上させるのに役立ちます。</block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">このドキュメントは、MLPerf Inference v0.7 コード、MLPerf Inference v1.1 コードとルールに従います。このセクションに示す表で定義されているように、エッジでの推論用に設計されたベンチマークを実行しました。</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">テスト計画</block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">コード</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">ルール</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">このドキュメントはMLPerf Inference v0.7に準拠しています。<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> 、MLPerf 推論 v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> 、 そして<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>。次の表で定義されているように、エッジでの推論用に設計された MLPerf ベンチマークを実行しました。</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">領域</block>
  <block id="a559b87068921eec05086ce5485e9784" category="cell">モデル</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">データセット</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSLサイズ</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">品質</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">マルチストリームのレイテンシ制約</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">ビジョン</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">画像分類</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">イメージネット（224x224）</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32の99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">物体検出（大）</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">COCO（1200x1200）</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">物体検出（小）</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD-MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">COCO（300x300）</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">医療画像のセグメンテーション</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">ブラTS 2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32の99%と99.9%</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">スピーチ</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">音声テキスト変換</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">Librispeech 開発クリーン</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">言語</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">言語処理</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">SQuAD v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">次の表は、Edge ベンチマークのシナリオを示しています。</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">シナリオ</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">画像分類</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">シングルストリーム、オフライン、マルチストリーム</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">単一ストリーム、オフライン</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="cell">音声テキスト変換</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">私たちは、この検証で開発されたネットワーク ストレージ アーキテクチャを使用してこれらのベンチマークを実行し、結果を、以前 MLPerf に送信されたエッジ サーバーでのローカル実行の結果と比較しました。この比較は、共有ストレージが推論パフォーマンスにどの程度の影響を与えるかを判断するためのものです。</block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">このセクションでは、このソリューションを検証するために使用されるテスト手順について説明します。</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">テスト手順</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">オペレーティングシステムとAI推論のセットアップ</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190では、 NVIDIAドライバーとNVIDIA GPUをサポートするDockerを搭載したUbuntu 18.04を使用し、MLPerfを使用しました。<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> MLPerf Inference v0.7 への Lenovo 提出の一部として利用可能です。</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280では、 NVIDIAドライバーとNVIDIA GPUとMLPerfをサポートするDockerを搭載したUbuntu 20.04を使用しました。<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> MLPerf Inference v1.1 への Lenovo の提出物の一部として利用可能です。</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 推論を設定するには、次の手順に従います。</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">登録が必要なデータセット、ImageNet 2012 検証セット、Criteo Terabyte データセット、BraTS 2019 トレーニング セットをダウンロードし、ファイルを解凍します。</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">少なくとも1TBの作業ディレクトリを作成し、環境変数を定義します。<block ref="597c05a331d3bca9b42845049a851c94" prefix=" " category="inline-code"></block>ディレクトリを参照します。</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">ネットワーク ストレージを使用する場合は共有ストレージでこのディレクトリを共有し、ローカル データでテストする場合はローカル ディスクでこのディレクトリを共有する必要があります。</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">makeを実行する<block ref="ba8a3d8e03d727387e03ca6ef842d4c5" prefix=" " category="inline-code"></block>このコマンドは、必要な推論タスク用の Docker コンテナを構築して起動します。</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">以下のコマンドはすべて、実行中の Docker コンテナ内から実行されます。</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf 推論タスク用の事前トレーニング済み AI モデルをダウンロードします。<block ref="b59a4beb5c95f2e0e1fed56d89e16cf0" prefix=" " category="inline-code"></block></block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">無料でダウンロードできる追加のデータセットをダウンロードしてください。<block ref="fd0245b042cdcee1ab8bd760c8b4bfbc" prefix=" " category="inline-code"></block></block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">データを前処理する:<block ref="03275934d57d2ecfe9e68f7023f456ce" prefix=" " category="inline-code"></block></block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">走る：<block ref="be647e69451a82a2f326980291e0f781" prefix=" " category="inline-code"></block> 。</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">コンピューティング サーバーの GPU 向けに最適化された推論エンジンを構築します。<block ref="37496efe33254cb883b0705fde55fcc1" prefix=" " category="inline-code"></block></block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">推論ワークロードを実行するには、次のコマンドを実行します (1 つのコマンド)。</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI推論実行</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">3 種類の実行が実行されました。</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">ローカルストレージを使用した単一サーバーAI推論</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">ネットワークストレージを使用した単一サーバーAI推論</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">ネットワークストレージを使用したマルチサーバーAI推論</block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">提案されたアーキテクチャのパフォーマンスを評価するために、多数のテストが実行されました。  6 つの異なるワークロード (画像分類、オブジェクト検出 [小]、オブジェクト検出 [大]、医療用画像処理、音声テキスト変換、自然言語処理 [NLP]) があり、オフライン、単一ストリーム、マルチストリームの 3 つの異なるシナリオで実行できます。</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">テスト結果</block>
  <block id="a274daca2deace9b89099b24f248715c" category="paragraph">提案されたアーキテクチャのパフォーマンスを評価するために、多数のテストが実行されました。</block>
  <block id="37bf74d7f686cd395d40af1cc2ed7c55" category="paragraph">6 つの異なるワークロード (画像分類、オブジェクト検出 [小]、オブジェクト検出 [大]、医療用画像処理、音声テキスト変換、自然言語処理 [NLP]) があり、オフライン、単一ストリーム、マルチストリームの 3 つの異なるシナリオで実行できます。</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">最後のシナリオは、画像分類とオブジェクト検出のみに実装されています。</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">これにより、15 のワークロードが考えられます。これらはすべて、3 つの異なる設定でテストされました。</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">単一サーバー/ローカルストレージ</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">単一サーバー/ネットワークストレージ</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">マルチサーバー/ネットワークストレージ</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">結果については次のセクションで説明します。</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFFのオフラインシナリオにおけるAI推論</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">このシナリオでは、すべてのデータがサーバーで利用可能であり、すべてのサンプルを処理するのにかかる時間が測定されました。テストの結果として、帯域幅を 1 秒あたりのサンプル数で報告します。複数のコンピューティング サーバーが使用された場合、すべてのサーバーの合計帯域幅が報告されます。  3 つのユースケースすべての結果を下の図に示します。  2 台のサーバーの場合、両方のサーバーの合計帯域幅を報告します。</block>
  <block id="50c1d1baa999e0997ecc5b2fb7ce848c" category="paragraph"><block ref="50c1d1baa999e0997ecc5b2fb7ce848c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">結果は、ネットワーク ストレージがパフォーマンスに悪影響を与えないことを示しています。変化は最小限であり、一部のタスクではまったく影響が見られません。  2 台目のサーバーを追加すると、合計帯域幅はちょうど 2 倍になるか、最悪の場合でも変化は 1% 未満になります。</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFFの単一ストリーム シナリオにおける AI 推論</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">このベンチマークはレイテンシを測定します。複数の計算サーバーの場合、平均レイテンシを報告します。一連のタスクの結果は以下の図に示されています。  2 台のサーバーの場合、両方のサーバーからの平均待ち時間を報告します。</block>
  <block id="e3a127ece515b351ac983cdc09f48eb3" category="paragraph"><block ref="e3a127ece515b351ac983cdc09f48eb3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">結果は、ネットワーク ストレージがタスクを処理するのに十分であることを示しています。 1 台のサーバーの場合、ローカル ストレージとネットワーク ストレージの違いは最小限か、まったくありません。同様に、2 台のサーバーが同じストレージを使用する場合、両方のサーバーのレイテンシは同じままか、わずかに変化します。</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFFのマルチストリーム シナリオにおける AI 推論</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">この場合、結果は、QoS 制約を満たしながらシステムが処理できるストリームの数になります。したがって、結果は常に整数になります。複数のサーバーがある場合、すべてのサーバー上のストリームの合計数を報告します。すべてのワークロードがこのシナリオをサポートしているわけではありませんが、サポートしているワークロードは実行済みです。テストの結果は下の図にまとめられています。  2 台のサーバーの場合、両方のサーバーからのストリームの合計数を報告します。</block>
  <block id="79bd7075b14462178ff1e836cefd5d04" category="paragraph"><block ref="79bd7075b14462178ff1e836cefd5d04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">結果はセットアップの完璧なパフォーマンスを示しています。ローカル ストレージとネットワーク ストレージは同じ結果をもたらし、2 番目のサーバーを追加すると、提案されたセットアップで処理できるストリームの数が 2 倍になります。</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EFのテスト結果</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">提案されたアーキテクチャのパフォーマンスを評価するために、多数のテストが実行されました。 6 つの異なるワークロード (画像分類、オブジェクト検出 [小]、オブジェクト検出 [大]、医療用画像処理、音声テキスト変換、自然言語処理 [NLP]) があり、オフラインと単一ストリームの 2 つの異なるシナリオで実行されました。結果については次のセクションで説明します。</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EFのオフラインシナリオにおけるAI推論</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">このシナリオでは、すべてのデータがサーバーで利用可能であり、すべてのサンプルを処理するのにかかる時間が測定されました。テストの結果として、帯域幅を 1 秒あたりのサンプル数で報告します。単一ノード実行の場合は両方のサーバーからの平均を報告しますが、2 サーバー実行の場合はすべてのサーバーの合計帯域幅を報告します。ユースケースの結果は以下の図に示されています。</block>
  <block id="063dd3a1aadafc5ef1c52be7451bda1d" category="paragraph"><block ref="063dd3a1aadafc5ef1c52be7451bda1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF の単一ストリーム シナリオにおける AI 推論</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">このベンチマークはレイテンシを測定します。すべてのケースにおいて、実行に関係するすべてのサーバーの平均レイテンシを報告します。一連のタスクの結果が示されます。</block>
  <block id="bcd5a75126c6cafd37838b2f3c6e138b" category="paragraph"><block ref="bcd5a75126c6cafd37838b2f3c6e138b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">結果は、ネットワーク ストレージがタスクを処理するのに十分であることを再度示しています。 1 台のサーバーの場合、ローカル ストレージとネットワーク ストレージの違いは最小限か、まったくありません。同様に、2 台のサーバーが同じストレージを使用する場合、両方のサーバーのレイテンシは同じままか、わずかに変化します。</block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">検証に使用する設定を他のユースケースに合わせて調整できます。</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">アーキテクチャのサイズ設定オプション</block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">コンピューティングサーバー</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">SE350 でサポートされている CPU の中で最も低レベルである、物理コア 4 個、TDP 60W の Intel Xeon D-2123IT CPU を使用しました。サーバーは CPU の交換をサポートしていませんが、より強力な CPU を注文することは可能です。サポートされる最上位の CPU は、16 コア、2.20GHz で動作する 100W の Intel Xeon D-2183IT です。これにより、CPU の計算能力が大幅に向上します。 CPU は推論ワークロード自体の実行のボトルネックではありませんでしたが、データ処理や推論に関連するその他のタスクに役立ちます。現時点では、エッジユースケースに使用できる GPU はNVIDIA T4 のみであるため、現時点では GPU をアップグレードまたはダウングレードする機能はありません。</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">共有ストレージ</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">このドキュメントでは、テストと検証のために、最大 50.5 TB のストレージ容量、シーケンシャル読み取りのスループット 4.4 GBps、小規模ランダム読み取りのスループット 230K IOPS を備えたNetApp AFF C190システムが使用され、エッジ推論ワークロードに適していることが実証されています。</block>
  <block id="44114b1635cead15f56735bad0467251" category="inline-link">NetApp EF300</block>
  <block id="043774815e3806ded716086e0c8c3d03" category="paragraph">ただし、より多くのストレージ容量やより高速なネットワーク速度が必要な場合は、 NetApp AFF A220またはNetApp AFF A250ストレージ システムを使用する必要があります。さらに、このソリューションの検証には、最大容量 1.5PB、帯域幅 10GBps のNetApp EF280 システムも使用されました。より高い帯域幅でより多くのストレージ容量をご希望の場合は、<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block>使用できます。</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">このセクションでは、この AI ソリューションの技術的基盤について説明します。</block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFFシステム</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">最先端のNetApp AFFストレージ システムは、業界をリードするパフォーマンス、優れた柔軟性、クラウド統合、クラス最高のデータ管理により、エッジでの AI 推論の導入を可能にし、エンタープライズ ストレージの要件を満たします。フラッシュ専用に設計されたNetApp AFFシステムは、ビジネスクリティカルなデータの高速化、管理、保護に役立ちます。</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">エントリーレベルのNetApp AFFストレージシステムは、 FAS2750ハードウェアとSSDフラッシュメディアをベースにしています。</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA構成の2つのコントローラ</block>
  <block id="b2ed189fbf328f509ec4ca77960d3e1a" category="paragraph"><block ref="b2ed189fbf328f509ec4ca77960d3e1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetAppエントリー レベルのAFF C190ストレージ システムは、次の機能をサポートしています。</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">最大ドライブ数は24x960GB SSD</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">可能な構成は 2 つあります。</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">イーサネット（10GbE）：4x 10GBASE-T（RJ-45）ポート</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">統合（16Gb FC または 10GbE）：統合ターゲット アダプタ 2（UTA2）ポート x 4</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">最大50.5TBの実効容量</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS ワークロードの場合、単一のエントリー レベルのAFF C190システムは、1 ミリ秒以下のレイテンシで、シーケンシャル読み取りで 4.4 GBps、小規模なランダム読み取りで 230K IOPS のスループットをサポートします。</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">NetApp は、大規模な導入向けに高いパフォーマンスと拡張性を提供する他のエントリー レベルのストレージ システムも提供しています。  NAS ワークロードの場合、単一のエントリーレベルのAFF A220システムが以下をサポートします。</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">シーケンシャルリードのスループットは6.2GBps</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">1 ミリ秒以下のレイテンシで小規模なランダム読み取りを実行する場合、375K IOPS</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">最大ドライブ数は 144 台、960 GB、3.8 TB、または 7.6 TB SSD</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220は1PBを超える実効容量まで拡張可能</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">最大有効容量は35PB、最大スケールアウトは2～24ノード（12HAペア）</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220と比較して45%以上のパフォーマンス向上を実現</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS ランダム読み取り @1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">最新のNetApp ONTAPリリースに基づいて構築: ONTAP 9.8</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HAとクラスタ相互接続に2つの25Gbイーサネットを活用</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp EシリーズEFシステム</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF シリーズは、エントリー レベルおよびミッドレンジのオールフラッシュ SAN ストレージ アレイ ファミリであり、 NetApp SANtricityソフトウェアを使用してデータへのアクセスを高速化し、データからより早く価値を引き出すことができます。これらのシステムは、SAS と NVMe の両方のフラッシュ ストレージを提供し、手頃な価格から極めて高い IOPS、100 マイクロ秒未満の応答時間、最大 44 GBps の帯域幅を提供するため、AI 推論や高性能コンピューティング (HPC) などの混合ワークロードや要求の厳しいアプリケーションに最適です。</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">次の図は、 NetApp EF280 ストレージ システムを示しています。</block>
  <block id="94bb9af4c6eb62dbf44f691e2565e77e" category="paragraph"><block ref="94bb9af4c6eb62dbf44f691e2565e77e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC、25Gb/10Gb iSCSI、および12Gb SASのサポート</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">最大有効容量は96ドライブで合計1.5PB</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10GBpsのスループット（シーケンシャルリード）</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPS（ランダム読み取り）</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280は、 NetAppポートフォリオの中で最も低コストのオールフラッシュアレイ（AFA）です。</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24台のNVMe SSDドライブで合計367TBの容量</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">拡張オプションは合計240台のNL-SAS HDD、96台のSAS SSD、またはその組み合わせ</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB、NVMe/RoCE、iSER/IB、および SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVME/FC、FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25Gb iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps（シーケンシャルリード）</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS（ランダム読み取り）</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EFシリーズNetApp EFシリーズ オールフラッシュアレイ EF600、F300、EF570、EF280 データシート</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">詳細については、<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block> 。</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">NetAppの最新世代のストレージ管理ソフトウェアであるONTAP 9.8.1 により、企業はインフラストラクチャを最新化し、クラウド対応のデータセンターに移行できるようになります。 ONTAP は業界をリードするデータ管理機能を活用し、データの保存場所に関係なく、単一のツール セットでデータの管理と保護を可能にします。また、エッジ、コア、クラウドなど、必要な場所にデータを自由に移動することもできます。  ONTAP 9.8.1 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッド クラウド アーキテクチャ全体で次世代のインフラストラクチャ機能を有効にする多数の機能が含まれています。</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">データ管理は、アプリケーションとデータセットに適切なリソースが使用されるようにするための、企業の IT 運用にとって非常に重要です。  ONTAP には、運用を合理化および簡素化し、総運用コストを削減するための次の機能が含まれています。</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">*インライン データ圧縮と拡張重複排除。*データ圧縮によりストレージ ブロック内の無駄なスペースが削減され、重複排除により実効容量が大幅に増加します。これは、ローカルに保存されたデータとクラウドに階層化されたデータに適用されます。</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">*最小、最大、および適応型サービス品質 (AQoS)。*きめ細かなサービス品質 (QoS) 制御により、高度に共有された環境における重要なアプリケーションのパフォーマンス レベルを維持できます。</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetAppFabricPool。*この機能により、Amazon Web Services (AWS)、Azure、 NetApp StorageGRIDストレージ ソリューションなどのパブリックおよびプライベート クラウド ストレージ オプションへのコールド データの自動階層化が可能になります。  FabricPoolの詳細については、以下を参照してください。<block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block> 。</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9 は優れたレベルのパフォーマンスとデータ保護を提供し、これらの機能を次のように拡張します。</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">*パフォーマンスと低レイテンシー。*  ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">*データ保護*  ONTAP は、すべてのプラットフォームにわたる共通管理を備えた組み込みのデータ保護機能を提供します。</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NetAppボリューム暗号化 (NVE)。*  ONTAP は、オンボードと外部キー管理の両方をサポートするネイティブのボリューム レベルの暗号化を提供します。</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">*マルチテナントと多要素認証。*  ONTAP は、最高レベルのセキュリティでインフラストラクチャ リソースを共有できるようにします。</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9 は、次の機能により、要求が厳しく常に変化するビジネス ニーズへの対応に役立ちます。</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">*シームレスなスケーリングと中断のない運用。* ONTAP は、既存のコントローラおよびスケールアウト クラスタへの無停止の容量追加をサポートします。お客様は、コストのかかるデータ移行や停止なしで、NVMe や 32Gb FC などの最新テクノロジーにアップグレードできます。</block>
  <block id="7d97721ced74a2279b6645f506722980" category="list-text">*クラウド接続。*  ONTAP は、すべてのパブリック クラウドでソフトウェア定義ストレージ (ONTAP Select) とクラウド ネイティブ インスタンス (Google Cloud NetApp Volumes) のオプションを備えた、最もクラウドに接続されたストレージ管理ソフトウェアです。</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">*新興アプリケーションとの統合。*  ONTAP は、既存のエンタープライズ アプリケーションをサポートするのと同じインフラストラクチャを使用して、自律走行車、スマート シティ、インダストリー 4.0 などの次世代プラットフォームとアプリケーション向けにエンタープライズ グレードのデータ サービスを提供します。</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp EシリーズSANtricityソフトウェア データシート</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricityは、E シリーズ ハイブリッド フラッシュ アレイと EF シリーズ オールフラッシュ アレイに業界をリードするパフォーマンス、信頼性、シンプルさを提供するように設計されています。データ分析、ビデオ監視、バックアップとリカバリなどの高負荷アプリケーション向けに、E シリーズ ハイブリッド フラッシュ アレイと EF シリーズ オールフラッシュ アレイのパフォーマンスと使用率を最大限に高めます。  SANtricityを使用すると、ストレージがオンラインのまま、構成の調整、メンテナンス、容量の拡張などのタスクを完了できます。 SANtricity は、優れたデータ保護、プロアクティブな監視、認定されたセキュリティも提供しており、すべて使いやすいオンボックスの System Manager インターフェイスからアクセスできます。詳細については、<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block> 。</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">パフォーマンス最適化</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">パフォーマンスが最適化されたSANtricityソフトウェアは、高い IOPS、高いスループット、低いレイテンシで、すべてのデータ分析、ビデオ監視、バックアップ アプリにデータを配信します。高 IOPS、低レイテンシのアプリケーションと高帯域幅、高スループットのアプリケーションのパフォーマンスを高速化します。</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">稼働時間を最大化</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">ストレージがオンラインのまま、すべての管理タスクを完了します。 I/O を中断することなく、構成を微調整したり、メンテナンスを実行したり、容量を拡張したりできます。自動化機能、オンライン構成、最先端のダイナミック ディスク プール (DPP) テクノロジーなどにより、クラス最高の信頼性を実現します。</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">安心してください</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricityソフトウェアは、使いやすいオンボックスの System Manager インターフェイスを通じて、優れたデータ保護、プロアクティブな監視、認定されたセキュリティを実現します。ストレージ管理の作業を簡素化します。すべての E シリーズ ストレージ システムの高度なチューニングに必要な柔軟性が得られます。 NetApp E シリーズ システムをいつでもどこでも管理できます。当社のオンボックスの Web ベースのインターフェースにより、管理ワークフローが効率化されます。</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="inline-link">Trident</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block>NetAppの は、永続ストレージの作成、管理、および使用を簡素化する、Docker および Kubernetes 向けのオープンソースの動的ストレージ オーケストレーターです。  Kubernetes ネイティブ アプリケーションであるTrident は、Kubernetes クラスター内で直接実行されます。  Trident を使用すると、顧客は DL コンテナ イメージをNetAppストレージにシームレスに導入でき、AI コンテナの導入にエンタープライズ グレードのエクスペリエンスを提供できます。  Kubernetes ユーザー (ML 開発者やデータ サイエンティストなど) は、オーケストレーションとクローンを作成、管理、自動化して、 NetAppテクノロジーを活用したNetApp の高度なデータ管理機能を活用できます。</block>
  <block id="9b6334cb865bfb3ae702677852339a38" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>高速かつ安全なデータ同期を実現するNetAppサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google Cloud Storage、または IBM Cloud Object Storage の間でファイルを転送する必要がある場合でも、 BlueXP Copy and Sync を使用すると、必要な場所にファイルを迅速かつ安全に移動します。データが転送されると、ソースとターゲットの両方で完全に使用できるようになります。  BlueXP Copy and Sync は、事前に定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データ複製にかかる時間とコストが最小限に抑えられます。  BlueXP Copy and Sync は、セットアップと使用が非常に簡単な SaaS (Software as a Service) ツールです。  BlueXP Copy and Sync によってトリガーされるデータ転送は、データ ブローカーによって実行されます。  BlueXPコピーおよび同期データブローカーは、AWS、Azure、Google Cloud Platform、またはオンプレミスにデプロイできます。</block>
  <block id="8eb0c6a27656d04de6abfc6d24a1a8d5" category="paragraph">Lenovo ThinkSystem サーバーは、今日の顧客の課題を解決し、将来の課題にも対応できる進化型で目的に合ったモジュール型設計アプローチを提供する革新的なハードウェア、ソフトウェア、サービスを備えています。これらのサーバーは、クラス最高の業界標準テクノロジーと Lenovo の差別化されたイノベーションを組み合わせることで、x86 サーバーに最大限の柔軟性を提供します。</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem サーバーを導入する主な利点は次のとおりです。</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">ビジネスの成長に合わせて拡張可能なモジュール設計</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">業界をリードする回復力により、コストのかかる予定外のダウンタイムを何時間も節約</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">低レイテンシ、高速応答、リアルタイムのスマートなデータ管理を実現する高速フラッシュテクノロジー</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">AI 分野では、Lenovo は企業が ML と AI の利点を理解し、ワークロードに導入できるよう支援する実践的なアプローチを採用しています。 Lenovo のお客様は、Lenovo AI イノベーション センターで Lenovo AI 製品を探索および評価し、特定のユース ケースの価値を十分に理解することができます。価値実現までの時間を短縮するために、この顧客中心のアプローチでは、すぐに使用でき、AI 向けに最適化されたソリューション開発プラットフォームの概念実証を顧客に提供します。</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">エッジ コンピューティングにより、IoT デバイスからのデータをデータ センターやクラウドに送信する前に、ネットワークのエッジで分析できるようになります。下の図に示すように、Lenovo ThinkSystem SE350 は、コンパクトで耐久性があり、環境耐性に優れたフォーム ファクターで、柔軟性、接続性、セキュリティ、リモート管理性を重視し、エッジでの展開に固有の要件を満たすように設計されています。</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">SE350 は、エッジ AI ワークロードの加速をサポートする柔軟性を備えた Intel Xeon D プロセッサーを搭載し、データセンター外のさまざまな環境でのサーバー導入の課題に対処するために特別に設計されています。</block>
  <block id="c45cd4236e9fecc47291c206c4aac70a" category="paragraph"><block ref="c45cd4236e9fecc47291c206c4aac70a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16bb0d66e42a8bb99cbefc63c53bcfdc" category="paragraph"><block ref="16bb0d66e42a8bb99cbefc63c53bcfdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf 推論 v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf は、AI パフォーマンスを評価するための業界をリードするベンチマーク スイートです。画像分類、物体検出、医用画像処理、自然言語処理 (NLP) など、応用 AI の多くの分野をカバーしています。この検証では、この検証の完了時点での MLPerf 推論の最新バージョンである Inference v0.7 ワークロードを使用しました。その<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block>このスイートには、データ センターとエッジ システム向けの 4 つの新しいベンチマークが含まれています。</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">*バート。*  SQuAD データセットを使用して質問回答用に微調整された Bi-Directional Encoder Representation from Transformers (BERT)。</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">*DLRM。*ディープラーニング推奨モデル (DLRM) は、クリックスルー率 (CTR) を最適化するようにトレーニングされたパーソナライズおよび推奨モデルです。</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">*3D U-ネット*  3D U-Net アーキテクチャは、脳腫瘍セグメンテーション (BraTS) データセットでトレーニングされています。</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">*RNN-T* リカレント ニューラル ネットワーク トランスデューサー (RNN-T) は、LibriSpeech のサブセットでトレーニングされた自動音声認識 (ASR) モデルです。  MLPerf 推論の結果とコードは公開されており、Apache ライセンスの下でリリースされています。  MLPerf Inference には、次のシナリオをサポートするエッジ部門があります。</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">*シングルストリーム。*このシナリオは、スマートフォンで実行されるオフライン AI クエリなど、応答性が重要な要素となるシステムを模倣しています。個々のクエリがシステムに送信され、応答時間が記録されます。すべての応答の 90 パーセンタイルのレイテンシが結果として報告されます。</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">*マルチストリーム*このベンチマークは、複数のセンサーからの入力を処理するシステム用です。テスト中、クエリは一定の時間間隔で送信されます。 QoS 制約 (最大許容遅延) が課せられます。テストでは、QoS 制約を満たしながらシステムが処理できるストリームの数を報告します。</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">*オフライン。*これはバッチ処理アプリケーションをカバーする最も単純なシナリオであり、メトリックは 1 秒あたりのサンプル単位のスループットです。すべてのデータはシステムで利用可能であり、ベンチマークではすべてのサンプルを処理するのにかかる時間を測定します。</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="13176cbb826705821e77b735791d29d4" category="paragraph">Lenovo は、このドキュメントで使用されているサーバーである T4 を搭載した SE350 の MLPerf 推論スコアを公開しました。結果はこちら<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block>エントリ #0.7-145 の「エッジ、閉じた分割」セクション。</block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">検証に使用される設定は、他のユースケースに合わせて調整できます。</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">アーキテクチャの調整</block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">この検証に使用される設定は、他のユースケースに合わせて調整できます。</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU調整</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">この検証には、Lenovo の推奨に従い、Skylake Intel Xeon Platinum 8360Y プロセッサを使用しました。このワークロードは CPU に依存しないため、同等の Cascade Lake CPU である Intel Xeon Gold 6330 プロセッサで同様のパフォーマンスが得られると予想されます。</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">ストレージ容量の増加</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">追加のディスク シェルフとコントローラー モデルがある場合は、ストレージ容量のニーズに基づいて、共有ストレージ (NFS ボリューム) をオンデマンドで増やすことができます。これは、CLI から、またはストレージ コントローラのNetApp Web インターフェイスから管理者ユーザーとして実行できます。</block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">このNetAppと Lenovo のソリューションは、中規模エンタープライズ AI への参入に最適な柔軟なスケールアウト アーキテクチャです。  NetAppストレージは、ローカル SSD ストレージと同等以上のパフォーマンスを提供し、データ サイエンティスト、データ エンジニア、IT 意思決定者に次の利点をもたらします。</block>
  <block id="994c1f46e0860094a86d2a822416646b" category="paragraph">ここで検証されたNetAppと Lenovo のソリューションは、中規模エンタープライズ AI への参入に最適な柔軟なスケールアウト アーキテクチャです。</block>
  <block id="bcbfcce438abee9a9a41cb7e588eb4de" category="paragraph">NetAppストレージは、ローカル SSD ストレージと同等以上のパフォーマンスを提供し、データ サイエンティスト、データ エンジニア、IT 意思決定者に次のようなメリットをもたらします。</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">コストを最小限に抑え、リソースの使用率を向上させるために、コンピューティングとストレージを独立して拡張できます。</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">統合されたスナップショットとクローンを使用して合理化された開発および展開ワークフローにより、瞬時にスペース効率の高いユーザー ワークスペース、統合バージョン管理、および自動展開が実現します。</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">災害復旧とビジネス継続性のためのエンタープライズ グレードのデータ保護。</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">Karthikeyan Nagalingam 氏、 NetAppテクニカル マーケティング エンジニア</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton、Lenovo AI Lab Systems 管理者</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetAppオールフラッシュアレイ製品ページ</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400ページ</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAPデータ管理ソフトウェア製品ページ</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI (nvidia-smi)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">このセクションでは、テストされた構成、ネットワーク インフラストラクチャ、SR670 V2 サーバー、およびストレージ プロビジョニングの詳細について説明します。</block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">このセクションでは、テストされた構成、ネットワーク インフラストラクチャ、SR670 V2 サーバー、およびNetAppストレージ プロビジョニングの詳細について説明します。</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">この検証には、次の表に示すソリューション コンポーネントを使用しました。</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">2台のSR670 V2サーバー（各サーバーにNVIDIA A100 80GB GPUカード8枚搭載）</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">各サーバーには、2つのIntel Xeon Platinum 8360Y CPU（28個の物理コア）と1TBのRAMが搭載されています。</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux（Ubuntu – 20.04、CUDA 11.8）</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFFストレージシステム（HAペア）</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1 ソフトウェア</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">コントローラごとに 1 つのインターフェース グループ (ifgrp)、マウント ポイント用の 4 つの論理 IP アドレス</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">この検証では、MLPerf v2.0 で指定された ImageNet 基底セットを備えた ResNet v2.0 を使用しました。データセットは、NFS プロトコルを使用してNetApp AFFストレージ システムに保存されます。  SR670 は、100GbE スイッチを介してNetApp AFF A400ストレージ システムに接続されていました。</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet は頻繁に使用される画像データセットです。約 130 万枚の画像が含まれており、合計サイズは 144 GB になります。平均画像サイズは108KBです。</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">次の図は、テストされた構成のネットワーク トポロジを示しています。</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">この図は、コンピューティング層 (Lenovo ThinkSystem SR670 V2)、ネットワーク層 (Lenovo Ethernet スイッチ)、およびストレージ層 ( NetApp AFF A400ストレージ コントローラ) を示しています。すべてのネットワーク接続が含まれています。</block>
  <block id="74ae44f09af988f16e87e4e2e31ef81a" category="paragraph"><block ref="74ae44f09af988f16e87e4e2e31ef81a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">次の表にストレージ構成を示します。</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">総量</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">ボリューム サイズ</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">オペレーティング システムのマウント ポイント</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9 TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19 TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g フォルダーには、ResNet 検証に使用されるデータセットが含まれています。</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">このセクションでは、詳細なテスト手順の結果について説明します。</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">テスト手順と詳細な結果</block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">ONTAPの ResNet を使用した画像認識トレーニング</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">ResNet50 ベンチマークを 1 台と 2 台の SR670 V2 サーバーで実行しました。このテストでは、MXNet 22.04-py3 NGC コンテナを使用してトレーニングを実行しました。</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">この検証では次のテスト手順を使用しました。</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">データがすでにキャッシュされていないことを確認するために、スクリプトを実行する前にホスト キャッシュをクリアしました。</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">ベンチマーク スクリプトは、サーバー ストレージ (ローカル SSD ストレージ) とNetApp AFFストレージ システム上の ImageNet データセットを使用して実行しました。</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">ネットワークとローカルストレージのパフォーマンスを検証するために、<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block>指示。</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">単一ノード実行では、次のコマンドを使用しました。</block>
  <block id="cf9a86ba8909a23b4d67d509b389a080" category="list-text">分散実行では、パラメータ サーバーの並列化モデルを使用しました。ノードごとに 2 つのパラメータ サーバーを使用し、エポック数を単一ノード実行と同じに設定しました。これを行った理由は、プロセス間の同期が不完全なために、分散トレーニングではより多くのエポックが必要になることが多いためです。エポック数が異なると、単一ノードの場合と分散の場合の比較が歪む可能性があります。</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">データ読み取り速度: ローカルストレージとネットワークストレージ</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">読み取り速度は、<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> ImageNet データセットのファイルの 1 つに対してコマンドを実行します。具体的には、ローカル データとネットワーク データの両方に対して次のコマンドを実行しました。</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">両方の値は似ており、ネットワーク ストレージがローカル ストレージと同様の速度でデータを配信できることを示しています。</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">共有ユースケース: 複数の独立した同時ジョブ</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">このテストでは、このソリューションの予想されるユースケースである、マルチジョブ、マルチユーザーの AI トレーニングをシミュレートしました。各ノードは共有ネットワーク ストレージを使用しながら独自のトレーニングを実行しました。結果は次の図に表示されており、ソリューション ケースではすべてのジョブが個々のジョブと基本的に同じ速度で実行され、優れたパフォーマンスが実現されたことがわかります。合計スループットはノード数に応じて直線的に増加しました。</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">この数字は 1 秒あたりの合計画像数を示しています。</block>
  <block id="568b99e77256e0aa65f03e3612709ffc" category="paragraph"><block ref="568b99e77256e0aa65f03e3612709ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">この図は実行時間を分単位で表示します。</block>
  <block id="c8a726b6eb44bab6b01c319420a7605a" category="paragraph"><block ref="c8a726b6eb44bab6b01c319420a7605a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">これらのグラフは、同時トレーニング モデルと単一トレーニング モデルの両方を組み合わせた、100 GbE クライアント ネットワーク上の各サーバーから 8 個の GPU を使用したコンピューティング ノードの実行時間 (分単位) と 1 秒あたりの合計イメージ数を示しています。トレーニング モデルの平均実行時間は 35 分 9 秒でした。それぞれの実行時間は、34 分 32 秒、36 分 21 秒、34 分 37 秒、35 分 25 秒、34 分 31 秒でした。トレーニング モデルの 1 秒あたりの平均画像は 22,573 枚で、1 秒あたりの個々の画像は 21,764、23,438、22,556、22,564、および 22,547 枚でした。</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">当社の検証によると、 NetAppデータ ランタイムを使用した 1 つの独立したトレーニング モデルは、22,231 画像/秒で 34 分 54 秒でした。ローカル データ (DAS) を使用した 1 つの独立したトレーニング モデルの実行時間は 34 分 21 秒で、画像数 22,102 枚/秒でした。これらの実行中、nvidia-smi で観測された平均 GPU 使用率は 96% でした。この平均には、GPU が使用されず、mpstat で測定された CPU 使用率が 40% であったテスト フェーズも含まれていることに注意してください。これは、各ケースでデータ配信速度が十分であることを示しています。</block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">このソリューションは、人工知能ワークロード向けに最適化されたNetAppストレージと Lenovo サーバーを使用した、エントリーレベルとミッドレンジの両方のクラスター アーキテクチャに重点を置いています。これは、ほとんどのコンピューティング ジョブが単一ノード (単一または複数の GPU) であるか、少数のコンピューティング ノードに分散されている小規模および中規模のチームを対象としています。ほとんどの日常的な AI トレーニング ジョブは単一ノードであるため、これは大きな制限ではありません。</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: AIおよびMLモデルトレーニング向けNetApp AFF A400とLenovo ThinkSystem SR670 V2</block>
  <block id="db297dc3a6b72858a5039fa6507a2b34" category="paragraph">Sathish Thyagarajan、David Arnette、 NetApp Mircea Troaca、Lenovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">このソリューションは、人工知能 (AI) ワークロード向けに最適化されたNetAppストレージと Lenovo サーバーを使用したミッドレンジ クラスター アーキテクチャを提供します。これは、ほとんどのコンピューティング ジョブが単一ノード (単一またはマルチ GPU) であるか、少数のコンピューティング ノードに分散されている中小企業を対象としています。このソリューションは、多くの企業の日常的な AI トレーニング ジョブのほとんどに適合します。</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">このドキュメントでは、8 つの GPU を搭載した Lenovo SR670V2 サーバー、ミッドレンジのNetApp AFF A400ストレージ システム、および 100GbE 相互接続スイッチで構成されるコンピューティングおよびストレージ構成のテストと検証について説明します。パフォーマンスを測定するために、ImageNet データセット、バッチ サイズ 408、半精度、CUDA、cuDNN を使用した ResNet50 を使用しました。このアーキテクチャは、 NetApp ONTAPクラウド接続データ ストレージのエンタープライズ グレードの機能を必要とする AI イニシアチブを開始したばかりの中小規模の組織に、効率的でコスト効率の高いソリューションを提供します。</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">データサイエンティスト、データエンジニア、データ管理者、AIシステムの開発者</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">AIモデル開発のためのソリューションを設計するエンタープライズアーキテクト</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">ディープラーニング（DL）と機械学習（ML）の開発目標を達成するための効率的な方法を探しているデータサイエンティストとデータエンジニア</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">AIイニシアチブの市場投入までの時間を最短にしたいと考えているビジネスリーダーとOT/IT意思決定者</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Lenovo ThinkSystem サーバーとAFFストレージを備えたNetApp ONTAPを使用したこのソリューションは、従来の CPU に加えて GPU の処理能力を使用して、大規模なデータセットでの AI トレーニングを処理するように設計されています。この検証では、1 台、2 台、または 4 台の Lenovo SR670 V2 サーバーと単一のNetApp AFF A400ストレージ システムを組み合わせたスケールアウト アーキテクチャにより、高いパフォーマンスと最適なデータ管理が実現されることが実証されています。次の図は、アーキテクチャの概要を示しています。</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">この画像は、管理サーバー、それぞれ 8 個の GPU を搭載した 4 台の SR670 V2、およびNetApp ONTAPストレージ システムに囲まれたイーサネット スイッチを示しています。</block>
  <block id="98230d6fe5f2e966446d65810c888228" category="paragraph"><block ref="98230d6fe5f2e966446d65810c888228" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">複数のトレーニングジョブを並行して実行する場合の非常に効率的でコスト効率の高いパフォーマンス</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">異なる数のLenovoサーバーと異なるモデルのNetAppストレージコントローラーに基づいてスケーラブルなパフォーマンスを実現します。</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">データ損失なしで低いリカバリポイント目標 (RPO) とリカバリ時間目標 (RTO) を満たす堅牢なデータ保護</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">スナップショットとクローンによる最適化されたデータ管理により開発ワークフローを効率化</block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">今回の検証では、MLPerf v2.0 の仕様に従って画像認識トレーニングを実行しました。具体的には、ImageNet データセットを使用して ResNet v2.0 モデルをトレーニングしました。主な指標は、望ましい精度に到達するまでの時間です。スケールアウトの効率をより適切に判断できるように、トレーニング帯域幅を 1 秒あたりの画像数で報告します。</block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">今回の検証では、MLPerf v2.0 の仕様に従って画像認識トレーニングを実行しました。具体的には、ImageNet データセットを使用して ResNet v2.0 モデルをトレーニングし、精度が 76.1% に達するまでトレーニングしました。主な指標は、望ましい精度に到達するまでの時間です。スケールアウトの効率をより適切に判断できるように、トレーニング帯域幅を 1 秒あたりの画像数で報告します。</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">主なテスト ケースでは、同時に実行される複数の独立したトレーニング プロセス (ノードごとに 1 つ) を評価しました。これは、複数のデータ サイエンティストが使用する共有システムという主なユース ケースをシミュレートします。  2 番目のテスト ケースでは、スケールアウトの効率を評価しました。</block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">このセクションでは、このソリューションでのテストの結果をまとめます。</block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">次の表は、このソリューションに対して実行されたすべてのテストの結果をまとめたものです。</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">テストの説明</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">結果の要約</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">画像認識トレーニング: 複数の同時ジョブ</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">非常に効率的なパフォーマンス。クラスターが完全に使用されたときでも、すべてのジョブはフルスピードで実行されました。  NetAppストレージ システムは、サーバー間でのデータ共有を容易にしながら、ローカル SSD ストレージに匹敵するトレーニング パフォーマンスを実現しました。</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">画像認識トレーニング：スケールアウト</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">最大 4 つのノードまで高効率です。その時点では、スケールアウトは効率が悪かったものの、まだ実現可能でした。より高速な計算ネットワークを使用すると、スケーラビリティが向上します。  NetAppストレージ システムは、サーバー間でのデータ共有を容易にしながら、ローカル SSD ストレージに匹敵するトレーニング パフォーマンスを実現しました。</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">このセクションでは、このソリューションの主要コンポーネントについて詳しく説明します。</block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">NetApp AFFストレージ システムにより、企業は業界をリードするパフォーマンス、優れた柔軟性、クラウド統合、クラス最高のデータ管理により、エンタープライズ ストレージの要件を満たすことができます。フラッシュ専用に設計されたAFFシステムは、ビジネスクリティカルなデータの高速化、管理、保護に役立ちます。</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">この図は、 NetApp AFF A400ストレージ コントローラの前面を示しています。</block>
  <block id="f150868d2ce410023c5087a2a86bf51e" category="paragraph"><block ref="f150868d2ce410023c5087a2a86bf51e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">この図は、 NetApp AFF A400ストレージ コントローラの背面を示しています。</block>
  <block id="11540913656d83142b2b0f7aed3df7e4" category="paragraph"><block ref="11540913656d83142b2b0f7aed3df7e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32fbd740c28afd94422aeceef5424762" category="paragraph">NetApp AFF A400は、次の機能を備えたミッドレンジ NVMe フラッシュ ストレージ システムです。</block>
  <block id="4b78ed4e994ac9de0ed2b09e38067a6a" category="list-text">最大有効容量: 約20PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">最大スケールアウト: 2～24ノード (12 HAペア)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbEおよび16Gb FCホストのサポート</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">NVMe拡張ストレージシェルフへの100GbE RDMA over Converged Ethernet（RoCE）接続</block>
  <block id="e9038c807b352c2a4dcfd8cf1ac2cdd4" category="list-text">NVMeシェルフが接続されていない場合、100GbE RoCEポートをホストネットワーク接続に使用できます。</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">フル12Gbps SAS接続拡張ストレージシェルフ</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">2 つの構成で利用可能:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">イーサネット: 4x 25Gb イーサネット (SFP28) ポート</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">ファイバーチャネル: 4x 16Gb FC (SFP+) ポート</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8KB ランダム読み取り @.4 ms 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">エントリー レベルの AI/ML 導入向けのNetApp AFF A250 の機能は次のとおりです。</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">最大有効容量：35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">最大スケールアウト: 2～24ノード (12 HAペア)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">最新のNetApp ONTAPリリースONTAP 9.8 以降をベースに構築</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">HAおよびクラスタ相互接続用の2つの25Gbイーサネットポート</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">NetApp は、大規模な AI/ML 導入向けに高いパフォーマンスと拡張性を提供するAFF A800やAFF A700などの他のストレージ システムも提供しています。</block>
  <block id="3f0cb8a376b551c058cd6886f68bceb0" category="paragraph">NetAppの最新世代のストレージ管理ソフトウェアであるONTAP 9 により、企業はインフラストラクチャを最新化し、クラウド対応のデータセンターに移行できるようになります。 ONTAP は業界をリードするデータ管理機能を活用し、データの保存場所に関係なく、単一のツール セットでデータの管理と保護を可能にします。データは、エッジ、コア、クラウドなど、必要な場所に自由に移動することもできます。  ONTAP 9 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッド クラウド アーキテクチャ全体にわたって将来を見据えたインフラストラクチャを実現する多数の機能が含まれています。</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">*最小、最大、および適応型のサービス品質 (QoS)。*きめ細かな QoS 制御により、高度に共有された環境における重要なアプリケーションのパフォーマンス レベルを維持できます。</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAPFabricPool。*この機能は、Amazon Web Services (AWS)、Azure、 NetApp StorageGRIDオブジェクト ストレージなどのパブリックおよびプライベート クラウド ストレージ オプションにコールド データを自動的に階層化します。</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">*パフォーマンスと低レイテンシー。*  ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetAppボリューム暗号化。*  ONTAP は、オンボードと外部の両方のキー管理サポートを備えたネイティブのボリューム レベルの暗号化を提供します。</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9 は、要求が厳しく、常に変化するビジネス ニーズへの対応に役立ちます。</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">*シームレスなスケーリングと中断のない運用。* ONTAP は、既存のコントローラおよびスケールアウト クラスタへの無停止の容量追加をサポートします。お客様は、コストのかかるデータ移行や停止なしで、NVMe や 32Gb FC などの最新テクノロジーにアップグレードできます。</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">*新興アプリケーションとの統合。*  ONTAP は、既存のエンタープライズ アプリケーションをサポートするのと同じインフラストラクチャを使用して、OpenStack、Hadoop、MongoDB などの次世代プラットフォームとアプリケーションにエンタープライズ グレードのデータ サービスを提供します。</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroupボリューム</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">トレーニング データセットは通常、数十億に及ぶ可能性のあるファイルのコレクションです。ファイルには、並列に読み取るために保存および処理する必要があるテキスト、オーディオ、ビデオ、およびその他の形式の非構造化データが含まれる場合があります。ストレージ システムは多数の小さなファイルを保存し、順次およびランダム I/O でそれらのファイルを並列に読み取る必要があります。</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroupボリューム (次の図) は、複数の構成メンバー ボリュームで構成された単一のネームスペースであり、ストレージ管理者に対してNetApp FlexVol volumeのように管理され、機能します。 FlexGroupボリューム内のファイルは個々のメンバー ボリュームに割り当てられ、ボリュームまたはノード間でストライプ化されません。これらにより、次の機能が有効になります。</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">最大 20 ペタバイトの容量と、高メタデータ ワークロード向けの予測可能な低レイテンシ</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">同じ名前空間に最大4000億個のファイル</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">CPU、ノード、アグリゲート、および構成FlexVolボリュームにわたるNASワークロードの並列処理</block>
  <block id="55f5279d0b1378eee63af77d4c7ac7bd" category="inline-image-macro">この画像は、 FlexGroup内にメイン ファイルを含む多数のボリュームを含むストレージ コントローラの HA ペアを示しています。</block>
  <block id="27f19cee54b11d13039a99839ca83e4c" category="paragraph"><block ref="27f19cee54b11d13039a99839ca83e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Lenovo ThinkSystemポートフォリオ</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Lenovo ThinkSystem サーバーを導入する主な利点は次のとおりです。</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">ビジネスの成長に合わせて拡張可能なモジュール設計</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">AI 分野では、Lenovo は企業が ML と AI の利点を理解し、ワークロードに導入できるよう支援する実践的なアプローチを採用しています。 Lenovo のお客様は、Lenovo AI イノベーション センターで Lenovo AI 製品を探索および評価し、特定のユース ケースの価値を十分に理解することができます。価値実現までの時間を短縮するために、この顧客中心のアプローチでは、すぐに使用でき、AI 向けに最適化されたソリューション開発プラットフォームの概念実証を顧客に提供します。</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">レノボ SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Lenovo ThinkSystem SR670 V2 ラック サーバーは、高速 AI と高性能コンピューティング (HPC) に最適なパフォーマンスを提供します。  SR670 V2 は最大 8 個の GPU をサポートし、ML、DL、推論の計算集約型のワークロード要件に適しています。</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">この画像は 3 つの SR670 構成を示しています。最初は、8 つの 2.5 インチ HS ドライブと 2 つの PCIe I/O スロットを備えた 4 つの SXM GPU を示しています。  2 番目は、4 つのダブルワイドまたは 8 つのシングルワイド GPU スロットと、8 つの 2.5 インチまたは 4 つの 3.5 インチ HS ドライブを備えた 2 つの PCIe I/O スロットを示しています。  3 番目は、6 つの EDSFF HS ドライブと 2 つの PCIe I/O スロットを備えた 8 つのダブルワイド GPU スロットを示しています。</block>
  <block id="20b8a0ab50b43efab313a63b4c461c6e" category="paragraph"><block ref="20b8a0ab50b43efab313a63b4c461c6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">ThinkSystem SR670 V2 は、ハイエンド GPU ( NVIDIA A100 80GB PCIe 8x GPU を含む) をサポートする最新のスケーラブルな Intel Xeon CPU を搭載し、AI および HPC ワークロード向けに最適化され、高速化されたパフォーマンスを提供します。</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">アクセラレータのパフォーマンスを利用するワークロードが増えるため、GPU 密度に対する需要が高まっています。小売、金融サービス、エネルギー、ヘルスケアなどの業界では、GPU を使用して、ML、DL、推論技術によってより深い洞察を抽出し、イノベーションを推進しています。</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2 は、高速化された HPC および AI ワークロードを本番環境に導入し、次世代プラットフォームによるスーパーコンピューティング クラスターのデータセンター密度を維持しながらシステム パフォーマンスを最大化するために最適化されたエンタープライズ グレードのソリューションです。</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">その他の機能は次のとおりです:</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">高速ネットワーク アダプターを GPU に直接接続して I/O パフォーマンスを最大化する GPU ダイレクト RDMA I/O のサポート。</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">NVMe ドライブを GPU に直接接続してストレージ パフォーマンスを最大化する GPU ダイレクト ストレージのサポート。</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf は、AI パフォーマンスを評価するための業界をリードするベンチマーク スイートです。この検証では、最も人気のある AI フレームワークの 1 つである MXNet を使用した画像分類ベンチマークを使用しました。 AI トレーニングを実行するために、MXNet_benchmarks トレーニング スクリプトが使用されました。このスクリプトには、いくつかの一般的な従来モデルの実装が含まれており、可能な限り高速になるように設計されています。単一のマシン上で実行することも、複数のホスト間で分散モードで実行することもできます。</block>
  <block id="75c1d09e56fd67f885464b85c424c1a6" category="summary">このホワイト ペーパーでは、Intel Xeon 6 プロセッサとNetAppデータ管理ソリューションのテクノロジと組み合わせた機能を備えた、エンタープライズ RAG 向けNetApp AIPodの検証済みリファレンス デザインについて説明します。このソリューションは、大規模な言語モデルを活用したダウンストリーム ChatQnA アプリケーションを示し、同時ユーザーに正確でコンテキストに適した応答を提供します。応答は、エアギャップ RAG 推論パイプラインを通じて組織の内部知識リポジトリから取得されます。</block>
  <block id="98082f297da0ed06e10c426d26145b83" category="doc">NetApp AIPod Mini - NetAppとIntelによるエンタープライズRAG推論</block>
  <block id="f7b06c1111212ddff169549b5e723f7d" category="inline-image-macro">インテルロゴ</block>
  <block id="0e15068b5c1105ba9f4537e00817149b" category="paragraph"><block ref="0e15068b5c1105ba9f4537e00817149b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c6562cf6ae61e882bf5b2ce4cfcba9d" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp</block>
  <block id="609170132b6430c9060811e3315d482b" category="paragraph">生産性とビジネス価値を高めるために、検索拡張生成 (RAG) アプリケーションと大規模言語モデル (LLM) を活用して、ユーザーのプロンプトを解釈し、応答を生成する組織が増えています。これらのプロンプトと応答には、組織の内部ナレッジベース、データ レイク、コード リポジトリ、ドキュメント リポジトリから取得されたテキスト、コード、画像、さらには治療用タンパク質構造などが含まれます。このホワイト ペーパーでは、 NetApp AFFストレージと Intel Xeon 6 プロセッサを搭載したサーバーで構成されるNetApp AIPod Mini ソリューションのリファレンス デザインについて説明します。これには、Intel Advanced Matrix Extensions (Intel AMX) と組み合わせたNetApp ONTAPデータ管理ソフトウェアと、Open Platform for Enterprise AI (OPEA) 上に構築された Intel AI for Enterprise Retrieval-augmented Generation (RAG) ソフトウェアが含まれます。 NetApp AIPod Mini for enterprise RAG を使用すると、組織はパブリック LLM をプライベート生成 AI (GenAI) 推論ソリューションに拡張できます。このソリューションは、信頼性を高め、独自の情報をより適切に制御できるように設計された、エンタープライズ規模での効率的でコスト効率の高い RAG 推論を実現します。</block>
  <block id="ad17078c7a931a9c4e7e96f485d5a504" category="section-title">Intel ストレージ パートナーの検証</block>
  <block id="56f2eda910ca62395eb64d1a789a0edd" category="paragraph">Intel Xeon 6 プロセッサーを搭載したサーバーは、Intel AMX を使用して最高のパフォーマンスを実現し、要求の厳しい AI 推論ワークロードを処理できるように構築されています。最適なストレージ パフォーマンスとスケーラビリティを実現するために、このソリューションはNetApp ONTAPを使用して検証されており、企業は RAG アプリケーションのニーズを満たすことができます。この検証は、Intel Xeon 6 プロセッサを搭載したサーバーで実施されました。  Intel とNetApp は、最適化され、拡張可能で、顧客のビジネス要件に適合した AI ソリューションの提供に重点を置いた強力なパートナーシップを築いています。</block>
  <block id="679a14435daad5bf55fe65cf54175466" category="section-title">NetAppでRAGシステムを実行する利点</block>
  <block id="320696921fb4cab1e55c519f97302d91" category="paragraph">RAG アプリケーションでは、PDF、テキスト、CSV、Excel、ナレッジ グラフなど、さまざまな形式で企業のドキュメント リポジトリからナレッジを取得します。このデータは通常、データのソースとして S3 オブジェクト ストレージやオンプレミスの NFS などのソリューションに保存されます。  NetApp は、エッジ、データセンター、クラウドのエコシステム全体にわたって、データ管理、データ モビリティ、データ ガバナンス、データ セキュリティ テクノロジーのリーダーです。  NetApp ONTAPデータ管理は、バッチやリアルタイム推論などのさまざまなタイプの AI ワークロードをサポートするエンタープライズ グレードのストレージを提供し、次のような利点をもたらします。</block>
  <block id="18fb2614ff78418dcaae1e9141862c62" category="list-text">速度とスケーラビリティ。パフォーマンスと容量を個別に拡張できるため、大規模なデータセットを高速に処理してバージョン管理を行うことができます。</block>
  <block id="71861e9c8f9e5be0d026ab6bdf1a8a1a" category="list-text">データアクセス。マルチプロトコル サポートにより、クライアント アプリケーションは S3、NFS、SMB ファイル共有プロトコルを使用してデータを読み取ることができます。  ONTAP S3 NAS バケットは、マルチモーダル LLM 推論シナリオでのデータ アクセスを容易にします。</block>
  <block id="27a2888f3fc62ef093e756c75c45081e" category="list-text">信頼性と機密性。  ONTAP は、データ保護、組み込みのNetApp Autonomous Ransomware Protection (ARP)、ストレージの動的プロビジョニングを提供し、機密性とセキュリティを強化するためにソフトウェアベースとハードウェアベースの両方の暗号化を提供します。  ONTAP は、すべての SSL 接続に関して FIPS 140-2 に準拠しています。</block>
  <block id="104d96e571b334e50365e35ae17299d9" category="paragraph">このドキュメントは、エンタープライズ RAG および GenAI ソリューションを提供するために構築されたインフラストラクチャを活用したい AI 意思決定者、データ エンジニア、ビジネス リーダー、部門幹部を対象としています。  AI 推論、LLM、Kubernetes、ネットワークとそのコンポーネントに関する事前の知識は、実装フェーズで役立ちます。</block>
  <block id="63b41ad25402b4d0e25695e062bb14ad" category="section-title">インテルAIテクノロジー</block>
  <block id="d8f5efc84f626ba14a7b3cf5ec1b06c7" category="inline-link">Xeon 6プロセッサ</block>
  <block id="9dc22cb886e2ea682197d9ab3292ba79" category="paragraph">Xeon 6 をホスト CPU として使用することで、高速化されたシステムは、高いシングルスレッド パフォーマンス、メモリ帯域幅の拡大、信頼性、可用性、保守性 (RAS) の向上、および I/O レーンの増加といったメリットを享受できます。  Intel AMX は、INT8 および BF16 の推論を高速化し、FP16 トレーニング済みモデルのサポートを提供します。INT8 の場合はコアあたりサイクルあたり最大 2,048 回の浮動小数点演算、BF16/FP16 の場合はコアあたりサイクルあたり最大 1,024 回の浮動小数点演算が可能です。 Xeon 6 プロセッサを使用して RAG ソリューションを展開するには、通常、最低 250 GB の RAM と 500 GB のディスク容量が推奨されます。ただし、これは LLM モデルのサイズに大きく依存します。詳細については、Intel<block ref="5d6ada86cc7a762cca0505b98060c709" category="inline-link-rx"></block>製品概要。</block>
  <block id="c3f5f2ae46fce3305ec2b138111a93b9" category="inline-image-macro">300,300</block>
  <block id="1e2eb4a765ee46d2a2a5ec4ace0544fc" category="paragraph">図1 - Intel Xeon 6プロセッサを搭載したコンピューティングサーバー<block ref="791fbab5dd410f620397cbb8a7265767" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7c9993f09f717fcec0e1d09837e1efc" category="section-title">NetApp AFFストレージ</block>
  <block id="969e81477626b41849d992785dfcd02d" category="paragraph">エントリーレベルおよびミッドレベルのNetApp AFF A シリーズ システムは、より強力なパフォーマンス、密度、および優れた効率性を提供します。  NetApp AFF A20、 AFF A30、 AFF A50 システムは、ハイブリッド クラウド全体で最低コストで RAG アプリケーションのデータをシームレスに管理、保護、および移動できる単一の OS に基づいて、ブロック、ファイル、およびオブジェクトをサポートする真の統合ストレージを提供します。</block>
  <block id="f89af68595f296408d40bf9a33b8df16" category="paragraph">図 2 - NetApp AFF A シリーズ システム。<block ref="f19ab1d9dc0e27bd83c8759fade26d2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">*ハードウェア*</block>
  <block id="ddcac68770926479de530a8b7b73319e" category="cell">*量*</block>
  <block id="9bdc480955b350f1fe8089392ad36cbe" category="cell">*コメント*</block>
  <block id="f0ef78c28754fd06e4d1d893f113852d" category="cell">Intel Xeon 6ベースのサーバー</block>
  <block id="3e18c872662c63bcc37a4934b1161411" category="cell">RAG 推論ノード - デュアル ソケット Intel Xeon 6900 シリーズまたは Intel Xeon 6700 シリーズ プロセッサと、DDR5 (6400 MHz) または MRDIMM (8800 MHz) の 250 GB ～ 3 TB の RAM を搭載。  2Uサーバー。</block>
  <block id="e5cb14453a0aa5c9218e9b6f4a2468d1" category="cell">Intel プロセッサを搭載したコントロール プレーン サーバー</block>
  <block id="f5aa1aa461d9a8bb35210fb241f42cda" category="cell">Kubernetes コントロール プレーン/1U サーバー。</block>
  <block id="5a0cd1929a98cebd107b65ee74abdd78" category="cell">100Gbイーサネットスイッチの選択</block>
  <block id="8bfef0f2ef10319beae9f37e53900e5a" category="cell">データセンタースイッチ。</block>
  <block id="7a2bdeec28cc635e8de5bbcea81978e1" category="cell">NetApp AFF A20（またはAFF A30、 AFF A50）</block>
  <block id="4e42b39bc940168c6df430c647a36a11" category="cell">最大ストレージ容量: 9.3PB。注: ネットワーク: 10/25/100 GbE ポート。</block>
  <block id="44959688d91c76b11d501b550db01844" category="paragraph">このリファレンス デザインの検証には、Supermicro の Intel Xeon 6 プロセッサ (222HA-TN-OTO-37) を搭載したサーバーと Arista の 100GbE スイッチ (7280R3A) が使用されました。</block>
  <block id="aa6ecfe41f4b8c352896cd6cf7bc99f7" category="section-title">エンタープライズAI向けオープンプラットフォーム</block>
  <block id="6fbfd0726b7202aebde976680ced22c4" category="paragraph">Open Platform for Enterprise AI (OPEA) は、Intel がエコシステム パートナーと協力して主導するオープン ソース イニシアチブです。  RAG に重点を置いた最先端の生成 AI システムの開発を加速するように設計された、構成可能なビルディング ブロックのモジュール式プラットフォームを提供します。  OPEA には、LLM、データストア、プロンプト エンジン、RAG アーキテクチャ ブループリント、パフォーマンス、機能、信頼性、エンタープライズ準備に基づいて生成 AI システムを評価する 4 段階の評価方法を備えた包括的なフレームワークが含まれています。</block>
  <block id="cbe45632fbbac4e94036260c2653169b" category="paragraph">OPEA は、主に次の 2 つの主要コンポーネントで構成されています。</block>
  <block id="4293e41be4afaf5127828398b7c550da" category="list-text">GenAIComps: マイクロサービスコンポーネントで構成されたサービスベースのツールキット</block>
  <block id="b93ca66f4736b98ad6d348c3b08a6806" category="list-text">GenAIExamples: ChatQnAのような、実用的なユースケースを示すすぐに導入できるソリューション</block>
  <block id="de3c6a3259d3e324c7703889f55a4dde" category="inline-link">OPEAプロジェクトドキュメント</block>
  <block id="95a35f38b1c8257e521a361226ddc22d" category="paragraph">詳細については、<block ref="61827ec0b891f01987001b685543f04f" category="inline-link-rx"></block></block>
  <block id="515b4067e1d91f462d68de8996b254f6" category="section-title">OPEA を搭載した Intel AI for Enterprise 推論</block>
  <block id="36a128563cdcf54e3a3e0bfe9a0952a5" category="paragraph">Intel AI for Enterprise RAG の OPEA は、エンタープライズ データを実用的な洞察へと変換することを簡素化します。 Intel Xeon プロセッサーを搭載し、業界パートナーのコンポーネントを統合して、エンタープライズ ソリューションを導入するための合理的なアプローチを提供します。実績のあるオーケストレーション フレームワークを使用してシームレスに拡張し、企業が必要とする柔軟性と選択肢を提供します。</block>
  <block id="9cc188487c3944246ae7f6c5402d3c53" category="paragraph">OPEA の基盤を基に、Intel AI for Enterprise RAG は、スケーラビリティ、セキュリティ、ユーザー エクスペリエンスを強化する主要な機能によってこの基盤を拡張します。これらの機能には、最新のサービスベースのアーキテクチャとのシームレスな統合を実現するサービス メッシュ機能、パイプラインの信頼性を本番環境で検証できる機能、ワークフローの管理と監視を容易にする RAG as a Service 用の機能豊富な UI などが含まれます。さらに、インテルとパートナーのサポートにより、安全でコンプライアンスに準拠した運用を実現する UI とアプリケーションを備えた統合 ID およびアクセス管理 (IAM) と組み合わせた、幅広いソリューション エコシステムへのアクセスが提供されます。プログラム可能なガードレールにより、パイプラインの動作をきめ細かく制御でき、セキュリティとコンプライアンスの設定をカスタマイズできます。</block>
  <block id="1671448a75b3c116c61a1ac925267b0b" category="inline-link">ONTAP S3 の構成について学ぶ</block>
  <block id="90c6a896851e2b2d442ba1cd9d8de55a" category="paragraph">NetApp ONTAP は、NetApp の重要なデータ ストレージ ソリューションを支える基盤テクノロジーです。 ONTAP には、サイバー攻撃に対する自動ランサムウェア保護、組み込みのデータ転送機能、ストレージ効率機能など、さまざまなデータ管理およびデータ保護機能が含まれています。これらの利点は、オンプレミスから、NAS、SAN、オブジェクト、LLM 展開のソフトウェア定義ストレージのハイブリッド マルチクラウドまで、さまざまなアーキテクチャに適用されます。 ONTAPクラスタ内のONTAP S3 オブジェクト ストレージ サーバを使用して RAG アプリケーションを導入し、承認されたユーザーとクライアント アプリケーションを通じて提供されるONTAPのストレージ効率とセキュリティを活用できます。詳細については、<block ref="5ba5b9c5717eb24d2b5fdfe0fd9cfc0e" category="inline-link-rx"></block></block>
  <block id="c1b379b8a85b20135cbeae3496ac9cb9" category="inline-link">Git 上のNetApp Trident</block>
  <block id="05ff24c52b7f489f2df6dab1ac93a444" category="paragraph">NetApp Tridentソフトウェアは、Red Hat OpenShift を含むコンテナおよび Kubernetes ディストリビューション向けのオープンソースで完全にサポートされているストレージ オーケストレーターです。 Trident は、 NetApp ONTAPを含むNetAppストレージ ポートフォリオ全体と連携し、NFS および iSCSI 接続もサポートします。詳細については、<block ref="b09494428fb81fc17c232fdf3cd6ebfd" category="inline-link-rx"></block></block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">*ソフトウェア*</block>
  <block id="45cc01ab5f209e8760027e9c30097025" category="cell">*バージョン*</block>
  <block id="b968b232dc718c194c40c140b496647a" category="cell">エンタープライズ RAG 向けインテル AI の OPEA</block>
  <block id="522c33efdda0b8dc6ce90c991beb9666" category="cell">1.1.2</block>
  <block id="cec6a9b163aa2911c259a1fd129fafec" category="cell">OPEAマイクロサービスに基づくエンタープライズRAGプラットフォーム</block>
  <block id="7b02c13e31cd24ff2d950fc29a8f9d53" category="cell">コンテナ ストレージ インターフェース (CSI ドライバー)</block>
  <block id="a821a7b77c7f65a585f8b5e2b6679cd3" category="cell">NetAppTrident25.02</block>
  <block id="4d437b953db79f111d6140d4d62384e4" category="cell">動的プロビジョニング、 NetAppスナップショット コピー、ボリュームを有効にします。</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">Ubuntu</block>
  <block id="5e3add1fd258bd782aade74ed9a9877d" category="cell">22.04.5</block>
  <block id="d63705a0c12ee1eea0e9fa2f30be636d" category="cell">2ノードクラスタ上のOS</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">コンテナオーケストレーション</block>
  <block id="307ea69c7c6931f75ee51c5349fefb05" category="cell">Kubernetes 1.31.4</block>
  <block id="382fc90b48fccde9d59f816ea9dc9b4a" category="cell">RAGフレームワークを実行する環境</block>
  <block id="6f72c11338419e7cbef5d90da27338b1" category="cell">ONTAP 9.16.1P4</block>
  <block id="345ec8aa297f872cecdbf6b3c0e32bfd" category="cell">AFF A20 上のストレージ OS。  Vscan と ARP を備えています。</block>
  <block id="77e4d80ae2f4257081e17476b146608a" category="section-title">ソリューションの展開</block>
  <block id="e137b1b38be73f6e2bb5d628d2325215" category="section-title">ソフトウェアスタック</block>
  <block id="4b9b3f178d68004f22177def38ac1a0a" category="paragraph">このソリューションは、Intel Xeon ベースのアプリケーション ノードで構成される Kubernetes クラスターに展開されます。 Kubernetes コントロール プレーンの基本的な高可用性を実装するには、少なくとも 3 つのノードが必要です。次のクラスター レイアウトを使用してソリューションを検証しました。</block>
  <block id="9a5c044d129dc6879fa0ab37fdf1da36" category="paragraph">表3 - Kubernetesクラスタレイアウト</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">ノード</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">ロール</block>
  <block id="f6deba375b4908f8ab44946cb1ac15ec" category="cell">Intel Xeon 6プロセッサと1TB RAMを搭載したサーバー</block>
  <block id="5e13dbdc232ae09e4bcf3ca30f51de88" category="cell">アプリノード、コントロールプレーンノード</block>
  <block id="c8b75ba615f900ff258046bb36a7fc62" category="cell">汎用サーバー</block>
  <block id="6f8f92d5847446fe4b0ae5b71badd7cd" category="cell">コントロールプレーンノード</block>
  <block id="b1ee6de34c23dd606b6401a06907e658" category="inline-image-macro">600,600</block>
  <block id="13c96942dd3c3b3bdb84e02b2a303778" category="paragraph">次の図は、ソリューションの「ソフトウェア スタック ビュー」を示しています。<block ref="841e6c807fed1e7947a5b7ebff264e4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8388066510b59c8d3387373b6969a7af" category="section-title">導入手順</block>
  <block id="6c00804e5ebc94e7610086e3e0f7e581" category="section-title">ONTAPストレージアプライアンスを導入する</block>
  <block id="ec6e72d1c4bb7dccdc62b6caf35c95f7" category="inline-link">ONTAPハードウェア システムのドキュメント</block>
  <block id="c5ba881390fd2c8d5f9d0fb165ad1049" category="paragraph">NetApp ONTAPストレージ アプライアンスを導入およびプロビジョニングします。参照<block ref="8f6fc8fb2a7bb6f821a0fddf6c335b91" category="inline-link-rx"></block>詳細については。</block>
  <block id="9df0c5d4eab5f45fac1c5ad20e8fdade" category="section-title">NFSおよびS3アクセス用にONTAP SVMを構成する</block>
  <block id="b0e271f740ae6f03e699c988b5b7c576" category="paragraph">Kubernetes ノードからアクセス可能なネットワーク上で、NFS および S3 アクセス用のONTAPストレージ仮想マシン (SVM) を構成します。</block>
  <block id="05ef9b22209f0e35efc9b6f875ad3c55" category="inline-link">ONTAP のドキュメント。</block>
  <block id="a647bfcaa1b11c3008439f5c2a0a888f" category="paragraph">ONTAP System Manager を使用して SVM を作成するには、[ストレージ] &gt; [ストレージ VM] に移動し、[+ 追加] ボタンをクリックします。 SVM の S3 アクセスを有効にするときは、システム生成の証明書ではなく、外部 CA (証明機関) 署名付き証明書を使用するオプションを選択します。自己署名証明書または公的に信頼された CA によって署名された証明書のいずれかを使用できます。詳細については、<block ref="9162972b1d9e1d587a9c620aa7cb22be" category="inline-link-rx"></block></block>
  <block id="59ea3be65306f9546fb9ed8da06a4fc4" category="paragraph">次のスクリーンショットは、 ONTAP System Manager を使用して SVM を作成する様子を示しています。環境に応じて必要に応じて詳細を変更します。</block>
  <block id="ba045795e96e030beb3430fdc0bcf388" category="paragraph">図 4 - ONTAP System Manager を使用した SVM の作成。<block ref="eddc39049915c5d642c02b97b2cbe95e" category="inline-image-macro-rx" type="image"></block> <block ref="d6e1134442a83aae943e8555fe42f14e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e98de7098944681485c37173696a48b" category="section-title">S3の権限を設定する</block>
  <block id="9e677f1fe64f248526596041ab78f505" category="paragraph">前の手順で作成した SVM の S3 ユーザー/グループ設定を構成します。その SVM のすべての S3 API 操作へのフルアクセス権を持つユーザーがいることを確認します。詳細については、 ONTAP S3 のドキュメントを参照してください。</block>
  <block id="8182eb49f0464e8a5b6d2e7b642a6da5" category="paragraph">注: このユーザーは、Intel AI for Enterprise RAG アプリケーションのデータ取り込みサービスに必要になります。  ONTAP System Managerを使用してSVMを作成した場合、System Managerは自動的に次の名前のユーザーを作成します。<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>そして、<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block> SVMを作成したときに権限が割り当てられていません<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>。</block>
  <block id="c00a2800b71457eb0e0cabb2511b615a" category="paragraph">このユーザーの権限を編集するには、[ストレージ] &gt; [ストレージ VM] に移動し、前の手順で作成した SVM の名前をクリックして、[設定] をクリックし、[S3] の横にある鉛筆アイコンをクリックします。与える<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>すべてのS3 API操作へのフルアクセスを付与するには、関連付ける新しいグループを作成します。<block ref="331dbbf377ee7b82a198a7a8bb5f24e6" prefix=" " category="inline-code"></block>と<block ref="0268c876e4588f7ad98bacb113933dab" prefix=" " category="inline-code"></block>次のスクリーンショットに示すようなポリシーです。</block>
  <block id="229c665cb2b8cb2576229fea9470bfe6" category="paragraph">図 5 - S3 のアクセス許可。</block>
  <block id="3ce7236b065597bbadf2a14e9845558e" category="paragraph"><block ref="3ce7236b065597bbadf2a14e9845558e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cc27c397bf2aa7589869b84e048e24c" category="section-title">S3バケットを作成する</block>
  <block id="bd31776e6efcf27fc82ed6ba0862c4fb" category="paragraph">先ほど作成した SVM 内に S3 バケットを作成します。 ONTAP System Manager を使用して SVM を作成するには、[ストレージ] &gt; [バケット] に移動し、[+ 追加] ボタンをクリックします。詳細については、 ONTAP S3 のドキュメントを参照してください。</block>
  <block id="0b755fcdfc7b6b61938269f21db3f841" category="paragraph">次のスクリーンショットは、 ONTAP System Manager を使用して S3 バケットを作成する様子を示しています。</block>
  <block id="9568e70889a07b151a91a53d10969aed" category="paragraph">図 6 - S3 バケットを作成する。<block ref="06e84b109f1e09150cd4d15502f0a16d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="847d5eae44750df0abbb4d655d69c6a7" category="section-title">S3バケットの権限を設定する</block>
  <block id="c23ccda8191e76cb192f1bd40cae534b" category="paragraph">前の手順で作成した S3 バケットのアクセス許可を設定します。前の手順で設定したユーザーに次の権限があることを確認します。<block ref="82cabf6bd017130caa599103617f61df" prefix=" " category="inline-code"></block></block>
  <block id="c3bf5d608f066a6b405a40012a2fc10c" category="inline-link">ONTAP S3 ドキュメント</block>
  <block id="cc944a7541814572eb9767d03e306277" category="paragraph">ONTAP System Manager を使用して S3 バケットの権限を編集するには、[ストレージ] &gt; [バケット] に移動し、バケットの名前をクリックして、[権限] をクリックし、[編集] をクリックします。参照<block ref="3c678e24d354397cff48df8b3cf3f717" category="inline-link-rx"></block>詳細については、こちらをご覧ください。</block>
  <block id="0d1bf17e818c5b150c239afaa05e5f17" category="paragraph">次のスクリーンショットは、 ONTAP System Manager で必要なバケット権限を示しています。</block>
  <block id="54bf7776c2d0b7f0ee45097aaad50403" category="paragraph">図 7 - S3 バケットのアクセス許可。<block ref="cc0f8d7f1fe9cc3d53404327451495be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="000356058e153b3be211db974d645a75" category="section-title">バケットのクロスオリジンリソース共有ルールを作成する</block>
  <block id="004935665424a8d10e5e54b7140e97e1" category="paragraph">ONTAP CLI を使用して、前の手順で作成したバケットのバケット クロスオリジン リソース共有 (CORS) ルールを作成します。</block>
  <block id="51704d982c17dad72393ced89212b5ca" category="paragraph">このルールにより、OPEA for Intel AI for Enterprise RAG Web アプリケーションは、Web ブラウザー内からバケットと対話できるようになります。</block>
  <block id="d2a899c39e099bd681cfe52af554b20c" category="section-title">サーバーの展開</block>
  <block id="fa3bc02ffb34d7c680db187aa209dddd" category="paragraph">サーバーを展開し、各サーバーに Ubuntu 22.04 LTS をインストールします。  Ubuntu をインストールしたら、すべてのサーバーに NFS ユーティリティをインストールします。  NFS ユーティリティをインストールするには、次のコマンドを実行します。</block>
  <block id="5ed0c66dfa2ac395ad8e9830aa5964aa" category="section-title">Kubernetesをインストールする</block>
  <block id="7a21958624d0a70f3a6b70bcf03ba09a" category="inline-link">Kubespray ドキュメント</block>
  <block id="eb6273ed753aae187941e09aa142f02a" category="paragraph">Kubespray を使用してサーバーに Kubernetes をインストールします。参照<block ref="1d9598782a4be0d8f1003429c1865811" category="inline-link-rx"></block>詳細については。</block>
  <block id="b0583213f3e2e379b7dd549fd41f909f" category="section-title">Trident CSIドライバをインストールする</block>
  <block id="c17b9b6d3e5d228bcc6c08edc3438f7f" category="inline-link">Tridentインストール ドキュメント</block>
  <block id="1ba254856621ddad1eb72d0beee0001c" category="paragraph">Kubernetes クラスターにNetApp Trident CSI ドライバーをインストールします。参照<block ref="0fa543c14587a20e022922b0d6d40500" category="inline-link-rx"></block>詳細については。</block>
  <block id="cca56b6e3954004aac402213ce3054e6" category="section-title">Tridentバックエンドを作成する</block>
  <block id="f95ebb45354495c835f81296b11e95c1" category="inline-link">Tridentバックエンドドキュメント</block>
  <block id="31f53fbd09b24f455b372567da98766f" category="paragraph">以前に作成した SVM のTridentバックエンドを作成します。バックエンドを作成するときは、<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>ドライバ。参照<block ref="4b8fa33525637fa26acc3e336d80affb" category="inline-link-rx"></block>詳細については。</block>
  <block id="14f4c7abe09c4481722f1fa6563f2604" category="section-title">ストレージクラスを作成する</block>
  <block id="bdecb047bffb568e0e8e84eeca503f89" category="paragraph">前の手順で作成したTridentバックエンドに対応する Kubernetes ストレージ クラスを作成します。詳細については、 Tridentストレージ クラスのドキュメントを参照してください。</block>
  <block id="6a61b11e836f0eeccddb33643f7aa4cd" category="inline-link">エンタープライズ向けインテル AI RAG 展開</block>
  <block id="ba489bb61012c1097c380a06f7b20cbe" category="paragraph">Kubernetes クラスターに Intel AI for Enterprise RAG 用の OPEA をインストールします。参照<block ref="d6f70ce0ce5c9ddf0b1e28a93f0968a7" category="inline-link-rx"></block>詳細についてはドキュメントを参照してください。このホワイト ペーパーの後半で説明する、必要な構成ファイルの変更に注意してください。  Intel AI for Enterprise RAG アプリケーションがONTAPストレージ システムで正しく動作するためには、インストール プレイブックを実行する前にこれらの変更を行う必要があります。</block>
  <block id="cd806c912d9a85a913016682326e17bc" category="section-title">ONTAP S3の使用を有効にする</block>
  <block id="4a65f719a33b2a0cdefdd371bc5b4aa9" category="paragraph">Intel AI for Enterprise RAG 用の OPEA をインストールするときは、メイン構成ファイルを編集して、 ONTAP S3 をソース データ リポジトリとして使用できるようにします。</block>
  <block id="3bbecd0884a5e013f45ca28fdee8daf4" category="paragraph">ONTAP S3の使用を有効にするには、<block ref="ed9bdb883dd5d0bf37bd5d208a17fadc" prefix=" " category="inline-code"></block>セクション。</block>
  <block id="799685b83814ceb35225cd15c9221159" category="paragraph">注: デフォルトでは、Intel AI for Enterprise RAG アプリケーションは、SVM 内の既存のすべてのバケットからデータを取り込みます。  SVMに複数のバケットがある場合は、<block ref="50d6f108d2717f6e9be4eae460e94414" prefix=" " category="inline-code"></block>特定のバケットからのみデータが取り込まれるようにフィールドを設定します。</block>
  <block id="533e38d744354d370be3e86bd8fe8b28" category="section-title">スケジュールされた同期設定を構成する</block>
  <block id="ad99b73b01de134452a17a0dfa32cec2" category="paragraph">OPEA for Intel AI for Enterprise RAGアプリケーションをインストールするときは、<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>アプリケーションが S3 バケットから新しいファイルや更新されたファイルを自動的に取り込むようになります。</block>
  <block id="c64dcda39c59bb872461bbb0e651a561" category="paragraph">いつ<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>有効になっている場合、アプリケーションはソース S3 バケットで新しいファイルや更新されたファイルを自動的にチェックします。この同期プロセスの一環として見つかった新しいファイルまたは更新されたファイルは自動的に取り込まれ、RAG ナレッジ ベースに追加されます。アプリケーションは、事前に設定された時間間隔に基づいてソース バケットをチェックします。デフォルトの時間間隔は 60 秒です。つまり、アプリケーションは 60 秒ごとに変更をチェックします。特定のニーズに合わせてこの間隔を変更する必要があるかもしれません。</block>
  <block id="6d6914305f62085b3a9f416c96b4d127" category="paragraph">有効にするには<block ref="a8f39acdcf1094097a8bc645ced45455" prefix=" " category="inline-code"></block>同期間隔を設定するには、次の値を設定します。<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="b9edd7aa680f588a01b814c4969d387b" category="section-title">ボリュームアクセスモードを変更する</block>
  <block id="2fe889d552298c286373b708cafda8e7" category="paragraph">で<block ref="cd37fd54d9ac25bbfe45a164824d6194" prefix=" " category="inline-code"></block>、各巻ごとに<block ref="642542e40351edbd731ebad352b31317" prefix=" " category="inline-code"></block>リストを変更する<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>に<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>。</block>
  <block id="edad21c5950d7e773534103192f18dd8" category="section-title">（オプション）SSL証明書の検証を無効にする</block>
  <block id="6aaadab147a2227d76985e7ef0fc2680" category="paragraph">SVM の S3 アクセスを有効にするときに自己署名証明書を使用した場合は、SSL 証明書の検証を無効にする必要があります。公的に信頼された CA によって署名された証明書を使用した場合は、この手順をスキップできます。</block>
  <block id="2bb2c1d3d614a1de0e2e1e97fe3ac3c1" category="paragraph">SSL証明書の検証を無効にするには、次の値を設定します。<block ref="84bfd070139b7efc56f8e85ce50bc0b4" prefix=" " category="inline-code"></block></block>
  <block id="dd88285a7105f2f3e6756070ae0535e2" category="section-title">Enterprise RAG UI 向けインテル AI の OPEA にアクセスする</block>
  <block id="123b51539e81bc36af05f29733939680" category="inline-link">Intel AI for Enterprise RAG 導入ドキュメント</block>
  <block id="c1b501f6d4c8c6a8616b9ca35cd2fc45" category="paragraph">Intel AI for Enterprise RAG UI の OPEA にアクセスします。参照<block ref="746fad554462625e79393992880c7bc6" category="inline-link-rx"></block>詳細については。</block>
  <block id="922ca547bcfcab30994177a3c1d383ae" category="paragraph">図 8 - Enterprise RAG UI 用インテル AI の OPEA。<block ref="4cedb9bc094b7a9f8925870620118f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71b202e61cbdf7d879691cc22fff5944" category="section-title">RAGのデータを取り込む</block>
  <block id="1e5926c65c9a0919b7d73b19b2df9d53" category="paragraph">RAG ベースのクエリ拡張に含めるファイルを取り込むことができるようになりました。ファイルの取り込みには複数のオプションがあります。ニーズに応じて適切なオプションを選択してください。</block>
  <block id="36dc767aab6b2ad698f45815826a1a29" category="paragraph">注: ファイルが取り込まれた後、OPEA for Intel AI for Enterprise RAG アプリケーションはファイルの更新を自動的にチェックし、それに応じて更新を取り込みます。</block>
  <block id="39ba5d380c5ff87759539eee68e65d99" category="paragraph">*オプション 1: S3 バケットに直接アップロードする 一度に多くのファイルを取り込むには、任意の S3 クライアントを使用して、ファイルを S3 バケット (以前に作成したバケット) にアップロードすることをお勧めします。一般的な S3 クライアントには、AWS CLI、Amazon SDK for Python (Boto3)、s3cmd、S3 Browser、Cyberduck、Commander One などがあります。ファイルがサポートされているタイプである場合、S3 バケットにアップロードしたファイルは、OPEA for Intel AI for Enterprise RAG アプリケーションによって自動的に取り込まれます。</block>
  <block id="e8c9e1c06420b69e589d260def731d88" category="paragraph">注: この文書の執筆時点では、PDF、HTML、TXT、DOC、DOCX、PPT、PPTX、MD、XML、JSON、JSONL、YAML、XLS、XLSX、CSV、TIFF、JPG、JPEG、PNG、SVG のファイル タイプがサポートされています。</block>
  <block id="bc974fb6199b9073fbf1026bd2d236d2" category="paragraph">OPEA for Intel AI for Enterprise RAG UI を使用して、ファイルが適切に取り込まれたことを確認できます。詳細については、Intel AI for Enterprise RAG UI のドキュメントを参照してください。アプリケーションが大量のファイルを取り込むには時間がかかる場合があることに注意してください。</block>
  <block id="25ce0ebd12d3573d98440a5151efd06e" category="paragraph">*オプション 2: UI を使用してアップロードする 少数のファイルのみを取り込む必要がある場合は、OPEA for Intel AI for Enterprise RAG UI を使用して取り込むことができます。詳細については、Intel AI for Enterprise RAG UI のドキュメントを参照してください。</block>
  <block id="aad57997fffb9169edca9049f6c408fc" category="paragraph">図 9 - データ取り込み UI。<block ref="55969be455b6eb9c434a32c9edf9a19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aab14042462d545cbc81ccbd5144183" category="section-title">チャットクエリを実行する</block>
  <block id="37afbf2924fcb8ec313cd060eae9317c" category="paragraph">付属のチャット UI を使用して、OPEA for Intel AI for Enterprise RAG アプリケーションと「チャット」できるようになりました。クエリに応答する際、アプリケーションは取り込んだファイルを使用して RAG を実行します。つまり、アプリケーションは取り込んだファイル内の関連情報を自動的に検索し、クエリに応答するときにこの情報を組み込みます。</block>
  <block id="2ed19e65997a81f69c25a47d5bf28407" category="paragraph">検証作業の一環として、Intel と連携してパフォーマンス テストを実施しました。このテストの結果、次の表に示すサイズ設定のガイドラインが得られました。</block>
  <block id="b0e166baec472090eb9b8fe69dd5736a" category="cell">特徴づけ</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">Value</block>
  <block id="a48c8e3a66454b67fa81ad9e940c8b27" category="cell">モデルサイズ</block>
  <block id="4f4ccdf1d741c3c95db91bbc2930fb82" category="cell">200億のパラメータ</block>
  <block id="9be9211aab4b7a1e7b93895b22cac265" category="cell">ラマ-8B、ラマ-13B、ミストラル7B、クウェン14B、ディープシーク・ディスティル8B</block>
  <block id="5b176800a4fa5f818733bbc47bf50c58" category="cell">入力サイズ</block>
  <block id="5da438d3d127ea08ac04b3ad27565f86" category="cell">約2,000トークン</block>
  <block id="ec110f5087b1200011dcf2f34914001b" category="cell">約4ページ</block>
  <block id="2e422b9da98e2d0a7b8c31aa22986312" category="cell">出力サイズ</block>
  <block id="0de7dbc3b2f780207078fda7fe5f5312" category="cell">同時ユーザー数</block>
  <block id="2dda44ea1754f4e550f1a5cc97bd2f88" category="cell">「同時ユーザー」とは、同時にクエリを送信しているプロンプト要求を指します。</block>
  <block id="e8d9bc5e8e6b28217a5661b56a0ce38d" category="paragraph">_注: 上記のサイズ設定ガイダンスは、96 コアの Intel Xeon 6 プロセッサを使用して収集されたパフォーマンス検証およびテスト結果に基づいています。同様の I/O トークンとモデル サイズ要件を持つお客様には、96 または 128 コアの Xeon 6 プロセッサを搭載したサーバーの使用をお勧めします。</block>
  <block id="d83a33143fe76973b5528ae0d2b5750c" category="paragraph">エンタープライズ RAG システムと LLM は連携して動作し、組織が正確でコンテキストに応じた応答を提供できるようにするテクノロジーです。これらの対応には、膨大な個人データと社内企業データに基づく情報検索が含まれます。  RAG、API、ベクトル埋め込み、高性能ストレージ システムを使用して、企業データを含むドキュメント リポジトリをクエリすることで、データはより高速かつ安全に処理されます。  NetApp AIPod Mini は、NetApp のインテリジェント データ インフラストラクチャとONTAPデータ管理機能、Intel Xeon 6 プロセッサ、Intel AI for Enterprise RAG、OPEA ソフトウェア スタックを組み合わせ、高性能 RAG アプリケーションの導入を支援し、組織を AI リーダーシップへと導きます。</block>
  <block id="37bea4d3bbce78210e52efa42aff98fc" category="section-title">了承</block>
  <block id="9d17f4dbd111838ecf2ecb0306f6c255" category="paragraph">このドキュメントは、 NetAppソリューション エンジニアリング チームのメンバーである Sathish Thyagarajan と Michael Ogelsby が作成したものです。著者らはまた、NetAppの他のチーム メンバー (Lawrence Bunka、Bobby Oommen、Jeff Liborio) にも感謝の意を表します。</block>
  <block id="638409a97591a74cbaf8ecaac7bc356a" category="section-title">部品表</block>
  <block id="faf3c2849bae24ab9045ae5add024400" category="paragraph">以下は、このソリューションの機能検証に使用された BOM であり、参照として使用できます。次の構成に適合する任意のサーバーまたはネットワーク コンポーネント (または、100GbE 帯域幅が望ましい既存のネットワーク) を使用できます。</block>
  <block id="74953ad13674266e8135ca232d6d7d5d" category="paragraph">アプリサーバーの場合:</block>
  <block id="6737192650f0c3a81629128ea7774174" category="cell">*部品番号*</block>
  <block id="eb6fa4e6fed41e388b4d654a174c1b82" category="cell">*製品説明*</block>
  <block id="a3b91229cc5a5eb0d50908cc956824b3" category="cell">222HA-TN-OTO-37</block>
  <block id="2302a4ae44cddff506100b112f4645c6" category="cell">ハイパースーパーサーバー SYS-222HA-TN /2U</block>
  <block id="e53619c1fe611a51eeeb8d148ba6e532" category="cell">RAM</block>
  <block id="673b9923dda6787459c6a0ae7f711593" category="cell">MEM-DR564MC-ER64(x16)64GB DDR5-6400 2RX4 (16Gb) ECC RDIMM</block>
  <block id="0be247e8eaad16189d4e7ce0829add7a" category="cell">HDS-M2N4-960G0-E1-TXD-NON-080(x2) SSD M.2 NVMe PCIe4 960GB 1DWPD TLC D、80mm</block>
  <block id="c3ca791a9361b57a8fa217067084b891" category="cell">WS-1K63A-1R(x2)1U 692W/1600W冗長シングル出力電源。熱放散は 2361 BTU/時、最高温度は 59 ℃（約）</block>
  <block id="7d83e48371fe2b2bd396527bf08497f1" category="paragraph">制御サーバーの場合:</block>
  <block id="4bf51ddd79708218d2ca40addbf3f2fb" category="cell">511R-M-OTO-17</block>
  <block id="870f227b084b6f0c047a533d218e9874" category="cell">1U X13SCH-SYS、CSE-813MF2TS-R0RCNBP、PWS-602A-1Rまで最適化</block>
  <block id="7c3e6ed807c306444b3bddd7fc90cb2a" category="cell">MEM-DR516MB-EU48(x2)16GB DDR5-4800 1Rx8 (16Gb) ECC UDIMM</block>
  <block id="c104b47ab1794697f8c929d251599740" category="paragraph">ネットワーク スイッチの場合:</block>
  <block id="1bf595c07879a3e4909b5196570ee253" category="cell">DCS-7280CR3A</block>
  <block id="60e4b729f0a2b5471a6c6209bc49aac5" category="cell">アリスタ 7280R3A 28x100 GbE</block>
  <block id="40f46282e86b9c228e0cce6e2011f35c" category="paragraph">NetApp AFFストレージ:</block>
  <block id="39ff721f18a3edbb373a8c8f54cd3f14" category="cell">AFF-A20A-100-C</block>
  <block id="c133ed5a1928378c2f6a29bf6b6f1135" category="cell">AFF A20 HAシステム、-C</block>
  <block id="52b142796a871ab98369e293ae4d91c2" category="cell">X800-42U-R6-C</block>
  <block id="c6b0cc56d77c17a08efb3742ab92e776" category="cell">ジャンパーカード、インキャブ、C13-C14、-C</block>
  <block id="128bdeded7a535e68b0f98e463111407" category="cell">X97602A-C</block>
  <block id="f14bf71f2d74fbf0d0560b5a355bbf63" category="cell">電源、1600W、チタン、-C</block>
  <block id="2a0cfc5d71abb55759a510240510f87a" category="cell">X66211B-2-NC</block>
  <block id="d50feb7d1470a9fb63d75f5a39b4b8bd" category="cell">ケーブル、100GbE、QSFP28-QSFP28、Cu、2m、-C</block>
  <block id="9d4b1f9c3df948f2260e6332be9d5aed" category="cell">X66240A-05-NC</block>
  <block id="7229ff7ba1f700db7ec3bd4b5221db26" category="cell">ケーブル、25GbE、SFP28-SFP28、Cu、0.5m、-C</block>
  <block id="1ab2d2badc8592e1d029782bd25632a5" category="cell">X5532A-NC</block>
  <block id="4688dd909d449010ca4b23347351a707" category="cell">レール、4ポスト、薄型、Rnd/Sq-Hole、Sm、Adj、24-32、-C</block>
  <block id="b24ac50247ba189d666fdae929cede64" category="cell">X4024A-2-AC</block>
  <block id="25630a46b821a822994c9b1e0dd238d5" category="cell">ドライブ パック 2X1.92TB、NVMe4、SED、-C</block>
  <block id="326b6bb4ee61f9700e237d78e0a70b27" category="cell">X60130A-C</block>
  <block id="f2acaac754bf0c08463a09096b25ebd5" category="cell">IO モジュール、2PT、100GbE、-C</block>
  <block id="826f0d850b56b5bcd6026118ee4048b5" category="cell">X60132A-C</block>
  <block id="f567279f3d616d5bcfbd134b1e39b047" category="cell">IOモジュール、4PT、10/25GbE、-C</block>
  <block id="7090ee7c22ea0bf45e028538870d276f" category="cell">SW-ONTAPB-FLASH-A20-C</block>
  <block id="c2375e9a630d78f92c99f36859f2dc63" category="cell">SW、 ONTAPベース パッケージ、TB 単位、フラッシュ、A20、-C</block>
  <block id="37693cfc748049e45d87b8c7d8b9aacd" category="cell">23</block>
  <block id="1006bcc3d9e9f1297760c57c62541267" category="paragraph"><block ref="1006bcc3d9e9f1297760c57c62541267" category="inline-link-rx"></block></block>
  <block id="9bf497d692d0e146d05a76e3a34ae95f" category="inline-link-macro">OPEAプロジェクト</block>
  <block id="feeb32cac2847bc01bfab8eb7dfbbbfe" category="paragraph"><block ref="feeb32cac2847bc01bfab8eb7dfbbbfe" category="inline-link-macro-rx"></block></block>
  <block id="a64127d2271b6c8ff07ae84c3a53c90c" category="inline-link">OPEA エンタープライズ RAG 導入プレイブック</block>
  <block id="3d766654d6f2d85f314e655c63e91d81" category="paragraph"><block ref="3d766654d6f2d85f314e655c63e91d81" category="inline-link-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: 自動運転ワークロード向けNetApp StorageGRIDデータレイク - ソリューション設計</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">デビッド・アーネット、 NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851 は、機械学習 (ML) およびディープラーニング (DL) ソフトウェア開発用のデータ リポジトリおよび管理システムとしてNetApp StorageGRIDオブジェクト ストレージを使用する方法を示します。このホワイト ペーパーでは、自律走行車のソフトウェア開発におけるデータ フローと要件、およびデータ ライフサイクルを合理化するStorageGRID の機能について説明します。このソリューションは、ML および DL 開発プロセスで一般的な多段階データ パイプライン ワークフローに適用されます。</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">法律上の表示</block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="paragraph">法的通知から、著作権情報、商標、特許などを確認できます。</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">著作権</block>
  <block id="52009bb7ee17227f566cd26a02caee56" category="inline-link-macro"><block ref="52009bb7ee17227f566cd26a02caee56" category="inline-link-rx"></block></block>
  <block id="a1a9afcf552a769c282769271829889a" category="paragraph"><block ref="a1a9afcf552a769c282769271829889a" category="inline-link-macro-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">商標</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp、NetAppのロゴ、NetAppの商標一覧のページに掲載されているマークは、NetApp, Inc.の商標です。その他の会社名と製品名は、それを所有する各社の商標である場合があります。</block>
  <block id="f99aa604031e5049799e73b5c3748a98" category="inline-link-macro"><block ref="f99aa604031e5049799e73b5c3748a98" category="inline-link-rx"></block></block>
  <block id="5d545fe5152641e2ebe654e336e520e5" category="paragraph"><block ref="5d545fe5152641e2ebe654e336e520e5" category="inline-link-macro-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">特許</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">現在NetAppが所有する特許の一覧は以下のページから閲覧できます。</block>
  <block id="88e5eabd3917048b6927c42496b98f86" category="inline-link-macro"><block ref="88e5eabd3917048b6927c42496b98f86" category="inline-link-rx"></block></block>
  <block id="dd38f906b37d412de7d1c1dcf4cbf31c" category="paragraph"><block ref="dd38f906b37d412de7d1c1dcf4cbf31c" category="inline-link-macro-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">プライバシー ポリシー</block>
  <block id="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-macro"><block ref="8acb58cbd50ef1b468a020ee0bd351d3" category="inline-link-rx"></block></block>
  <block id="2352c4e1f4d0024ade0869e00e6243f4" category="paragraph"><block ref="2352c4e1f4d0024ade0869e00e6243f4" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">この検証では、生の画像セットを使用して、画像検出ユースケースの推論を実行しました。次に、推論前に Protopia 難読化を追加した同じ画像セットに対して、同じ推論タスクを実行しました。  Protopia 難読化コンポーネントの ALPHA の異なる値を使用してタスクを繰り返しました。</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">推論精度の比較</block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">この検証では、生の画像セットを使用して、画像検出ユースケースの推論を実行しました。次に、推論前に Protopia 難読化を追加した同じ画像セットに対して、同じ推論タスクを実行しました。  Protopia 難読化コンポーネントの ALPHA の異なる値を使用してタスクを繰り返しました。 Protopia 難読化のコンテキストでは、ALPHA 値は適用される難読化の量を表し、ALPHA 値が高いほど難読化のレベルが高くなります。次に、これらの異なる実行間で推論の精度を比較しました。</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">次の 2 つの表は、ユースケースの詳細と結果の概要を示しています。</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia は顧客と直接連携し、特定のユースケースに適切な ALPHA 値を決定します。</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">フェイスボックス（PyTorch） -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDBデータセット</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">プロトピアの難読化</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">アルファ</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">正確さ</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">いいえ</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">該当なし</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">はい</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.9028766627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="cf285ec96f684d6597b7ffbbfcf16197" category="doc">追加情報と謝辞の参照先</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">プロトピアAI - 機密推論</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="list-text">NVIDIA Triton 推論サーバー</block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton 推論サーバーのドキュメント</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorchのFaceBoxes</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">NetApp主席プロダクトマネージャー、マーク・ケイツ氏</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">NetApp 、テクニカル マーケティング エンジニア、Sufian Ahmad 氏</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">プロトピアAI最高技術責任者兼教授、ハディ・エスマイルザデ</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">データは、保存中、転送中、計算中の 3 つの状態で存在します。あらゆる AI 推論サービスの重要な部分は、プロセス全体を通じてデータを脅威から保護することです。推論プロセスでは外部の顧客と推論サービスを提供する企業の両方に関する個人情報が公開される可能性があるため、推論中のデータの保護は重要です。</block>
  <block id="cd9ef21e97d9c9e701bfc6d1a77634d5" category="paragraph">データは、保存中、転送中、計算中の 3 つの状態で存在します。あらゆる AI 推論サービスの重要な部分は、プロセス全体を通じてデータを脅威から保護することです。推論プロセスでは外部の顧客と推論サービスを提供する企業の両方に関する個人情報が公開される可能性があるため、推論中のデータの保護は重要です。  Protopia AI は、今日の市場における機密 AI 推論のための、目立たないソフトウェアのみのソリューションです。 Protopia では、AI には、現在の AI/ML タスクを実行するために不可欠なデータ レコード内の変換された情報のみが供給され、それ以上は供給されません。この確率的変換はマスキングの形式ではなく、キュレーションされたノイズを使用してデータの表現を数学的に変更することに基づいています。</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">ONTAP機能を備えたNetAppストレージ システムは、ローカル SSD ストレージと同等以上のパフォーマンスを提供し、 NetApp DataOps Toolkit と組み合わせることで、データ サイエンティスト、データ エンジニア、AI/ML 開発者、ビジネスまたはエンタープライズ IT 意思決定者に次のメリットをもたらします。</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">災害復旧、事業継続性、規制要件に対応したエンタープライズ グレードのデータ保護とデータ ガバナンス。</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">データ管理操作の呼び出しが簡素化され、Jupyter ノートブックのNetApp DataOps Toolkit からデータ サイエンティストのワークスペースのスナップショット コピーを迅速に取得して、バックアップと追跡が可能になります。</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetAppと Protopia のソリューションは、エンタープライズ グレードの AI 推論の導入に最適な、柔軟なスケールアウト アーキテクチャを提供します。オンプレミスとハイブリッド クラウドの両方の展開において、責任ある AI プラクティスによって機密 AI 推論要件を満たすことができるため、データ保護が可能になり、機密情報のプライバシーが確保されます。</block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">このセクションでは、ソリューション設計検証環境の概要を説明します。</block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">次の表は、ソリューション設計の検証環境の概要を示しています。</block>
  <block id="30136395f01879792198317c11831ea4" category="cell">Kubernetes</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="8b2b11d27dd7d347de30cae2db2ab86d" category="cell">NetApp Trident CSI ドライバー</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kubernetes 用NetApp DataOps ツールキット</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-py3</block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">このドキュメントでは、プライバシーの保護と責任ある AI ソリューションの導入に関連する、画像の難読化の有無にかかわらず、3 つの異なるシナリオにおける検証済みの設計ソリューションについて説明します。</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: 責任あるAIと機密推論 - NetApp AIとProtopiaイメージおよびデータ変換</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">Sathish Thyagarajan、Michael Oglesby、 NetApp Byung Hoon Ahn、Jennifer Cwagenberg、Protopia</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">画像キャプチャと画像処理の出現により、視覚的な解釈はコミュニケーションの不可欠な部分になりました。デジタル画像処理における人工知能 (AI) は、がんやその他の病気の特定といった医療分野、環境危険の研究のための地理空間視覚分析、パターン認識、犯罪対策のためのビデオ処理など、新たなビジネスチャンスをもたらします。しかし、この機会には特別な責任も伴います。</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">組織が AI に意思決定を委ねるほど、データのプライバシーとセキュリティ、および法律、倫理、規制の問題に関連するリスクを受け入れることになります。責任ある AI により、企業や政府機関は、大規模な企業における AI の導入に不可欠な信頼とガバナンスを構築できるようになります。このドキュメントでは、 NetApp のデータ管理テクノロジと Protopia データ難読化ソフトウェアを使用して機密データを非公開化し、リスクと倫理的な懸念を軽減する、3 つの異なるシナリオでNetAppによって検証された AI 推論ソリューションについて説明します。</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">消費者と企業の両方によって、さまざまなデジタルデバイスを使用して毎日何百万もの画像が生成されています。その結果、データと計算ワークロードが爆発的に増加し、企業は規模と効率を求めてクラウド コンピューティング プラットフォームを導入するようになりました。一方、パブリッククラウドへの転送では、画像データに含まれる機密情報に対するプライバシーの懸念が生じます。セキュリティとプライバシーの保証の欠如は、画像処理 AI システムの導入における主な障壁となります。</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">消去権</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">プライバシー法</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">さらに、<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> GDPR により、個人は組織に対して自分の個人データをすべて消去するよう要求する権利を有します。また、<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>公正な情報慣行の規範を確立する。写真などのデジタル画像は、データの収集、処理、消去方法を規定する GDPR では個人データを構成する場合があります。これを怠ると GDPR に準拠していないことになり、コンプライアンス違反に対する高額の罰金が科せられ、組織に深刻な損害を与える可能性があります。プライバシー原則は、機械学習 (ML) およびディープラーニング (DL) モデルの予測における公平性を確保し、プライバシー違反や規制遵守に関連するリスクを低減する、責任ある AI を実装するための基盤の 1 つです。</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">このドキュメントでは、プライバシーの保護と責任ある AI ソリューションの導入に関連する、画像の難読化の有無にかかわらず、3 つの異なるシナリオにおける検証済みの設計ソリューションについて説明します。</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">*シナリオ1*  Jupyter ノートブック内でのオンデマンド推論。</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">*シナリオ2*  Kubernetes でのバッチ推論。</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">*シナリオ3*  NVIDIA Triton 推論サーバー。</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">このソリューションでは、制約のない顔検出の問題を研究するために設計された顔領域のデータセットである顔検出データセットとベンチマーク (FDDB) を、FaceBoxes の実装用の PyTorch 機械学習フレームワークと組み合わせて使用します。このデータセットには、さまざまな解像度の 2845 枚の画像セットに含まれる 5171 個の顔の注釈が含まれています。さらに、この技術レポートでは、このソリューションを適用できる状況において、 NetApp の顧客とフィールド エンジニアから収集されたソリューション領域と関連するユース ケースの一部を紹介します。</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">この技術レポートは、次の読者を対象としています。</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">責任ある AI を設計および導入し、公共空間での顔画像処理に関するデータ保護とプライバシーの問題に対処したいビジネス リーダーおよびエンタープライズ アーキテクト。</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">プライバシーの保護と保全を目的とするデータ サイエンティスト、データ エンジニア、AI/機械学習 (ML) 研究者、AI/ML システムの開発者。</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">GDPR、CCPA、国防総省 (DoD) および政府機関のプライバシー法などの規制基準に準拠した AI/ML モデルおよびアプリケーションのデータ難読化ソリューションを設計するエンタープライズ アーキテクト。</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">機密情報を保護するディープラーニング (DL) および AI/ML/DL 推論モデルを効率的に導入する方法を探しているデータ サイエンティストと AI エンジニア。</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">このソリューションは、従来の CPU と並行して GPU の処理能力を活用し、大規模なデータセットに対するリアルタイムおよびバッチ推論 AI ワークロードを処理するように設計されています。この検証は、責任ある AI 導入を目指す組織に必要な、ML のプライバシー保護推論と最適なデータ管理を実証しています。このソリューションは、オンプレミスの中核にあるNetApp ONTAP AI、 NetApp DataOps Toolkit、および Jupyter Lab と CLI インターフェイスを使用した Protopia 難読化ソフトウェアと相互接続された、エッジおよびクラウド コンピューティング用の単一またはマルチノードの Kubernetes プラットフォームに適したアーキテクチャを提供します。次の図は、DataOps Toolkit と Protopia を搭載したNetAppによるデータ ファブリックの論理アーキテクチャの概要を示しています。</block>
  <block id="28afcbd6e097b781313de9c75adccb13" category="paragraph"><block ref="28afcbd6e097b781313de9c75adccb13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia 難読化ソフトウェアは、 NetApp DataOps Toolkit 上でシームレスに実行され、ストレージ サーバーから送信される前にデータを変換します。</block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">このセクションでは、このソリューションで検証された 3 つのシナリオの概要を説明します。</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">テストおよび検証計画</block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">このソリューション設計では、次の 3 つのシナリオが検証されました。</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">NetApp DataOps Toolkit for Kubernetes を使用してオーケストレーションされた JupyterLab ワークスペース内の推論タスク（Protopia 難読化ありとなし）。</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">NetApp DataOps Toolkit for Kubernetes を使用してオーケストレーションされたデータ ボリュームを持つ Kubernetes 上のバッチ推論ジョブ (Protopia 難読化ありとなし)。</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">NetApp DataOps Toolkit for Kubernetes を使用してオーケストレーションされたNVIDIA Triton Inference Server インスタンスを使用した推論タスク。 Triton 推論 API を呼び出す前に、画像に Protopia 難読化を適用し、ネットワーク経由で送信されるすべてのデータは難読化する必要があるという一般的な要件をシミュレートしました。このワークフローは、データが信頼できるゾーン内で収集されるが、推論のためにその信頼できるゾーンの外部に渡す必要があるユースケースに適用できます。  Protopia の難読化がなければ、機密データが信頼できるゾーンから出ることなく、このタイプのワークフローを実装することはできません。</block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">このセクションでは、検証を完了するために必要なタスクについて説明します。</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">前提条件</block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">このセクションで説明するタスクを実行するには、次のツールがインストールおよび構成された Linux または macOS ホストにアクセスできる必要があります。</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl (既存の Kubernetes クラスターにアクセスできるように構成)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">インストールと設定の手順については、<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block> 。</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">インストール手順については、<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block> 。</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">シナリオ1 – JupyterLabでのオンデマンド推論</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">AI/ML 推論ワークロード用の Kubernetes 名前空間を作成します。</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">NetApp DataOps Toolkit を使用して、推論を実行するデータを保存するための永続ボリュームをプロビジョニングします。</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">NetApp DataOps Toolkit を使用して、新しい JupyterLab ワークスペースを作成します。前の手順で作成した永続ボリュームをマウントするには、<block ref="49477e975a03ac8fbc68aea44a67d49d" prefix=" " category="inline-code"></block>オプション。必要に応じて、ワークスペースにNVIDIA GPUを割り当てます。<block ref="dfc4755b60ee7dfab3c1e88693efd099" prefix=" " category="inline-code"></block>オプション。</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">次の例では、永続ボリューム<block ref="682303bbf677ac9a205caf2d086b33d3" prefix=" " category="inline-code"></block>JupyterLabワークスペースコンテナにマウントされます。<block ref="a88bf20c35f897f8c2c3a03189e90c09" prefix=" " category="inline-code"></block> 。公式のProject Jupyterコンテナイメージを使用する場合、<block ref="3b8e9b793a1a95056575343e279719df" prefix=" " category="inline-code"></block> JupyterLab Web インターフェース内の最上位ディレクトリとして表示されます。</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">出力に指定されたURLを使用してJupyterLabワークスペースにアクセスします。<block ref="d9eb9b67c69b49a1b002e09de33d9ed9" prefix=" " category="inline-code"></block>指示。データ ディレクトリは、ワークスペースにマウントされた永続ボリュームを表します。</block>
  <block id="87209231def3204e4e4d9a18544294dd" category="paragraph"><block ref="87209231def3204e4e4d9a18544294dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">開く<block ref="8d777f385d3dfec8815d20f7496026dc" prefix=" " category="inline-code"></block>ディレクトリを作成し、推論を実行するファイルをアップロードします。ファイルがデータ ディレクトリにアップロードされると、ワークスペースにマウントされた永続ボリュームに自動的に保存されます。ファイルをアップロードするには、次の画像に示すように、「ファイルのアップロード」アイコンをクリックします。</block>
  <block id="e3b5f0c1efdf69526c759b1d33d05e5b" category="paragraph"><block ref="e3b5f0c1efdf69526c759b1d33d05e5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">最上位ディレクトリに戻り、新しいノートブックを作成します。</block>
  <block id="8c8d84a9a1e17bebaa40920247f46e13" category="paragraph"><block ref="8c8d84a9a1e17bebaa40920247f46e13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">推論コードをノートブックに追加します。次の例は、画像検出ユースケースの推論コードを示しています。</block>
  <block id="cf7a1e02f4be1c22e175847fae951746" category="paragraph"><block ref="cf7a1e02f4be1c22e175847fae951746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fa1b8c326d7c59c16ba99f22361e9e4" category="paragraph"><block ref="9fa1b8c326d7c59c16ba99f22361e9e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">推論コードに Protopia 難読化を追加します。 Protopia は顧客と直接連携してユースケース固有のドキュメントを提供しており、この技術レポートの範囲外です。次の例は、Protopia 難読化が追加された画像検出ユースケースの推論コードを示しています。</block>
  <block id="a782d09a204dcf45c8852abf7684c340" category="paragraph"><block ref="a782d09a204dcf45c8852abf7684c340" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b937401d5d173ae3750bccadcff9481e" category="paragraph"><block ref="b937401d5d173ae3750bccadcff9481e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">シナリオ2 – Kubernetesでのバッチ推論</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">新しい永続ボリュームに推論を実行するデータを入力します。</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps Toolkit S3 データムーバーの機能</block>
  <block id="685f44c17611b1391b579c696f310b98" category="paragraph">PVC にデータをロードする方法はいくつかあります。データが現在NetApp StorageGRIDやAmazon S3などのS3互換オブジェクトストレージプラットフォームに保存されている場合は、<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block> 。もう1つの簡単な方法は、JupyterLabワークスペースを作成し、JupyterLabウェブインターフェースからファイルをアップロードすることです。これは、「<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> 。"</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">バッチ推論タスク用の Kubernetes ジョブを作成します。次の例は、画像検出ユースケースのバッチ推論ジョブを示しています。このジョブは、画像セット内の各画像に対して推論を実行し、推論精度メトリックを stdout に書き込みます。</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">推論ジョブが正常に完了したことを確認します。</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">推論ジョブに Protopia 難読化を追加します。 Protopia から直接 Protopia 難読化を追加するためのユースケース固有の手順は、この技術レポートの範囲外です。次の例は、ALPHA 値 0.8 を使用して Protopia 難読化を追加した顔検出ユースケースのバッチ推論ジョブを示しています。このジョブは、画像セット内の各画像に対して推論を実行する前に Protopia 難読化を適用し、推論精度メトリックを標準出力に書き込みます。</block>
  <block id="babeb9cd0280f29f38c9a4c3029f7ba0" category="inline-link-macro">推論精度の比較。</block>
  <block id="f4d99d417d0adde7f8d0f1a70caac126" category="paragraph">この手順を ALPHA 値 0.05、0.1、0.2、0.4、0.6、0.8、0.9、0.95 に対して繰り返しました。結果は以下でご覧いただけます<block ref="b3380bdc8f9311566c95bcb62c7aea42" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">シナリオ3 – NVIDIA Triton推論サーバー</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">NetApp DataOps Toolkit を使用して、 NVIDIA Triton Inference Server のモデル リポジトリとして使用する永続ボリュームをプロビジョニングします。</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">形式</block>
  <block id="898dfcda591317ac60dd8d6af3aff189" category="list-text">モデルを新しい永続ボリュームに保存します。<block ref="2001a6caf72de652d98c6c64bc75a4e8" category="inline-link-rx"></block> NVIDIA Triton 推論サーバーによって認識されます。</block>
  <block id="23ed8d1b8cbc461ebdbedcdb67ee7718" category="paragraph">PVC にデータをロードする方法はいくつかあります。簡単な方法は、JupyterLabワークスペースを作成し、JupyterLabウェブインターフェースからファイルをアップロードすることです。これは、「<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block> 。"</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">NetApp DataOps Toolkit を使用して、新しいNVIDIA Triton Inference Server インスタンスを展開します。</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Triton クライアント SDK を使用して推論タスクを実行します。次の Python コードの抜粋では、Triton Python クライアント SDK を使用して、顔検出ユースケースの推論タスクを実行します。この例では、Triton API を呼び出して推論用の画像を渡します。その後、Triton 推論サーバーはリクエストを受信し、モデルを呼び出し、推論出力を API 結果の一部として返します。</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">推論コードに Protopia 難読化を追加します。 Protopia から直接 Protopia 難読化を追加するためのユースケース固有の手順は見つかりますが、このプロセスはこの技術レポートの範囲外です。次の例は、前の手順 5 で示したものと同じ Python コードですが、Protopia の難読化が追加されています。</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">画像が Triton API に渡される前に、Protopia 難読化が画像に適用されることに注意してください。したがって、難読化されていないイメージはローカル マシンから外に出ることはありません。難読化された画像のみがネットワークを介して渡されます。このワークフローは、データが信頼できるゾーン内で収集されるが、推論のためにその信頼できるゾーンの外部に渡す必要があるユースケースに適用できます。  Protopia の難読化がなければ、機密データが信頼できるゾーンから出ることなく、このタイプのワークフローを実装することはできません。</block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">この検証では、1920 x 1080 ピクセルの画像に Protopia 難読化を 5 回適用し、そのたびに難読化手順が完了するまでにかかった時間を測定しました。</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">難読化速度</block>
  <block id="6977bb3543f8de6dcfa78f7970349ba1" category="paragraph">難読化を適用するために、単一のNVIDIA V100 GPU 上で実行される PyTorch を使用し、実行の合間に GPU キャッシュをクリアしました。難読化ステップは、5 回の実行でそれぞれ 5.47 ミリ秒、5.27 ミリ秒、4.54 ミリ秒、5.24 ミリ秒、4.84 ミリ秒かかりました。平均速度は5.072msでした。</block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">このセクションでは、このソリューションを完了するために必要なさまざまな技術コンポーネントの概要を説明します。</block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">プロトピア</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI は、今日の市場において、目立たない、機密推論のためのソフトウェアのみのソリューションを提供しています。  Protopia ソリューションは、機密情報の漏洩を最小限に抑えることで、推論サービスに比類のない保護を提供します。 AI には、手元のタスクを実行するために本当に必要なデータ レコードの情報のみが与えられ、それ以上の情報は与えられません。ほとんどの推論タスクでは、すべてのデータ レコードに存在するすべての情報が使用されるわけではありません。 AI が画像、音声、ビデオ、あるいは構造化された表形式のデータを使用するかどうかに関係なく、Protopia は推論サービスに必要なものだけを提供します。特許取得済みのコアテクノロジーは、数学的にキュレーションされたノイズを使用してデータを確率的に変換し、特定の ML サービスに必要のない情報を改ざんします。このソリューションはデータをマスクするのではなく、厳選されたランダムノイズを使用してデータ表現を変更します。</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">Protopia ソリューションは、モデルの機能に関する入力特徴空間内の関連情報を保持しながら、表現を変更する問題を勾配ベースの摂動最大化法として定式化します。この検出プロセスは、ML モデルのトレーニングの最後に微調整パスとして実行されます。パスによって確率分布のセットが自動的に生成された後、低オーバーヘッドのデータ変換によってこれらの分布からのノイズ サンプルがデータに適用され、推論のためにモデルに渡される前に難読化されます。</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">DGX A100 システムとNetAppクラウド接続ストレージ システムを搭載したNetApp ONTAP AI リファレンス アーキテクチャは、 NetAppとNVIDIAによって開発および検証されました。これにより、IT 組織に次の利点をもたらすアーキテクチャが提供されます。</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">設計の複雑さを排除</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">コンピューティングとストレージの独立したスケーリングが可能</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">顧客が小規模から始めてシームレスに拡張できるようにする</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">さまざまなパフォーマンスとコストポイントに応じた幅広いストレージオプションを提供</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI は、DGX A100 システムとNetApp AFF A800ストレージ システムを最先端のネットワークと緊密に統合します。 ONTAP AI は、設計の複雑さと推測を排除することで AI の導入を簡素化します。お客様は、エッジからコア、クラウドに至るまでデータをインテリジェントに管理しながら、小規模から始めて中断なく拡張することができます。</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">次の図は、DGX A100 システムを使用したONTAP AI ファミリ ソリューションのいくつかのバリエーションを示しています。  AFF A800システムのパフォーマンスは、最大 8 台の DGX A100 システムで検証されます。 ONTAPクラスタにストレージ コントローラ ペアを追加することで、アーキテクチャを複数のラックに拡張し、多数の DGX A100 システムとペタバイト単位のストレージ容量を線形パフォーマンスでサポートできるようになります。このアプローチは、使用される DL モデルのサイズと必要なパフォーマンス メトリックに基づいて、コンピューティングとストレージの比率を個別に変更できる柔軟性を提供します。</block>
  <block id="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="paragraph"><block ref="a28d0dc585dd816bf7bcce4c5f5f6dd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NVIDIA DGX A100 システムと Mellanox Spectrum Ethernet スイッチを搭載したNetApp ONTAP AI。</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">ONTAP AIの詳細については、以下を参照してください。<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">NetAppの最新世代のストレージ管理ソフトウェアであるONTAP 9.11 により、企業はインフラストラクチャを最新化し、クラウド対応のデータセンターに移行できるようになります。 ONTAP は業界をリードするデータ管理機能を活用し、データの保存場所に関係なく、単一のツール セットでデータの管理と保護を可能にします。また、エッジ、コア、クラウドなど、必要な場所にデータを自由に移動することもできます。  ONTAP 9.11 には、データ管理を簡素化し、重要なデータを高速化および保護し、ハイブリッド クラウド アーキテクチャ全体で次世代のインフラストラクチャ機能を有効にする多数の機能が含まれています。</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit は、開発者、データ サイエンティスト、DevOps エンジニア、データ エンジニアが、新しいデータ ボリュームまたは JupyterLab ワークスペースのほぼ瞬時のプロビジョニング、データ ボリュームまたは JupyterLab ワークスペースのほぼ瞬時のクローン作成、追跡可能性やベースライン設定のためのデータ ボリュームまたは JupyterLab ワークスペースのほぼ瞬時のスナップショット作成など、さまざまなデータ管理タスクを簡単に実行できるようにする Python ライブラリです。この Python ライブラリは、コマンドライン ユーティリティとして、または任意の Python プログラムや Jupyter ノートブックにインポートできる関数のライブラリとして機能します。</block>
  <block id="2dcb054d023d8770b9ba0125434b8f20" category="paragraph">NVIDIA Triton Inference Server は、モデルの展開と実行を標準化し、実稼働環境で高速かつスケーラブルな AI を実現するのに役立つオープンソースの推論サービス ソフトウェアです。  Triton Inference Server は、チームが GPU または CPU ベースのインフラストラクチャ上の任意のフレームワークからトレーニング済みの AI モデルを展開、実行、拡張できるようにすることで、AI 推論を効率化します。  Triton Inference Server は、TensorFlow、 NVIDIA TensorRT、PyTorch、MXNet、OpenVINO など、すべての主要なフレームワークをサポートしています。 Triton は Kubernetes と統合されており、主要なパブリック クラウド AI および Kubernetes プラットフォームで使用できるオーケストレーションとスケーリングを実現します。また、多くの MLOps ソフトウェア ソリューションとも統合されています。</block>
  <block id="6532191b754c006509ce4006a972990e" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block>オープンソースの ML フレームワークです。  GPU と CPU を使用するディープラーニング向けに最適化されたテンソル ライブラリです。 PyTorch パッケージには、他の便利なユーティリティの中でも、テンソルを効率的にシリアル化するための多くのユーティリティを提供する多次元テンソルのデータ構造が含まれています。また、コンピューティング機能を備えたNVIDIA GPU でテンソル計算を実行できるようにする CUDA 対応機能も備えています。この検証では、OpenCV-Python (cv2) ライブラリを使用して、Python の最も直感的なコンピューター ビジョンの概念を活用しながらモデルを検証します。</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">パフォーマンスと低レイテンシ。  ONTAP は、可能な限り低いレイテンシで最高のスループットを提供します。</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">データ保護：ONTAP は、すべてのプラットフォームにわたる共通管理を備えた組み込みのデータ保護機能を提供します。</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">マルチテナントと多要素認証。  ONTAP は、最高レベルのセキュリティでインフラストラクチャ リソースを共有できるようにします。</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">シームレスなスケーリングと中断のない運用。 ONTAP は、既存のコントローラおよびスケールアウト クラスタへの無停止の容量追加をサポートします。お客様は、コストのかかるデータ移行や停止なしで、NVMe や 32Gb FC などの最新テクノロジーにアップグレードできます。</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astraコントロール</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astraコントロールサービス</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra製品ファミリーは、 NetAppのストレージおよびデータ管理テクノロジーを活用し、オンプレミスおよびパブリック クラウドの Kubernetes アプリケーション向けのストレージおよびアプリケーション対応のデータ管理サービスを提供します。これにより、Kubernetes アプリケーションを簡単にバックアップし、データを別のクラスターに移行し、実用的なアプリケーションのクローンを即座に作成できるようになります。パブリッククラウドで実行されるKubernetesアプリケーションを管理する必要がある場合は、<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block> 。  Astra Control Service は、Google Kubernetes Engine (GKE) および Azure Kubernetes Service (AKS) 内の Kubernetes クラスターのアプリケーション対応データ管理を提供する、 NetAppが管理するサービスです。</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">Astra<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block>NetAppの は、永続ストレージの作成、管理、および使用を簡素化する、Docker および Kubernetes 向けのオープンソースの動的ストレージ オーケストレーターです。  Kubernetes ネイティブ アプリケーションであるTridentは、Kubernetes クラスター内で直接実行されます。  Trident を使用すると、顧客は DL コンテナ イメージをNetAppストレージにシームレスに導入でき、AI コンテナの導入にエンタープライズ グレードのエクスペリエンスを提供できます。  Kubernetes ユーザー (ML 開発者、データ サイエンティストなど) は、オーケストレーションとクローンを作成、管理、自動化して、 NetAppテクノロジーを活用した高度なデータ管理機能を活用できます。</block>
  <block id="45a189f17e7eec44ce720f6a979e501e" category="paragraph"><block ref="9f25cf06e22037e38bb7442b4d301b6c" category="inline-link-rx"></block>高速かつ安全なデータ同期を実現するNetAppサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、Amazon Simple Storage Service (Amazon S3)、Amazon Elastic File System (Amazon EFS)、Azure Blob、Google Cloud Storage、または IBM Cloud Object Storage の間でファイルを転送する必要がある場合でも、 BlueXP Copy and Sync を使用すると、必要な場所にファイルを迅速かつ安全に移動します。データが転送されると、ソースとターゲットの両方で完全に使用できるようになります。  BlueXP Copy and Syncc は、事前に定義されたスケジュールに基づいてデータを継続的に同期し、差分のみを移動するため、データ複製にかかる時間とコストが最小限に抑えられます。  BlueXP Copy and Sync は、セットアップと使用が非常に簡単なソフトウェア アズ ア サービス (SaaS) ツールです。  BlueXP Copy and Sync によってトリガーされるデータ転送は、データ ブローカーによって実行されます。  BlueXPコピーおよび同期データブローカーは、AWS、Azure、Google Cloud Platform、またはオンプレミスにデプロイできます。</block>
  <block id="b8bc3287c1345ab1a36c796d2de0aaa2" category="section-title">NetApp BlueXP分類</block>
  <block id="196f1872673d3381d912260929325605" category="paragraph">強力なAIアルゴリズムによって駆動され、<block ref="860dd213c65646bc2292a7454f4cfbac" category="inline-link-rx"></block>データ資産全体にわたって自動制御とデータ ガバナンスを提供します。コスト削減箇所を簡単に特定し、コンプライアンスとプライバシーに関する懸念を特定し、最適化の機会を見つけることができます。  BlueXP分類ダッシュボードを使用すると、重複データを識別して冗長性を排除し、個人データ、非個人データ、機密データをマッピングし、機密データと異常に関するアラートをオンにするための洞察が得られます。</block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">デジタル画像処理には多くの利点があり、多くの組織が視覚表現に関連するデータを最大限に活用できるようになります。このNetAppと Protopia のソリューションは、ML/DL ライフサイクル全体にわたって AI/ML データを保護し、プライベート化するための独自の AI 推論設計を提供します。これにより、顧客は機密データの所有権を保持し、プライバシーに関する懸念を軽減することでパブリック クラウドまたはハイブリッド クラウドの導入モデルを使用して拡張性と効率性を高め、エッジで AI 推論を導入できるようになります。</block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">環境情報</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">環境危険の分野で、業界が地理空間分析を活用できる方法は数多くあります。政府や公共事業局は、公衆衛生や気象状況に関する実用的な洞察を得て、パンデミックや山火事などの自然災害の際に国民に適切なアドバイスを提供できるようになります。たとえば、空港や病院などの公共の場で、感染者のプライバシーを侵害することなく COVID 陽性患者を特定し、関係当局や付近の一般の人々に必要な安全対策を警告することができます。</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">エッジデバイスウェアラブル</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">軍隊や戦場では、エッジでの AI 推論をウェアラブル デバイスとして使用し、兵士の健康状態を追跡し、運転者の行動を監視し、兵士のプライバシーを維持し保護しながら、軍用車両に近づく際の安全性と関連するリスクについて当局に警告することができます。軍隊の未来は、戦場のモノのインターネット (IoBT) と軍事用のモノのインターネット (IoMT) によってハイテク化しており、兵士が敵を識別し、迅速なエッジ コンピューティングを使用して戦闘でより優れたパフォーマンスを発揮できるように支援するウェアラブル戦闘装備が登場しています。ドローンやウェアラブル機器などのエッジデバイスから収集された視覚データを保護し、保存することは、ハッカーや敵を寄せ付けないために非常に重要です。</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">非戦闘員避難作戦</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">非戦闘員避難作戦（NEO）は、生命の危険にさらされている米国市民および米国国民、国防総省の民間人、および指定された人物（ホスト国（HN）および第三国国民（TCN））を適切な安全な避難場所へ避難させるのを支援するために国防総省によって実施されます。実施されている行政管理では、主に手作業による避難者の審査プロセスが採用されています。ただし、高度に自動化された AI/ML ツールと AI/ML ビデオ難読化テクノロジーを組み合わせることで、避難者の識別、避難者の追跡、脅威のスクリーニングの精度、セキュリティ、速度が向上する可能性があります。</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">ヘルスケアとバイオメディカル研究</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">画像処理は、コンピューター断層撮影 (CT) や磁気共鳴画像 (MRI) から取得した 3D 画像から病理を診断し、手術計画を立てるために使用されます。  HIPAA プライバシー ルールは、すべての個人情報や写真などのデジタル画像について、組織がデータを収集、処理、消去する方法を規定しています。 HIPAA セーフ ハーバー規制に基づいてデータを共有可能にするには、顔全体の写真画像およびそれに類似する画像を削除する必要があります。構造CT/MR画像から個人の顔の特徴を隠すために使用される匿名化や頭蓋骨除去アルゴリズムなどの自動化技術は、生物医学研究機関のデータ共有プロセスの不可欠な部分になっています。</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI/ML分析のクラウド移行</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">データ保護</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">従来、エンタープライズ顧客は AI/ML モデルをオンプレミスでトレーニングおよび展開してきました。規模の経済と効率性の理由から、これらの顧客は AI/ML 機能をパブリック、ハイブリッド、またはマルチクラウドのクラウド展開に移行するように拡大しています。ただし、他のインフラストラクチャに公開できるデータには制限があります。  NetAppソリューションは、次のようなあらゆるサイバーセキュリティの脅威に対応します。<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block>セキュリティ評価も実行し、Protopia のデータ変換と組み合わせることで、画像処理 AI/ML ワークロードをクラウドに移行する際のリスクを最小限に抑えます。</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link-macro">TR-4886 エッジにおけるAI推論</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">知性 vs プライバシー</block>
  <block id="7c93429acdde399d280f2e20425ac745" category="paragraph">他の業界におけるエッジコンピューティングとAI推論のさらなるユースケースについては、以下を参照してください。<block ref="c2ef3f1fa710d59c08d58b9025616182" category="inline-link-macro-rx"></block> NetApp AIブログ<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>。</block>
  <block id="59a6ec9eb2075dc5ac847799c3c9b4e0" category="summary">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps - 追加情報の入手先</block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">詳細情報の入手方法</block>
  <block id="44997fb529c7b7d20853c30af9ad918a" category="list-text">ドミノデータラボ</block>
  <block id="1182c61de35b31af3e72f77e61442c77" category="inline-link-macro"><block ref="1182c61de35b31af3e72f77e61442c77" category="inline-link-rx"></block></block>
  <block id="bd0007c3dcc92207ee01f0427da0a4be" category="paragraph"><block ref="bd0007c3dcc92207ee01f0427da0a4be" category="inline-link-macro-rx"></block></block>
  <block id="d7574cd2803b94ddaa90cab193a19ba2" category="list-text">ドミノネクサス</block>
  <block id="2703dd45bd40545fb60997c2d3afe208" category="inline-link-macro"><block ref="2703dd45bd40545fb60997c2d3afe208" category="inline-link-rx"></block></block>
  <block id="14a3e5a8d5046236b5959a8860c405eb" category="paragraph"><block ref="14a3e5a8d5046236b5959a8860c405eb" category="inline-link-macro-rx"></block></block>
  <block id="1273c8a63109161e6fd1f18d6998523f" category="list-text">NetAppBlueXP</block>
  <block id="43e196fd7d1a86adce26084a27e3d664" category="inline-link-macro"><block ref="43e196fd7d1a86adce26084a27e3d664" category="inline-link-rx"></block></block>
  <block id="2edabab990aa6b9914f978e6885781f2" category="paragraph"><block ref="2edabab990aa6b9914f978e6885781f2" category="inline-link-macro-rx"></block></block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="list-text">NetApp ONTAPデータ管理ソフトウェア</block>
  <block id="5b8aea48f614361f60f00e194e1b0976" category="inline-link-macro"><block ref="5b8aea48f614361f60f00e194e1b0976" category="inline-link-rx"></block></block>
  <block id="59f3782142c74894e9aa57873085e394" category="paragraph"><block ref="59f3782142c74894e9aa57873085e394" category="inline-link-macro-rx"></block></block>
  <block id="13ed1686110be86a2aeef6d76d4ec65e" category="list-text">NetApp AIソリューション</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-macro"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="501b3e03ab68e967ec7e74647ece575b" category="paragraph"><block ref="501b3e03ab68e967ec7e74647ece575b" category="inline-link-macro-rx"></block></block>
  <block id="5acaa2031a97473b7a185dc30ce9e62d" category="list-text">Domino Data Lab、技術提携担当 SA ディレクター、Josh Mineroff 氏</block>
  <block id="ed2311020217442776d108d1f99b7521" category="list-text">ニコラス・ジャブロンスキー、Domino Data Lab フィールド CTO</block>
  <block id="5c38b0c6106b026873b5212202e5eb20" category="list-text">NetApp 、ソリューション アーキテクト、Prabu Arjunan 氏</block>
  <block id="958996b71437140af7dadceec3c0acf1" category="list-text">ブライアン・ヤング、 NetApp 、テクノロジーアライアンスパートナー、グローバルアライアンスディレクター</block>
  <block id="182f685e8ff46f3bde7c8c63a6d3e8eb" category="summary">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps - アーキテクチャ</block>
  <block id="22a02f1b77fcd49462c4d58a6e2425fb" category="paragraph">このソリューションは、Domino Nexus のハイブリッド マルチクラウド ワークロード スケジューリング機能とNetAppデータ サービスを組み合わせて、統合されたハイブリッド クラウド MLOps プラットフォームを作成します。詳細については、次の表を参照してください。</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">環境</block>
  <block id="1a01eb6a884a288b667e023501d09eea" category="cell">MLOps コントロールプレーン</block>
  <block id="51c0d15bebbbdb19d5e1bde9bf2bc1ba" category="inline-link-macro">Domino Nexus を搭載した Domino エンタープライズ AI プラットフォーム</block>
  <block id="a0133d74aa4167bee7ec6bb2830b32ab" category="cell"><block ref="a0133d74aa4167bee7ec6bb2830b32ab" category="inline-link-macro-rx"></block></block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="cell">AWS</block>
  <block id="dedb71b645ad83baa13a64e834ea32a3" category="cell">MLOps プラットフォーム コンピューティング環境</block>
  <block id="1f26213ee3d03d1bce28558ef8ff15ff" category="inline-link-macro">Domino Nexus データプレーン</block>
  <block id="f2d3c460a5a76b316899ec775650d7ea" category="cell"><block ref="f2d3c460a5a76b316899ec775650d7ea" category="inline-link-macro-rx"></block></block>
  <block id="89f5a1a21bf30d5f2db943911b2d22f2" category="cell">AWS、オンプレミスデータセンター</block>
  <block id="1698863d644408b6fdc41803a6a1c234" category="cell">オンプレミスコンピューティングプラットフォーム</block>
  <block id="2c02a900da9ea696e0b13c405974ca0b" category="cell"><block ref="e08fa5b25dd32bed0a8727bee0e3fdd0" category="inline-link-macro-rx"></block>と<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="59f10558cba0587bc03fb56826f8cd4b" category="cell">オンプレミスデータセンター</block>
  <block id="29e13ea538f81a8bf3cea3900519c8a1" category="cell">クラウドコンピューティングプラットフォーム</block>
  <block id="480c9b5f979d1ce95ea2a58b09826d1b" category="inline-link-macro">Amazon Elastic Kubernetes サービス (EKS)</block>
  <block id="ff969739d0750911a50d47ea892fad80" category="cell"><block ref="4ecdb2c4c840fbc0e496687cc8bf58fe" category="inline-link-macro-rx"></block>と<block ref="c8e9826c7461e34f8a6ee68d2d629f27" category="inline-link-macro-rx"></block></block>
  <block id="cd3aefaae18f11e3ecc3de62739183f3" category="cell">オンプレミスデータプラットフォーム</block>
  <block id="e16a11bc6041db3c2b26ef054c8b8847" category="inline-link-macro">NetAppストレージアプライアンス</block>
  <block id="b331d50869bea7c3b019d322cffc1f03" category="cell"><block ref="ea0807fcd7c8182254e93c3bfdf94abc" category="inline-link-macro-rx"></block>搭載<block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="0c9ae535d9e81d6e268c0ea087be535f" category="cell">クラウドデータプラットフォーム</block>
  <block id="35f7c29efc923e8a7920a0b331095d71" category="inline-link-macro">Amazon FSx ONTAP</block>
  <block id="2a9165a68b73a53b924deda7b9ec0251" category="cell"><block ref="2a9165a68b73a53b924deda7b9ec0251" category="inline-link-macro-rx"></block></block>
  <block id="b497a71f092b521e07c06ade7296c159" category="paragraph"><block ref="b497a71f092b521e07c06ade7296c159" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f92651ef1a171bf24e3a0279a4f656f" category="summary">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps - 異なる環境間で同じデータにアクセス</block>
  <block id="2167fcd754f38c037a8a5fc219634638" category="doc">異なる環境間で同じデータにアクセスする</block>
  <block id="2b2213cc89a71238bd2629046704d311" category="paragraph">このセクションでは、異なるコンピューティング環境間で同じデータにアクセスするために実行する必要があるタスクについて説明します。 Domino MLOps プラットフォームでは、コンピューティング環境は「データ プレーン」と呼ばれます。データが 1 つのデータ プレーンのNetAppボリューム上に存在し、別のデータ プレーンからそのデータにアクセスする必要がある場合は、このセクションで概説されているタスクに従ってください。この種のシナリオは、多くの場合「バースト」と呼ばれますが、宛先環境がクラウドの場合は「クラウド バースト」と呼ばれます。この機能は、制約のあるコンピューティング リソースや過剰にサブスクライブされたコンピューティング リソースを処理するときに必要になることがよくあります。たとえば、オンプレミスのコンピューティング クラスターがオーバーサブスクライブされている場合、ワークロードをクラウドにスケジュールして、すぐに開始できるようにすることができます。</block>
  <block id="8e259831056b970e9e9ad97044e756ea" category="paragraph">別のデータ プレーンに存在するNetAppボリュームにアクセスするには、2 つの推奨オプションがあります。これらのオプションについては、以下のサブセクションで概説します。特定の要件に応じて、これらのオプションのいずれかを選択してください。次の表に、2 つのオプションの利点と欠点を示します。</block>
  <block id="054b4f3ea543c990f6b125f41af6ebf7" category="cell">オプション</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="cell">利点</block>
  <block id="0cfc0523189294ac086e11c8e286ba2d" category="cell">欠点</block>
  <block id="a5a315a3bc09fc65d5b92a61203e604b" category="cell">オプション1 - キャッシュ</block>
  <block id="542d0200f163f8f3533463dd59fe0270" category="cell">- よりシンプルなワークフロー - ニーズに基づいてデータのサブセットをキャッシュする機能 - データをソースに書き戻す機能 - リモートコピーの管理が不要</block>
  <block id="7426e3bde1c62fb806a70f18c6134316" category="cell">- キャッシュがハイドレートされるため、初期データ アクセスのレイテンシが増加します。</block>
  <block id="aaa4d30d61e64cea712b7c05c68eb117" category="cell">オプション2 - ミラー</block>
  <block id="cbefd7ef29f92291b21681c43ba469b7" category="cell">- ソースボリュームの完全なコピー - キャッシュハイドレーションによるレイテンシの増加なし（ミラー操作完了後）</block>
  <block id="03dab0d003c274e0f366cd0df3efb059" category="cell">- データにアクセスする前にミラー操作が完了するまで待つ必要がある - リモートコピーを管理する必要がある - ソースに書き戻す機能がない</block>
  <block id="f794ea935b3f3b976964bf0990d05005" category="section-title">オプション1 - 別のデータプレーンにあるボリュームのキャッシュを作成する</block>
  <block id="79849c69657d54d5bfdd901f71375897" category="inline-link-macro">NetApp FlexCacheテクノロジー</block>
  <block id="a816bf9775484a9a7049d55ece7f5396" category="paragraph">と<block ref="bb0419306e9b544a3e597acbf1d444f1" category="inline-link-macro-rx"></block>、別のデータ プレーンに存在するNetAppボリュームのキャッシュを作成できます。たとえば、オンプレミスのデータプレーンにNetAppボリュームがあり、AWS データプレーンでそのボリュームにアクセスする必要がある場合は、AWS にボリュームのキャッシュを作成できます。このセクションでは、別のデータ プレーンに存在するNetAppボリュームのキャッシュを作成するために実行する必要があるタスクの概要を説明します。</block>
  <block id="d93488703b54616875bcacc4afd140a7" category="section-title">移行先環境でFlexCacheボリュームを作成する</block>
  <block id="5d03f3f921e1e11afbd6bc02646a4b6f" category="admonition">移行先環境がオンプレミスのデータセンターである場合は、オンプレミスのONTAPシステムにFlexCacheボリュームを作成します。移行先環境が AWS の場合は、 Amazon FSx ONTAPインスタンスにFlexCacheボリュームを作成します。</block>
  <block id="a53f62411ee21cbe84822e3eba531ca4" category="paragraph">まず、移行先環境にFlexCacheボリュームを作成する必要があります。</block>
  <block id="671e0b00bec7311fe1a27ae3b1374868" category="inline-link-macro">BlueXP volume cachingのドキュメント</block>
  <block id="25d1d7fbc173abf20974acc2fd19014b" category="paragraph">FlexCacheボリュームを作成するには、 BlueXPを使用することをお勧めします。  BlueXPでFlexCacheボリュームを作成するには、<block ref="13882193b90946980fb2e14f0dc3f833" category="inline-link-macro-rx"></block> 。</block>
  <block id="597fd5f01aeae294735b75c08203b6dd" category="paragraph">BlueXPを使用しない場合は、 ONTAP System Manager またはONTAP CLI を使用してFlexCacheボリュームを作成できます。  System ManagerでFlexCacheボリュームを作成するには、<block ref="01bbf1f7353a360c52874272bfd82e21" category="inline-link-macro-rx"></block> 。  ONTAP CLIを使用してFlexCacheボリュームを作成するには、<block ref="91e4088944fb7c016c63d36e00422b16" category="inline-link-macro-rx"></block> 。</block>
  <block id="e4de6f9df9cd48ef525131de3cb21481" category="inline-link-macro">BlueXP API</block>
  <block id="0ec641cfacd36c8e22a334135e2abdac" category="inline-link-macro">ONTAP REST API</block>
  <block id="ebf440be7bdce857e55ec25910ae837b" category="inline-link-macro">ONTAP Ansibleコレクション</block>
  <block id="dd7a007ea7e610e168238b6d6ab542a1" category="paragraph">このプロセスを自動化したい場合は、<block ref="f07bcb7e875f8bb20680b339fb58364a" category="inline-link-macro-rx"></block> 、その<block ref="0966e902a53f3a5becbd165bbdc18e79" category="inline-link-macro-rx"></block>、または<block ref="62c3d824298cc8f488bda82279b91e73" category="inline-link-macro-rx"></block>。</block>
  <block id="2f37e297d79532f437d3ab48727a61c0" category="admonition">System Manager はAmazon FSx ONTAPでは使用できません。</block>
  <block id="20f99b2a7f22945f3d769fa1def1e403" category="section-title">FlexCacheボリュームをDominoに公開する</block>
  <block id="c9743d6f9b7fcd7047ce3eb9d1f2a273" category="inline-link-macro">「既存のNetAppボリュームをDominoに公開する」セクション</block>
  <block id="82a25bd099304632e33529b36f2ac5de" category="paragraph">次に、 FlexCacheボリュームを Domino MLOps プラットフォームに公開する必要があります。  FlexCacheボリュームをDominoに公開するには、「 Tridentによってプロビジョニングされていない既存のNFSボリュームを公開する」サブセクションに記載されている手順に従ってください。<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>このソリューションの。</block>
  <block id="1d25e828bd3386ce7ef8b97572c88781" category="paragraph">これで、次のスクリーンショットに示すように、宛先データ プレーンでジョブとワークスペースを起動するときに、 FlexCacheボリュームをマウントできるようになります。</block>
  <block id="edaa69742537cd645340e6ec55f0e7c2" category="section-title">FlexCacheボリュームを作成する前に</block>
  <block id="7708950a83e2f559b43ad1d7bc08a440" category="paragraph"><block ref="7708950a83e2f559b43ad1d7bc08a440" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7bf27913e6097a43d318c500146c1e1" category="section-title">FlexCacheボリュームをDominoに公開した後</block>
  <block id="acacf35ed5b32878a29f6d32e6a11ffe" category="paragraph"><block ref="acacf35ed5b32878a29f6d32e6a11ffe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9be78ccf5bdf4dc10f0e5d25b893eeb" category="section-title">オプション2 - 別のデータプレーンにあるボリュームを複製する</block>
  <block id="0e6ab030c4eacec9efa80d3df6cd643b" category="inline-link-macro">NetApp SnapMirrorデータレプリケーションテクノロジー</block>
  <block id="124468d30e8b5047c5fe1b160b4fcbd2" category="paragraph">と<block ref="ebe914c00393f99bd92af5cffa8376b0" category="inline-link-macro-rx"></block>、別のデータ プレーンに存在するNetAppボリュームのコピーを作成できます。たとえば、オンプレミスのデータプレーンにNetAppボリュームがあり、AWS データプレーンでそのボリュームにアクセスする必要がある場合は、AWS にボリュームのコピーを作成できます。このセクションでは、別のデータ プレーンに存在するNetAppボリュームのコピーを作成するために実行する必要があるタスクの概要を説明します。</block>
  <block id="050a227810327b3bcfd311be38b7d202" category="section-title">SnapMirror関係の作成</block>
  <block id="fef6b7d4f88331bab85d2eb944d43e9b" category="paragraph">まず、ソース ボリュームと宛先環境の新しい宛先ボリュームの間にSnapMirror関係を作成する必要があります。宛先ボリュームは、 SnapMirror関係を作成するプロセスの一環として作成されることに注意してください。</block>
  <block id="62390de09bd56fbb6d4533a188f4f201" category="inline-link-macro">BlueXP replicationドキュメント</block>
  <block id="6fbd84bba212db826d8a94b992bd6324" category="paragraph">SnapMirror関係を作成するには、 BlueXPを使用することをお勧めします。  BlueXPとのSnapMirror関係を作成するには、<block ref="b08e4ece79f7d1aa7f110b298b659fae" category="inline-link-macro-rx"></block> 。</block>
  <block id="052be79cbb457a1391bb0a6839e610d3" category="paragraph">BlueXPを使用しない場合は、 ONTAP System Manager またはONTAP CLI を使用してSnapMirror関係を作成できます。  System ManagerでSnapMirror関係を作成するには、<block ref="665d2354c4ea508e65993c5ec9dc3fa1" category="inline-link-macro-rx"></block> 。  ONTAP CLIを使用してSnapMirror関係を作成するには、<block ref="bf03311f5c6980a3d817528b27741438" category="inline-link-macro-rx"></block> 。</block>
  <block id="805b58c51fa6bf98d530bbc76f317e74" category="section-title">SnapMirror関係を解除する</block>
  <block id="9ee42869e01344256cee7824a61c3f00" category="paragraph">次に、データ アクセス用に宛先ボリュームをアクティブ化するために、 SnapMirror関係を解除する必要があります。この手順を実行する前に、初期レプリケーションが完了するまで待機してください。</block>
  <block id="c16b6b1cdf70d97ab9f143b23f304ee5" category="admonition">BlueXP、 ONTAP System Manager、またはONTAP CLI でミラー状態を確認することで、レプリケーションが完了したかどうかを確認できます。レプリケーションが完了すると、ミラー状態は「snapmirrored」になります。</block>
  <block id="acab4369131a8c646dc85deedc5c4abb" category="paragraph">SnapMirror関係を解除するには、 BlueXPを使用することをお勧めします。  BlueXPとのSnapMirror関係を解除するには、<block ref="eb8fade3a2fe398b39f82043fade1a22" category="inline-link-macro-rx"></block> 。</block>
  <block id="96009cd50e3918957734c7c1dbe9bbb1" category="paragraph">BlueXPを使用しない場合は、 ONTAP System Manager またはONTAP CLI を使用してSnapMirror関係を解除できます。  System ManagerとのSnapMirror関係を解除するには、<block ref="2feb8ad9799acf2d659fb0cab9f5c802" category="inline-link-macro-rx"></block> 。  ONTAP CLIを使用してSnapMirror関係を解除するには、<block ref="a5d68b350f5308762130d0f350fbb93c" category="inline-link-macro-rx"></block> 。</block>
  <block id="67a1a8de2d55c1b2a31ec40db952c0cf" category="section-title">宛先ボリュームを Domino に公開する</block>
  <block id="0de56c363db9af31c3fe36cd53b5deaf" category="paragraph">次に、宛先ボリュームを Domino MLOps プラットフォームに公開する必要があります。宛先ボリュームをDominoに公開するには、「 Tridentによってプロビジョニングされていない既存のNFSボリュームを公開する」サブセクションに記載されている手順に従ってください。<block ref="37f39ecc5e06a679f4975effd49fb9b8" category="inline-link-macro-rx"></block>このソリューションの。</block>
  <block id="aa4e6b2b0a9165bbe6adb64ff972dbb0" category="paragraph">これで、次のスクリーンショットに示すように、宛先データ プレーンでジョブとワークスペースを起動するときに、宛先ボリュームをマウントできるようになります。</block>
  <block id="6c2d9f4c43e6e539a1b0bf3be24de513" category="section-title">SnapMirror関係を作成する前に</block>
  <block id="800f74671431bfc6b9efb2f7e294020f" category="section-title">宛先ボリュームをDominoに公開した後</block>
  <block id="a2207225ebdd3d675188d927e34ace5a" category="summary">Domino Nexus は、あらゆるクラウド、リージョン、オンプレミスのあらゆるコンピューティング クラスター全体でデータ サイエンスと機械学習のワークロードを実行できる単一の管理画面です。</block>
  <block id="1882311bf64ae464a0b9653b463c8584" category="doc">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">マイク・オグルスビー、NetApp</block>
  <block id="c716184d878cbe2fda94903e01c21291" category="paragraph">現在、世界中の組織がビジネスとプロセスの変革に AI を導入しています。このため、AI 対応のコンピューティング インフラストラクチャが不足することがよくあります。企業は、さまざまな地域、データセンター、クラウドにわたる利用可能なコンピューティング環境を活用し、コスト、可用性、パフォーマンスのバランスをとるために、ハイブリッド マルチクラウド MLOps アーキテクチャを採用しています。</block>
  <block id="542493ebb9768d33d834c6edcade57dc" category="paragraph">Domino Data Lab の Domino Nexus は、あらゆるクラウド、リージョン、オンプレミスのあらゆるコンピューティング クラスターでデータ サイエンスと機械学習のワークロードを実行できる統合 MLOps コントロール プレーンです。企業全体のデータ サイエンスのサイロを統合し、モデルの構築、展開、監視を 1 か所で実行できるようになります。同様に、NetApp のハイブリッド クラウド データ管理機能を使用すると、ジョブやワークスペースがどこで実行されているかに関係なく、データをジョブやワークスペースに持ち込むことができます。 Domino Nexus をNetAppと組み合わせると、データの可用性を気にすることなく、環境間でワークロードを柔軟にスケジュールできるようになります。つまり、ワークロードとデータを適切なコンピューティング環境に送信する機能があり、データのプライバシーと主権に関する規制を遵守しながら AI の導入を加速できます。</block>
  <block id="3eb3ace35104f92d82777b3219f769d7" category="paragraph">このソリューションは、オンプレミスの Kubernetes クラスターと Amazon Web Services (AWS) で実行される Elastic Kubernetes Service (EKS) クラスターを組み込んだ統合 MLOps コントロール プレーンのデプロイメントを示します。</block>
  <block id="5be0395276ff3840daa0a0cb7643b68d" category="summary">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps - 初期セットアップ</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="doc">初期セットアップ</block>
  <block id="ef81709626b455fffcd99d9f67085d18" category="paragraph">このセクションでは、オンプレミスのデータセンターと AWS を統合したハイブリッド環境で Domino Nexus をNetAppデータ サービスと連携して利用するために実行する必要がある初期セットアップ タスクについて説明します。</block>
  <block id="87b13b0a04193ccc830f23d041d6f3ba" category="paragraph">このセクションで説明する手順を実行する前に、次のタスクが既に実行されていることを前提としています。</block>
  <block id="677ae9330aedf715db07a33be39cbbeb" category="list-text">オンプレミスのNetApp ONTAPストレージ プラットフォームはすでに導入および構成されています。詳細については、 <block ref="077b296918e9131d07388450dbd7a243" category="inline-link-macro-rx"></block> 。</block>
  <block id="8f117f8e1e04a7113b95048bd0077b28" category="inline-link-macro">Amazon FSx ONTAP製品ページ</block>
  <block id="837adf3f87eb8a7f5893e4b6a6f7cee5" category="list-text">AWS でAmazon FSx ONTAPインスタンスがすでにプロビジョニングされています。詳細については、 <block ref="88e07f6417e37f8ff711e34864e5d89c" category="inline-link-macro-rx"></block> 。</block>
  <block id="6bd1aa1204077ccb610d72dbc07f11b1" category="inline-link-macro">Domino 管理者ガイド</block>
  <block id="83a12488d43dae9419d61f6f83fa014a" category="list-text">オンプレミスのデータセンターに Kubernetes クラスターがすでにプロビジョニングされています。詳細については、 <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="6b59c41a4554c4e0f63a7da5ad17b347" category="list-text">AWS で Amazon EKS クラスターがすでにプロビジョニングされています。詳細については、 <block ref="ae2d81862ffd2c0afcf7ba06af1fbd2e" category="inline-link-macro-rx"></block> 。</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link-macro">NetApp Tridentドキュメント</block>
  <block id="1ac8e4f74be6c2aad80e2d33e0bdef83" category="list-text">オンプレミスの Kubernetes クラスターにNetApp Tridentをインストールしました。さらに、ストレージ リソースのプロビジョニングと管理時にオンプレミスのNetApp ONTAPストレージ プラットフォームを使用するようにこのTridentインスタンスを構成しました。詳細については、 <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="6c45529675023ab110b59c01a71b6038" category="list-text">Amazon EKS クラスターにNetApp Tridentをインストールしました。さらに、ストレージリソースのプロビジョニングと管理時にAmazon FSx ONTAPインスタンスを使用するようにこのTridentインスタンスを設定しました。詳細については、 <block ref="eaacbbbc0da023a88cdd2b5800b9ea3b" category="inline-link-macro-rx"></block> 。</block>
  <block id="f8090d27d981a98d65c4401bdd84b3bf" category="inline-link-macro">Amazon 仮想プライベートネットワーク (VPN) ドキュメント</block>
  <block id="c09961db559c7c906d851ebf8ba40ac5" category="list-text">オンプレミスのデータセンターと AWS の仮想プライベートクラウド (VPC) の間には双方向のネットワーク接続が必要です。これを実装するためのさまざまなオプションの詳細については、<block ref="f5c50c4f502917d968e827ba0a3b9d8e" category="inline-link-macro-rx"></block> 。</block>
  <block id="077b7144cc60353e8c8fdc9663398f24" category="section-title">AWS に Domino Enterprise AI プラットフォームをインストールする</block>
  <block id="5e1251e5d0134550a0ea5f1f02c14c3a" category="paragraph">AWSにDomino Enterprise MLOpsプラットフォームをインストールするには、<block ref="7ebd1f818144f08a887fe5d8dbad016a" category="inline-link-macro-rx"></block> 。以前にプロビジョニングしたのと同じ Amazon EKS クラスターに Domino をデプロイする必要があります。さらに、この EKS クラスターにはNetApp Tridentがすでにインストールおよび設定されている必要があり、domino.yml インストール設定ファイルで共有ストレージ クラスとして Trident 管理ストレージ クラスを指定する必要があります。</block>
  <block id="feee67bbfd0f30a09eeb08ca21cdf38d" category="inline-link-macro">Domino インストール設定リファレンスガイド</block>
  <block id="8facc83d9ba07b807b37a1cf4c7f8a74" category="admonition">参照<block ref="ace9eaa491d11b57c3774d7e21b1cd72" category="inline-link-macro-rx"></block>domino.yml インストール構成ファイルで共有ストレージ クラスを指定する方法の詳細については、こちらをご覧ください。</block>
  <block id="11f21d6309deb4cfcdc7f2cdb4fd0839" category="inline-link-macro">技術レポート TR-4952</block>
  <block id="78dd0d0a7a9f103f53daa672d459adb9" category="admonition"><block ref="3de90155c2505cad82b61f16af3049bc" category="inline-link-macro-rx"></block>Amazon FSx ONTAPを使用して AWS で Domino を展開する手順について説明しており、発生する問題のトラブルシューティングに役立つリファレンスとなる可能性があります。</block>
  <block id="aa2a36e425ea068322a0e37b07481ba8" category="section-title">Domino Nexusを有効にする</block>
  <block id="1a942f929d8ad029b828b8e738a86a07" category="paragraph">次に、Domino Nexus を有効にする必要があります。参照<block ref="31b0fd9bf4991ddcfdb80d02c1415fe4" category="inline-link-macro-rx"></block>詳細については。</block>
  <block id="fa64dcf7a96dbbcd90b8729d4d59ab2f" category="section-title">オンプレミスデータセンターに Domino データプレーンを導入する</block>
  <block id="4ad85753a09f6b6e21cf6089aa28f2b2" category="paragraph">次に、オンプレミスのデータセンターに Domino データプレーンを展開する必要があります。このデータ プレーンは、以前にプロビジョニングしたオンプレミスの Kubernetes クラスターにデプロイする必要があります。さらに、この Kubernetes クラスターにはNetApp Tridentがすでにインストールされ、設定されている必要があります。参照<block ref="d46974ff7fcd2c0e55b6b55f2aa698e1" category="inline-link-macro-rx"></block>詳細については。</block>
  <block id="9fac4fc4e1be67e589c110f0c4647f2e" category="summary">Domino Data Lab とNetAppによるハイブリッド マルチクラウド MLOps - テクノロジー概要</block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">テクノロジの概要</block>
  <block id="f0bbbdb43782a17fdb1b5541f4c2d25f" category="paragraph">このセクションでは、Domino Data Lab とNetAppを使用したハイブリッド マルチクラウド MLOps の技術概要を説明します。</block>
  <block id="4e00c35efcd0578992f4821557db1c9e" category="paragraph">Domino Data Lab は、Fortune 100 企業の 20% 以上から信頼されている最先端のエンタープライズ AI プラットフォームにより、モデル駆動型ビジネスを強化します。  Domino は、コラボレーションとガバナンスを強化しながら、データ サイエンス作業の開発と展開を加速します。  Domino を使用すると、世界中の企業がより優れた医薬品を開発し、より生産性の高い作物を栽培し、より優れた自動車を製造するなど、さまざまなことが可能になります。  2013年に設立されたDominoは、Coatue Management、Great Hill Partners、Highland Capital、Sequoia Capitalなどの大手投資家の支援を受けています。</block>
  <block id="582cc4e2654a5d265b3a9c8960a43e88" category="paragraph">Domino を使用すると、企業とそのデータ サイエンティストは、統合されたエンドツーエンドのプラットフォーム上で AI を迅速かつ責任を持ってコスト効率よく構築、展開、管理できます。チームは、あらゆる環境で必要なすべてのデータ、ツール、コンピューティング、モデル、プロジェクトにアクセスできるため、共同作業、過去の作業の再利用、本番環境でのモデルの追跡による精度の向上、ベスト プラクティスによる標準化、AI の責任ある管理が可能になります。</block>
  <block id="79aba99e2c2c50a4d5627b787bde8eae" category="list-text">*オープンで柔軟:* オープンソースと商用ツール、インフラストラクチャの最も広範なエコシステムにアクセスして、最高のイノベーションを実現し、ベンダー ロックインを排除します。</block>
  <block id="720b80ab9ad18c5e500ae8203bb712f2" category="list-text">*記録システム:* 企業全体の AI 運用と知識の中心ハブであり、ベスト プラクティス、部門間のコラボレーション、イノベーションの迅速化、効率化を実現します。</block>
  <block id="8d89627678490a8b88c851ea2fac357d" category="list-text">*統合:* エンタープライズ プロセス、制御、ガバナンス向けに構築された統合ワークフローと自動化により、コンプライアンスと規制のニーズを満たします。</block>
  <block id="9e390a9660aa9f11963ef8d4ebe9b58a" category="list-text">*ハイブリッド マルチクラウド:* オンプレミス、ハイブリッド、任意のクラウド、マルチクラウドなど、どこからでもデータの近くで AI ワークロードを実行し、コストを削減し、最適なパフォーマンスとコンプライアンスを実現します。</block>
  <block id="5bfd375703bc2df982ba9c5193150b90" category="paragraph"><block ref="5bfd375703bc2df982ba9c5193150b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80603873e677eebf28ec5645b40f7453" category="paragraph">Domino Nexus は、あらゆるクラウド、リージョン、オンプレミスのあらゆるコンピューティング クラスター全体でデータ サイエンスと機械学習のワークロードを実行できる単一の管理画面です。企業全体のデータ サイエンスのサイロを統合し、モデルの構築、展開、監視を 1 か所で実行できるようになります。</block>
  <block id="991a53642be15661dc9369ee1ae2085c" category="paragraph">NetApp BlueXP は、NetApp のすべてのストレージ サービスとデータ サービスを 1 つのツールに統合し、ハイブリッド マルチクラウド データ資産の構築、保護、管理を可能にします。オンプレミスとクラウド環境全体にわたるストレージとデータ サービスの統合エクスペリエンスを提供し、今日のクラウド主導の世界に求められる柔軟な消費パラメータと統合保護を備え、AIOps のパワーを通じて運用の簡素化を実現します。</block>
  <block id="8814f8d780d4b85a940aa27445d68549" category="list-text">クラウド接続。  ONTAP は、すべてのパブリック クラウドのソフトウェア定義ストレージとクラウド ネイティブ インスタンスのオプションを備えた、最もクラウドに接続されたストレージ管理ソフトウェアです。</block>
  <block id="5dbf44a3195cc10e2873e76a30df05ac" category="section-title">Amazon FSx for NetApp ONTAP (FSx ONTAP)</block>
  <block id="bca10fd5d70f83556ba989ecf392df97" category="paragraph">Amazon FSx ONTAP は、NetApp の人気のONTAPファイルシステム上に構築された、信頼性が高く、スケーラブルで、高性能で、機能豊富なファイルストレージを提供する、ファーストパーティの完全マネージド型 AWS サービスです。FSx ONTAP は、 NetAppファイルシステムの使い慣れた機能、パフォーマンス、機能、API 操作と、完全に管理された AWS サービスの俊敏性、拡張性、シンプルさを兼ね備えています。</block>
  <block id="193e0bb6f3a76822b629d0fae08bdb7e" category="paragraph">Tridentを使用すると、 ONTAP (AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP)、Element ソフトウェア (NetApp HCI、 SolidFire)、 Azure NetApp Filesサービス、Google Cloud 上の Google Cloud NetApp Google Cloud NetApp Volumesなど、パブリック クラウドまたはオンプレミスのすべての一般的な NetApp ストレージ プラットフォームにわたってストレージ リソースの使用と管理が可能になります。  Trident は、Kubernetes とネイティブに統合される、Container Storage Interface (CSI) 準拠の動的ストレージ オーケストレーターです。</block>
  <block id="978ecccb92a71c90363dfd222ebdfe77" category="paragraph">Kubernetes は、もともと Google によって設計され、現在は Cloud Native Computing Foundation (CNCF) によって管理されているオープンソースの分散型コンテナ オーケストレーション プラットフォームです。  Kubernetes は、コンテナ化されたアプリケーションの展開、管理、スケーリング機能の自動化を可能にし、エンタープライズ環境における主要なコンテナ オーケストレーション プラットフォームです。</block>
  <block id="b2a7a79ed7fe83cbfb6fe2140e6fb60a" category="paragraph">Amazon Elastic Kubernetes Service (Amazon EKS) は、AWS クラウド内のマネージド Kubernetes サービスです。  Amazon EKS は、コンテナのスケジュール設定、アプリケーションの可用性の管理、クラスターデータの保存、その他の重要なタスクを担当する Kubernetes コントロールプレーンノードの可用性とスケーラビリティを自動的に管理します。  Amazon EKS を使用すると、AWS インフラストラクチャのパフォーマンス、スケール、信頼性、可用性をすべて活用できるほか、AWS ネットワークおよびセキュリティ サービスとの統合も実現できます。</block>
  <block id="7bdb77faa0d23db500f55d38c7812837" category="summary">Domino Data LabとNetAppによるハイブリッドマルチクラウドMLOps - 既存のNetAppボリュームをDominoに公開</block>
  <block id="5f385895d8f69d19670414fea115c17e" category="doc">既存のNetAppボリュームをDominoに公開する</block>
  <block id="012942ee2856a3a30e386d999ab4decd" category="paragraph">このセクションでは、既存のNetApp ONTAP NFS ボリュームを Domino MLOps プラットフォームに公開するために実行する必要があるタスクについて説明します。これらの同じ手順は、オンプレミスと AWS の両方に適用されます。</block>
  <block id="216745145dbb2663dd8ef64d1e7b70ce" category="section-title">NetApp ONTAPボリュームを Domino に公開する理由は何ですか?</block>
  <block id="4f49bbf1791537d3f9cea32729bcf171" category="paragraph">NetAppボリュームを Domino と組み合わせて使用すると、次のような利点があります。</block>
  <block id="bdf339cbdff188396b615acb6642682f" category="list-text">NetApp ONTAP のスケールアウト機能を活用することで、非常に大規模なデータセットに対してワークロードを実行できます。</block>
  <block id="ad859808af9509052afa68845ee13abf" category="list-text">データを個々のノードにコピーすることなく、複数のコンピューティング ノードにわたってワークロードを実行できます。</block>
  <block id="3019efb93cfae9d2074cee3ecba248ce" category="list-text">NetApp のハイブリッド マルチクラウド データ移動および同期機能を利用すると、複数のデータセンターやクラウドにわたってデータにアクセスできます。</block>
  <block id="72410fa7689169a336be6540fbab04cb" category="list-text">別のデータ センターまたはクラウドにデータのキャッシュをすばやく簡単に作成できるようにしたいと考えています。</block>
  <block id="6d4734babb6928dd0a6f21c21a95be6a" category="section-title">Tridentによってプロビジョニングされていない既存の NFS ボリュームを公開する</block>
  <block id="908d8e50ed4f87ffd16293ce7689ffa3" category="paragraph">既存のNetApp ONTAP NFS ボリュームがTridentによってプロビジョニングされていない場合は、このサブセクションで説明する手順に従ってください。</block>
  <block id="b0604699a0737b4da7a79ed81a611605" category="section-title">KubernetesでPVとPVCを作成する</block>
  <block id="0b8e803956828c77b5f9c0745c726ca8" category="admonition">オンプレミスのボリュームの場合は、オンプレミスの Kubernetes クラスターに PV と PVC を作成します。  Amazon FSx ONTAPボリュームの場合は、Amazon EKS で PV と PVC を作成します。</block>
  <block id="7ea686752cd0065765a1f236f52b6a86" category="inline-link-macro">NFS PV/PVC の例</block>
  <block id="21daa905ac0fe45b36e98c4b7c6cbfaf" category="paragraph">まず、Kubernetes クラスターに永続ボリューム (PV) と永続ボリューム要求 (PVC) を作成する必要があります。 PVとPVCを作成するには、<block ref="a25b642a6322d7659714e6bd71e7cd4f" category="inline-link-macro-rx"></block> Domino 管理ガイドから値を更新して、環境に反映させます。正しい値を指定してください。<block ref="89801e9e98979062e84647433a8ed3e9" prefix=" " category="inline-code"></block> 、<block ref="0a087fd97387c110f029a7a2550ff280" prefix=" " category="inline-code"></block> 、 そして<block ref="34ae7d3a708b57f81af8fcfcd13c7a55" prefix=" " category="inline-code"></block>フィールド。さらに、対応するONTAP NFS ボリュームに保存されているデータの性質を表す一意の名前を付けることをお勧めします。たとえば、ボリュームに製造上の欠陥の画像が含まれている場合、PVに次のような名前を付けます。<block ref="7146834334002e1c2c8bbb00348a951c" prefix=" " category="inline-code"></block> 、そしてPVC、<block ref="2d04ce24c553ffe8e7f9b69269696618" prefix=" " category="inline-code"></block> 。</block>
  <block id="3a0e23ff2bfd7dc5b55c1aeb14b0ce33" category="section-title">Domino に外部データボリュームを登録する</block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">確認方法</block>
  <block id="6d38ad9604bf23123ad6f1505f8f64ce" category="paragraph">次に、Domino に外部データ ボリュームを登録する必要があります。外部データボリュームを登録するには、<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> Domino 管理者ガイドを参照してください。ボリュームを登録するときは、「ボリューム タイプ」ドロップダウン メニューから必ず「NFS」を選択してください。  「NFS」を選択すると、「使用可能なボリューム」リストに PVC が表示されます。</block>
  <block id="f759d0a96176c0ce67a4269c5b45bc42" category="paragraph"><block ref="f759d0a96176c0ce67a4269c5b45bc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f91c183558f2466e2e75a92424f7a3bf" category="section-title">Tridentによってプロビジョニングされた既存のボリュームを公開する</block>
  <block id="733e83e8c2052942f7f0e96fcd19e8a4" category="paragraph">既存のボリュームがTridentによってプロビジョニングされた場合は、このサブセクションで概説されている手順に従ってください。</block>
  <block id="57a045b809f3298056d203360becbd66" category="section-title">既存のPVCを編集する</block>
  <block id="aaf6f0a313e2fa37d3584aa97603489a" category="paragraph">ボリュームがTridentによってプロビジョニングされている場合は、ボリュームに対応する永続ボリューム要求 (PVC) がすでに存在します。このボリュームをDominoに公開するには、PVCを編集し、次のラベルをラベルリストに追加する必要があります。<block ref="9cc59534218c9b00f7eb481861d14401" prefix=" " category="inline-code"></block>分野：</block>
  <block id="d2790ed8ab25c08ee1efd69f0773cade" category="paragraph">次に、Domino に外部データ ボリュームを登録する必要があります。外部データボリュームを登録するには、<block ref="1b56e73c8083d7259fd3343f2f8d6ce6" category="inline-link-macro-rx"></block> Domino 管理者ガイドを参照してください。ボリュームを登録するときは、「ボリューム タイプ」ドロップダウン メニューから必ず「汎用」を選択してください。  「Generic」を選択すると、「使用可能なボリューム」リストに PVC が表示されます。</block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise with NetApp and VMware - 詳細情報の入手先</block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise と VMware</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen 氏、シニア マネージャー、 NetApp</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac、 NetAppシステム管理者</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">ロニー・ダニエル、 NetAppテクニカル マーケティング エンジニア</block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NVIDIA AI Enterprise とNetApp 、VMware のアーキテクチャ</block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">このソリューションは、 NetApp、VMware、 NVIDIA認定システムを採用した、実績のある使い慣れたアーキテクチャに基づいて構築されています。詳細については、次の表を参照してください。</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">AIおよびデータ分析ソフトウェア</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">VMware 向けNVIDIA AI エンタープライズ</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">仮想化プラットフォーム</block>
  <block id="8887a9a417a1629326acdb917d224337" category="inline-link-macro">VMware vSphere</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">コンピューティングプラットフォーム</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA認定システム</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">データ管理プラットフォーム</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="3e549e3b22de98c96646fb0586a93db3" category="paragraph"><block ref="3e549e3b22de98c96646fb0586a93db3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise は、あらゆる組織が AI を活用して成功できるように最適化された、エンドツーエンドのクラウド ネイティブな AI およびデータ分析ソフトウェア スイートです。</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NVIDIA AI Enterprise とNetApp 、VMware</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">IT アーキテクトや管理者にとって、AI ツールは複雑で馴染みのない場合があります。さらに、多くの AI プラットフォームはエンタープライズ対応ではありません。  NetAppと VMware の技術を活用したNVIDIA AI Enterprise は、合理化されたエンタープライズ クラスの AI アーキテクチャを提供するために開発されました。</block>
  <block id="eb7e5009de0ce355dc9131d958a1541e" category="paragraph"><block ref="eb7e5009de0ce355dc9131d958a1541e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NetAppと VMware を使用したNVIDIA AI Enterprise - NVIDIA NGC ソフトウェアの活用 - セットアップ</block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">セットアップ</block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">このセクションでは、 NVIDIA AI Enterprise 環境内でNVIDIA NGC エンタープライズ ソフトウェアを利用するために実行する必要がある初期セットアップ タスクについて説明します。</block>
  <block id="1eb5d19d2c5071a5a7a569f58f2c9613" category="paragraph">このセクションで説明する手順を実行する前に、 NVIDIA AI Entrpriseホストソフトウェアが、<block ref="b97b75086b5941ac63fab1eee89b4777" category="inline-link-macro-rx"></block>ページ。</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">vGPU を搭載した Ubuntu ゲスト VM を作成する</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI エンタープライズ導入ガイド</block>
  <block id="4be8ecb3320915437222a84e9761bcec" category="paragraph">まず、vGPU を搭載した Ubuntu 20.04 ゲスト VM を作成する必要があります。  vGPUを搭載したUbuntu 20.04ゲストVMを作成するには、<block ref="2009ba36309e23fc0bb68cec4d4a3e0d" category="inline-link-macro-rx"></block> 。</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">NVIDIAゲスト ソフトウェアのダウンロードとインストール</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI エンタープライズ クイック スタート ガイド</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">次に、前の手順で作成したゲスト VM 内に必要なNVIDIAゲスト ソフトウェアをインストールする必要があります。ゲストVM内で必要なNVIDIAゲストソフトウェアをダウンロードしてインストールするには、<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> 。</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">セクション 5.4 で概説されている検証タスクを実行する場合、ガイドの作成以降に CUDA コンテナ イメージが更新されているため、異なる CUDA コンテナ イメージ バージョン タグを使用する必要がある場合があります。検証では、「nvidia/cuda:11.0.3-base-ubuntu20.04」を使用しました。</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">AI/分析フレームワークコンテナをダウンロード</block>
  <block id="939ac3b79a18fc027a13bea0aeebcd3c" category="paragraph">次に、必要な AI または分析フレームワーク コンテナー イメージをNVIDIA NGC からダウンロードして、ゲスト VM 内で使用できるようにする必要があります。ゲストVM内でフレームワークコンテナをダウンロードするには、<block ref="7ea494a5b1819fa63a0ad0f42cf94b43" category="inline-link-macro-rx"></block> 。</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">NetApp DataOps ツールキットのインストールと設定</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">次に、ゲスト VM 内に従来の環境向けのNetApp DataOps Toolkit をインストールする必要があります。 NetApp DataOps Toolkit を使用すると、ゲスト VM 内のターミナルから直接ONTAPシステム上のスケールアウト データ ボリュームを管理できます。ゲスト VM 内にNetApp DataOps Toolkit をインストールするには、次のタスクを実行します。</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">pip をインストールします。</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">ゲスト VM ターミナルからログアウトし、再度ログインします。</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">NetApp DataOps ツールキットを構成します。この手順を完了するには、 ONTAPシステムの API アクセスの詳細が必要になります。ストレージ管理者からこれらを取得する必要がある場合があります。</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">ゲストVMテンプレートを作成する</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">最後に、ゲスト VM に基づいて VM テンプレートを作成する必要があります。このテンプレートを使用すると、 NVIDIA NGC ソフトウェアを利用するためのゲスト VM をすばやく作成できます。</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">ゲスト VM に基づいて VM テンプレートを作成するには、VMware vSphere にログインし、ゲスト VM 名を右クリックして、「クローン」を選択し、「テンプレートにクローン...」を選択して、ウィザードに従います。</block>
  <block id="ae46b5fec5e9fa6540317c6aff2886d0" category="paragraph"><block ref="ae46b5fec5e9fa6540317c6aff2886d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NVIDIA AI Enterprise with NetAppおよび VMware - 初期セットアップ</block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">このセクションでは、 NetAppおよび VMware でNVIDIA AI Enterprise を利用するために実行する必要がある初期セットアップ タスクについて説明します。</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI エンタープライズ製品サポートマトリックス</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetAppおよび VMware ソリューションのドキュメント</block>
  <block id="06a8848af5cbb48d04a6b9d27ea22cae" category="paragraph">このセクションで説明する手順を実行する前に、VMware vSphere とNetApp ONTAPがすでに導入されていることを前提としています。参照<block ref="fca8480728eb091fdea60a7b3cdc16f7" category="inline-link-macro-rx"></block>サポートされている vSphere バージョンの詳細については、こちらをご覧ください。参照<block ref="dde322875ea0d7cfe426ecec0c0dad4c" category="inline-link-macro-rx"></block>VMware vSphere をNetApp ONTAPとともに導入する方法の詳細については、 を参照してください。</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">NVIDIA AI Enterprise Host ソフトウェアをインストールする</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">NVIDIA AI Entrpriseホストソフトウェアをインストールするには、<block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block> 。</block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NVIDIA AI Enterprise with NetApp and VMware - テクノロジー概要</block>
  <block id="d54433e43cda21e1ff5ab715c73883de" category="paragraph">このセクションでは、 NetAppおよび VMware を使用したNVIDIA AI Enterprise のテクノロジの概要を説明します。</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise は、 NVIDIA認定システムを搭載した VMware vSphere で実行できるようにNVIDIAによって最適化、認定、サポートされている、エンドツーエンドのクラウド ネイティブな AI およびデータ分析ソフトウェア スイートです。このソフトウェアは、最新のハイブリッド クラウド環境での AI ワークロードのシンプルかつ迅速な導入、管理、スケーリングを可能にします。</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC は、AI 実践者が AI ソリューションを開発できるように、GPU に最適化されたソフトウェアのカタログをホストしています。また、モデルトレーニング用のNVIDIA Base Command、モデルの展開と監視用のNVIDIA Fleet Command、独自の AI ソフトウェアに安全にアクセスして管理するための NGC Private Registry など、さまざまな AI サービスへのアクセスも提供します。また、 NVIDIA AI Enterprise のお客様は、NGC ポータルを通じてサポートをリクエストできます。</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere は、データセンターを CPU、ストレージ、ネットワークリソースを含む統合コンピューティング インフラストラクチャへと変革する VMware の仮想化プラットフォームです。vSphere はこれらのインフラストラクチャを統合されたオペレーティング環境として管理し、その環境に参加するデータセンターを管理するためのツールを管理者に提供します。</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere の 2 つのコア コンポーネントは、ESXi と vCenter Server です。  ESXiは、管理者が仮想マシンと仮想アプライアンスを作成および実行するための仮想化プラットフォームです。vCenter Serverは、管理者がネットワークに接続された複数のホストを管理し、ホストリソースをプールするためのサービスです。</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps Toolkit は、高性能なスケールアウトNetAppストレージを基盤とする開発/トレーニング ワークスペースと推論サーバーの管理を簡素化する Python ベースのツールです。主な機能は次のとおりです。</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">実験や迅速な反復を可能にするために、大容量の JupyterLab ワークスペースをほぼ瞬時に複製します。</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">バックアップやトレーサビリティ/ベースライン作成のために、大容量の JupyterLab ワークスペースのスナップショットをほぼ瞬時に保存します。</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">大容量、高パフォーマンスのデータ ボリュームをほぼ瞬時にプロビジョニング、クローン作成、スナップショット作成します。</block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NetAppと VMware を使用したNVIDIA AI Enterprise - NVIDIA NGC ソフトウェアの活用 - ユースケース例 - TensorFlow トレーニング ジョブ</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">使用例 - TensorFlow トレーニングジョブ</block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">このセクションでは、 NVIDIA AI Enterprise 環境内で TensorFlow トレーニング ジョブを実行するために実行する必要があるタスクについて説明します。</block>
  <block id="0733928d94b0eba77ac6cf7f3c950257" category="paragraph">このセクションで説明する手順を実行する前に、ゲストVMテンプレートが、<block ref="ad0d852572366b07cdb7f9f854b3aedf" category="inline-link-macro-rx"></block>ページ。</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">テンプレートからゲストVMを作成する</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">まず、前のセクションで作成したテンプレートから新しいゲスト VM を作成する必要があります。テンプレートから新しいゲスト VM を作成するには、VMware vSphere にログインし、テンプレート名を右クリックして、「このテンプレートから新しい VM を作成...」を選択し、ウィザードに従います。</block>
  <block id="d31d5f91fee0f03911daa3d20a90e607" category="paragraph"><block ref="d31d5f91fee0f03911daa3d20a90e607" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">データボリュームの作成とマウント</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">次に、トレーニング データセットを保存する新しいデータ ボリュームを作成する必要があります。 NetApp DataOps Toolkit を使用すると、新しいデータ ボリュームをすばやく作成できます。次の例のコマンドは、容量が 2 TB の「imagenet」という名前のボリュームの作成を示しています。</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">データ ボリュームにデータを入力する前に、それをゲスト VM 内にマウントする必要があります。 NetApp DataOps Toolkit を使用して、データ ボリュームをすばやくマウントできます。次のサンプルコマンドは、前の手順で作成されたボリュームのマウントを示しています。</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">データボリュームを入力する</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">新しいボリュームがプロビジョニングされマウントされたら、トレーニング データセットをソースの場所から取得し、新しいボリュームに配置できます。これには通常、S3 または Hadoop データ レイクからデータを取得することが含まれ、場合によってはデータ エンジニアの支援が必要になることもあります。</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">TensorFlowトレーニングジョブを実行する</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">これで、TensorFlow トレーニング ジョブを実行する準備が整いました。  TensorFlow トレーニング ジョブを実行するには、次のタスクを実行します。</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">NVIDIA NGC エンタープライズ TensorFlow コンテナー イメージをプルします。</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">NVIDIA NGC エンタープライズ TensorFlow コンテナのインスタンスを起動します。  '-v' オプションを使用して、データ ボリュームをコンテナーに接続します。</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">コンテナ内で TensorFlow トレーニング プログラムを実行します。次のサンプル コマンドは、コンテナ イメージに含まれているサンプル ResNet-50 トレーニング プログラムの実行を示しています。</block>
  <block id="9dd88053035e8518106da3a40ce3aa3b" category="summary">NetAppによるオープンソース MLOps - Apache Airflow の導入</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow デプロイメント</block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="paragraph">このセクションでは、Kubernetes クラスターに Airflow をデプロイするために完了する必要があるタスクについて説明します。</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Airflow は Kubernetes 以外のプラットフォームにもデプロイできます。  Kubernetes 以外のプラットフォームに Airflow をデプロイすることは、このソリューションの範囲外です。</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">このセクションで説明する展開演習を実行する前に、次のタスクが既に実行されていることを前提としています。</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">すでに動作中の Kubernetes クラスターがあります。</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link-macro">Tridentのドキュメント</block>
  <block id="85dd9fb465515fcb64ad8d6b67591898" category="list-text">Kubernetes クラスターにNetApp Tridentがすでにインストールされ、構成されています。Tridentの詳細については、<block ref="6bc4e9e49caf522f01de7c1314cd2006" category="inline-link-macro-rx"></block> 。</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">Helmをインストールする</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">インストール手順</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Airflow は、Kubernetes の一般的なパッケージ マネージャーである Helm を使用してデプロイされます。 Airflow をデプロイする前に、デプロイ ジャンプ ホストに Helm をインストールする必要があります。デプロイメントジャンプホストにHelmをインストールするには、<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>公式 Helm ドキュメントに記載されています。</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">デフォルトのKubernetesストレージクラスを設定する</block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow デプロイメント</block>
  <block id="53b8c224038ee8370989019811dd9379" category="paragraph">Airflow をデプロイする前に、Kubernetes クラスター内でデフォルトの StorageClass を指定する必要があります。 Airflow のデプロイメント プロセスでは、デフォルトの StorageClass を使用して新しい永続ボリュームをプロビジョニングしようとします。デフォルトの StorageClass として StorageClass が指定されていない場合、デプロイメントは失敗します。クラスター内でデフォルトのストレージクラスを指定するには、<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>セクション。クラスター内でデフォルトの StorageClass をすでに指定している場合は、この手順をスキップできます。</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm を使用して Airflow をデプロイする</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm を使用して Kubernetes クラスターに Airflow をデプロイするには、デプロイメント ジャンプ ホストから次のタスクを実行します。</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">展開手順</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">Helmを使用してAirflowをデプロイするには、<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Artifact Hub の公式 Airflow チャートをご覧ください。次のサンプルコマンドは、Helm を使用した Airflow のデプロイメントを示しています。値を変更、追加、削除します。<block ref="b03054dec41b4d504351d411d8221d7f" prefix=" " category="inline-code"></block>環境と希望する構成に応じて、必要に応じてファイルを変更します。</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">すべての Airflow ポッドが稼働していることを確認します。すべてのポッドが起動するまでに数分かかる場合があります。</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">手順 1 で Helm を使用して Airflow をデプロイしたときにコンソールに表示された手順に従って、Airflow Web サービス URL を取得します。</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Airflow Web サービスにアクセスできることを確認します。</block>
  <block id="ae954beef496ebe087806e1ce5f985b1" category="paragraph"><block ref="ae954beef496ebe087806e1ce5f985b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1358ee6f6793d8ad5c774e77af0ef2f8" category="summary">NetAppによるオープンソース MLOps - Airflow でNetApp DataOps ツールキットを使用する</block>
  <block id="a6341ca5ab25e7d3076dec050c9e5a97" category="doc">NetApp DataOps Toolkit を Airflow と併用する</block>
  <block id="a408a973f45f990bcd545653e35109ff" category="paragraph">その<block ref="d2f8e20a78f43c00804244e7ccbfa516" category="inline-link-rx"></block>Airflowと併用できます。  NetApp DataOps Toolkit を Airflow と併用すると、スナップショットやクローンの作成などのNetAppデータ管理操作を、Airflow によってオーケストレーションされる自動化されたワークフローに組み込むことができます。</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">空気の流れの例</block>
  <block id="b6cc356bf5062501529145b3a4643413" category="paragraph">参照<block ref="7c367129528d87aa1adf73a57a51aa4d" category="inline-link-rx"></block>Airflow でツールキットを使用する方法の詳細については、 NetApp DataOps Toolkit GitHub リポジトリ内のセクションを参照してください。</block>
  <block id="95cd1b9d487589b619592ac7a94f1001" category="summary">NetAppによるオープンソース MLOps - アーキテクチャ</block>
  <block id="21d5dd37b5f077a36d22ba32af4054e6" category="paragraph">このソリューションは特定のハードウェアに依存しません。このソリューションは、 NetApp TridentでサポートされているすべてのNetApp物理ストレージ アプライアンス、ソフトウェア定義インスタンス、またはクラウド サービスと互換性があります。例としては、 NetApp AFFストレージ システム、 Amazon FSx ONTAP、 Azure NetApp Files、 Google Cloud NetApp Volumes、 NetApp Cloud Volumes ONTAPインスタンスなどが挙げられます。さらに、使用されている Kubernetes バージョンがNetApp Tridentおよび実装されているその他のソリューション コンポーネントでサポートされている限り、このソリューションは任意の Kubernetes クラスターに実装できます。 Tridentでサポートされている Kubernetes バージョンの一覧については、<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> 。このソリューションのさまざまなコンポーネントを検証するために使用された環境の詳細については、次の表を参照してください。</block>
  <block id="f9004e284a207cf92c8642965dc258f6" category="section-title">Apache Airflow 検証環境</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">ソフトウェアコンポーネント</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">Apacheエアフロー</block>
  <block id="78fd3ce4c7835c8336b8c4f52bbd8570" category="inline-link-macro">Apache Airflow Helm チャート</block>
  <block id="923fc06abfe0b856f72313cb88706558" category="cell">2.0.1、導入<block ref="d1ea82e80be31e00d2b939c38f87e0a0" category="inline-link-macro-rx"></block>8.0.8</block>
  <block id="836eb480bf66641d4fb44675e000d22b" category="cell">1.18</block>
  <block id="d029b605d0129cdb050642645b32b1db" category="cell">21.01</block>
  <block id="44ce1bc6a7380dccbb311f0fa6cd1972" category="section-title">JupyterHub 検証環境</block>
  <block id="6a1bd94b05289cc97fd96ec055920439" category="cell">ジュピターハブ</block>
  <block id="263ec1d326c1f5a1bfd24b88cb972a38" category="inline-link-macro">JupyterHub Helm チャート</block>
  <block id="6af30397902bd26914df2ae5955c4be8" category="cell">4.1.5、デプロイ経由<block ref="26830a1e301761faef592d8e74481ce6" category="inline-link-macro-rx"></block>3.3.7</block>
  <block id="c272116b61605b9462784a01f5899785" category="cell">1.29</block>
  <block id="4e9b156e7e2788c8cd4b0877fd922657" category="cell">24.02</block>
  <block id="aa3652d1dedca9375b76c8e59797d756" category="section-title">MLflow 検証環境</block>
  <block id="c8d3451e7307fb1b46769ec23ea7906a" category="cell">MLフロー</block>
  <block id="04d257103d25b778df7089d6dbb0cb44" category="inline-link-macro">MLflow Helmチャート</block>
  <block id="4814bad32946214124af37f70a7bee91" category="cell">2.14.1、以下でデプロイ<block ref="4baf34adb826df0481d498e42290114c" category="inline-link-macro-rx"></block>1.4.12</block>
  <block id="6eeb675638e9c361028379b88415e2de" category="section-title">Kubeflow 検証環境</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">キューブフロー</block>
  <block id="e0d8584ae6ed8fd534954ae8ed8755a3" category="inline-link-macro">デプロイKF</block>
  <block id="bb675cbb86ae4db4a1f3da16e57113cd" category="cell">1.7、導入<block ref="f0761e2008489c964db22d8d03da0a67" category="inline-link-macro-rx"></block>0.1.1</block>
  <block id="32b2e96c4f6d14da1df5b25db372de8f" category="cell">1.26</block>
  <block id="217af7d1776d22530d98be04d104fd49" category="cell">23.07</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">サポート</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">ネットアップに連絡</block>
  <block id="952c6ea6549ebf347f6aae3d6b029756" category="paragraph">NetApp は、Apache Airflow、JupyterHub、MLflow、Kubeflow、Kubernetes に対するエンタープライズ サポートを提供していません。完全にサポートされたMLOpsプラットフォームにご興味がございましたら、<block ref="15a32e54137b30751a17b6bf2b412f99" category="inline-link-macro-rx"></block> NetApp がパートナーと共同で提供する、完全にサポートされた MLOps ソリューションについて説明します。</block>
  <block id="6999319a5a39a9ca41436977f2cb8b8d" category="summary">NetAppによるオープンソース MLOps - テクノロジー概要</block>
  <block id="4c9ffff73cd2c66ec9f6be3cb2b21333" category="paragraph">このセクションでは、 NetAppを使用した OpenSource MLOps のテクノロジの概要に焦点を当てます。</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">人工知能</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI は、コンピューターが人間の心の認知機能を模倣するようにトレーニングするコンピューター サイエンスの分野です。 AI 開発者は、コンピューターが人間と同様、あるいは人間よりも優れた方法で学習し、問題を解決できるようにトレーニングします。ディープラーニングと機械学習は AI のサブフィールドです。組織は、重要なビジネスニーズをサポートするために AI、ML、DL を導入するケースが増えています。次にいくつかの例を示します。</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">膨大なデータを分析し、これまで知られていなかったビジネスインサイトを発見する</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">自然言語処理を使用して顧客と直接対話する</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">さまざまなビジネスプロセスと機能の自動化</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">最新の AI トレーニングおよび推論ワークロードには、超並列コンピューティング機能が必要です。そのため、GPU の並列処理能力は汎用 CPU よりもはるかに優れているため、AI 演算の実行に GPU がますます使用されるようになっています。</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="section-title">コンテナ</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">コンテナは、共有ホスト オペレーティング システム カーネル上で実行される分離されたユーザー空間インスタンスです。コンテナの導入が急速に増加しています。コンテナーは、仮想マシン (VM) が提供するのと同じアプリケーション サンドボックスの利点の多くを提供します。ただし、VM が依存するハイパーバイザーとゲスト オペレーティング システム レイヤーが削除されているため、コンテナーははるかに軽量です。次の図は、仮想マシンとコンテナを視覚的に表したものです。</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Dockerウェブサイト</block>
  <block id="d1920cb2aa1d83b6e74ea477546e30a3" category="paragraph">コンテナーを使用すると、アプリケーションの依存関係や実行時間などをアプリケーションに直接効率的にパッケージ化することもできます。最も一般的に使用されるコンテナ パッケージ形式は Docker コンテナです。 Docker コンテナ形式でコンテナ化されたアプリケーションは、Docker コンテナを実行できる任意のマシンで実行できます。すべての依存関係はコンテナー自体にパッケージ化されるため、アプリケーションの依存関係がマシン上に存在しない場合でも、これは当てはまります。詳細については、<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block> 。</block>
  <block id="0d64529eaeaf491f582b2ba0df6149c7" category="paragraph"><block ref="0d64529eaeaf491f582b2ba0df6149c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetesウェブサイト</block>
  <block id="f0ce8ef614fdf23fe30bc43ff89f53d3" category="paragraph">Kubernetes は、もともと Google によって設計され、現在は Cloud Native Computing Foundation (CNCF) によって管理されているオープンソースの分散型コンテナ オーケストレーション プラットフォームです。 Kubernetes を使用すると、コンテナ化されたアプリケーションの展開、管理、スケーリング機能を自動化できます。近年、Kubernetes は主要なコンテナ オーケストレーション プラットフォームとして登場しました。詳細については、<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block> 。</block>
  <block id="759b696484e9a0ab24afe3237dd85e66" category="paragraph"><block ref="0d26e0900d0eeb1b6e1c8f5cfee8510e" category="inline-link-macro-rx"></block>ONTAP (AFF、 FAS、Select、Cloud、 Amazon FSx ONTAP)、 Azure NetApp Filesサービス、 Google Cloud NetApp Volumesなど、パブリック クラウドまたはオンプレミスのすべての一般的なNetAppストレージ プラットフォームにわたるストレージ リソースの使用と管理を可能にします。  Trident は、Kubernetes とネイティブに統合される、Container Storage Interface (CSI) 準拠の動的ストレージ オーケストレーターです。</block>
  <block id="db7f413e96e248375d3fabd005ca4fee" category="paragraph">その<block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block>は、高性能なスケールアウトNetAppストレージを基盤とする開発/トレーニング ワークスペースと推論サーバーの管理を簡素化する Python ベースのツールです。主な機能は次のとおりです。</block>
  <block id="b96dbbd391395e38a8ba72ae75c21dc9" category="list-text">高性能のスケールアウトNetAppストレージを活用した新しい大容量ワークスペースを迅速にプロビジョニングします。</block>
  <block id="629509198041b5749e015afa6a9b2629" category="list-text">実験や迅速な反復を可能にするために、大容量のワークスペースをほぼ瞬時に複製します。</block>
  <block id="01f719401b5bc2f16f328b588b0bef97" category="list-text">バックアップやトレーサビリティ/ベースライン作成のために、大容量のワークスペースのスナップショットをほぼ瞬時に保存します。</block>
  <block id="8b4d3b8f8e04f8cfef020d43ad93e87a" category="paragraph">Apache Airflow は、複雑なエンタープライズ ワークフローのプログラムによる作成、スケジュール設定、監視を可能にするオープン ソースのワークフロー管理プラットフォームです。これは、ETL およびデータ パイプライン ワークフローを自動化するためによく使用されますが、これらのタイプのワークフローに限定されません。  Airflow プロジェクトは Airbnb によって開始されましたが、その後業界で非常に人気となり、現在は Apache Software Foundation の管轄下にあります。 Airflow は Python で記述され、Airflow ワークフローは Python スクリプトを介して作成され、Airflow は「コードとしての構成」の原則に基づいて設計されています。現在、多くのエンタープライズ Airflow ユーザーは Kubernetes 上で Airflow を実行しています。</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">有向非巡回グラフ（DAG）</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">Airflow では、ワークフローは有向非巡回グラフ (DAG) と呼ばれます。  DAG は、DAG 定義に応じて、順番に、並列に、またはその 2 つの組み合わせで実行されるタスクで構成されます。  Airflow スケジューラは、DAG 定義で指定されたタスク レベルの依存関係に従って、ワーカーの配列で個々のタスクを実行します。  DAG は Python スクリプトによって定義および作成されます。</block>
  <block id="802125395813e0bec35472d0403ab94e" category="section-title">Jupyterノートブック</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyterのウェブサイト</block>
  <block id="2ea401316bb56cd0dd460196fdb8bddc" category="paragraph">Jupyter Notebook は、ライブ コードと説明テキストを含む wiki のようなドキュメントです。  Jupyter Notebook は、AI および ML プロジェクトを文書化、保存、共有する手段として、AI および ML コミュニティで広く使用されています。  Jupyter Notebookの詳細については、<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block> 。</block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="section-title">Jupyter ノートブック サーバー</block>
  <block id="1ceb0a3b747e9e685e69bf855aa91001" category="paragraph">Jupyter Notebook サーバーは、ユーザーが Jupyter Notebook を作成できるようにするオープン ソースの Web アプリケーションです。</block>
  <block id="d837769caeb4d9edfd53e4a5a4b94fce" category="inline-link">JupyterHubウェブサイト</block>
  <block id="aa77da24b3b7d00c6c4b22044c64a028" category="paragraph">JupyterHub は、個々のユーザーが独自の Jupyter Notebook サーバーをプロビジョニングしてアクセスできるようにするマルチユーザー アプリケーションです。  JupyterHubの詳細については、<block ref="8b235ac1daecf8d06ace248b8ac07b97" category="inline-link-rx"></block> 。</block>
  <block id="891056fdef376263d6563716a06437cd" category="inline-link">MLflowウェブサイト</block>
  <block id="ea79d93ff06996ce8a177ec9a6f59b26" category="paragraph">MLflow は、人気の高いオープンソースの AI ライフサイクル管理プラットフォームです。  MLflow の主な機能には、AI/ML 実験追跡と AI/ML モデル リポジトリが含まれます。  MLflowの詳細については、<block ref="7d5e77d7cbcfeeed8850444afe1d66af" category="inline-link-rx"></block> 。</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflowウェブサイト</block>
  <block id="9a9c31b74376d75ed88c300dfd734acf" category="paragraph">Kubeflow は、もともと Google によって開発された、Kubernetes 用のオープンソース AI および ML ツールキットです。  Kubeflow プロジェクトは、Kubernetes 上での AI および ML ワークフローのデプロイメントをシンプル、移植可能、かつスケーラブルなものにします。 Kubeflow は Kubernetes の複雑な部分を抽象化し、データ サイエンティストが最も得意とする分野、つまりデータ サイエンスに集中できるようにします。視覚的に表すと次の図を参照してください。 Kubeflow は、オールインワンの MLOps プラットフォームを好む組織にとって優れたオープンソース オプションです。詳細については、<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block> 。</block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow パイプライン</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflowの公式ドキュメント</block>
  <block id="f69bb06b79f60baced2f6faf97fc9e14" category="paragraph">Kubeflow Pipelines は Kubeflow の重要なコンポーネントです。 Kubeflow Pipelines は、移植可能でスケーラブルな AI および ML ワークフローを定義およびデプロイするためのプラットフォームおよび標準です。詳細については、<block ref="34d1e4686e190f53e3511c4faa8ac68b" category="inline-link-rx"></block> 。</block>
  <block id="7724cfbda1ff4c3052c280f6b4af599c" category="section-title">Kubeflow ノートブック</block>
  <block id="352ec4b0886cdd10b69d3efaa4071648" category="paragraph">Kubeflow は、Kubernetes 上の Jupyter Notebook サーバーのプロビジョニングとデプロイメントを簡素化します。  KubeflowのコンテキストにおけるJupyter Notebookの詳細については、<block ref="273f9b54e4f57ca19b4597f14d191196" category="inline-link-rx"></block> 。</block>
  <block id="d8d51bb44e1cdcb1d7fde82b687339bd" category="section-title">カティブ</block>
  <block id="8f5f81b63b950128a2104cb77339c846" category="paragraph">Katib は、自動機械学習 (AutoML) のための Kubernetes ネイティブ プロジェクトです。  Katib は、ハイパーパラメータ調整、早期停止、ニューラル アーキテクチャ検索 (NAS) をサポートしています。 Katib は、機械学習 (ML) フレームワークに依存しないプロジェクトです。ユーザーが選択した任意の言語で記述されたアプリケーションのハイパーパラメータを調整でき、TensorFlow、MXNet、PyTorch、XGBoost などの多くの ML フレームワークをネイティブにサポートします。  Katib は、ベイズ最適化、パルゼン木推定量、ランダム検索、共分散行列適応進化戦略、ハイパーバンド、効率的なニューラル アーキテクチャ検索、微分可能アーキテクチャ検索など、さまざまな AutoML アルゴリズムをサポートしています。  KubeflowのコンテキストにおけるJupyter Notebookの詳細については、<block ref="5b959b0f3dbfc4557138b63a781b201c" category="inline-link-rx"></block> 。</block>
  <block id="592d6ad3868437ff65a70353ab870f50" category="list-text">シームレスなスケーリングと中断のない運用。 ONTAP は、既存のコントローラおよびスケールアウト クラスタへの無停止の容量追加をサポートします。顧客は、コストのかかるデータ移行や停止なしに、最新のテクノロジーにアップグレードできます。</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetAppスナップショットコピー</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetAppスナップショット コピーは、ボリュームの読み取り専用の特定時点のイメージです。次の図に示すように、イメージは最後のスナップショット コピーの作成以降に作成されたファイルの変更のみを記録するため、消費するストレージ スペースは最小限で、パフォーマンスのオーバーヘッドもごくわずかです。</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">スナップショット コピーの効率性は、 ONTAP のコア ストレージ仮想化テクノロジである Write Anywhere File Layout (WAFL) によって実現されています。WAFLは、データベースのように、メタデータを使用してディスク上の実際のデータ ブロックを参照します。ただし、データベースとは異なり、既存のブロックは上書きされません。更新されたデータは新しいブロックに書き込まれ、メタデータが変更されます。 ONTAP は、データ ブロックをコピーするのではなく、Snapshot コピーを作成するときにメタデータを参照するため、Snapshot コピーは非常に効率的です。こうすることで、他のシステムがコピーするブロックを探すために要するシーク時間と、コピー自体の作成コストが削減されます。</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">スナップショット コピーを使用すると、個々のファイルまたは LUN を回復したり、ボリュームの内容全体を復元したりできます。Snapshotコピーのポインタ情報をディスク上のデータと比較することで、ダウンタイムや多大なパフォーマンス コストなしで損失オブジェクトや破損オブジェクトが再構築されます。</block>
  <block id="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="paragraph"><block ref="fbfe7fb9706620c5ddb7b53cd9e06fa0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexCloneテクノロジ</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexCloneテクノロジーは、スナップショット メタデータを参照して、ボリュームの書き込み可能なポイントインタイム コピーを作成します。コピーは親とデータ ブロックを共有し、次の図に示すように、変更がコピーに書き込まれるまで、メタデータに必要なストレージ以外は消費しません。従来の手法でコピーを作成すると数分から数時間かかりますが、FlexCloneソフトウェアを使用すれば大規模なデータセットのコピーもほぼ瞬時に作成できます。そのため、同一のデータセットの複数のコピー (開発ワークスペースなど) やデータセットの一時的なコピー (本番データセットに対するアプリケーションのテストなど) が必要な状況に最適です。</block>
  <block id="f28d7ba8bb28ad8ce873b4ec7ed61164" category="paragraph"><block ref="f28d7ba8bb28ad8ce873b4ec7ed61164" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirrorデータレプリケーションテクノロジー</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirrorソフトウェアは、データ ファブリック全体にわたるコスト効率に優れ、使いやすい統合レプリケーション ソリューションです。 LAN または WAN 経由で高速にデータを複製します。仮想環境と従来の環境の両方で、ビジネスに不可欠なアプリケーションを含むあらゆる種類のアプリケーションに高いデータ可用性と高速なデータ複製を提供します。データを 1 つ以上のNetAppストレージ システムに複製し、セカンダリ データを継続的に更新すると、データは最新の状態に保たれ、必要なときにいつでも利用できるようになります。外部のレプリケーション サーバーは必要ありません。  SnapMirrorテクノロジーを活用したアーキテクチャの例については、次の図を参照してください。</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirrorソフトウェアは、変更されたブロックのみをネットワーク経由で送信することで、 NetApp ONTAPストレージの効率を活用します。  SnapMirrorソフトウェアは、組み込みのネットワーク圧縮機能を使用して、データ転送を高速化し、ネットワーク帯域幅の使用率を最大 70% 削減します。  SnapMirrorテクノロジーを使用すると、1 つのシン レプリケーション データ ストリームを活用して、アクティブ ミラーと以前のポイントインタイム コピーの両方を保持する単一のリポジトリを作成し、ネットワーク トラフィックを最大 50% 削減できます。</block>
  <block id="2ab1a10694bb0d67320839630a1c9ccb" category="paragraph"><block ref="c4152c5b1804294b9bc91a2fa3a92230" category="inline-link-macro-rx"></block>高速かつ安全なデータ同期を実現するNetAppサービスです。オンプレミスの NFS または SMB ファイル共有、 NetApp StorageGRID、 NetApp ONTAP S3、 Google Cloud NetApp Volumes、 Azure NetApp Files、AWS S3、AWS EFS、Azure Blob、Google Cloud Storage、IBM Cloud Object Storage の間でファイルを転送する必要がある場合でも、 BlueXP Copy and Sync を使用すると、必要な場所にファイルを迅速かつ安全に移動します。</block>
  <block id="7e333cc0e24ef7489559129fd944c91f" category="paragraph">データが転送されると、ソースとターゲットの両方で完全に使用できるようになります。 BlueXP Copy and Sync は、更新がトリガーされたときにオンデマンドでデータを同期したり、事前定義されたスケジュールに基づいて継続的にデータを同期したりできます。いずれにしても、 BlueXP Copy and Sync はデルタのみを移動するため、データ複製にかかる時間とコストは最小限に抑えられます。</block>
  <block id="22716a1c6493f7fb09f4caf2084ad23c" category="paragraph">BlueXP Copy and Sync は、セットアップと使用が非常に簡単な SaaS (Software as a Service) ツールです。  BlueXP Copy and Sync によってトリガーされるデータ転送は、データ ブローカーによって実行されます。  BlueXPコピーおよび同期データブローカーは、AWS、Azure、Google Cloud Platform、またはオンプレミスにデプロイできます。</block>
  <block id="204b9ffafe28e07fef53f08e2924e621" category="paragraph"><block ref="8eb894646a418e33ca3d088f11e4914c" category="inline-link-macro-rx"></block>は、any-to- NetAppおよびNetApp-to- NetAppのデータ移行とファイルシステム分析のためのクライアントベースのソフトウェアです。  XCP は、利用可能なすべてのシステム リソースを活用して大容量のデータセットと高パフォーマンスの移行を処理し、拡張して最大のパフォーマンスを実現するように設計されています。  XCP は、レポートを生成するオプションを使用して、ファイル システムの完全な可視性を得るのに役立ちます。</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroupボリューム</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">トレーニング データセットは、数十億のファイルのコレクションになる可能性があります。ファイルには、並列に読み取るために保存および処理する必要があるテキスト、オーディオ、ビデオ、およびその他の形式の非構造化データが含まれる場合があります。ストレージ システムは、多数の小さなファイルを保存し、順次およびランダム I/O でそれらのファイルを並列に読み取る必要があります。</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroupボリュームは、次の図に示すように、複数の構成メンバー ボリュームで構成される単一の名前空間です。ストレージ管理者の観点から見ると、 FlexGroupボリュームはNetApp FlexVol volumeのように管理され、動作します。 FlexGroupボリューム内のファイルは個々のメンバー ボリュームに割り当てられ、ボリュームまたはノード間でストライプ化されません。これらにより、次の機能が有効になります。</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroupボリュームは、高メタデータ ワークロードに対して、数ペタバイトの容量と予測可能な低レイテンシを提供します。</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">同じ名前空間で最大 4000 億のファイルをサポートします。</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">これらは、CPU、ノード、アグリゲート、および構成するFlexVolボリューム全体にわたる NAS ワークロードでの並列操作をサポートします。</block>
  <block id="b0d8567b3e8a1e892d0b59f7a3c27292" category="paragraph"><block ref="b0d8567b3e8a1e892d0b59f7a3c27292" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6459218853a974bb2b38718e6db79ed" category="summary">このソリューションは、MLOps ワークフローに組み込むことができるさまざまなオープンソース ツールとフレームワークを示すことを目的としています。これらのさまざまなツールとフレームワークは、要件とユースケースに応じて、一緒に使用することも、単独で使用することもできます。</block>
  <block id="eb1b19572557d2f13528a30754e9997a" category="doc">NetAppによるオープンソース MLOps</block>
  <block id="aa27e598d8d01ff612acd83b47a13b21" category="paragraph">Mike Oglesby、 NetApp Sufian Ahmad、 NetApp Rick Huang、 NetApp Mohan Acharya、 NetApp</block>
  <block id="36160a80da6291faa3ebc68ede194279" category="paragraph">あらゆる規模や業種の企業や組織が、現実世界の問題を解決し、革新的な製品やサービスを提供して、競争が激化する市場で優位に立つために、人工知能 (AI) を導入しています。多くの組織は、業界の急速なイノベーションのペースに対応するために、オープンソースの MLOps ツールに注目しています。これらのオープンソース ツールは高度な機能と最先端の機能を提供しますが、データの可用性とデータのセキュリティが考慮されていないことがよくあります。残念ながら、これは高度なスキルを持つデータ サイエンティストが、データにアクセスできるようになるまで、または基本的なデータ関連の操作が完了するまで、かなりの時間を費やさざるを得ないことを意味します。人気のオープンソース MLOps ツールとNetAppのインテリジェント データ インフラストラクチャを組み合わせることで、組織はデータ パイプラインを高速化し、AI イニシアチブを加速できます。データの保護とセキュリティを維持しながら、データから価値を引き出すことができます。このソリューションは、これらの課題に対処するために、 NetApp のデータ管理機能といくつかの一般的なオープンソース ツールおよびフレームワークを組み合わせる方法を示しています。</block>
  <block id="ad3ca69dbfa62630ace9a188e93d1f45" category="paragraph">次のリストは、このソリューションによって有効になる主な機能の一部を示しています。</block>
  <block id="e6ffdd80d6efdfae1a367b394ef6afdf" category="list-text">ユーザーは、高性能なスケールアウトNetAppストレージを活用した新しい大容量データ ボリュームと開発ワークスペースを迅速にプロビジョニングできます。</block>
  <block id="24f5e64e89b475fca21e0a2d5536aa48" category="list-text">ユーザーは、実験や迅速な反復を可能にするために、大容量のデータ ボリュームと開発ワークスペースをほぼ瞬時に複製できます。</block>
  <block id="4657d40d11cf0257f60a599a2bc266b6" category="list-text">ユーザーは、バックアップやトレーサビリティ/ベースライン作成のために、大容量データ ボリュームや開発ワークスペースのスナップショットをほぼ瞬時に保存できます。</block>
  <block id="953c95173b5d3944693633d3b6ae7711" category="paragraph"><block ref="953c95173b5d3944693633d3b6ae7711" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3e3d207c7705b0f7dc0142df9cc2790a" category="inline-link-macro">Jupyterノートブック</block>
  <block id="d1a5554bae0723fdaf349b8047aa0d08" category="paragraph">典型的なMLOpsワークフローには開発ワークスペースが組み込まれており、通常は次のような形式をとります。<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> ; 実験の追跡、自動トレーニング パイプライン、データ パイプライン、および推論/デプロイメント。このソリューションは、ワークフローのさまざまな側面に対処するために、独立して、または組み合わせて使用できるさまざまなツールとフレームワークに重点を置いています。また、 NetApp のデータ管理機能とこれらの各ツールの組み合わせについても説明します。このソリューションは、組織がユースケースと要件に合わせてカスタマイズされた MLOps ワークフローを構築するための構成要素を提供することを目的としています。</block>
  <block id="0b34fcae55a765c46410fb4116433e75" category="paragraph">このソリューションでは、次のツール/フレームワークがカバーされています。</block>
  <block id="074cd5ab3a3581efcb92b990cd4ed3b6" category="list-text"><block ref="074cd5ab3a3581efcb92b990cd4ed3b6" category="inline-link-macro-rx"></block></block>
  <block id="ac10ff0174545b18e3fd3b7ab41ebc08" category="list-text"><block ref="ac10ff0174545b18e3fd3b7ab41ebc08" category="inline-link-macro-rx"></block></block>
  <block id="4275daa2701a7c7ad4c1c5df1088ada8" category="list-text"><block ref="4275daa2701a7c7ad4c1c5df1088ada8" category="inline-link-macro-rx"></block></block>
  <block id="a0cf58c060e740cca7f48b1bb399e974" category="list-text"><block ref="a0cf58c060e740cca7f48b1bb399e974" category="inline-link-macro-rx"></block></block>
  <block id="9717b9722e82e47dc4445d7ffc90b79d" category="paragraph">次のリストでは、これらのツールを個別に、または組み合わせて展開するための一般的なパターンについて説明します。</block>
  <block id="3f7626e711a1e660dae85d17fdc35882" category="list-text">JupyterHub、MLflow、Apache Airflowを組み合わせてデプロイ - JupyterHub for<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、実験追跡用の MLflow、自動トレーニングおよびデータ パイプライン用の Apache Airflow です。</block>
  <block id="1dceee44b0bde0ef7364704241dced5a" category="list-text">KubeflowとApache Airflowを組み合わせてデプロイ - Kubeflow for<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block> 、実験の追跡、自動化されたトレーニング パイプライン、推論、およびデータ パイプライン用の Apache Airflow です。</block>
  <block id="aa815dfaf0c405504952ea2a361a2a3e" category="list-text">KubeflowをオールインワンのMLOpsプラットフォームソリューションとして導入<block ref="cd3acaabeea76372e8a706ccab36a6b8" category="inline-link-macro-rx"></block>、実験の追跡、自動化されたトレーニングとデータ パイプライン、および推論。</block>
  <block id="6ca687fb1fabca3bf671bc9bf39dbf27" category="summary">NetAppを使用したオープンソース MLOps - JupyterHub の導入</block>
  <block id="09d2043b79460eb224957589f59ab494" category="doc">JupyterHub デプロイメント</block>
  <block id="2ab6902fa61e1ea6912baf903a3b0bf1" category="paragraph">このセクションでは、Kubernetes クラスターに JupyterHub をデプロイするために完了する必要があるタスクについて説明します。</block>
  <block id="26e29fcdb4d615c34b7fedb3a0564f8f" category="admonition">JupyterHub は Kubernetes 以外のプラットフォームにもデプロイできます。  Kubernetes 以外のプラットフォームに JupyterHub をデプロイすることは、このソリューションの範囲外です。</block>
  <block id="99b37bb800ce4a91a3634a32f40b891b" category="list-text">Kubernetes クラスターにNetApp Tridentがすでにインストールされ、構成されています。Tridentの詳細については、<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> 。</block>
  <block id="2ac6b5f4951f689f17ae54334df0112f" category="paragraph">JupyterHub は、Kubernetes の一般的なパッケージ マネージャーである Helm を使用してデプロイされます。  JupyterHub をデプロイする前に、Kubernetes コントロール ノードに Helm をインストールする必要があります。  Helmをインストールするには、<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>公式 Helm ドキュメントに記載されています。</block>
  <block id="c0b1a9427c281e6178bd6cbeb95bc3a8" category="paragraph">JupyterHub をデプロイする前に、Kubernetes クラスター内でデフォルトの StorageClass を指定する必要があります。クラスター内でデフォルトのストレージクラスを指定するには、<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>セクション。クラスター内でデフォルトの StorageClass をすでに指定している場合は、この手順をスキップできます。</block>
  <block id="771d8827304382e84db174fab916e726" category="section-title">JupyterHubをデプロイする</block>
  <block id="cca32ccd336a1d99e57fe4b732c1db03" category="paragraph">上記の手順を完了すると、JupyterHub をデプロイする準備が整います。  JupyterHub のデプロイメントには次の手順が必要です。</block>
  <block id="02e6e3cd99fedc7e13d22d86bad5b831" category="section-title">JupyterHub デプロイメントを構成する</block>
  <block id="ce95551547fa8ef240a593be5a20f5ee" category="paragraph">デプロイメントの前に、それぞれの環境に合わせて JupyterHub デプロイメントを最適化することをお勧めします。  *config.yaml* ファイルを作成し、Helm チャートを使用してデプロイ中にそれを利用できます。</block>
  <block id="53db901aeed4328fe567404ccb21206d" category="paragraph">*config.yaml* ファイルの例は次の場所にあります。<block ref="8c152549701847c833121b3ad8e4af72" category="inline-link-rx"></block></block>
  <block id="d4acad87b1acbfd617a3b4988bfb1864" category="admonition">この config.yaml ファイルでは、 NetApp Trident StorageClass の *(singleuser.storage.dynamic.storageClass)* パラメータを設定できます。これは、個々のユーザー ワークスペースのボリュームをプロビジョニングするために使用されるストレージ クラスです。</block>
  <block id="fc1be4924094aec74f37b59bbd957af8" category="section-title">共有ボリュームの追加</block>
  <block id="67e834a52ce0a7019fd9a1bec4bae36f" category="paragraph">すべての JupyterHub ユーザーに共有ボリュームを使用する場合は、それに応じて *config.yaml* を調整できます。たとえば、jupyterhub-shared-volume という共有 PersistentVolumeClaim がある場合、次のようにすべてのユーザー ポッドで /home/shared としてマウントできます。</block>
  <block id="a66a54102aa462ebdfe0146ca96eaf33" category="admonition">これはオプションの手順であり、これらのパラメータは必要に応じて調整できます。</block>
  <block id="67c7fe5cd005737db341f115281a5f71" category="section-title">Helm ChartでJupyterHubをデプロイする</block>
  <block id="54ad8b66fcd369a80298610d95ca37d9" category="paragraph">Helm に JupyterHub Helm チャート リポジトリを認識させます。</block>
  <block id="f98aad3b24c5bab5b4737b8fad3a723f" category="paragraph">次のような出力が表示されます。</block>
  <block id="4e29332ac1db944879502e11ab327960" category="paragraph">次に、config.yaml が含まれているディレクトリから次のコマンドを実行して、config.yaml で構成されたチャートをインストールします。</block>
  <block id="be118fb1d0e987a9d25c71312374ffdf" category="admonition">この例では、</block>
  <block id="750e13a1159e4f2b96ba2d8fadfb1aab" category="paragraph">&lt;helm-release-name&gt; は my-jupyterhub に設定されており、これが JupyterHub リリースの名前になります。  &lt;k8s-namespace&gt; は、JupyterHub をインストールする名前空間である my-namespace に設定されています。  --create-namespace フラグは、名前空間がまだ存在しない場合に名前空間を作成するために使用されます。  --values フラグは、必要な構成オプションを含む config.yaml ファイルを指定します。</block>
  <block id="0873eec3dcb328f01cc596581047ae60" category="section-title">デプロイメントの確認</block>
  <block id="5b252fe874ba4bfb32f7c039993801ab" category="paragraph">ステップ 2 の実行中に、次のコマンドでポッドが作成されていることを確認できます。</block>
  <block id="828e0f094cad198231ffd340f281e098" category="paragraph">ハブとプロキシ ポッドが実行状態になるまで待ちます。</block>
  <block id="4f8f16ff2582a84eb01cbef90f467393" category="section-title">JupyterHub にアクセスする</block>
  <block id="c7433009ea218afe4c1117491e4afccb" category="paragraph">JupyterHub にアクセスするために使用できる IP を見つけます。出力例のように、proxy-public サービスの EXTERNAL-IP が使用可能になるまで、次のコマンドを実行します。</block>
  <block id="7261a4593eb504b7857e5e4dd9a5459c" category="admonition">config.yaml ファイルで NodePort サービスを使用しましたが、設定に基づいて環境に合わせて調整できます (例: LoadBalancer)。</block>
  <block id="a5673ab624b33fdb767b6ec77b9901ca" category="paragraph">JupyterHub を使用するには、ブラウザにプロキシ パブリック サービスの外部 IP を入力します。</block>
  <block id="9b5d03606d5f2609a4b9a6f1ac626a8d" category="summary">NetAppによるオープンソース MLOps - JupyterHub でNetApp DataOps ツールキットを使用する</block>
  <block id="8fc5f752dfcb57cd9232177f28b14765" category="doc">JupyterHubでNetApp DataOpsツールキットを使用する</block>
  <block id="0162e970f8577425266cb5c97d21c2a7" category="paragraph">その<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>JupyterHub と組み合わせて使用できます。  NetApp DataOps Toolkit を JupyterHub と併用すると、エンド ユーザーは、ワークスペースのバックアップやデータセットからモデルへのトレーサビリティのためのボリューム スナップショットを Jupyter Notebook 内から直接作成できるようになります。</block>
  <block id="8f08aaf2916d1654fc96af766c150251" category="paragraph">DataOps Toolkit を JupyterHub で使用する前に、JupyterHub が個々のユーザーの Jupyter Notebook Server ポッドに割り当てる Kubernetes サービス アカウントに適切な権限を付与する必要があります。  JupyterHubは、<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block> JupyterHub Helm チャート構成ファイルの変数。</block>
  <block id="a815fb28e94390b627bc7915911578cf" category="section-title">DataOps ツールキットのクラスターロールを作成する</block>
  <block id="333372e6f3961af5df82304243a2d5ba" category="paragraph">まず、ボリューム スナップショットを作成するために必要な Kubernetes API 権限を持つ「netapp-dataops」という名前のクラスター ロールを作成します。</block>
  <block id="3805f69a30879fb016e5c3d0a85fab77" category="section-title">ノートブック サーバーのサービス アカウントにクラスター ロールを割り当てる</block>
  <block id="19506ab4aa03158eeea933145bd0471d" category="paragraph">適切な名前空間内の適切なサービス アカウントに 'netapp-dataops-snapshots' クラスター ロールを割り当てるロール バインディングを作成します。たとえば、JupyterHubを「jupyterhub」名前空間にインストールし、<block ref="b8c80a6db053e98d7341438c2eb0aea3" prefix=" " category="inline-code"></block>変数を使用する場合は、次の例に示すように、 'netapp-dataops-snapshots' クラスター ロールを 'jupyterhub' 名前空間の 'default' サービス アカウントに割り当てます。</block>
  <block id="fe7233ebd9f644239a2437c55d3419e1" category="section-title">Jupyter Notebook 内でボリューム スナップショットを作成する</block>
  <block id="02dd051970bea675e5def458342cd6e3" category="paragraph">現在、JupyterHub ユーザーは、次の例に示すように、 NetApp DataOps Toolkit を使用して、Jupyter Notebook 内から直接ボリューム スナップショットを作成できます。</block>
  <block id="6bd0178572fd0f85ae777cd2c67d0907" category="paragraph"><block ref="6bd0178572fd0f85ae777cd2c67d0907" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ffc4debfa03808ebe14380555e9a891" category="summary">NetApp SnapMirrorでデータを取り込む</block>
  <block id="c9cfa55f76ce30116dc6c4a9d937fa9d" category="doc">NetApp SnapMirrorを使用してJupyterHubにデータを取り込む</block>
  <block id="98aa5dbb610473a52540e5d0699bd079" category="paragraph">NetApp SnapMirrorは、 NetAppストレージ システム間でデータを複製できるレプリケーション テクノロジです。  SnapMirror を使用すると、リモート環境から JupyterHub にデータを取り込むことができます。</block>
  <block id="815eb616a6188ae082d3024fbb91e45e" category="section-title">ワークフローとデモの例</block>
  <block id="a3e50a098653f80e6a42662ee52e8b55" category="inline-link-macro">このTech ONTAPブログ投稿</block>
  <block id="5eae3f83c7f60bb551b097ccf3a4012b" category="paragraph">参照<block ref="585bdb2d9e21d8036a261701b86d814c" category="inline-link-macro-rx"></block>NetApp SnapMirrorを使用して JupyterHub にデータを取り込む詳細なワークフロー例とデモをご覧ください。</block>
  <block id="ba47b65d29a2bcf968281d1e04ee29bb" category="summary">NetAppを使用したオープンソース MLOps - Kubeflow のデプロイメント</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">このセクションでは、Kubernetes クラスターに Kubeflow をデプロイするために完了する必要があるタスクについて説明します。</block>
  <block id="f3538dfada37d551dd71f26249dd82c6" category="list-text">すでに稼働中の Kubernetes クラスターがあり、デプロイする予定の Kubeflow バージョンでサポートされている Kubernetes のバージョンを実行しています。サポートされているKubernetesのバージョンのリストについては、Kubeflowバージョンの依存関係を参照してください。<block ref="b84967824090781ee960169bb3232fc6" category="inline-link-macro-rx"></block> 。</block>
  <block id="84d21063d216560d873bc66cd38d62e8" category="paragraph">Kubeflow をデプロイする前に、Kubernetes クラスター内でデフォルトの StorageClass を指定することをお勧めします。 Kubeflow のデプロイメント プロセスでは、デフォルトの StorageClass を使用して新しい永続ボリュームのプロビジョニングが試行される場合があります。デフォルトの StorageClass として StorageClass が指定されていない場合、デプロイメントは失敗する可能性があります。クラスター内でデフォルトの StorageClass を指定するには、デプロイメント ジャンプ ホストから次のタスクを実行します。クラスター内でデフォルトの StorageClass をすでに指定している場合は、この手順をスキップできます。</block>
  <block id="d371ec612c125519e69855ad89d4445b" category="list-text">既存の StorageClass の 1 つをデフォルトの StorageClass として指定します。以下のコマンド例は、StorageClassの指定を示しています。<block ref="19a55e78496416c8db6565a114cfd5f3" prefix=" " category="inline-code"></block>デフォルトの StorageClass として。</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">その<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>Tridentバックエンド タイプは、最小 PVC サイズがかなり大きくなります。デフォルトでは、Kubeflow はサイズが数 GB しかない PVC をプロビジョニングしようとします。したがって、<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block> Kubeflow デプロイメントの目的で、デフォルトの StorageClass としてバックエンド タイプを指定します。</block>
  <block id="7724a5f9edc284eef2e4bc112adc1dd9" category="section-title">Kubeflow のデプロイメント オプション</block>
  <block id="e135506d2171533787a405262eeb67bc" category="paragraph">Kubeflow をデプロイするにはさまざまなオプションがあります。参照<block ref="59d814781a574912b676e75f9fe0e882" category="inline-link-macro-rx"></block>展開オプションのリストを確認し、ニーズに最適なオプションを選択してください。</block>
  <block id="07379a7db414d96104f4d3ab35ee3d59" category="admonition">検証のために、Kubeflow 1.7をデプロイしました。<block ref="f36b6222867dc75589b32398e1411061" category="inline-link-macro-rx"></block> 0.1.1。</block>
  <block id="0dbcc7b3c9a4c5ed6afff19c771a989d" category="summary">NetAppによるオープンソース MLOps - Kubeflow でNetApp DataOps ツールキットを使用する</block>
  <block id="3b70474868bce72e0d5d1fac42d1f643" category="doc">KubeflowでNetApp DataOpsツールキットを使用する</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kubernetes 向けNetAppデータ サイエンス ツールキット</block>
  <block id="4065ea77b68b6d949a165c54fc532d2a" category="paragraph">その<block ref="6f920cea43eeb6dd3a1bfb8ce1f9946a" category="inline-link-rx"></block>Kubeflow と組み合わせて使用できます。  NetApp Data Science Toolkit を Kubeflow と併用すると、次のような利点があります。</block>
  <block id="0a19b387d7028ea674dc64f74ecb97ea" category="list-text">データ サイエンティストは、スナップショットやクローンの作成など、高度なNetAppデータ管理操作を Jupyter Notebook 内から直接実行できます。</block>
  <block id="f4a972e1ae8aa85c6e67d7ad0ccc6dc4" category="list-text">スナップショットやクローンの作成などの高度なNetAppデータ管理操作は、Kubeflow Pipelines フレームワークを使用して自動化されたワークフローに組み込むことができます。</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflowの例</block>
  <block id="f1db0bc6ea6a4eee559e5d9946fd92ea" category="paragraph">参照<block ref="a5886b5aa215f1fd67a69d09a2725b9d" category="inline-link-rx"></block>Kubeflow でツールキットを使用する方法の詳細については、 NetApp Data Science Toolkit GitHub リポジトリ内のセクションを参照してください。</block>
  <block id="0e82e7615bc43e60306731cd1402df29" category="summary">NetAppによるオープンソース MLOps - データ サイエンティストや開発者向けに Jupyter Notebook ワークスペースをプロビジョニングする</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">データ サイエンティストまたは開発者向けに Jupyter Notebook ワークスペースをプロビジョニングする</block>
  <block id="b09a995a770ac7d1022303afcc4effb0" category="paragraph">Kubeflow は、データ サイエンティストのワークスペースとして機能する新しい Jupyter Notebook サーバーを迅速にプロビジョニングできます。  Kubeflowコンテキスト内のJupyter Notebookの詳細については、<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block> 。</block>
  <block id="6b9617f7154782faea34239e9eb5ea4a" category="paragraph"><block ref="6b9617f7154782faea34239e9eb5ea4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6dc629616db1f269870318e89e7522" category="summary">NetAppを使用したオープンソース MLOps - ワークフロー例 - Kubeflow とNetApp DataOps Toolkit を使用して画像認識モデルをトレーニングする</block>
  <block id="659e23f00660c05c4b7cf730eae0befe" category="doc">ワークフロー例 - Kubeflow とNetApp DataOps Toolkit を使用して画像認識モデルをトレーニングする</block>
  <block id="cc799f8653f5775220453347865834a9" category="paragraph">このセクションでは、Kubeflow とNetApp DataOps Toolkit を使用して画像認識用のニューラル ネットワークをトレーニングおよび展開する手順について説明します。これは、 NetAppストレージを組み込んだトレーニング ジョブを示す例として提供することを目的としています。</block>
  <block id="b759ef76b26f922987fbf418c77766cb" category="paragraph">Kubeflow パイプライン内のトレーニングおよびテストのステップに使用するために必要な構成を含む Dockerfile を作成します。  Dockerfileの例は以下のとおりです。</block>
  <block id="d1658ed5f5e35aee28cc518869591c5b" category="paragraph">要件に応じて、プログラムの実行に必要なすべてのライブラリとパッケージをインストールします。機械学習モデルをトレーニングする前に、すでに機能している Kubeflow デプロイメントがあることを前提としています。</block>
  <block id="1d7fb7fa777edda515304ad19af75036" category="section-title">PyTorch と Kubeflow パイプラインを使用して MNIST データで小規模な NN をトレーニングする</block>
  <block id="a2d6c085b2bfbb3fc92caceedba6806e" category="paragraph">MNIST データでトレーニングされた小さなニューラル ネットワークの例を使用します。 MNIST データセットは、0 〜 9 の数字の手書き画像で構成されています。画像のサイズは 28x28 ピクセルです。データセットは、60,000 枚のトレーニング画像と 10,000 枚の検証画像に分かれています。この実験に使用されたニューラル ネットワークは 2 層のフィードフォワード ネットワークです。トレーニングは Kubeflow Pipelines を使用して実行されます。ドキュメントを参照してください<block ref="bcb10ee1db2d847a3cadc06c872375ac" category="inline-link-rx"></block>詳細についてはこちらをご覧ください。  Kubeflow パイプラインには、前提条件セクションの Docker イメージが組み込まれています。</block>
  <block id="edfa32db89306c0de4efde13667133a5" category="inline-image-macro">Kubeflow パイプライン実行の可視化</block>
  <block id="c0bdd0d6d088108de0d2d172bd2f25be" category="paragraph"><block ref="c0bdd0d6d088108de0d2d172bd2f25be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7d85cbff0f5dec5d5092004b5b8774e" category="section-title">Tensorboard を使用して結果を視覚化する</block>
  <block id="d3246eab9678602f9301a80184803dff" category="inline-link">テンソルボード</block>
  <block id="12e2a8be9c4e17ffc7dc66217d8530ff" category="paragraph">モデルをトレーニングしたら、Tensorboard を使用して結果を視覚化できます。<block ref="a07862d9a0e51dec9c3587e87c541181" category="inline-link-rx"></block> Kubeflow ダッシュボードの機能として利用できます。ジョブに合わせてカスタム テンソルボードを作成できます。以下の例は、トレーニング精度とエポック数、およびトレーニング損失とエポック数のプロットを示しています。</block>
  <block id="1618fe0e500d9ed850d5e614c6620fd8" category="inline-image-macro">トレーニング損失と精度のTensorboardグラフ</block>
  <block id="cd45b495d2fd4d214ea7c430a9980d0a" category="paragraph"><block ref="cd45b495d2fd4d214ea7c430a9980d0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbdd778d6f4497497010df3f4ae35a67" category="section-title">Katib を使用したハイパーパラメータの実験</block>
  <block id="a47bff2eb2b867ca89a553eeb14da493" category="paragraph"><block ref="98b590f3a453d1e0809708b45d553c8f" category="inline-link-rx"></block>は、モデルのハイパーパラメータを試すために使用できる Kubeflow 内のツールです。実験を作成するには、まず目的の指標/目標を定義します。これは通常、テストの精度です。メトリックが定義されたら、試してみたいハイパーパラメータ (オプティマイザー/学習率/レイヤー数) を選択します。 Katib は、ユーザー定義の値を使用してハイパーパラメータ スイープを実行し、目的のメトリックを満たす最適なパラメータの組み合わせを見つけます。これらのパラメータは UI の各セクションで定義できます。あるいは、必要な仕様を記述した *YAML* ファイルを定義することもできます。以下はカティブ実験の図解です。</block>
  <block id="70e367edef0d0f2a63f6fff084365aa4" category="inline-image-macro">ハイパーパラメータ付きの Katib 実験ダッシュボード</block>
  <block id="12f61d15ca34416b644cbd8238634541" category="paragraph"><block ref="12f61d15ca34416b644cbd8238634541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd53955b02bf4a8bb0a318390df24ae6" category="inline-image-macro">トライアルチェック成功</block>
  <block id="600782cca16442259d603526a7cd0b29" category="paragraph"><block ref="600782cca16442259d603526a7cd0b29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d3e96caf95415deff9bb8b5bc25063" category="section-title">NetAppスナップショットを使用して追跡可能なデータを保存する</block>
  <block id="0b6ef7f84e44ffbb76d4eef1ef587269" category="paragraph">モデルのトレーニング中に、追跡可能性のためにトレーニング データセットのスナップショットを保存する場合があります。これを実行するには、以下に示すように、パイプラインにスナップショット ステップを追加します。スナップショットを作成するには、<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block> 。</block>
  <block id="9f205d5330ff4142363e15d261753156" category="inline-image-macro">Kubeflow でスナップショット パイプラインを構築するためのコード</block>
  <block id="18242bdffd149a4d04c88b7208997f55" category="paragraph"><block ref="18242bdffd149a4d04c88b7208997f55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe2b6f01ffb206a03c2e0fd0a802a4ca" category="inline-link">Kubeflow 用のNetApp DataOps Toolkit の例</block>
  <block id="7ba41dac79bc84ef4a806ce87fc4f97a" category="paragraph">参照<block ref="f0b3c05b3c22509c21d3296c77ee92d9" category="inline-link-rx"></block>詳細についてはこちらをご覧ください。</block>
  <block id="8ec1b3ffcff14d3a7476fee4a3e80bbd" category="summary">NetAppによるオープンソース MLOps - MLflow の導入</block>
  <block id="1e24ddb7a6a8df2478eebd688cf1f1df" category="doc">MLflow デプロイメント</block>
  <block id="eba75f7702c8d580f100f5c6e819419a" category="paragraph">このセクションでは、Kubernetes クラスターに MLflow をデプロイするために完了する必要があるタスクについて説明します。</block>
  <block id="1988a9fc415911c1b6cb091f9672aa99" category="admonition">MLflow は Kubernetes 以外のプラットフォームにもデプロイできます。  Kubernetes 以外のプラットフォームに MLflow をデプロイすることは、このソリューションの範囲外です。</block>
  <block id="effe3b356a9db8beeafdbe3692a3df6b" category="paragraph">MLflow は、Kubernetes の一般的なパッケージ マネージャーである Helm を使用してデプロイされます。  MLflow をデプロイする前に、Kubernetes コントロール ノードに Helm をインストールする必要があります。  Helmをインストールするには、<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block>公式 Helm ドキュメントに記載されています。</block>
  <block id="01fb0f36d01f7edcdcc66273b214f218" category="paragraph">MLflow をデプロイする前に、Kubernetes クラスター内でデフォルトの StorageClass を指定する必要があります。クラスター内でデフォルトのストレージクラスを指定するには、<block ref="a8e87de8c7ac570587ad7744774f8330" category="inline-link-macro-rx"></block>セクション。クラスター内でデフォルトの StorageClass をすでに指定している場合は、この手順をスキップできます。</block>
  <block id="6369a4aa768b1882566ceb106febe885" category="section-title">MLflowをデプロイする</block>
  <block id="4996360f41c2160eefec53bc938631c4" category="paragraph">前提条件が満たされたら、Helm チャートを使用して MLflow のデプロイを開始できます。</block>
  <block id="9b40c49f5b19b6b30c8e46c9a322cfa9" category="section-title">MLflow Helm Chart のデプロイメントを構成します。</block>
  <block id="54662ab0339cacf58980938d0d2997f6" category="paragraph">Helm チャートを使用して MLflow をデプロイする前に、*config.yaml* ファイルを使用して、 NetApp Tridentストレージ クラスを使用するようにデプロイを構成し、ニーズに合わせて他のパラメータを変更できます。  *config.yaml* ファイルの例は、次の場所にあります。<block ref="3fb631fe4b90fe5302819c1b11e0f768" category="inline-link-rx"></block></block>
  <block id="3ffd497fc5215b526be90b762ad3c730" category="admonition">config.yaml ファイルの *global.defaultStorageClass* パラメータでTrident storageClass を設定できます (例: storageClass: "ontap-flexvol")。</block>
  <block id="b0e9e89059c66feb24d2bae1faade5b4" category="section-title">Helm Chartのインストール</block>
  <block id="e2de44bdf60d5282b2d1f5dce8ef9fb8" category="paragraph">Helm チャートは、次のコマンドを使用して、MLflow のカスタム *config.yaml* ファイルとともにインストールできます。</block>
  <block id="b8fe21ea18633e2ba5c911e2b6c64135" category="admonition">このコマンドは、提供された *config.yaml* ファイルを介してカスタム構成で Kubernetes クラスターに MLflow をデプロイします。  MLflow は指定された名前空間にデプロイされ、リリースに対して Kubernetes 経由でランダムなリリース名が与えられます。</block>
  <block id="fe92b5543c9bb0daa69543a737a9937a" category="paragraph">Helm チャートのデプロイが完了したら、次のコマンドを使用してサービスにアクセスできるかどうかを確認できます。</block>
  <block id="5001194091e3ac05acb36e50188181cd" category="admonition">*jupyterhub* を、デプロイ時に使用した名前空間に置き換えます。</block>
  <block id="624995aae5a71a1b6b698d125dfa593f" category="paragraph">次のサービスが表示されます。</block>
  <block id="0727c036d98dcf728bf3678abc379532" category="admonition">NodePort サービスを使用してポート 30002 の MLflow にアクセスするように config.yaml ファイルを編集しました。</block>
  <block id="49ed0a1879305290bd3f5a83a6ebc4a2" category="section-title">MLflow にアクセスする</block>
  <block id="4336069c7c6830c86e24b3590bc33968" category="paragraph">MLflowに関連するすべてのサービスが起動したら、指定されたNodePortまたはLoadBalancerのIPアドレス（例：<block ref="4470100f30fdceb8d4bf43ad086f55fe" prefix=" " category="inline-code"></block> ）</block>
  <block id="4cdff711c1556a59f967422b42a85088" category="summary">NetAppを使用したオープンソース MLOps - NetAppと MLflow を使用したデータセットからモデルへのトレーサビリティ</block>
  <block id="96ea5f01f5435b957b4ccda05e9edc2a" category="doc">NetAppと MLflow によるデータセットからモデルへのトレーサビリティ</block>
  <block id="49f4e58115751b6e777c0881bed17f7b" category="paragraph">その<block ref="6bc4513613cdc996b868b94d9e9ded69" category="inline-link-rx"></block>データセットからモデル、またはワークスペースからモデルへのトレーサビリティを実装するために、MLflow の実験追跡機能と組み合わせて使用できます。</block>
  <block id="a6086bfa36daf4e19b000df54ab1dd1e" category="paragraph">データセットからモデルへ、またはワークスペースからモデルへのトレーサビリティを実装するには、次のサンプルコード スニペットに示すように、トレーニング実行の一部として DataOps ツールキットを使用してデータセットまたはワークスペース ボリュームのスナップショットを作成します。このコードは、MLflow 実験追跡サーバーに記録する特定のトレーニング実行に関連付けられたタグとして、データ ボリューム名とスナップショット名を保存します。</block>
  <block id="f8e6fa4a88901fdc129b3ce376463f53" category="summary">NetAppによるオープンソース MLOps - 同期分散 AI ワークロードの実行</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">同期分散AIワークロードを実行する</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes クラスターで同期マルチノード AI および ML ジョブを実行するには、デプロイメント ジャンプ ホストで次のタスクを実行します。このプロセスにより、 NetAppボリュームに保存されているデータを活用し、単一のワーカー ノードが提供できるよりも多くの GPU を使用できるようになります。同期分散 AI ジョブの図については、次の図を参照してください。</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">同期分散ジョブは、非同期分散ジョブと比較して、パフォーマンスとトレーニングの精度を向上させることができます。同期ジョブと非同期ジョブの長所と短所に関する説明は、このドキュメントの範囲外です。</block>
  <block id="dd02d155f88fd3ea2f5dfd5720641a55" category="paragraph"><block ref="dd02d155f88fd3ea2f5dfd5720641a55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46300fa439cc237919f854816fc89fc2" category="inline-link-macro">単一ノードのAIワークロードを実行する</block>
  <block id="252bb749f76608017bf1d4a822ebba6d" category="list-text">以下のコマンド例は、セクションの例で単一ノードで実行された同じTensorFlowベンチマークジョブの同期分散実行に参加する1つのワーカーの作成を示しています。<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> 。この特定の例では、ジョブが 2 つのワーカー ノード間で実行されるため、1 つのワーカーのみがデプロイされます。</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetesの公式ドキュメント</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">この例のワーカー デプロイメントでは 8 個の GPU が要求されるため、8 個以上の GPU を備えた単一の GPU ワーカー ノードで実行できます。  GPU ワーカー ノードに 8 個を超える GPU が搭載されている場合は、パフォーマンスを最大限に高めるために、この数をワーカー ノードに搭載されている GPU の数と同じになるように増やすことをおすすめします。  Kubernetesのデプロイメントの詳細については、<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block> 。</block>
  <block id="4b59e69845bd812b9cddcb0b700f3680" category="paragraph">この例では、この特定のコンテナ化されたワーカーは単独では完了しないため、Kubernetes デプロイメントが作成されます。したがって、Kubernetes ジョブ構造を使用してデプロイするのは意味がありません。ワーカーが単独で完了するように設計または記述されている場合は、ジョブ コンストラクトを使用してワーカーをデプロイすると効果的です。</block>
  <block id="57e84b8262eb9db582d9f861e85ed291" category="paragraph">この例のデプロイメント仕様で指定されているポッドには、<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>の価値<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。この値は、Kubernetes が通常各ポッドに対して作成する仮想ネットワーク スタックではなく、ホスト ワーカー ノードのネットワーク スタックをポッドが使用することを意味します。この場合、このアノテーションが使用されるのは、特定のワークロードが Open MPI、NCCL、および Horovod に依存して、ワークロードを同期分散方式で実行するためです。したがって、ホスト ネットワーク スタックへのアクセスが必要です。 Open MPI、NCCL、Horovod に関する説明は、このドキュメントの範囲外です。これが<block ref="02cbe2b15bc778c7658250053bbc5a5c" prefix=" " category="inline-code"></block>アノテーションが必要かどうかは、実行している特定のワークロードの要件によって異なります。詳細については、<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>フィールドについては、<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block> 。</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">手順 1 で作成したワーカー デプロイメントが正常に起動したことを確認します。次のコマンド例は、デプロイメント定義に示されているように、デプロイメントに対して単一のワーカー ポッドが作成され、このポッドが現在 GPU ワーカー ノードの 1 つで実行されていることを確認します。</block>
  <block id="77fed810b2a592adcab667c30e5c0bdb" category="list-text">同期マルチノード ジョブの実行を開始、参加、追跡するマスター用の Kubernetes ジョブを作成します。以下のコマンド例は、セクションの例で単一ノードで実行された同じTensorFlowベンチマークジョブの同期分散実行を開始、参加、追跡するマスターを1つ作成します。<block ref="055e86cc3668b8856dedbd3ee4c3f307" category="inline-link-macro-rx"></block> 。</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">この例のマスタージョブは 8 つの GPU を要求するため、8 個以上の GPU を備えた単一の GPU ワーカーノードで実行できます。  GPU ワーカー ノードに 8 個を超える GPU が搭載されている場合は、パフォーマンスを最大限に高めるために、この数をワーカー ノードに搭載されている GPU の数と同じになるように増やすことをおすすめします。</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">このジョブ定義例で指定されているマスターポッドには、<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>の価値<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>労働者ポッドに与えられたのと同じように<block ref="e3b493bcbdc62af28f127a151a9fb487" prefix=" " category="inline-code"></block>の価値<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>ステップ1で。この値が必要な理由の詳細については、手順 1 を参照してください。</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">手順 3 で作成したマスター ジョブが正しく実行されていることを確認します。次のコマンド例は、ジョブ定義に示されているように、ジョブに対して単一のマスター ポッドが作成され、このポッドが現在 GPU ワーカー ノードの 1 つで実行されていることを確認します。また、手順 1 で最初に確認したワーカー ポッドがまだ実行されており、マスター ポッドとワーカー ポッドが異なるノードで実行されていることも確認する必要があります。</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">手順 3 で作成したマスター ジョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">不要になったらワーカーデプロイメントを削除します。次のコマンド例は、手順 1 で作成されたワーカー デプロイメント オブジェクトの削除を示しています。</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">ワーカー デプロイメント オブジェクトを削除すると、Kubernetes は関連付けられているワーカー ポッドを自動的に削除します。</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">*オプション:* マスタージョブアーティファクトをクリーンアップします。次のコマンド例は、手順 3 で作成されたマスター ジョブ オブジェクトの削除を示しています。</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">マスタージョブオブジェクトを削除すると、Kubernetes は関連付けられているすべてのマスターポッドを自動的に削除します。</block>
  <block id="3b1ef0ea9661ba5d2eeba15fab13cf00" category="summary">NetAppによるオープンソース MLOps - 単一ノードの AI ワークロードを実行</block>
  <block id="9e339bbe1fec0fc2a91b7c2f8dd9d7f7" category="paragraph">Kubernetes クラスターで単一ノードの AI および ML ジョブを実行するには、デプロイメント ジャンプ ホストから次のタスクを実行します。 Tridentを使用すると、ペタバイト規模のデータを含む可能性のあるデータ ボリュームを、Kubernetes ワークロードから迅速かつ簡単にアクセスできるようになります。このようなデータ ボリュームを Kubernetes ポッド内からアクセスできるようにするには、ポッド定義で PVC を指定するだけです。</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">このセクションでは、Kubernetes クラスターで実行しようとしている特定の AI および ML ワークロードがすでにコンテナー化 (Docker コンテナー形式) されていることを前提としています。</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNetウェブサイト</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">次のコマンド例は、ImageNet データセットを使用する TensorFlow ベンチマーク ワークロード用の Kubernetes ジョブの作成を示しています。  ImageNetデータセットの詳細については、<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block> 。</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">このサンプルジョブは 8 個の GPU を要求するため、8 個以上の GPU を備えた単一の GPU ワーカーノードで実行できます。このサンプルジョブは、8 個以上の GPU を搭載したワーカーノードが存在しない、または現在別のワークロードで使用されているクラスターで送信できます。その場合、そのようなワーカーノードが利用可能になるまで、ジョブは保留状態のままになります。</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">さらに、ストレージ帯域幅を最大化するために、必要なトレーニング データを含むボリュームは、このジョブによって作成されるポッド内に 2 回マウントされます。ポッドには別のボリュームも搭載されています。この 2 番目のボリュームは、結果とメトリックを保存するために使用されます。これらのボリュームは、PVC の名前を使用してジョブ定義で参照されます。  Kubernetesジョブの詳細については、<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block> 。</block>
  <block id="c1cf1b159caffa27246be2b5201cdd54" category="paragraph">アン<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>ボリューム付き<block ref="075a3e36a0a52dcbc568c05788e8a713" prefix=" " category="inline-code"></block>の価値<block ref="4789f23283b3a61f858b641a1bef19a3" prefix=" " category="inline-code"></block>に取り付けられている<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>このサンプルジョブが作成するポッド内。デフォルトのサイズは<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>Docker コンテナ ランタイムによって自動的に作成される仮想ボリュームは、TensorFlow のニーズを満たせない場合があります。マウント<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>次の例のようなボリュームは、十分な大きさの<block ref="edd846be807ebc0ca06f1fcb0258172c" prefix=" " category="inline-code"></block>仮想ボリューム。詳細については<block ref="77ea5ef86c2c650eb37fa7374f084bbc" prefix=" " category="inline-code"></block>巻については、<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block> 。</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">この例のジョブ定義で指定されている単一のコンテナには、<block ref="616a0bdac22bb48049712f2f41741fd1" prefix=" " category="inline-code"></block>の価値<block ref="b326b5062b2f0e69046810717534cb09" prefix=" " category="inline-code"></block>。この値は、コンテナがホスト上で実質的にルートアクセス権を持っていることを意味します。この場合、実行される特定のワークロードにはルート アクセスが必要であるため、このアノテーションが使用されます。具体的には、ワークロードが実行するキャッシュクリア操作にはルート アクセスが必要です。これが<block ref="8be504a312b42bc24ff61c9c2c31990d" prefix=" " category="inline-code"></block>アノテーションが必要かどうかは、実行している特定のワークロードの要件によって異なります。</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">手順 1 で作成したジョブが正しく実行されていることを確認します。次のコマンド例は、ジョブ定義で指定されたとおりにジョブに対して単一のポッドが作成され、このポッドが現在 GPU ワーカー ノードの 1 つで実行されていることを確認します。</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">手順 1 で作成したジョブが正常に完了したことを確認します。次のコマンド例は、ジョブが正常に完了したことを確認します。</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">*オプション:* ジョブの成果物をクリーンアップします。次のコマンド例は、手順 1 で作成されたジョブ オブジェクトの削除を示しています。</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">ジョブ オブジェクトを削除すると、Kubernetes は関連付けられているポッドを自動的に削除します。</block>
  <block id="91ab0152618ead1fcdc42eff8c2d0735" category="summary">NetAppを使用したオープンソース MLOps - NetApp AIPod導入のためのTridentバックエンドの例</block>
  <block id="9137107e8d97a11b9174eb6766c2051f" category="doc">NetApp AIPod導入におけるTridentバックエンドの例</block>
  <block id="bf498d2b211c45a57e0eaa477b958b58" category="inline-link-macro">NetApp AIPod</block>
  <block id="8b57fa6d8107ac5ef8cc72bed591a355" category="paragraph">Tridentを使用して Kubernetes クラスター内でストレージ リソースを動的にプロビジョニングする前に、1 つ以上のTridentバックエンドを作成する必要があります。以下の例は、このソリューションのコンポーネントをデプロイする場合に作成する可能性のあるさまざまなタイプのバックエンドを表しています。<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。バックエンドの詳細、および他のプラットフォーム/環境のバックエンドの例については、<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> 。</block>
  <block id="5bce19d939aea54f55df565bb07b573b" category="list-text">NetApp、 AIPod用にFlexGroup対応のTrident Backend を作成することを推奨しています。</block>
  <block id="987adc3703d1f7aeb77e70a3d25e35ca" category="paragraph">次のサンプルコマンドは、 AIPodストレージ仮想マシン (SVM) 用のFlexGroup対応Tridentバックエンドの作成を示しています。このバックエンドは<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>ストレージ ドライバー。  ONTAP は、 FlexVolとFlexGroup2 つの主要なデータ ボリューム タイプをサポートしています。 FlexVolボリュームにはサイズ制限があります (この執筆時点では、最大サイズは特定の展開によって異なります)。一方、 FlexGroupボリュームは、最大 20PB および 4000 億ファイルまで直線的に拡張でき、単一の名前空間を提供することでデータ管理を大幅に簡素化します。したがって、 FlexGroupボリュームは、大量のデータに依存する AI および ML ワークロードに最適です。</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">少量のデータで作業していて、 FlexGroupボリュームの代わりにFlexVolボリュームを使用する場合は、<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>ストレージドライバーの代わりに<block ref="844e84da8e822b4a33c4d8188da97937" prefix=" " category="inline-code"></block>ストレージ ドライバー。</block>
  <block id="112efecf6dc8105639ea7e0b2a19f0e1" category="list-text">NetApp、 FlexVol対応のTridentバックエンドの作成も推奨しています。永続的なアプリケーションのホスティング、結果、出力、デバッグ情報などの保存には、 FlexVolボリュームを使用することをお勧めします。 FlexVolボリュームを使用する場合は、 FlexVol対応のTridentバックエンドを 1 つ以上作成する必要があります。次のサンプル コマンドは、単一のFlexVol対応Tridentバックエンドの作成を示しています。</block>
  <block id="860fee506515550a9fba4086f9358bf0" category="summary">NetAppを使用したオープンソース MLOps - Tridentオペレーションの例</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="doc">Trident操作の例</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">このセクションには、 Tridentで実行するさまざまな操作の例が含まれています。</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">既存のボリュームをインポートする</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Kubernetes クラスター内のコンテナーにマウントするが、クラスター内の PVC に関連付けられていない既存のボリュームがNetAppストレージ システム/プラットフォーム上に存在する場合は、これらのボリュームをインポートする必要があります。これらのボリュームをインポートするには、 Tridentボリューム インポート機能を使用できます。</block>
  <block id="8a87b71bee3405ddd29416b675ef7c61" category="paragraph">以下のコマンド例は、<block ref="49f0544a1f0d45f5d68ad2e883eaec4a" prefix=" " category="inline-code"></block> 。 PVCの詳細については、<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> 。ボリュームインポート機能の詳細については、<block ref="7e5b92b70f9fb8a6ea9680492953995f" category="inline-link-rx"></block> 。</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">アン<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>の価値<block ref="c24ad3d99a666c95edd149419c958ee0" prefix=" " category="inline-code"></block>サンプルの PVC 仕様ファイルで指定されています。詳細については、<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>フィールドについては、<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> 。</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">新しいボリュームをプロビジョニングする</block>
  <block id="6b2d9cc0e6416b1fddc173d87e1ebad4" category="paragraph">Tridentを使用して、 NetAppストレージ システムまたはプラットフォームに新しいボリュームをプロビジョニングできます。</block>
  <block id="4268e244b7de91b44bea226a48855c28" category="section-title">kubectl を使用して新しいボリュームをプロビジョニングする</block>
  <block id="d5c5993dfd543be5e01f6d98516d64cb" category="paragraph">次のコマンド例は、kubectl を使用して新しいFlexVol volumeをプロビジョニングする方法を示しています。</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">アン<block ref="1963d17f24888bdf1f22d7ea7f72f607" prefix=" " category="inline-code"></block>の価値<block ref="caa8dc1f4bb28d2d11226494cd05a123" prefix=" " category="inline-code"></block>次のサンプル PVC 定義ファイルで指定されています。詳細については、<block ref="556f4fe5afbf7b3614f70dcf9e38c44c" prefix=" " category="inline-code"></block>フィールドについては、<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block> 。</block>
  <block id="3b12f01a10ad45fb526861fc286c7953" category="section-title">NetApp DataOps ツールキットを使用して新しいボリュームをプロビジョニングする</block>
  <block id="55876228853abf632dec9346a4f372ec" category="inline-link-macro">ドキュメント</block>
  <block id="b1e49394b547d60433afdf0d608bc52b" category="paragraph">NetApp DataOps Toolkit for Kubernetes を使用して、 NetAppストレージ システムまたはプラットフォームに新しいボリュームをプロビジョニングすることもできます。 NetApp DataOps Toolkit for Kubernetes は、 Tridentを使用してボリュームをプロビジョニングしますが、ユーザーのプロセスを簡素化します。参照<block ref="37e4d77423419479f43c92e2fdd640ea" category="inline-link-macro-rx"></block>詳細については。</block>
  <block id="fdc02d1c80a87a40b5361ca1abf33964" category="summary">NetAppを使用したオープンソース MLOps - NetApp AIPodデプロイメント向けの Kubernetes ストレージクラスの例</block>
  <block id="d25894e802e87270d1f6b560c3332055" category="doc">NetApp AIPodデプロイメント用の Kubernetes ストレージクラスの例</block>
  <block id="98384d229f6fec246185f9bfa14fcb7a" category="paragraph">Tridentを使用して Kubernetes クラスター内でストレージ リソースを動的にプロビジョニングする前に、1 つ以上の Kubernetes StorageClasses を作成する必要があります。以下の例は、このソリューションのコンポーネントを次の場所に展開する場合に作成する可能性のあるさまざまなタイプのストレージクラスを表しています。<block ref="b2fcf1ac0e8df6bdaefce420e27d6368" category="inline-link-macro-rx"></block> 。  StorageClassesの詳細、および他のプラットフォーム/環境のStorageClassesの例については、<block ref="81f3e4134a6f5ebea4459e5f629a42dc" category="inline-link-macro-rx"></block> 。</block>
  <block id="3f91a2c4d8ba66304e817a6c1c8d8086" category="inline-link-macro">NFS over RDMA</block>
  <block id="5f9e4626ef73df529e1be620feb3c403" category="list-text">NetAppは、セクションで作成したFlexGroup対応Tridentバックエンド用のStorageClassを作成することを推奨します。<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block> 、ステップ 1。以下のコマンド例は、セクションで作成されたサンプルバックエンドに対応する複数のストレージクラスの作成を示しています。<block ref="ba9f980165fbda795fa9abfedd793128" category="inline-link-macro-rx"></block>ステップ1 - 活用するもの<block ref="2f98f20aaeb2334cc6d03f1e60eea86f" category="inline-link-macro-rx"></block>そしてそうではないもの。</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetesドキュメント</block>
  <block id="063f66d6e76f1f9cc44a56824e67f49c" category="paragraph">対応するPersistentVolumeClaim（PVC）が削除されたときに永続ボリュームが削除されないように、次の例では<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>の価値<block ref="afece4245269582cb2f1009d4fb52047" prefix=" " category="inline-code"></block>。詳細については、<block ref="fa29931471789c6ada456d62b5bc803a" prefix=" " category="inline-code"></block>フィールドについては、公式<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>。</block>
  <block id="b1c0c18c267e82c16a2fb0fd855fea96" category="paragraph">注: 次の例の StorageClasses では、最大転送サイズとして 262144 を使用します。この最大転送サイズを使用するには、 ONTAPシステムで最大転送サイズを適切に設定する必要があります。参照<block ref="e88143f84eca8f5af17b24d59e272642" category="inline-link-macro-rx"></block>詳細については。</block>
  <block id="611c47063b50d4e29ff14b57ac5d1a76" category="paragraph">注: NFS over RDMA を使用するには、 ONTAPシステムで NFS over RDMA を設定する必要があります。参照<block ref="299f3386ca6234337ede91409b59779f" category="inline-link-macro-rx"></block>詳細については。</block>
  <block id="8dffb2755e3c128c00970dd619da5b34" category="paragraph">注: 次の例では、StorageClass 定義ファイルの storagePool フィールドに特定のバックエンドが指定されています。</block>
  <block id="cce8016ccbbe58eeb47eb8596b78018e" category="inline-link-macro">AIPodデプロイメント用のTridentバックエンドの例</block>
  <block id="6c9233cf2164bf9b74bbca02d5360c85" category="list-text">NetApp、セクションで作成したFlexVol対応Tridentバックエンドに対応するStorageClassを作成することも推奨しています。<block ref="f93f354f4df9d1f116edb5ebdff3f7d5" category="inline-link-macro-rx"></block> 、ステップ2。次のサンプルコマンドは、 FlexVolボリューム用の単一の StorageClass の作成を示しています。</block>
  <block id="fc614170d6c05a82aef1df8658cdddbb" category="paragraph">注: 次の例では、StorageClass 定義ファイルの storagePool フィールドに特定の Backend が指定されていません。このStorageClassを使用してKubernetesでボリュームを管理する場合、 Tridentは利用可能なバックエンドを使用しようとします。<block ref="8321592ce24c8a122ecf26a63cfca407" prefix=" " category="inline-code"></block>ドライバ。</block>
  <block id="3ad98aba8e7b278dbcb8d707671576f7" category="list-text">実験や迅速な反復を可能にするために、大容量の JupyterLab ワークスペースをほぼ瞬時に複製します。</block>
  <block id="85ca8d103a016e6e8898855c4ecfa6e2" category="list-text">バックアップやトレーサビリティ/ベースライン作成のために、大容量の JupyterLab ワークスペースのスナップショットをほぼ瞬時に保存します。</block>
  <block id="60a1b5ff80d3333df7174eb4d8d7f4e1" category="list-text">大容量、高パフォーマンスのデータ ボリュームをほぼ瞬時にプロビジョニング、クローン作成、スナップショット作成します。</block>
  <block id="c4bca757471e0afa8bcb4da8a5f5e802" category="paragraph"><block ref="c4bca757471e0afa8bcb4da8a5f5e802" category="inline-link-macro-rx"></block></block>
  <block id="e74b9287ad8cc207ad48fbfdff9cf078" category="summary">結論 - NetApp向けベクトルデータベースソリューション</block>
  <block id="b4eb3fd5fa52ba6b8d0eac43bac21d6f" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューションについて説明します。</block>
  <block id="ec77b1d1c933a6b137ec223a695b5ace" category="paragraph">最後に、このドキュメントでは、Milvus や pgvector などのベクトル データベースをNetAppストレージ ソリューションに導入および管理する方法の包括的な概要を示します。  NetApp ONTAPとStorageGRIDオブジェクトストレージを活用するためのインフラストラクチャガイドラインについて説明し、ファイルとオブジェクトストアを通じて AWS FSx ONTAPの Milvus データベースを検証しました。</block>
  <block id="9799eea6b7d21ae2ad3b8f14f6de8b57" category="paragraph">私たちは、NetApp のファイルとオブジェクトの二重性について調査し、ベクター データベースのデータだけでなく、他のアプリケーションでもその有用性を実証しました。また、NetApp のエンタープライズ管理製品であるSnapCenterが、ベクター データベース データのバックアップ、リストア、クローン機能を提供し、データの整合性と可用性を確保する方法についても説明しました。</block>
  <block id="31068d7cc739be3f40f71a1c2165b247" category="paragraph">このドキュメントでは、NetApp のハイブリッド クラウド ソリューションがオンプレミスとクラウド環境全体でデータのレプリケーションと保護を提供し、シームレスで安全なデータ管理エクスペリエンスを実現する方法についても詳しく説明します。  NetApp ONTAP上の Milvus や pgvecto などのベクトル データベースのパフォーマンス検証に関する洞察を提供し、その効率性と拡張性に関する貴重な情報を提供しました。</block>
  <block id="48b5d59439c5cbfd986de5db0e4585aa" category="paragraph">最後に、LLM を使用した RAG と NetApp の内部 ChatAI という 2 つの生成 AI の使用例について説明しました。これらの実用的な例は、このドキュメントで概説されている概念と実践の実際の応用と利点を強調しています。全体として、このドキュメントは、NetApp の強力なストレージ ソリューションを活用してベクター データベースを管理しようとしているすべての人にとって包括的なガイドとして役立ちます。</block>
  <block id="95ab8b5192fec6278c61d897cbcc59b7" category="paragraph">著者は、このホワイト ペーパーをNetApp の顧客とNetApp の分野にとって価値あるものにするためにフィードバックとコメントを提供してくれた以下の協力者およびその他の関係者に心から感謝の意を表します。</block>
  <block id="cf069f89f8b650e3f6d927f7417a21f1" category="list-text">Sathish Thyagarajan 氏、 NetApp 、 ONTAP AI &amp; Analytics、テクニカル マーケティング エンジニア</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">マイク・オグルスビー、 NetAppテクニカル マーケティング エンジニア</block>
  <block id="633e7060d92a08658a3f5248a7c7cdf2" category="list-text">AJ マハジャン、 NetAppシニア ディレクター</block>
  <block id="4963f582fdf68104e20554eb28bcf2ca" category="list-text">Joe Scott、 NetAppワークロード パフォーマンス エンジニアリング マネージャー</block>
  <block id="710fcc80e2c0809a7239d471028d8f70" category="list-text">Puneet Dhawan、 NetApp 、FSX製品管理担当シニアディレクター</block>
  <block id="7b62519a4ae964c6b307925c68166ca7" category="list-text">Yuval Kalderon、 NetApp FSx 製品チーム シニア プロダクト マネージャー</block>
  <block id="b97cdeb80b669ea57564c9bf0542d2ef" category="list-text">Milvusドキュメント -<block ref="35e085709f47cfca6bbc0746cd0ba49f" category="inline-link-rx"></block></block>
  <block id="f7356e8678620084b93884e3b7a23a9f" category="list-text">Milvus スタンドアロン ドキュメント -<block ref="a47fb3f2bfaa36fa0b44dc5f5ba452a4" category="inline-link-rx"></block></block>
  <block id="8b8bc5296c7be638754abb2f408d2099" category="list-text">NetApp製品ドキュメント<block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="3852b719e664b2ae1596e622f21daba3" category="inline-link-macro">installcluster ドキュメント</block>
  <block id="9351f6d4d819e15d23724c78a36aea99" category="list-text">インスタクラスタ -<block ref="39b68163c56ae9979050121a6264d765" category="inline-link-macro-rx"></block></block>
  <block id="3b3d7bce734c0832c20ba464b1f2d199" category="cell">2024年4月</block>
  <block id="123ffe6774f72f5d1c22607445987e46" category="summary">NetApp 用ベクター データベース ソリューションへのデータの準備</block>
  <block id="f7ab9b609aa315a4d224e6e33b2a10ee" category="doc">付録 B: prepare_data_netapp_new.py</block>
  <block id="8d5099e275cc435c14417dc8e6bd49aa" category="paragraph">このセクションでは、ベクター データベース用のデータを準備するために使用されるサンプル Python スクリプトを示します。</block>
  <block id="fe51a53701c4e0dd7696bed40b6f70db" category="summary">ベクターデータベースの導入手順 - NetApp 向けベクターデータベースソリューション</block>
  <block id="19988795e8f88dfff005718f72472b6c" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューションの導入手順について説明します。</block>
  <block id="fa0b3671f099fc4fc4fbe3ac8374d92c" category="section-title">展開手順</block>
  <block id="b63c54c37cdb817c256ef1a7e50fc5fe" category="paragraph">このデプロイメント セクションでは、以下のようにラボのセットアップに Kubernetes を使用した milvus ベクター データベースを使用しました。</block>
  <block id="e275837fe1aa897ebc01eed7a7354278" category="paragraph"><block ref="e275837fe1aa897ebc01eed7a7354278" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b4b9b6998f8b3056b486430aa9c6fd" category="paragraph">NetApp ストレージは、顧客データと Milvus クラスター データを保存するためのクラスター用のストレージを提供します。</block>
  <block id="46d201d3a5d870036bd7573752054979" category="section-title">NetAppストレージのセットアップ – ONTAP</block>
  <block id="1fa9de5db47759d3e586f783f647d3e8" category="paragraph">NFS (ネットワーク ファイル システム) の場合は、次の手順に従ってください。</block>
  <block id="932d306add3eb18c39b41633590f1ad6" category="list-text">NFSv4 用のFlexGroupボリュームを作成します。この検証のセットアップでは、48 台の SSD を使用しました。1 台の SSD はコントローラのルート ボリューム専用で、47 台の SSD は NFSv4 用に分散されています。FlexGroup ボリュームの NFS エクスポート ポリシーに、Kubernetes (K8s) ノード ネットワークの読み取り/書き込み権限があることを確認FlexGroupます。これらの権限が設定されていない場合は、K8s ノード ネットワークに読み取り/書き込み (rw) 権限を付与します。</block>
  <block id="a53a2ae8c8ba1b0def8ad999e086f94c" category="list-text">すべての K8s ノードでフォルダーを作成し、各 K8s ノードの論理インターフェイス (LIF) を介してこのフォルダーにFlexGroupボリュームをマウントします。</block>
  <block id="b02cc86a747fc07392e2eceafa48816f" category="paragraph">NAS S3 (Network Attached Storage Simple Storage Service) の場合は、以下の手順に従ってください。</block>
  <block id="a1ec6ff754c8c8958a577b43995e9caf" category="list-text">NFS 用のFlexGroupボリュームを作成します。</block>
  <block id="c550fe4970f3cf4781625e620b4e30a9" category="list-text">タイプを「nas」に設定し、NFSv3 ボリュームへのパスを指定して NAS バケットを作成します。この目的のために S3 バケットを利用することもできます。</block>
  <block id="81f40424ce0b0dbbc91e2bc42bee8924" category="section-title">NetAppストレージのセットアップ – StorageGRID</block>
  <block id="c8462ad4cf62a8bf6b594e7929097b68" category="list-text">storageGRID ソフトウェアをインストールします。</block>
  <block id="aec1f80331e64507a359fd96a93d2dee" category="list-text">テナントとバケットを作成します。</block>
  <block id="6eea00d5693e3a2106cc3859939c6e8e" category="list-text">必要な権限を持つユーザーを作成します。</block>
  <block id="5288dc14a18d189389b382eda1a7f83a" category="paragraph">詳細については、<block ref="c095f7864703639165de914bdacb9488" category="inline-link-rx"></block></block>
  <block id="1b4b1bbd037e26c942386744e0c37fb6" category="summary">docker-compose.xml - NetApp 用ベクター データベース ソリューション</block>
  <block id="05b4af2cc796ae07ae3efb49a12abe45" category="doc">付録D: docker-compose.yml</block>
  <block id="4f50d45b7589f5ba7443aff7e641e0ce" category="paragraph">このセクションには、 NetAppのベクトル データベース ソリューションのサンプル YAML コードが含まれています。</block>
  <block id="1746460223f3daa35634698cf8a11429" category="summary">SnapCenterを使用したベクターデータベース保護 - NetApp向けベクターデータベースソリューション</block>
  <block id="72043cdd90d91317b18d2fcdc935eea8" category="doc">SnapCenterを使用したベクトル データベース保護</block>
  <block id="0cbe53988249acb8210e165c8f9d4ff1" category="paragraph">このセクションでは、 NetApp SnapCenterを使用してベクター データベースのデータ保護を提供する方法について説明します。</block>
  <block id="62e16ceab82346a15bf6bb06f5076498" category="section-title">NetApp SnapCenterを使用したベクトル データベース保護。</block>
  <block id="03e2211bf15aaf80440217e34090ab7a" category="paragraph">たとえば、映画制作業界では、顧客がビデオ ファイルやオーディオ ファイルなどの重要な埋め込みデータを所有していることがよくあります。ハードドライブの故障などの問題によりこのデータが失われると、業務に大きな影響が及び、数百万ドル規模の事業が危険にさらされる可能性があります。貴重なコンテンツが失われ、大きな混乱と経済的損失が発生する事例がありました。したがって、この重要なデータのセキュリティと整合性を確保することは、この業界にとって最も重要です。このセクションでは、 SnapCenter がONTAPにあるベクター データベース データと Milvus データをどのように保護するかについて詳しく説明します。この例では、顧客データ用にNFS ONTAPボリューム（vol1）から派生したNASバケット（milvusdbvol1）と、Milvusクラスタ構成データ用に別のNFSボリューム（vectordbpv）を使用しました。<block ref="d81f12ee1ce058489f6dd74377fd8f1e" category="inline-link-macro-rx"></block> SnapCenterバックアップワークフロー</block>
  <block id="e159df91d2537b3f0b589d157dfbffd9" category="list-text">SnapCenterコマンドを実行するために使用するホストを設定します。</block>
  <block id="0d3b27c161709a06da0484a310f325e3" category="paragraph"><block ref="0d3b27c161709a06da0484a310f325e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00ebf5cec061915cd0462d73602dcad8" category="inline-link-macro">NetAppオートメーションストア</block>
  <block id="e5dbb47baa2442a0c626c78cd3791dfb" category="list-text">ストレージ プラグインをインストールして構成します。追加されたホストから、「その他のオプション」を選択します。ダウンロードしたストレージプラグインを選択して、<block ref="6d50396c8bd3accea0ce09d72830daea" category="inline-link-macro-rx"></block> 。プラグインをインストールし、設定を保存します。</block>
  <block id="4225308f0df24ace1516a7673df5f583" category="paragraph"><block ref="4225308f0df24ace1516a7673df5f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="56efc857e5b28976189acb94af8f4ac8" category="list-text">ストレージ システムとボリュームを設定します。「ストレージ システム」の下にストレージ システムを追加し、SVM (ストレージ仮想マシン) を選択します。この例では、「vs_nvidia」を選択しました。</block>
  <block id="6d0b2d59ec18c3814b7e5430ff27609f" category="paragraph"><block ref="6d0b2d59ec18c3814b7e5430ff27609f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2dcb622158143845f18538a410575a" category="list-text">バックアップ ポリシーとカスタム スナップショット名を組み込んだベクター データベースのリソースを確立します。</block>
  <block id="a8f4ce53516fd9e67b7eb9a099d49120" category="list-text">デフォルト値で整合性グループ バックアップを有効にし、ファイルシステムの整合性なしでSnapCenterを有効にします。</block>
  <block id="6230f7a2a3dc9bac46ff1cd677466af1" category="list-text">[ストレージ フットプリント] セクションで、ベクター データベースの顧客データと Milvus クラスター データに関連付けられているボリュームを選択します。この例では、これらは「vol1」と「vectordbpv」です。</block>
  <block id="61f90f32ea94cd1e612c6ce7a1713b45" category="list-text">ベクター データベース保護のポリシーを作成し、そのポリシーを使用してベクター データベース リソースを保護します。</block>
  <block id="de59432e970871e34ec01050d133ea25" category="paragraph"><block ref="de59432e970871e34ec01050d133ea25" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc8a652b9ab6e0d4b7d2a344da503ff6" category="list-text">Python スクリプトを使用して S3 NAS バケットにデータを挿入します。私たちの場合、Milvus が提供するバックアップ スクリプト「prepare_data_netapp.py」を変更し、「sync」コマンドを実行してオペレーティング システムからデータをフラッシュしました。</block>
  <block id="3474edc9b3792a7404f86710df9ef875" category="list-text">S3 NAS バケット内のデータを検証します。この例では、タイムスタンプが「2024-04-08 21:22」のファイルは、「prepare_data_netapp.py」スクリプトによって作成されました。</block>
  <block id="d47a679804c0cbffd0dc44fe5bb8fd17" category="list-text">'milvusdb'リソースからコンシステンシグループ（CG）スナップショットを使用してバックアップを開始します。</block>
  <block id="fe4f644e0cbbb28bc2dc58c59ba4712f" category="paragraph"><block ref="fe4f644e0cbbb28bc2dc58c59ba4712f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511f6b9ef02b86884feaa7670c95ad25" category="list-text">バックアップ機能をテストするために、バックアップ プロセス後に新しいテーブルを追加するか、NFS (S3 NAS バケット) から一部のデータを削除しました。</block>
  <block id="b32454a703c99d763bb542ccb4127d18" category="paragraph">このテストでは、バックアップ後に誰かが新しい、不要な、または不適切なコレクションを作成したシナリオを想定します。このような場合、ベクター データベースを、新しいコレクションが追加される前の状態に戻す必要があります。たとえば、「hello_milvus_netapp_sc_testnew」や「hello_milvus_netapp_sc_testnew2」などの新しいコレクションが挿入されています。</block>
  <block id="90fecf651d0359e3ca580f04477241cd" category="list-text">以前のスナップショットから S3 NAS バケットの完全復元を実行します。</block>
  <block id="aad1d0bff0a7a377e2981515a3b2b613" category="paragraph"><block ref="aad1d0bff0a7a377e2981515a3b2b613" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78a091f299be6eaf4277ba82c2e35823" category="list-text">Python スクリプトを使用して、「hello_milvus_netapp_sc_test」および「hello_milvus_netapp_sc_test2」コレクションからのデータを検証します。</block>
  <block id="d680ce42e26a573726db92b9c2422bcc" category="list-text">不要または不適切なコレクションがデータベースに存在しないことを確認します。</block>
  <block id="9a792fb5937b90853e4c8d032e6cb887" category="paragraph">結論として、NetApp のSnapCenterを使用してONTAPに存在するベクトル データベース データと Milvus データを保護すると、特に映画制作など、データの整合性が最も重要となる業界の顧客に大きなメリットがもたらされます。 SnapCenter は一貫性のあるバックアップを作成し、完全なデータ復元を実行する機能を備えているため、埋め込まれたビデオ ファイルやオーディオ ファイルなどの重要なデータがハード ドライブの障害やその他の問題による損失から保護されます。これにより、業務の中断が防止されるだけでなく、多大な経済的損失も防ぐことができます。</block>
  <block id="2f51cfb1dd79ff854c52264b771ee6f7" category="paragraph">このセクションでは、ホストのセットアップ、ストレージ プラグインのインストールと構成、カスタム スナップショット名を持つベクター データベースのリソースの作成など、 ONTAPに存在するデータを保護するためにSnapCenterを構成する方法について説明しました。また、Consistency Group スナップショットを使用してバックアップを実行し、S3 NAS バケット内のデータを検証する方法も紹介しました。</block>
  <block id="f3b4f7a7e2767144ed9c5f0d9d729580" category="paragraph">さらに、バックアップ後に不要または不適切なコレクションが作成されるシナリオをシミュレートしました。このような場合、SnapCenter は以前のスナップショットから完全な復元を実行できるため、ベクター データベースを新しいコレクションを追加する前の状態に戻すことができ、データベースの整合性が維持されます。特定の時点にデータを復元するこの機能は顧客にとって非常に貴重であり、データが安全であるだけでなく、正しく維持されているという保証も提供します。したがって、NetApp のSnapCenter製品は、データ保護と管理のための堅牢で信頼性の高いソリューションを顧客に提供します。</block>
  <block id="8ceee6fd58c3c198cf913f99da69f893" category="summary">NetApp SnapMirrorを使用した災害復旧 - NetApp向けベクトルデータベースソリューション</block>
  <block id="e55b3630a4d66c6bf27e22779ce5d63e" category="doc">NetApp SnapMirrorを使用した災害復旧</block>
  <block id="86e29a6d4e0a7a64c8112c7cec13c84f" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューションにおけるSnapMirrorを使用した DR (災害復旧) について説明します。</block>
  <block id="b8bf217f690a13ed504fd70caf142a75" category="paragraph"><block ref="b8bf217f690a13ed504fd70caf142a75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b0f055a15ce6f9f633fb54c0d2436b6" category="paragraph">災害復旧は、特に高次元データの管理と複雑な類似性検索の実行という役割を考えると、ベクター データベースの整合性と可用性を維持するために非常に重要です。適切に計画され実装された災害復旧戦略により、ハードウェア障害、自然災害、サイバー攻撃などの予期しないインシデントが発生した場合でも、データが失われたり侵害されたりすることがなくなります。これは、データの損失や破損が重大な運用中断や経済的損失につながる可能性があるベクトル データベースに依存するアプリケーションにとって特に重要です。さらに、堅牢な災害復旧計画により、ダウンタイムを最小限に抑え、サービスの迅速な復旧が可能になり、ビジネスの継続性も確保されます。これは、さまざまな地理的な場所、定期的なバックアップ、およびフェイルオーバー メカニズムにわたるNetAppデータ レプリケーション製品 SnapMirror を通じて実現されます。したがって、災害復旧は単なる保護対策ではなく、責任ある効率的なベクター データベース管理の重要な要素です。</block>
  <block id="c37567d5fe01335124697e36ce452df7" category="paragraph">NetApp のSnapMirror は、あるNetApp ONTAPストレージ コントローラから別の NetApp ONTAP ストレージ コントローラへのデータ レプリケーションを提供し、主に災害復旧 (DR) およびハイブリッド ソリューションに使用されます。ベクター データベースのコンテキストでは、このツールはオンプレミス環境とクラウド環境間でのデータのスムーズな移行を容易にします。この移行は、データ変換やアプリケーションのリファクタリングを必要とせずに実現されるため、複数のプラットフォームにわたるデータ管理の効率と柔軟性が向上します。</block>
  <block id="b6c8a7338bea39b5f253444e1d873d4d" category="paragraph">ベクトル データベース シナリオにおけるNetAppハイブリッド ソリューションは、さらに多くの利点をもたらします。</block>
  <block id="bea498b35d669ee9af3e28b8fdb8e155" category="list-text">スケーラビリティ: NetApp のハイブリッド クラウド ソリューションは、要件に応じてリソースを拡張する機能を提供します。定期的な予測可能なワークロードにはオンプレミスのリソースを活用し、ピーク時や予期しない負荷にはAmazon FSx ONTAP for NetApp ONTAPや Google Cloud NetApp Volumes (NetApp Volumes) などのクラウド リソースを活用できます。</block>
  <block id="c471a0669949fb6902a8ba657759604f" category="list-text">コスト効率: NetApp のハイブリッド クラウド モデルでは、通常のワークロードにはオンプレミスのリソースを使用し、必要なときにのみクラウド リソースの料金を支払うことで、コストを最適化できます。この従量課金モデルは、 NetApp instaclustr サービス オファリングを使用すると、非常にコスト効率が高くなります。オンプレミスおよび大手クラウド サービス プロバイダー向けに、instaclustr はサポートとコンサルティングを提供します。</block>
  <block id="6544e3cb40acee466e12bad4b51cee88" category="list-text">柔軟性: NetApp のハイブリッド クラウドでは、データを処理する場所を柔軟に選択できます。たとえば、より強力なハードウェアを備えたオンプレミスで複雑なベクトル演算を実行し、クラウドではそれほど負荷のかからない演算を実行することを選択できます。</block>
  <block id="2a11cdb9dd362247d7154c07bd516471" category="list-text">ビジネス継続性: 災害が発生した場合でも、データをNetAppハイブリッド クラウドに保存することで、ビジネスの継続性を確保できます。オンプレミスのリソースが影響を受ける場合は、すぐにクラウドに切り替えることができます。  NetApp SnapMirrorを活用することで、オンプレミスからクラウドへ、あるいはその逆にデータを移動できます。</block>
  <block id="3350f193c79eb670e977c23ae0a74f52" category="list-text">イノベーション: NetApp のハイブリッド クラウド ソリューションは、最先端のクラウド サービスとテクノロジーへのアクセスを提供することで、イノベーションの迅速化も実現します。  Amazon FSx ONTAP for NetApp ONTAP、 Azure NetApp Files 、 Google Cloud NetApp VolumesなどのクラウドにおけるNetApp のイノベーションは、クラウド サービス プロバイダーの革新的な製品であり、推奨される NAS です。</block>
  <block id="2adc0d5a06f39e5bd606c62ac1bdec94" category="summary">instaclustr と pgvector - NetApp 向けベクター データベース ソリューション</block>
  <block id="8505d7d1a5bb8f0709861077b6053aac" category="doc">PostgreSQL を使用した Instaclustr によるベクターデータベース: pgvector</block>
  <block id="45b4ccfe4060d903229f2ce1dcae0219" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューションの pgvector 機能で instaclustr 製品が postgreSQL と統合される具体的な方法について説明します。</block>
  <block id="126ac9f6149081eb0e97c2e939eaad52" category="inline-link-macro">ブログ</block>
  <block id="d2674849e623e64434efc8a6aa010be4" category="paragraph">このセクションでは、instaclustr 製品が pgvector 機能で postgreSQL とどのように統合されるかを詳細に説明します。 「PGVector と PostgreSQL を使用して LLM の精度とパフォーマンスを向上させる方法: 埋め込みの概要と PGVector の役割」の例があります。ご確認ください<block ref="f7c4562444dacce2474e07621eb487a5" category="inline-link-macro-rx"></block>さらに詳しい情報を入手します。</block>
  <block id="755a3ba009d32e46dd37e73b1449ec79" category="summary">NetApp向けベクターデータベースソリューションの紹介</block>
  <block id="65fe25204f25a29d6784b93a3361bbd8" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューションについて紹介します。</block>
  <block id="16091ccd671260c1a85526587bdd6247" category="paragraph">ベクター データベースは、大規模言語モデル (LLM) と生成型人工知能 (AI) におけるセマンティック検索の複雑さを処理するために設計された課題に効果的に対処します。従来のデータ管理システムとは異なり、ベクター データベースは、ラベルやタグではなくデータ自体のコンテンツを使用して、画像、ビデオ、テキスト、オーディオ、その他の非構造化データなど、さまざまな種類のデータを処理および検索できます。</block>
  <block id="abd729dd7dfee14433df8341cdef1b8d" category="paragraph">リレーショナル データベース管理システム (RDBMS) の限界、特に AI アプリケーションで一般的な高次元データ表現や非構造化データに関する問題点は、十分に文書化されています。 RDBMS では、データをより管理しやすい構造にフラット化するという時間がかかり、エラーが発生しやすいプロセスが必要になることが多く、検索の遅延や非効率につながります。しかし、ベクター データベースはこれらの問題を回避するように設計されており、複雑で高次元のデータを管理および検索するためのより効率的で正確なソリューションを提供し、AI アプリケーションの進歩を促進します。</block>
  <block id="5059454011de9c1f28ed1489b3d5e352" category="paragraph">このドキュメントは、現在ベクター データベースを使用しているか、使用を計画しているお客様向けの包括的なガイドとして機能し、 NetApp ONTAP、 NetApp StorageGRID、 Amazon FSx ONTAP for NetApp ONTAP、 SnapCenterなどのプラットフォームでベクター データベースを活用するためのベスト プラクティスを詳しく説明します。ここで提供されるコンテンツは、さまざまなトピックをカバーしています。</block>
  <block id="a7e003a045fea49874b32ab9648eeff1" category="list-text">NetApp ONTAPおよびStorageGRIDオブジェクト ストレージを通じてNetAppストレージによって提供される、Milvus などのベクター データベース向けのインフラストラクチャ ガイドライン。</block>
  <block id="dad32bf9f8412e678e687e1cf7bb9ca2" category="list-text">ファイルおよびオブジェクト ストアを介して AWS FSx ONTAPの Milvus データベースを検証します。</block>
  <block id="68c4bdd7361d54de76b6a70ce9e66b6e" category="list-text">NetApp のファイルとオブジェクトの二重性を詳しく調べ、ベクター データベースやその他のアプリケーションのデータに対するその有用性を示します。</block>
  <block id="8aa4f3c0608b2b5d04870a90085180a0" category="list-text">NetApp のデータ保護管理製品SnapCenter が、ベクター データベース データのバックアップと復元機能をどのように提供するかについて説明します。</block>
  <block id="413963cd7c6051b3cbc48462a3167d68" category="list-text">NetApp のハイブリッド クラウドがオンプレミスとクラウド環境全体でデータ レプリケーションと保護を提供する仕組みについて説明します。</block>
  <block id="73d0a81a7f19b02b2cf3e9084b655966" category="list-text">NetApp ONTAP上の Milvus や pgvector などのベクトル データベースのパフォーマンス検証に関する洞察を提供します。</block>
  <block id="de2054eca65b6e345160d8320bfa3d17" category="list-text">2 つの具体的な使用例: 大規模言語モデル (LLM) を使用した検索拡張生成 (RAG) とNetApp IT チームの ChatAI。これにより、概説した概念と実践の実際的な例が提供されます。</block>
  <block id="11eb7151c13e504e17cca8ecf079bd88" category="summary">ベクターデータベース - NetApp 向けベクターデータベースソリューション</block>
  <block id="34e317d16a291e422cfed7563b8e4b74" category="doc">ベクターデータベース</block>
  <block id="bb6e7da57bf9b9f451aff5682584af81" category="paragraph">このセクションでは、 NetApp AI ソリューションにおけるベクター データベースの定義と使用について説明します。</block>
  <block id="02cf9216cd9290a38db4e591b2d891a3" category="paragraph">ベクター データベースは、機械学習モデルからの埋め込みを使用して非構造化データを処理、インデックス作成、検索するように設計された特殊なタイプのデータベースです。従来の表形式でデータを整理する代わりに、ベクトル埋め込みとも呼ばれる高次元ベクトルとしてデータを配置します。この独自の構造により、データベースは複雑な多次元データをより効率的かつ正確に処理できるようになります。</block>
  <block id="ee365553124acd5ca06a0026c4856306" category="paragraph">ベクター データベースの主な機能の 1 つは、生成 AI を使用して分析を実行することです。これには、データベースが特定の入力に類似するデータ ポイントを識別する類似性検索や、標準から大きく逸脱するデータ ポイントを見つける異常検出が含まれます。</block>
  <block id="145e8c4c44e4cdc9ac189d0799494e03" category="paragraph">さらに、ベクター データベースは、時間データ、つまりタイムスタンプ付きデータの処理に適しています。このタイプのデータは、特定の IT システム内で何がいつ起こったか、その順序や他のすべてのイベントとの関係についての情報を提供します。この時間的データの処理と分析の機能により、ベクター データベースは、時間の経過に伴うイベントの理解を必要とするアプリケーションに特に役立ちます。</block>
  <block id="196ef3e0d720a0c9b617f7c8c553f64f" category="section-title">ML および AI 向けベクトル データベースの利点:</block>
  <block id="2143262d5355c4a47b87575a67b2545b" category="list-text">高次元検索: ベクター データベースは、AI および ML アプリケーションで生成されることが多い高次元データの管理と取得に優れています。</block>
  <block id="eaec9d6e0bc3d169492279c991b5c1e1" category="list-text">スケーラビリティ: 大量のデータを効率的に処理して処理できるため、AI および ML プロジェクトの成長と拡大をサポートします。</block>
  <block id="1a581e9eb96703e6c387548283765d0f" category="list-text">柔軟性: ベクター データベースは高度な柔軟性を備えており、さまざまなデータ タイプと構造に対応できます。</block>
  <block id="23f1f41790fda943f83f4fee180eb9c7" category="list-text">パフォーマンス: AI および ML 操作の速度と効率に不可欠な、高パフォーマンスのデータ管理と取得を提供します。</block>
  <block id="5ec5f2c444dccfe97885b44e9f81c73a" category="list-text">カスタマイズ可能なインデックス作成: Vector データベースはカスタマイズ可能なインデックス作成オプションを提供し、特定のニーズに基づいて最適化されたデータの編成と取得を可能にします。</block>
  <block id="431b6b79e58c421f73a7d7653f3a2641" category="section-title">ベクター データベースと使用例。</block>
  <block id="03e65b2645d14a51684616a56e46e74b" category="paragraph">このセクションでは、さまざまなベクター データベースとその使用例の詳細について説明します。</block>
  <block id="4873dee9aab8428a3bad0247c8891122" category="section-title">ファイスとScaNN</block>
  <block id="f8255a0712bd834e092674fb685b593d" category="paragraph">これらは、ベクトル検索の分野で重要なツールとして機能するライブラリです。これらのライブラリは、ベクター データの管理と検索に役立つ機能を提供するため、データ管理のこの専門分野では非常に貴重なリソースとなります。</block>
  <block id="45e23a169652aaf95ce80da844f3df0d" category="section-title">Elasticsearch</block>
  <block id="7bdddec875d1ea093ba8b35566b1775c" category="paragraph">これは広く使用されている検索および分析エンジンであり、最近ベクター検索機能が組み込まれました。この新しい機能により機能が強化され、ベクター データをより効率的に処理および検索できるようになります。</block>
  <block id="f6af38c920e468b8adbdd5793a09b4ca" category="section-title">松ぼっくり</block>
  <block id="e50d3eac5e6bdb3d1ddd1f564ee13308" category="paragraph">これは、独自の機能セットを備えた堅牢なベクター データベースです。インデックス機能では密ベクトルと疎ベクトルの両方をサポートしており、柔軟性と適応性が向上します。その主な強みの 1 つは、従来の検索方法と AI ベースの高密度ベクトル検索を組み合わせて、両方の長所を活用したハイブリッド検索アプローチを作成できることです。</block>
  <block id="8a6b6fbe69ba556a5fee7b289943c80b" category="paragraph">Pinecone は主にクラウドベースで、機械学習アプリケーション向けに設計されており、GCP、AWS、Open AI、GPT-3、GPT-3.5、GPT-4、Catgut Plus、Elasticsearch、Haystack などのさまざまなプラットフォームと適切に統合されます。  Pinecone はクローズドソース プラットフォームであり、Software as a Service (SaaS) サービスとして利用できることに注意することが重要です。</block>
  <block id="b30cd65a7e403a5d3e792a3c02cfe9ef" category="paragraph">Pinecone は高度な機能を備えているため、高次元検索とハイブリッド検索機能を効果的に活用して脅威を検出し、対応できるため、サイバーセキュリティ業界に特に適してい ます。</block>
  <block id="12f586b0171cf0f06960a27796d811d6" category="section-title">彩度</block>
  <block id="44fcc1838437cfd155de42d2d5133fd3" category="paragraph">これは、4 つの主な機能を持つ Core-API を備えたベクター データベースであり、その 1 つにメモリ内ドキュメント ベクター ストアが含まれています。また、Face Transformers ライブラリを利用してドキュメントをベクトル化し、機能性と汎用性を高めています。 Chroma はクラウドとオンプレミスの両方で動作するように設計されており、ユーザーのニーズに基づいた柔軟性を提供します。特に、オーディオ関連のアプリケーションに優れているため、オーディオベースの検索エンジン、音楽推奨システム、その他のオーディオ関連のユースケースに最適です。</block>
  <block id="2a1e8d184d8101d9d99e3d491cd7be71" category="section-title">ウィービエイト</block>
  <block id="bd8b2ae24665811d42f62aa51b8f92c4" category="paragraph">これは多目的ベクター データベースであり、ユーザーは組み込みモジュールまたはカスタム モジュールを使用してコンテンツをベクター化することができ、特定のニーズに基づいた柔軟性が得られます。さまざまな展開設定に対応し、完全に管理されたソリューションとセルフホスト型ソリューションの両方を提供します。</block>
  <block id="5147cd0d10159454e367b25d270b0489" category="paragraph">Weaviate の主な機能の 1 つは、ベクトルとオブジェクトの両方を保存して、データ処理機能を強化することです。 ERP システムにおけるセマンティック検索やデータ分類など、さまざまなアプリケーションで広く使用されています。電子商取引分野では、検索エンジンや推奨エンジンを強化します。  Weaviate は、画像検索、異常検出、自動データ調和、サイバーセキュリティ脅威分析にも使用されており、複数のドメインにわたる汎用性を示しています。</block>
  <block id="e111446745a1825b862f8727ae63bce4" category="section-title">レディス</block>
  <block id="58cbcbf294faed43c2a7b44bb5dcafcc" category="paragraph">Redis は、高速なインメモリ ストレージで知られる高性能なベクター データベースであり、読み取り/書き込み操作のレイテンシが低いことが特長です。そのため、迅速なデータ アクセスを必要とする推奨システム、検索エンジン、データ分析アプリケーションに最適です。</block>
  <block id="4f9bdf8e8091be6f95cde54860bb88f7" category="paragraph">Redis は、リスト、セット、ソートされたセットなど、ベクトルのさまざまなデータ構造をサポートしています。また、ベクトル間の距離を計算したり、交差や結合を見つけたりするなどのベクトル演算も提供します。これらの機能は、類似性検索、クラスタリング、コンテンツベースの推奨システムに特に役立ちます。</block>
  <block id="2391a64216fab42522be1700985c5a9e" category="paragraph">スケーラビリティと可用性の面では、Redis は高スループットのワークロードの処理に優れており、データレプリケーションを提供します。また、従来のリレーショナル データベース (RDBMS) を含む他のデータ タイプとも適切に統合されます。 Redis には、リアルタイム更新のための Publish/Subscribe (Pub/Sub) 機能が含まれており、リアルタイム ベクトルの管理に役立ちます。さらに、Redis は軽量で使い方が簡単なため、ベクター データを管理するためのユーザーフレンドリーなソリューションになります。</block>
  <block id="4f3d528166032bacea5de8a509bb4d17" category="section-title">ミルバス</block>
  <block id="e6aa3b4ef4ac18024fd88c49647d8277" category="paragraph">これは、MongoDB と同様に、ドキュメント ストアのような API を提供する多目的ベクター データベースです。幅広いデータ タイプをサポートしていることが特徴で、データ サイエンスや機械学習の分野で人気のある選択肢となっています。</block>
  <block id="4b4464f60a3dfd428d4c07edb8cac802" category="paragraph">Milvus のユニークな機能の 1 つは、マルチベクトル化機能です。この機能により、ユーザーは実行時に検索に使用するベクトルの種類を指定できます。さらに、Faiss などの他のライブラリの上位にあるライブラリである Knowwhere を使用して、クエリとベクトル検索アルゴリズム間の通信を管理します。</block>
  <block id="bd3a3ade101e0f6fe46ad769dbf3cfa0" category="paragraph">Milvus は、PyTorch および TensorFlow との互換性により、機械学習ワークフローとのシームレスな統合も提供します。これにより、電子商取引、画像およびビデオ分析、オブジェクト認識、画像類似性検索、コンテンツベースの画像検索など、さまざまなアプリケーションに最適なツールになります。自然言語処理の分野では、Milvus はドキュメントのクラスタリング、セマンティック検索、質問応答システムに使用されます。</block>
  <block id="df5acf267fd9d50988a9132e88ec089f" category="paragraph">このソリューションでは、ソリューション検証に milvus を選択しました。パフォーマンスのために、milvus と postgres(pgvecto.rs) の両方を使用しました。</block>
  <block id="6b9a995b1c19c83b6360f58654598ab0" category="section-title">このソリューションに Milvus を選んだ理由は何ですか?</block>
  <block id="ac80bf421cb6dec4ca81d75401709fce" category="list-text">オープンソース: Milvus はオープンソースのベクター データベースであり、コミュニティ主導の開発と改善を促進します。</block>
  <block id="72e0b014c4927b1166a4c34028bf0a94" category="list-text">AI 統合: 埋め込み類似性検索と AI アプリケーションを活用して、ベクター データベースの機能を強化します。</block>
  <block id="1f3d7f832f4c276984a989e5a4760e7d" category="list-text">大容量処理: Milvus には、ディープ ニューラル ネットワーク (DNN) および機械学習 (ML) モデルによって生成された 10 億を超える埋め込みベクトルを保存、インデックス作成、管理する機能があります。</block>
  <block id="be23175f1d046ec7a81f41bbfbb7a710" category="list-text">ユーザーフレンドリー: セットアップは 1 分もかからず簡単に使用できます。  Milvus は、さまざまなプログラミング言語用の SDK も提供しています。</block>
  <block id="2c86f12d4bdb64f5ff99e182033e6664" category="list-text">速度: 他のいくつかの代替品よりも最大 10 倍高速な、非常に高速な取得速度を提供します。</block>
  <block id="23a12a1d1c53642355185e4cf7fd3d30" category="list-text">スケーラビリティと可用性: Milvus は非常にスケーラブルで、必要に応じてスケールアップおよびスケールアウトするオプションがあります。</block>
  <block id="eaa6e5cbb0e6c82b8217f591711c391a" category="list-text">機能が豊富: さまざまなデータ タイプ、属性フィルタリング、ユーザー定義関数 (UDF) のサポート、構成可能な一貫性レベル、移動時間をサポートしており、さまざまなアプリケーションに使用できる多用途のツールです。</block>
  <block id="cb1e9d4cfab2279dd63f9f75796dc14f" category="section-title">Milvusアーキテクチャの概要</block>
  <block id="9c5b9910474e7d9e8c210fd3d649af4d" category="paragraph"><block ref="9c5b9910474e7d9e8c210fd3d649af4d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03bd3b894648d2e8a48d648b0fcedfac" category="paragraph">このセクションでは、Milvus アーキテクチャで使用されるより高レベルのコンポーネントとサービスについて説明します。  * アクセス層 – ステートレス プロキシのグループで構成され、システムのフロント層およびユーザーへのエンドポイントとして機能します。 * コーディネーター サービス - タスクをワーカー ノードに割り当て、システムの頭脳として機能します。コーディネーターの種類には、ルート コーディネーター、データ コーディネーター、クエリ コーディネーターの 3 つがあります。  * ワーカー ノード: コーディネーター サービスからの指示に従い、ユーザーがトリガーした DML/DDL コマンドを実行します。クエリ ノード、データ ノード、インデックス ノードなど、3 種類のワーカー ノードがあります。 * ストレージ: データの永続性を維持します。メタストレージ、ログブローカー、オブジェクトストレージで構成されます。  ONTAPやStorageGRIDなどのNetAppストレージは、顧客データとベクター データベース データの両方に対して、Milvus にオブジェクト ストレージとファイル ベースのストレージを提供します。</block>
  <block id="3ad011fbf1a887f55fe5db0f1c95891f" category="summary">milvusとAmazon FSx ONTAP for NetApp ONTAP - NetApp向けベクターデータベースソリューション</block>
  <block id="dd69e86c3dc6fbad2a761367a22a0552" category="doc">Milvus とAmazon FSx ONTAP for NetApp ONTAP - ファイルとオブジェクトの二重性</block>
  <block id="8cec9207499fc7ae92bcaff5ffed4880" category="paragraph">このセクションでは、 NetAppのベクトルデータベースソリューション用のAmazon FSx ONTAPを使用した milvus クラスターのセットアップについて説明します。</block>
  <block id="74126d145913f667c84fb0fae63d5f30" category="section-title">Milvus とAmazon FSx ONTAP for NetApp ONTAP – ファイルとオブジェクトの二重性</block>
  <block id="de1f3a826ad4a683281aa07d427c615a" category="paragraph">このセクションでは、クラウドにベクター データベースをデプロイする必要がある理由と、Docker コンテナ内のAmazon FSx ONTAP for NetApp ONTAPにベクター データベース (milvus スタンドアロン) をデプロイする手順について説明します。</block>
  <block id="c7d712a8f39fa8b7654218edbb110e3e" category="paragraph">クラウドにベクター データベースを展開すると、特に高次元データの処理や類似性検索の実行を必要とするアプリケーションにとって、いくつかの大きなメリットが得られます。まず、クラウドベースの展開ではスケーラビリティが提供され、増大するデータ量やクエリ負荷に合わせてリソースを簡単に調整できます。これにより、データベースは高いパフォーマンスを維持しながら、増加した需要を効率的に処理できるようになります。  2 番目に、クラウドの導入により、地理的に異なる場所にデータを複製できるため、高可用性と災害復旧が可能になり、データ損失のリスクが最小限に抑えられ、予期しないイベントが発生した場合でも継続的なサービスが保証されます。 3 番目に、使用したリソースに対してのみ料金を支払い、需要に応じてスケールアップまたはスケールダウンできるため、ハードウェアへの多額の先行投資が不要となり、コスト効率が向上します。最後に、クラウドにベクター データベースを展開すると、どこからでもデータにアクセスして共有できるため、コラボレーションが強化され、チームベースの作業とデータに基づく意思決定が容易になります。この検証で使用したAmazon FSx ONTAP for NetApp ONTAPを搭載した milvus スタンドアロンのアーキテクチャを確認してください。</block>
  <block id="f95a160e2c9ead1dd272587d85c4a8e3" category="paragraph"><block ref="f95a160e2c9ead1dd272587d85c4a8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1e75d11a34279b79d1140edc8f509e3" category="list-text">Amazon FSx ONTAP for NetApp ONTAPインスタンスを作成し、VPC、VPC セキュリティグループ、サブネットの詳細を書き留めます。この情報は、EC2 インスタンスを作成するときに必要になります。詳細はこちらをご覧ください -<block ref="600df3e2da0b9de1446fabf4802a063b" category="inline-link-rx"></block></block>
  <block id="d91af2df00186cd53f523a257cb2565a" category="list-text">EC2 インスタンスを作成し、VPC、セキュリティグループ、サブネットがAmazon FSx ONTAP for NetApp ONTAPインスタンスのものと一致していることを確認します。</block>
  <block id="3f49259cc5a532eaad35643b8ddc6724" category="list-text">'apt-get install nfs-common' コマンドを使用して nfs-common をインストールし、 'sudo apt-get update' を使用してパッケージ情報を更新します。</block>
  <block id="7cd964c493dd7e6f0abd19075ad234a1" category="list-text">マウントフォルダを作成し、そこにAmazon FSx ONTAP for NetApp ONTAPをマウントします。</block>
  <block id="79f2982e5eb61f29ccc9204d1e575199" category="list-text">'apt-get install' を使用して Docker と Docker Compose をインストールします。</block>
  <block id="8b2bc8a7f7a7f8a83a1a126f0f97c496" category="list-text">Milvus Web サイトからダウンロードできる docker-compose.yaml ファイルに基づいて、Milvus クラスターをセットアップします。</block>
  <block id="6667d03b2d7af61cacf9ce4779fbb601" category="list-text">docker-compose.ymlファイルの「volumes」セクションで、 NetApp NFSマウントポイントを、etcd、minio、およびスタンドアロンの対応するMilvusコンテナパスにマッピングします。<block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block> ymlの変更の詳細については</block>
  <block id="40722d15b9f6ad02c869cf6f587fd141" category="list-text">マウントされたフォルダーとファイルを確認します。</block>
  <block id="b1c44a1b47e0ee05938bd8b62a636917" category="list-text">docker-compose.yml ファイルを含むディレクトリから 'docker-compose up -d' を実行します。</block>
  <block id="9a6325448af98c29154cb9ef7423c998" category="list-text">Milvus コンテナのステータスを確認します。</block>
  <block id="e5666f40cd9052040de973832a6b5fb8" category="list-text">Amazon FSx ONTAP for NetApp ONTAPのベクトルデータベースとそのデータの読み取りおよび書き込み機能を検証するために、Python Milvus SDK と PyMilvus のサンプルプログラムを使用しました。  'apt-get install python3-numpy python3-pip' を使用して必要なパッケージをインストールし、 'pip3 install pymilvus' を使用して PyMilvus をインストールします。</block>
  <block id="77b346f241703e75634a6437339f3874" category="list-text">ベクターデータベース内のAmazon FSx ONTAP for NetApp ONTAPからのデータ書き込みおよび読み取り操作を検証します。</block>
  <block id="edeedbd869dbb3831a9bfc7c26f04200" category="list-text">verify_data_netapp.py スクリプトを使用して読み取り操作を確認します。</block>
  <block id="bda2d30c9f3f0d40ab873d7c99e8c13b" category="list-text">顧客が AI ワークロード用の S3 プロトコルを介してベクトル データベースでテストされた NFS データにアクセス (読み取り) したい場合、簡単な Python プログラムを使用してこれを検証できます。このセクションの冒頭の図で説明したように、別のアプリケーションからの画像との類似性検索がその一例です。</block>
  <block id="8b97e19802900809af55c42c509e614a" category="paragraph">このセクションでは、 NetApp ONTAPデータ ストレージに Amazon のNetApp FSx ONTAPを使用して、Docker コンテナ内でスタンドアロンの Milvus セットアップを展開および操作する方法を効果的に示します。このセットアップにより、顧客は、スケーラブルで効率的な Docker コンテナ環境内で、ベクトル データベースのパワーを活用して高次元データを処理し、複雑なクエリを実行できるようになります。 Amazon FSx ONTAP for NetApp ONTAPインスタンスと対応する EC2 インスタンスを作成することで、お客様は最適なリソース使用率とデータ管理を実現できます。ベクトル データベースでの FSx ONTAPからのデータ書き込みおよび読み取り操作の検証が成功したことで、信頼性が高く一貫性のあるデータ操作が保証されます。さらに、S3 プロトコルを介して AI ワークロードからデータを一覧表示する (読み取る) 機能により、データ アクセス性が向上します。したがって、この包括的なプロセスにより、Amazon の FSx ONTAP for NetApp ONTAPの機能を活用して、大規模なデータ操作を管理するための堅牢で効率的なソリューションが顧客に提供されます。</block>
  <block id="80f3b490016fb09dd087c51b2a8b26f5" category="summary">Milvus クラスタのセットアップ - NetApp 向けベクター データベース ソリューション</block>
  <block id="c0f2e2b603c0c8186341bf2945e1ad13" category="doc">オンプレミスでの Kubernetes を使用した Milvus クラスターのセットアップ</block>
  <block id="4a6f6b145c2d627bc6b03f4b1e6dd96a" category="paragraph">このセクションでは、 NetAppのベクトル データベース ソリューション用の milvus クラスターのセットアップについて説明します。</block>
  <block id="b5be4c6d053fbcf3d99fa7a27f14df10" category="section-title">オンプレミスでの Kubernetes を使用した Milvus クラスターのセットアップ</block>
  <block id="ae5afd2c726fae66bdccf19c83604efb" category="paragraph">ストレージとコンピューティングを独立して拡張し、効果的なインフラストラクチャ管理とデータ管理を行うという顧客の課題に対し、Kubernetes とベクター データベースを組み合わせることで、大規模なデータ操作を管理するための強力でスケーラブルなソリューションが実現します。 Kubernetes はリソースを最適化し、コンテナを管理し、ベクトル データベースは高次元データと類似性検索を効率的に処理します。この組み合わせにより、大規模なデータセットに対する複雑なクエリを迅速に処理し、増大するデータ量に合わせてシームレスに拡張できるため、ビッグデータ アプリケーションや AI ワークロードに最適です。</block>
  <block id="b74b373b546797287d3c21cceba52d3d" category="list-text">このセクションでは、クラスター データと顧客データの両方にNetAppストレージ コントローラーを利用して、Kubernetes に Milvus クラスターをインストールするプロセスについて詳しく説明します。</block>
  <block id="65c0326e8e372682bfaae45cec62723f" category="list-text">Milvus クラスターをインストールするには、さまざまな Milvus クラスター コンポーネントからのデータを保存するための永続ボリューム (PV) が必要です。これらのコンポーネントには、etcd (インスタンス 3 つ)、pulsar-bookie-journal (インスタンス 3 つ)、pulsar-bookie-ledgers (インスタンス 3 つ)、pulsar-zookeeper-data (インスタンス 3 つ) が含まれます。</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link-macro">このリンク</block>
  <block id="d33fb2ef35d69747411b9e87c7d3d69f" category="admonition">Milvus クラスターでは、Milvus クラスターの信頼性の高いストレージとメッセージ ストリームの公開/サブスクリプションをサポートする基盤エンジンとして、Pulsar または Kafka のいずれかを使用できます。  NFS を使用した Kafka については、 NetApp はONTAP 9.12.1 以降で改善を行っており、これらの機能強化と、RHEL 8.7 または 9.1 以降に含まれる NFSv4.1 および Linux の変更により、NFS 経由で Kafka を実行するときに発生する可能性がある「silly rename」問題が解決されています。NetApp NFS ソリューションを使用した Kafka の実行に関する詳細情報については、以下を参照してください。<block ref="19b6a7adb53ddda340943365a4b691d7" category="inline-link-macro-rx"></block> 。</block>
  <block id="eea5737b25740da376e769b4f799f861" category="list-text">NetApp ONTAPから単一の NFS ボリュームを作成し、それぞれ 250 GB のストレージを持つ 12 個の永続ボリュームを確立しました。ストレージ サイズはクラスターのサイズに応じて異なります。たとえば、各 PV が 50 GB である別のクラスターがあります。詳細については、以下の PV YAML ファイルの 1 つを参照してください。このようなファイルは合計 12 個あります。各ファイルでは、storageClassName は「default」に設定されており、ストレージとパスは各 PV ごとに一意です。</block>
  <block id="4bd70516b6325446dd3ab13888cff57f" category="list-text">各PV YAMLファイルに対して「kubectl apply」コマンドを実行して永続ボリュームを作成し、「kubectl get pv」を使用して作成を確認します。</block>
  <block id="3468fc776a2c10c6b885c4b8f38fbb6f" category="list-text">Milvus は、顧客データを保存するために、MinIO、Azure Blob、S3 などのオブジェクト ストレージ ソリューションをサポートしています。このガイドでは、S3 を利用します。次の手順は、 ONTAP S3 とStorageGRIDオブジェクト ストアの両方に適用されます。  Milvus クラスターをデプロイするには Helm を使用します。 Milvus のダウンロード場所から構成ファイル values.yaml をダウンロードします。このドキュメントで使用した values.yaml ファイルについては、付録を参照してください。</block>
  <block id="ac8152f5c769ca08c180374241d9797c" category="list-text">ログ、etcd、zookeeper、bookkeeper などの各セクションで、「storageClass」が「default」に設定されていることを確認します。</block>
  <block id="3c27656d225ef946516e7bec88519049" category="list-text">MinIO セクションで、MinIO を無効にします。</block>
  <block id="a9c572c8c594acac80d859b834139c09" category="list-text">ONTAPまたはStorageGRIDオブジェクト ストレージから NAS バケットを作成し、オブジェクト ストレージ認証情報を使用して外部 S3 に含めます。</block>
  <block id="5c01f0212f13cb62a8e9c91143a9a0e8" category="list-text">Milvus クラスターを作成する前に、PersistentVolumeClaim (PVC) に既存のリソースがないことを確認してください。</block>
  <block id="8916cc7e0054297b71b9453a888657d1" category="list-text">Helm と values.yaml 構成ファイルを使用して、Milvus クラスターをインストールして起動します。</block>
  <block id="774a1cf197a96a839f6b770e85cb2445" category="list-text">PersistentVolumeClaims (PVC) のステータスを確認します。</block>
  <block id="63b2b2b30427688208b8a24971cee62e" category="list-text">ポッドのステータスを確認します。</block>
  <block id="1d419f9c469484aa1d54fd468448977e" category="paragraph">ポッドのステータスが「実行中」であり、期待どおりに動作していることを確認してください。</block>
  <block id="890a387ef3d7768088115e7fea8a9ff6" category="list-text">Milvus およびNetAppオブジェクト ストレージでのデータの書き込みと読み取りをテストします。</block>
  <block id="e5aef6bb28887bb265d168f37e539b38" category="list-text">「prepare_data_netapp_new.py」Python プログラムを使用してデータを書き込みます。</block>
  <block id="db12c3e2840ba5032e784bab8e8fb917" category="list-text">「verify_data_netapp.py」Python ファイルを使用してデータを読み取ります。</block>
  <block id="25ab62108c16e9b732c38f62755ec991" category="paragraph">上記の検証に基づき、 NetAppストレージ コントローラを使用して Kubernetes 上に Milvus クラスタを展開することで実証されているように、Kubernetes とベクトル データベースを統合すると、大規模なデータ操作を管理するための堅牢でスケーラブルかつ効率的なソリューションが顧客に提供されます。このセットアップにより、顧客は高次元データを処理し、複雑なクエリを迅速かつ効率的に実行できるようになるため、ビッグデータ アプリケーションや AI ワークロードに最適なソリューションになります。さまざまなクラスター コンポーネントに永続ボリューム (PV) を使用し、 NetApp ONTAPから単一の NFS ボリュームを作成することで、最適なリソース使用率とデータ管理が保証されます。 PersistentVolumeClaims (PVC) とポッドのステータスを検証し、データの書き込みと読み取りをテストするプロセスにより、信頼性が高く一貫性のあるデータ操作が保証されます。顧客データにONTAPまたはStorageGRIDオブジェクト ストレージを使用すると、データのアクセス性とセキュリティがさらに強化されます。全体として、この設定により、増大するデータ ニーズに合わせてシームレスに拡張できる、回復力に優れた高性能なデータ管理ソリューションが顧客に提供されます。</block>
  <block id="34d3fa32b415d892eb0e14786cafccea" category="summary">NetApp向けベクトルデータベースソリューションの概要</block>
  <block id="351df3cce379006f4ba6b903c32e39a0" category="paragraph">このセクションでは、 NetAppベクトル データベース ソリューションの概要を説明します。</block>
  <block id="84c35d4e8bb8f8f09d3728632bcee7ce" category="paragraph">このソリューションは、ベクター データベースのお客様が直面する課題に対処するためにNetAppが提供する独自の利点と機能を紹介します。 NetApp ONTAP、 StorageGRID、NetApp のクラウド ソリューション、 SnapCenterを活用することで、お客様はビジネス運営に大きな価値を加えることができます。これらのツールは、既存の問題に対処するだけでなく、効率性と生産性を向上させ、ビジネス全体の成長に貢献します。</block>
  <block id="d383216ef38104a4ae0ac03e48c3f38c" category="section-title">NetAppを選ぶ理由</block>
  <block id="c8850228b08f24ab3b77cf8228b9b2cf" category="list-text">ONTAPやStorageGRIDなどの NetApp の製品は、ストレージとコンピューティングの分離を可能にし、特定の要件に基づいて最適なリソース利用を実現します。この柔軟性により、お客様はNetAppストレージ ソリューションを使用してストレージを独自に拡張できるようになります。</block>
  <block id="40251a62505d04ab7d80bacded5fec97" category="list-text">NetApp ONTAP は、AWS、Azure、Google Cloud などの主要なクラウド サービス プロバイダー全体で NAS およびオブジェクト ストレージのネイティブ サポートを提供します。この幅広い互換性により、シームレスな統合が保証され、顧客データのモビリティ、グローバルなアクセス性、災害復旧、動的なスケーラビリティ、および高パフォーマンスが実現します。</block>
  <block id="6c1c83ac60affc59fcc3432ea130dd8f" category="list-text">NetApp の強力なデータ管理機能により、お客様はデータが潜在的なリスクや脅威から十分に保護されていることを確信できます。  NetApp はデータ セキュリティを最優先し、お客様の貴重な情報の安全性と整合性に関して安心を提供します。</block>
  <block id="738158dc90e1d60ff7273e21bc2d2c4e" category="summary">ベクターデータベースのパフォーマンス検証 - NetApp向けベクターデータベースソリューション</block>
  <block id="39301670f58445b6e5aed7e2a2694632" category="doc">ベクターデータベースのパフォーマンス検証</block>
  <block id="334e1c5c0681bc3d3d6b9321ff851f44" category="paragraph">このセクションでは、ベクター データベースで実行されたパフォーマンス検証について説明します。</block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">パフォーマンス検証</block>
  <block id="0dfe6e4dda5bda08f3b2f54fe5f51a3b" category="paragraph">パフォーマンス検証は、ベクター データベースとストレージ システムの両方で重要な役割を果たし、最適な操作と効率的なリソース利用を保証するための重要な要素となります。高次元データの処理や類似性検索の実行で知られるベクター データベースでは、複雑なクエリを迅速かつ正確に処理するために、高いパフォーマンス レベルを維持する必要があります。パフォーマンス検証は、ボトルネックを特定し、構成を微調整し、サービスの低下なしにシステムが予想される負荷を処理できることを保証するのに役立ちます。同様に、ストレージ システムでは、全体的なシステム パフォーマンスに影響を与える可能性のある遅延の問題やボトルネックが発生することなく、データが効率的に保存および取得されるようにするために、パフォーマンス検証が不可欠です。また、ストレージ インフラストラクチャの必要なアップグレードや変更について、情報に基づいた意思決定を行うのにも役立ちます。したがって、パフォーマンス検証はシステム管理の重要な側面であり、高いサービス品質、運用効率、およびシステム全体の信頼性の維持に大きく貢献します。</block>
  <block id="9115de397cf08aaab47480ba37fbda9b" category="paragraph">このセクションでは、Milvus や pgvecto.rs などのベクトル データベースのパフォーマンス検証を詳しく検討し、LLM ライフサイクル内での RAG および推論ワークロードをサポートする I/O プロファイルやネットアップ ストレージ コントローラの動作などのストレージ パフォーマンス特性に焦点を当てます。これらのデータベースをONTAPストレージ ソリューションと組み合わせた場合のパフォーマンスの差別化要因を評価し、特定します。私たちの分析は、1 秒あたりに処理されるクエリ数 (QPS) などの主要なパフォーマンス指標に基づいて行われます。</block>
  <block id="259349a97b2ad2022418ffa271915c7f" category="paragraph">milvus と進捗状況に使用された方法論については以下を確認してください。</block>
  <block id="3805969a7e504e8baa224367a87cc5a8" category="cell">Milvus (スタンドアロンおよびクラスター)</block>
  <block id="1cfad7d7743394085072e5f7fcc3a203" category="cell">Postgres(pgvecto.rs) #</block>
  <block id="2af72f100c356273d46284f6fd1dfc08" category="cell">version</block>
  <block id="c2ee74b62870d06b4b4ad6819b9bf142" category="cell">2.3.2</block>
  <block id="44b732a6709d52e07db0367d4938965c" category="cell">0.2.0</block>
  <block id="ac52cf637478f3656a1fdee5c02324fd" category="cell">Filesystem</block>
  <block id="6f27ca3ac8a02564ce2eef7e706e1e50" category="cell">iSCSI LUN 上の XFS</block>
  <block id="30b5bb1d010e4fe15e0541fa9b96dbdc" category="cell">ワークロードジェネレーター</block>
  <block id="73676a7da2a7cbd819e3a72dab6d2364" category="inline-link-macro">VectorDBベンチ</block>
  <block id="b9350528e041c5ef962f5553183ca801" category="cell"><block ref="5a4d2a4510eb4d9895b68971f8744a05" category="inline-link-macro-rx"></block>– v0.0.5</block>
  <block id="f1cb45f64cdd7b55480ba6aeecd7b797" category="cell">データセット</block>
  <block id="0adc231fd0cbf3d7d8d5a0ff68eb2783" category="cell">LAIONデータセット * 1000万個の埋め込み * 768次元 * 約300GBのデータセットサイズ</block>
  <block id="3941cf702a750210280a88643fe83810" category="cell">AFF 800 * バージョン – 9.14.1 * 4 x 100GbE – milvus用、2x 100GbE（postgres用） * iscsi</block>
  <block id="39138e4aea637ddf9fc568de53bed3af" category="section-title">Milvus スタンドアロン クラスターを使用した VectorDB-Bench</block>
  <block id="3a82e1f5d5f2195d71ba779a6ede894f" category="paragraph">VectorDB-Bench を使用して、milvus スタンドアロン クラスターで次のパフォーマンス検証を実行しました。  milvus スタンドアロン クラスターのネットワークとサーバー接続は次のとおりです。</block>
  <block id="ef436c3d7bb0f3687e078dce4b9bdb28" category="paragraph"><block ref="ef436c3d7bb0f3687e078dce4b9bdb28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="663c78b1d11f60d7440f91f77e4f328a" category="paragraph">このセクションでは、Milvus スタンドアロン データベースのテストから得た観察結果を共有します。 。これらのテストのインデックス タイプとして DiskANN を選択しました。 。約 100 GB のデータセットの取り込み、最適化、インデックス作成には約 5 時間かかりました。この期間の大半では、20 個のコア (ハイパースレッディングを有効にすると 40 個の vCPU に相当) を搭載した Milvus サーバーが最大 CPU 容量の 100% で動作していました。DiskANN は、システム メモリ サイズを超える大規模なデータセットで特に重要であることがわかりました。 。クエリフェーズでは、1 秒あたりのクエリ数 (QPS) レートが 10.93、リコールが 0.9987 でした。クエリの 99 パーセンタイル レイテンシは 708.2 ミリ秒と測定されました。</block>
  <block id="624dbbdc3175c82e67aadff554ee1850" category="paragraph">ストレージの観点から見ると、データベースは、取り込み、挿入後の最適化、およびインデックス作成の各フェーズで約 1,000 オペレーション/秒を発行しました。クエリフェーズでは、32,000 オペレーション/秒が要求されました。</block>
  <block id="2063cebb91be357ea64826c835821b9d" category="paragraph">次のセクションでは、ストレージ パフォーマンス メトリックを示します。</block>
  <block id="5805c53ecb86f7c7ae7765287eda00d6" category="cell">ワークロードフェーズ</block>
  <block id="216ab40cda5c7c00ff42a4efb1827d89" category="cell">指標</block>
  <block id="7f2bb2bf609fe39698d58a2d1d86863a" category="cell">データの取り込みと挿入後の最適化</block>
  <block id="79073619fba8242703524f16870ff858" category="cell">IOPS</block>
  <block id="648a472fd7585d9d0c15b90f36365597" category="cell">1,000未満</block>
  <block id="26ae7bdd1d6fb8c4886e6fde8d12601c" category="cell">レイテンシー</block>
  <block id="822500fd5bb8ac11d944779a6703df98" category="cell">400 マイクロ秒未満</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">ワークロード</block>
  <block id="59829f7cd61cf1113b8214b47aaeacd8" category="cell">読み取り/書き込みの混合、主に書き込み</block>
  <block id="991ff9e60b05b3e05e67404474611720" category="cell">IOサイズ</block>
  <block id="6b29aa131a7b968826c90e6801bacd23" category="cell">64 KB</block>
  <block id="66c1b4c7f3dc385b68a9fa903ccd016d" category="cell">クエリ</block>
  <block id="7d38c4599a45db6312f66bfac2fbba0d" category="cell">ピーク時32,000</block>
  <block id="866fc78d18122580af38eeff4375a3c0" category="cell">100%キャッシュ読み取り</block>
  <block id="9632dc4ffd7ab759c4fc53341977d887" category="cell">主に8KB</block>
  <block id="06b68ce1a31c0cdf5430d925dabff321" category="paragraph">VectorDB-benchの結果は以下の通りです。</block>
  <block id="2a8bd0e83a84e623eafaed41ef4a0b48" category="paragraph"><block ref="2a8bd0e83a84e623eafaed41ef4a0b48" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf13afd123e82c2f8504d046ac979ce6" category="paragraph">スタンドアロン Milvus インスタンスのパフォーマンス検証から、現在の設定では次元数が 1536 の 500 万ベクトルのデータセットをサポートするには不十分であることが明らかです。ストレージには十分なリソースがあり、システムのボトルネックにはならないと判断しました。</block>
  <block id="7a2e31e50716ca1d05ae61faa264e4d9" category="section-title">milvus クラスターを使用した VectorDB-Bench</block>
  <block id="1a3dd3962bc3776e2a670ea2dccbf4aa" category="paragraph">このセクションでは、Kubernetes 環境内での Milvus クラスターの展開について説明します。この Kubernetes セットアップは、Kubernetes マスター ノードとワーカー ノードをホストする VMware vSphere デプロイメント上に構築されました。</block>
  <block id="2f38e478e85318635a3c104d2f9689ea" category="paragraph">VMware vSphere および Kubernetes のデプロイメントの詳細については、次のセクションで説明します。</block>
  <block id="6b38cbd988bc17810219001208570634" category="paragraph"><block ref="ef20c4495e84beca29aabf20791bc97a" category="inline-image-macro-rx" type="image"></block> <block ref="6f1c220e845ab7b8291a1a21a3646cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09618a18978db1f9288bf0626e2e9d77" category="paragraph">このセクションでは、Milvus データベースのテストから得られた観察結果を紹介します。  * 使用されたインデックス タイプは DiskANN です。 * 以下の表は、1536 次元で 500 万のベクトルを扱う場合のスタンドアロン展開とクラスター展開の比較を示しています。クラスター展開では、データの取り込みと挿入後の最適化にかかる時間が短くなることがわかりました。スタンドアロン設定と比較して、クラスター展開ではクエリの 99 パーセンタイル レイテンシが 6 分の 1 に削減されました。  * クラスター展開では 1 秒あたりのクエリ数 (QPS) レートは高くなりましたが、望ましいレベルには達しませんでした。</block>
  <block id="fa7bae8c4e9fc0bec05867545cb65c08" category="paragraph"><block ref="fa7bae8c4e9fc0bec05867545cb65c08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec05b5e2e1b5d66f987712f952bfd377" category="paragraph">以下の画像は、ストレージ クラスターのレイテンシや合計 IOPS (1 秒あたりの入出力操作数) など、さまざまなストレージ メトリックを示しています。</block>
  <block id="866b04fa947dc783f0a1ca67687a0b46" category="paragraph"><block ref="866b04fa947dc783f0a1ca67687a0b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f34ceedf45c53ac5bfc4732c7e9eb992" category="paragraph">次のセクションでは、主要なストレージ パフォーマンス メトリックを示します。</block>
  <block id="40c9acf8f61419691d77b3dec178cdc9" category="cell">ピーク時14万7000人</block>
  <block id="971ae6b3c89c8ab12e0eed4e70f3ad7a" category="paragraph">スタンドアロン Milvus と Milvus クラスターの両方のパフォーマンス検証に基づいて、ストレージ I/O プロファイルの詳細を示します。  * I/O プロファイルは、スタンドアロン展開とクラスター展開の両方で一貫していることがわかりました。  * ピーク IOPS で観測された差は、クラスター展開内のクライアント数が多いことに起因します。</block>
  <block id="537edb0aa02f73a246f084214ff9a1e4" category="section-title">Postgres を使用した VectorDB ベンチ (pgvecto.rs)</block>
  <block id="62f6737d84249676fddeaa6678755d2a" category="paragraph">VectorDB-Bench を使用して PostgreSQL (pgvecto.rs) に対して次のアクションを実行しました。PostgreSQL (具体的には pgvecto.rs) のネットワークとサーバー接続に関する詳細は次のとおりです。</block>
  <block id="467a4cd74d7adb713cf4f94b3dd642b7" category="paragraph"><block ref="467a4cd74d7adb713cf4f94b3dd642b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd9a767006e111bd203547a99e12e650" category="paragraph">このセクションでは、特に pgvecto.rs を使用して PostgreSQL データベースをテストした結果と観察結果を共有します。  * テスト時点では DiskANN が pgvecto.rs で利用できなかったため、これらのテストのインデックス タイプとして HNSW を選択しました。 * データ取り込みフェーズでは、768 次元の 1,000 万ベクトルで構成される Cohere データセットをロードしました。このプロセスには約 4.5 時間かかりました。 * クエリフェーズでは、1 秒あたりのクエリ数 (QPS) が 1,068、リコールが 0.6344 でした。クエリの 99 パーセンタイル レイテンシは 20 ミリ秒と測定されました。実行時間のほとんどを通じて、クライアントの CPU は 100% の能力で動作していました。</block>
  <block id="1f3e94e90c6dc70493177c947144e128" category="paragraph">以下の画像は、ストレージ クラスターのレイテンシ合計 IOPS (1 秒あたりの入出力操作数) など、さまざまなストレージ メトリックを示しています。</block>
  <block id="887b48e40648d9beb4f86ffbf295813a" category="paragraph"><block ref="887b48e40648d9beb4f86ffbf295813a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59566b4d8c8fef1f2b244df87cbe1523" category="paragraph"><block ref="59566b4d8c8fef1f2b244df87cbe1523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa49276609916c00fd739a7d0474f2e0" category="section-title">ベクターDBベンチにおけるmilvusとpostgresのパフォーマンス比較</block>
  <block id="870f4bfca5a2e4c27797438cfbcdcafc" category="paragraph"><block ref="870f4bfca5a2e4c27797438cfbcdcafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a6bb1cc3086d7d67df39b7f25c55f2f" category="paragraph">VectorDBBench を使用した Milvus と PostgreSQL のパフォーマンス検証に基づいて、次のことがわかりました。</block>
  <block id="edec147efc5d9e9f8c60dd4f8475a94a" category="list-text">インデックスタイプ: HNSW</block>
  <block id="2d14d931ff962fab0d69fc6c540c032e" category="list-text">データセット: 768次元の1000万ベクトルを含むCohere</block>
  <block id="0e18fa0193d93ed358d7fdb6a65a8bbc" category="paragraph">pgvecto.rs は 1 秒あたりのクエリ数 (QPS) が 1,068、リコールが 0.6344 であったのに対し、Milvus は QPS が 106、リコールが 0.9842 であったことがわかりました。</block>
  <block id="6f8820eba6bfb1c4427de7e140948640" category="paragraph">クエリの高精度が優先される場合、Milvus はクエリごとに関連アイテムをより高い割合で取得するため、pgvecto.rs よりも優れています。しかし、1 秒あたりのクエリ数の方が重要な要素である場合、pgvecto.rs は Milvus を上回ります。ただし、pgvecto.rs 経由で取得されるデータの品質は低く、検索結果の約 37% が無関係な項目であることに注意することが重要です。</block>
  <block id="35a1dd67e98f2039e3b4dc79a35aaa3e" category="section-title">パフォーマンス検証に基づく観察:</block>
  <block id="e6b80e98176081ee739c8e730d3feb58" category="paragraph">パフォーマンス検証に基づいて、次のことが観察されました。</block>
  <block id="9d57f733c58a90a624b060f00ad469bd" category="paragraph">Milvus では、I/O プロファイルは、Oracle SLOB で見られるような OLTP ワークロードによく似ています。ベンチマークは、データ取り込み、事後最適化、クエリの 3 つのフェーズで構成されます。初期段階では主に 64 KB の書き込み操作が特徴で、クエリ段階では主に 8 KB の読み取りが行われます。  ONTAP がMilvus I/O 負荷を適切に処理することが期待されます。</block>
  <block id="e63d591f52bb0af8effc43c397a26a24" category="paragraph">PostgreSQL I/O プロファイルでは、困難なストレージ ワークロードは発生しません。現在進行中のメモリ内実装を考慮すると、クエリフェーズ中にディスク I/O は発生しませんでした。</block>
  <block id="dca2ae788fda893b11a6e115cfbd0c5d" category="paragraph">DiskANN は、ストレージの差別化に重要なテクノロジーとして登場しました。システム メモリの境界を超えたベクトル DB 検索の効率的なスケーリングが可能になります。ただし、HNSW などのメモリ内ベクトル DB インデックスでは、ストレージ パフォーマンスの差別化を確立できる可能性は低くなります。</block>
  <block id="dc94ef6a238640d927556506c546662f" category="paragraph">また、インデックス タイプが HSNW の場合、RAG アプリケーションをサポートするベクター データベースにとって最も重要な操作フェーズであるクエリ フェーズでは、ストレージが重要な役割を果たしないことにも注目に値します。ここでの意味は、ストレージ パフォーマンスがこれらのアプリケーションの全体的なパフォーマンスに大きな影響を与えないということです。</block>
  <block id="0a5775b4af8d3c53f18b8ccaf913945d" category="summary">これは、Netapp を使用したベクトル データベース ソリューションの概要ページです。</block>
  <block id="8df98bd508b3983f9578ff172fd33def" category="doc">NetAppによるベクトル データベース ソリューション</block>
  <block id="7dff0a79d9410666d77e5f2ac7d0344f" category="paragraph">NetApp 、Karthikeyan Nagalingam 氏と Rodrigo Nascimento 氏</block>
  <block id="01fbfceb794af743cb563e2676923b70" category="paragraph">このドキュメントでは、NetApp のストレージ ソリューションを使用して、Milvus などのベクター データベースやオープンソースの PostgreSQL 拡張機能である pgvecto の導入と管理について詳しく説明します。 NetApp ONTAPおよびStorageGRIDオブジェクトストレージを使用するためのインフラストラクチャガイドラインの詳細を説明し、AWS FSx ONTAPでの Milvus データベースの適用を検証します。このドキュメントでは、NetApp のファイルとオブジェクトの二重性と、ベクトル データベースおよびベクトル埋め込みをサポートするアプリケーションに対するその有用性について説明します。これは、ベクター データベースのバックアップと復元機能を提供し、データの整合性と可用性を確保する、NetApp のエンタープライズ管理製品であるSnapCenterの機能に重点を置いています。このドキュメントでは、NetApp のハイブリッド クラウド ソリューションについてさらに詳しく説明し、オンプレミスとクラウド環境にわたるデータのレプリケーションと保護におけるその役割について説明します。これには、 NetApp ONTAP上のベクトル データベースのパフォーマンス検証に関する洞察が含まれており、生成 AI に関する 2 つの実用的な使用例 (LLM を使用した RAG と NetApp の内部 ChatAI) で締めくくられています。このドキュメントは、NetApp のストレージ ソリューションを活用してベクター データベースを管理するための包括的なガイドとして役立ちます。</block>
  <block id="ad452e95198e544e4d893fc75ad47dd6" category="paragraph">リファレンス アーキテクチャは、次の点に重点を置いています。</block>
  <block id="710d95da54f78f69676ae8cb435c6e6e" category="list-text"><block ref="710d95da54f78f69676ae8cb435c6e6e" category="inline-link-macro-rx"></block></block>
  <block id="ada57c9cda1b1c751a4e899e578d38e3" category="list-text"><block ref="ada57c9cda1b1c751a4e899e578d38e3" category="inline-link-macro-rx"></block></block>
  <block id="82f4ace5dffbf97de80ca1ea103fbe56" category="list-text"><block ref="82f4ace5dffbf97de80ca1ea103fbe56" category="inline-link-macro-rx"></block></block>
  <block id="55496e6b06de6e72c19b578ad4ce71d8" category="inline-link-macro">技術要件</block>
  <block id="4abf02f5e3deeb5036c0eded610de05a" category="list-text"><block ref="4abf02f5e3deeb5036c0eded610de05a" category="inline-link-macro-rx"></block></block>
  <block id="19c63a75039d0a9cb4cec3458cfe0581" category="list-text"><block ref="19c63a75039d0a9cb4cec3458cfe0581" category="inline-link-macro-rx"></block></block>
  <block id="8c8f8b93bc06c57499a04ec1b06dae28" category="inline-link-macro">ソリューション検証の概要</block>
  <block id="ca47b69088a672a9b65069106989453e" category="list-text"><block ref="ca47b69088a672a9b65069106989453e" category="inline-link-macro-rx"></block></block>
  <block id="55d7ef09813b4d6fdcb2c5626efe487e" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block></block>
  <block id="0bf83d510fcfec34ea35ee03c83ce577" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus with Amazon FSx ONTAP for NetApp ONTAP – ファイルとオブジェクトの二重性]</block>
  <block id="d6b228867818081bf3ee3cecad050baf" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block></block>
  <block id="f7ba02d22d83dabd12f0465a68c210ea" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block></block>
  <block id="9e30995c6d4864b29eb56e92d196baec" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block></block>
  <block id="bd1287beca719fc00531ba3dd533f70c" category="list-text"><block ref="bd1287beca719fc00531ba3dd533f70c" category="inline-link-macro-rx"></block></block>
  <block id="a4349288a9fe8fecb32674ed8a0e5d15" category="inline-link-macro">ベクターデータベースのユースケース</block>
  <block id="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="list-text"><block ref="b8d3dfdbfce37d26c1f4f9d8acee71ca" category="inline-link-macro-rx"></block></block>
  <block id="da73b8a757c1735375b56d959d388619" category="list-text"><block ref="da73b8a757c1735375b56d959d388619" category="inline-link-macro-rx"></block></block>
  <block id="fec04177b34fde0762c2d0f1cb5bcf85" category="inline-link-macro">付録A: values.yaml</block>
  <block id="4076746ca906dfd472a39281440bca63" category="list-text"><block ref="4076746ca906dfd472a39281440bca63" category="inline-link-macro-rx"></block></block>
  <block id="2c0fbb0e17a27b8dbff673fb6b03c50b" category="list-text"><block ref="2c0fbb0e17a27b8dbff673fb6b03c50b" category="inline-link-macro-rx"></block></block>
  <block id="016166f68a717d3a544b77970134fe92" category="inline-link-macro">付録 C: verify_data_netapp.py</block>
  <block id="1fa29d4bb8db316d27c057bc2ab73bcb" category="list-text"><block ref="1fa29d4bb8db316d27c057bc2ab73bcb" category="inline-link-macro-rx"></block></block>
  <block id="cb2986bd8f2d29c4cca582736e0a680f" category="list-text"><block ref="cb2986bd8f2d29c4cca582736e0a680f" category="inline-link-macro-rx"></block></block>
  <block id="f60546114707495cbcefb83f806b47e2" category="summary">技術要件 - NetApp 向けベクトル データベース ソリューション</block>
  <block id="73877510aa37e2bcf501625512e358c3" category="paragraph">このセクションでは、 NetAppベクトル データベース ソリューションの要件の概要を説明します。</block>
  <block id="1507fd593972e19976a48675eb11483a" category="paragraph">パフォーマンスを除き、このドキュメントで実行された検証の大部分では、以下に概説するハードウェアおよびソフトウェア構成が使用されました。これらの構成は、環境を設定する際に役立つガイドラインとして機能します。ただし、具体的なコンポーネントは個々の顧客の要件に応じて異なる場合があることにご注意ください。</block>
  <block id="7e9534170bcf0d2cab4a69e22cdca79c" category="cell">* A800 * ONTAP 9.14.1 * 48 x 3.49TB SSD-NVM * 2 つの柔軟なグループ ボリューム: メタデータとデータ。  * メタデータ NFS ボリュームには、250 GB の永続ボリュームが 12 個あります。  * データはONTAP NAS S3 ボリュームです</block>
  <block id="bcb4d8bb0642dc62c114f2a0a31f5aa3" category="cell">富士通 PRIMERGY RX2540 M4 x 6</block>
  <block id="891b7b85ad27bcf31f4d6b9d3e5f55eb" category="cell">* 64個のCPU * Intel(R) Xeon(R) Gold 6142 CPU @ 2.60GHz * 256 GM物理メモリ * 1 x 100GbEネットワークポート</block>
  <block id="4515188d6af40c03b16b310778b865c8" category="cell">* 1 x SG100、3xSGF6024 * 3 x 24 x 7.68TB</block>
  <block id="e7f07d17d04d9ac60dd3ebc382a1d58b" category="cell">ミルバス星団</block>
  <block id="5c9a77f3be5149b25ef3dd4a0d42f61e" category="cell">* チャート - milvus-4.1.11。  * APPバージョン – 2.3.4 * Bookkeeper、Zookeeper、Pulsar、etcd、Proxy、QueryNode、Workerなどの依存バンドル</block>
  <block id="b0654cc6796be715102b69214bddfb52" category="cell">* 5ノードのK8sクラスター * 1つのマスターノードと4つのワーカーノード * バージョン – 1.7.2</block>
  <block id="5b8215321456694f36bc83a178e44856" category="cell">*3.10.12.</block>
  <block id="5a019cf3628ae4961c3ba86198ac5410" category="summary">ユースケース - NetApp 向けベクター データベース ソリューション</block>
  <block id="853fb1f37b200090af8f730400a34971" category="paragraph">このセクションでは、 NetAppベクトル データベース ソリューションの使用例の概要を説明します。</block>
  <block id="61798ad0c56d51680f77d6b9f4694877" category="paragraph">このセクションでは、大規模言語モデルを使用した検索拡張生成とNetApp IT チャットボットなどの 2 つのユースケースについて説明します。</block>
  <block id="2b376c37a6f0c2c21b8ba7b62ac86693" category="section-title">大規模言語モデル（LLM）を用いた検索拡張生成（RAG）</block>
  <block id="6a482cb4a386f8c0b7889b5dc11a997a" category="paragraph">NVIDIA Enterprise RAG LLM Operator は、企業内で RAG を実装するための便利なツールです。このオペレーターは、完全な RAG パイプラインをデプロイするために使用できます。 RAG パイプラインは、知識ベースの埋め込みを格納するためのベクター データベースとして Milvus または pgvecto のいずれかを利用するようにカスタマイズできます。詳細についてはドキュメントを参照してください。</block>
  <block id="4c1729beb205806fa130c0dbf0364b59" category="paragraph">図1) NVIDIA NeMo MicroservicesとNetAppを搭載したエンタープライズRAG</block>
  <block id="b14745e6302744b3b3c226e1fdee230a" category="paragraph"><block ref="b14745e6302744b3b3c226e1fdee230a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da66e40722180b5a0466a9ff253976af" category="section-title">NetApp IT チャットボットのユースケース</block>
  <block id="497416719429ff96f2462d991f6ea3f8" category="paragraph">NetApp のチャットボットは、ベクター データベースのもう 1 つのリアルタイム使用例として機能します。この例では、 NetApp Private OpenAI Sandbox は、NetApp の社内ユーザーからのクエリを管理するための効果的で安全かつ効率的なプラットフォームを提供します。厳格なセキュリティ プロトコル、効率的なデータ管理システム、高度な AI 処理機能を組み込むことで、SSO 認証を通じて組織内の役割と責任に基づいて、ユーザーへの高品質で正確な応答を保証します。このアーキテクチャは、高度なテクノロジーを統合してユーザー中心のインテリジェントなシステムを作成する可能性を強調しています。</block>
  <block id="8afdd8df71939b23b5b37041b4b0e243" category="paragraph"><block ref="8afdd8df71939b23b5b37041b4b0e243" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff2b3d5b17bdfc4a02990dd4115b7d4d" category="paragraph">ユースケースは主に 4 つのセクションに分けられます。</block>
  <block id="e21f69fe36aefc844dcebf8fb52262a3" category="section-title">ユーザー認証と検証:</block>
  <block id="7457d61423f49fa817953d3c8e0c08cf" category="list-text">ユーザー クエリは、まずNetAppシングル サインオン (SSO) プロセスを経て、ユーザーの ID を確認します。</block>
  <block id="3dedad86d8ac55d8b2b034f0ff353ea5" category="list-text">認証が成功すると、システムは VPN 接続をチェックし、安全なデータ転送を確保します。</block>
  <block id="34ef9101314d114f1bed9a4fc8c13666" category="section-title">データの転送と処理:</block>
  <block id="e5aa3164f4a76a72d1d074c0285a4d54" category="list-text">VPN が検証されると、データは NetAIChat または NetAICreate Web アプリケーションを通じて MariaDB に送信されます。  MariaDB は、ユーザー データを管理および保存するために使用される高速で効率的なデータベース システムです。</block>
  <block id="d0d4d700ca2ba3e943833a184fce15db" category="list-text">その後、MariaDB は情報をNetApp Azure インスタンスに送信し、NetApp Azure インスタンスはユーザー データを AI 処理ユニットに接続します。</block>
  <block id="b1cbaf6e413b3b5a92538942710197de" category="section-title">OpenAIとコンテンツフィルタリングとの相互作用:</block>
  <block id="e7a51c3da456741ac0fe5ae031a539a3" category="list-text">Azure インスタンスは、ユーザーの質問をコンテンツ フィルタリング システムに送信します。このシステムはクエリをクリーンアップし、処理の準備をします。</block>
  <block id="8449bc1c7d0f0641656072f90d8d06db" category="list-text">クリーンアップされた入力は Azure OpenAI ベース モデルに送信され、入力に基づいて応答が生成されます。</block>
  <block id="ce4abebf9a6d91e3d12d3bd86ebd308f" category="section-title">レスポンスの生成とモデレーション:</block>
  <block id="70ee91d51a5da426448f1ed59462804d" category="list-text">まず、ベース モデルからの応答がチェックされ、正確であり、コンテンツ標準を満たしているかどうかが確認されます。</block>
  <block id="40d26f0ba80199b0eaf7b7e0525c7f34" category="list-text">チェックに合格すると、応答がユーザーに返されます。このプロセスにより、ユーザーは質問に対して明確かつ正確で適切な回答を受け取ることができます。</block>
  <block id="705451e750819c9ce68fb278a7b09839" category="summary">values-xml - NetApp 向けベクター データベース ソリューション</block>
  <block id="6e6c82b93338e2283cf42123803b79d4" category="doc">付録A: Values.yaml</block>
  <block id="42cb737e154e9abe53c3f800eae00d4e" category="paragraph">このセクションでは、 NetAppベクトル データベース ソリューションで使用される値のサンプル YAML コードを示します。</block>
  <block id="bdcc26240ab0215ba46efad29038278d" category="summary">ソリューション検証の概要 - NetApp向けベクターデータベースソリューション</block>
  <block id="a11dfa705c151f0af3e80cc954126655" category="paragraph">当社では、5 つの主要領域に重点を置いた包括的なソリューション検証を実施しました。その詳細は以下に記載されています。各セクションでは、顧客が直面している課題、 NetAppが提供するソリューション、そしてそれによって顧客にもたらされるメリットについて詳しく説明します。</block>
  <block id="748a76b95c3f380357377aefd2ed0474" category="list-text"><block ref="55d7ef09813b4d6fdcb2c5626efe487e" category="inline-link-macro-rx"></block>顧客は、ストレージとコンピューティング、効果的なインフラストラクチャ管理、およびデータ管理に基づいて独立して拡張するという課題に直面しています。このセクションでは、クラスター データと顧客データの両方にNetAppストレージ コントローラーを利用して、Kubernetes に Milvus クラスターをインストールするプロセスについて詳しく説明します。</block>
  <block id="e840bff7e1e9715df98e16fead8076cb" category="list-text">link:vector-database-milvus-with-Amazon-FSx ONTAP-for- NetApp- ONTAP.html[Milvus とAmazon FSx ONTAP for NetApp ONTAP – ファイルとオブジェクトの二重性] このセクションでは、クラウドにベクトルデータベースをデプロイする必要がある理由と、Docker コンテナ内のAmazon FSx ONTAP for NetApp ONTAPにベクトルデータベース (milvus スタンドアロン) をデプロイする手順について説明します。</block>
  <block id="6cce3de9e8bf8cabbfe260cc36d61ac3" category="list-text"><block ref="d6b228867818081bf3ee3cecad050baf" category="inline-link-macro-rx"></block>このセクションでは、 SnapCenter がONTAPにあるベクター データベース データと Milvus データをどのように保護するかについて詳しく説明します。この例では、顧客データ用に NFS ONTAPボリューム (vol1) から派生した NAS バケット (milvusdbvol1) を使用し、Milvus クラスタ構成データ用に別の NFS ボリューム (vectordbpv) を使用しました。</block>
  <block id="918f8a4912d6a98fb31ac7ba46e00ffc" category="list-text"><block ref="f7ba02d22d83dabd12f0465a68c210ea" category="inline-link-macro-rx"></block>このセクションでは、ベクター データベースの災害復旧 (DR) の重要性と、NetApp の災害復旧製品 SnapMirror がベクター データベースに DR ソリューションを提供する方法について説明します。</block>
  <block id="2f1a6b813251891cca144a8b91cde4f5" category="list-text"><block ref="9e30995c6d4864b29eb56e92d196baec" category="inline-link-macro-rx"></block>このセクションでは、Milvus や pgvecto.rs などのベクトル データベースのパフォーマンス検証を詳しく検討し、LLM ライフサイクル内での RAG および推論ワークロードをサポートする I/O プロファイルやネットアップ ストレージ コントローラの動作などのストレージ パフォーマンス特性に焦点を当てます。これらのデータベースをONTAPストレージ ソリューションと組み合わせた場合のパフォーマンスの差別化要因を評価し、特定します。私たちの分析は、1 秒あたりに処理されるクエリ数 (QPS) などの主要なパフォーマンス指標に基づいて行われます。</block>
  <block id="87c3db9ccf444604c258b88ee8489364" category="summary">verify_data_netapp.py - netapp 用ベクター データベース ソリューション</block>
  <block id="599675cccffd45ab676aea932c3fdfbd" category="paragraph">このセクションには、 NetAppベクター データベース ソリューション内のベクター データベースを検証するために使用できるサンプル Python スクリプトが含まれています。</block>
  <block id="48e4e86482d1e72b17c82feb1e930352" category="doc">NetAppのAIソリューションに関するビデオを見る</block>
  <block id="a9f5e6dcd1d44f9ba3dc3398020d2404" category="paragraph">NetApp がAI と機械学習の取り組みをどのように強化しているかをご覧ください。これらの厳選されたビデオ プレイリストでは、 NetApp AI ソリューションと MLOps ワークフローを紹介し、高度な分析のための導入戦略、自動化、データ管理に焦点を当てています。</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="paragraph-title">NetApp AIソリューション</block>
  <block id="b4bf3d1dd932a4fb0e32b91623652e42" category="inline-link-macro">NetApp AIソリューションのプレイリストを見る</block>
  <block id="d3e2da82e7d75fc2a126141e7169de49" category="paragraph">AI インフラストラクチャ、統合システム、エンタープライズ AI の展開を網羅した包括的なビデオ プレイリスト。<block ref="af3f91668350fde9b89e361b330e6bf9" category="inline-link-macro-rx"></block></block>
  <block id="07aca6f404d3e6c525bac36328b0d27d" category="paragraph-title">機械学習運用（MLOps）</block>
  <block id="aee569e95a8498ede74e68ae8306e6e5" category="inline-link-macro">MLOps プレイリストを見る</block>
  <block id="d41374c7672e6e4fdbfbd6504b672d3c" category="paragraph">MLOps ワークフロー、データ パイプライン、運用のベスト プラクティスに関するビデオ シリーズ。<block ref="70aea7fc5134cd09b86d7ff27c954117" category="inline-link-macro-rx"></block></block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">NetAppの多くのソリューションの機能を説明するビデオとデモのシリーズ</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetAppソリューション: ビデオとデモ</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">NetApp の多くのソリューションの特定の機能を紹介するビデオとデモの概要。</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps</block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="181a90cd4ce68792d6ce2049bb1ff6ec" category="summary">NetApp人工知能ソリューション資料への最近の変更のログ。</block>
  <block id="232dfabf5b2a241a9f7473820c81bf15" category="doc">NetAppの人工知能ソリューションの新機能</block>
  <block id="be647982bfc8c0837c019b8fdbc711b3" category="paragraph">人工知能ソリューションの最新情報を学びます。</block>
  <block id="bab52961b58c502c7991d35556c25367" category="section-title">2025年8月18日</block>
  <block id="47e26e0d5bbeef43c544dd9ae72e66b0" category="inline-link-macro">NetAppソリューションファミリー</block>
  <block id="840125a006aee7dc0e8efd313e7b614e" category="paragraph">NetAppソリューションサイトは、<block ref="f083b096ae581e72c5ab727ef8bd5732" category="inline-link-macro-rx"></block>これには次のサイトが含まれます。</block>
  <block id="e87298059f60b0844dc971f315184cf5" category="list-text">NetAppの人工知能ソリューション</block>
  <block id="9cae574c1dc1ca50a949c1e889637ba7" category="inline-link-macro">NetAppコンテナソリューション</block>
  <block id="31d1ae0120af1d791e4320e17eb10687" category="list-text"><block ref="31d1ae0120af1d791e4320e17eb10687" category="inline-link-macro-rx"></block></block>
  <block id="3947417923606d3599bcba7a82f71f1b" category="inline-link-macro">NetAppデータ管理ソリューション</block>
  <block id="56c054d4bb919790ebe189f7a7d11c3c" category="list-text"><block ref="56c054d4bb919790ebe189f7a7d11c3c" category="inline-link-macro-rx"></block></block>
  <block id="9bb3e58246c5654a6d8e08a7bddd60ec" category="inline-link-macro">NetAppデータベースソリューション</block>
  <block id="3e2420ab1ec1d6e02b32b017d3ba969a" category="list-text"><block ref="3e2420ab1ec1d6e02b32b017d3ba969a" category="inline-link-macro-rx"></block></block>
  <block id="a37049a2a78422ac5627c7987db5c337" category="inline-link-macro">NetAppパブリックおよびハイブリッド クラウド ソリューション</block>
  <block id="144417321224efbf0afc2ae665a84a46" category="list-text"><block ref="144417321224efbf0afc2ae665a84a46" category="inline-link-macro-rx"></block></block>
  <block id="2729aba3baa90aaaed37b282e515f6e4" category="inline-link-macro">SAP向けNetAppソリューション</block>
  <block id="5e056430559fb77ac659dbb71ecce256" category="list-text"><block ref="5e056430559fb77ac659dbb71ecce256" category="inline-link-macro-rx"></block></block>
  <block id="4ead908c2ca3b4c7156e0e703642415d" category="inline-link-macro">NetApp仮想化ソリューション</block>
  <block id="3100186c9f62cec85ac05309c5d10217" category="list-text"><block ref="3100186c9f62cec85ac05309c5d10217" category="inline-link-macro-rx"></block></block>
  <block id="fac83ccf1756a0c9cb3b8982d7f17073" category="sidebar">NetApp は、エンタープライズ グレードのデータ管理、検証済みのリファレンス アーキテクチャ、戦略的パートナーシップを組み合わせた包括的な AI ソリューションを提供し、AI イニシアチブを加速し、重要なビジネス成果をサポートします。インフラストラクチャの導入から MLOps の自動化まで、当社のソリューションはエッジ、データセンター、ハイブリッド クラウド環境にわたってシームレスに拡張できます。</block>
  <block id="be11c74c1dd7f307bb80183a90dc2067" category="sidebar">始めましょう</block>
  <block id="33871b6190a8d5adbe8b15282054766c" category="sidebar">新機能</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="sidebar">ブログ</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="sidebar">ビデオとデモ</block>
  <block id="0356451dce8be030d34b4cddc51bd023" category="sidebar">AIインフラストラクチャと統合システム</block>
  <block id="9547dc55d95184a53ea1a8366b5aeced" category="sidebar">NVIDIA DGX システムを搭載したNetApp AIPod</block>
  <block id="1f403aa196fd2c94e882669641695d63" category="sidebar">NVIDIA DGX SuperPODと EF シリーズ</block>
  <block id="ca2b44ea641055fab6c572a1ec645f40" category="sidebar">NVIDIA OVX 対応の Lenovo 搭載NetApp AIPod</block>
  <block id="71194b59e7e6e05cdd5e38686d46dd11" category="sidebar">Eシリーズ搭載のBeeGFS並列ファイルシステム</block>
  <block id="0490c28d4251b3da040883241b9a245b" category="sidebar">AIのユースケースとアプリケーション</block>
  <block id="03a2eeb037be2a65352a6ce833a5352d" category="sidebar">RAG推論のためのAIPod Mini</block>
  <block id="2a5e8ee0f85321457b5b5051848b33df" category="sidebar">エッジでのAI推論</block>
  <block id="1f5ef80ba6fe60fcd8fc9b93428724ca" category="sidebar">ベクターデータベースソリューション</block>
  <block id="1c2e519ac88b24b944e313f1528b25ca" category="sidebar">自動運転のワークロード</block>
  <block id="1f2d4372bbd3f4944eec91b65eb55b69" category="sidebar">Quantum StorNextとEシリーズ</block>
  <block id="dd12d2c2197bdac0454f49eaf82efcb1" category="sidebar">MLOpsとデータ管理</block>
  <block id="55200dead19623a5ed7fd47347cc531d" category="sidebar">NetAppによるオープンソース MLOps</block>
  <block id="0fa95f40d436ae4b6b1a848a385c88f5" category="sidebar">Domino Data Lab によるハイブリッド マルチクラウド MLOps</block>
  <block id="ec441b7e7e90b2ae639b5c9784b469f9" category="sidebar">MLOps 向け FSx ONTAP</block>
  <block id="072e5110aacde0c4952afb7fa86bd5bf" category="sidebar">ビッグデータとハイブリッドクラウドAIソリューション</block>
  <block id="248d62097e51f823fbf1797b8d71b837" category="sidebar">ハイブリッドクラウドデータソリューション</block>
  <block id="01ba1aebae20e7ddfe20f3ea9572b0a6" category="sidebar">Apache Sparkソリューション</block>
  <block id="8f0ff6e8178c4e8f4ea0f489063d7586" category="sidebar">NetApp ONTAPストレージと Confluent Kafka</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore を搭載したNetApp StorageGRID</block>
  <block id="76a3eb07a798a5ace45b8500ba2aae19" category="sidebar">NetAppストレージを搭載したDremioレイクハウス</block>
  <block id="e95b75f557af9310f3d9c6299286a533" category="sidebar">ソリューションのリクエストとフィードバック</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">リクエストの自動化</block>
  <block id="776ab15fef436c9315c14738509d299e" category="sidebar">新しい解決策を提案する</block>
  <block id="cfdaac8ef24ac5b2612570c34da00954" category="sidebar">ソリューションのフィードバックを提供する</block>
  <block id="9e34d9d231e4cd17fbacda95fb51929b" category="sidebar">NetApp の包括的な MLOps およびデータ管理ソリューションを使用して、AI/ML ワークフローを合理化します。当社のソリューションは、オープンソース プラットフォームからエンタープライズ グレードのツールまで、データの一貫性とパフォーマンスを確保しながら、ハイブリッド クラウド環境全体での効率的なモデル開発、展開、スケーリングを可能にします。</block>
  <block id="e212a74da744d81b7be22fde8837f469" category="sidebar">NetApp MLOps とデータ管理ソリューション</block>
  <block id="7c9c1738224214245dd19322f112f008" category="sidebar">オープンソースのMLOpsプラットフォーム</block>
  <block id="8225e12837234b91ab0ddcd265042318" category="sidebar">AIPod用のNetApp Trident構成</block>
  <block id="8b4f0b6bb6bc359f491be13c6d4217c4" category="sidebar">Apache Airflow の展開と統合</block>
  <block id="948fee9aa5251e39df94d1c32d0c25cf" category="sidebar">JupyterHubのデプロイメントとデータ操作</block>
  <block id="73cee63b0ef47212c43598d623b858e0" category="sidebar">MLflowの展開とトレーサビリティ</block>
  <block id="938ff6f66cfc08077aee20a94cb3555a" category="sidebar">高度なMLOpsワークフロー</block>
  <block id="e037812c032cd0d9c22b13bc85e9e8b0" category="sidebar">Kubeflow のデプロイメントとノートブック</block>
  <block id="3ff4473b7f6cd29fd2f032383a101ad3" category="sidebar">Kubeflow で画像認識モデルをトレーニングする</block>
  <block id="4d72e4ce52deedeed5378320bb10ba60" category="sidebar">単一ノードのAIワークロード実行</block>
  <block id="d4090ff0c5d6e77994fe88d878931a09" category="sidebar">分散AIワークロード実行</block>
  <block id="6d49da972d2b3e8021183d3dd882efc3" category="sidebar">SnapMirrorによるデータ取り込み</block>
  <block id="13c4fd018be37b2e07ac1e3c7bf940da" category="sidebar">エンタープライズMLOpsソリューション</block>
  <block id="bf57be3e9bf09ff89214bcab0ffcd37f" category="sidebar">Domino Data Lab を使用したハイブリッド MLOps</block>
  <block id="5a938de20177e2b1dcb267d6d7b4f069" category="sidebar">Domino による環境間データアクセス</block>
  <block id="86c9440e933f2848898cd3a50e0d30c5" category="sidebar">NVIDIA NGCソフトウェア統合</block>
  <block id="e9eb61f514f368f5d8d0cf3ccfded4f9" category="sidebar">クラウド MLOps と AWS の統合</block>
  <block id="b9a33eec860aee8b042190248e9c0978" category="sidebar">Amazon FSx for ONTAP MLOps</block>
  <block id="19f22745fb509faf9a35f2999167b4b3" category="sidebar">SageMaker で FSx ONTAP をプライベート S3 として統合する</block>
  <block id="958182d4c4d2fbecef5e794dd36a2fcd" category="sidebar">SageMaker モデルトレーニング用の FSx ONTAP</block>
  <block id="765bac8adf0ce0c27f43291f5f38e36e" category="sidebar">FSx で簡素化された MLOps パイプラインを構築する</block>
  <block id="cff078ffafce4368253406707fe938e2" category="sidebar">ベクターデータベースとAIアプリケーション</block>
  <block id="8817647abcdf406ecb3f743ce1f4d0c3" category="sidebar">NetAppによるベクトルデータベースソリューション</block>
  <block id="eac46f1424b8a5f784861bfb337632d5" category="sidebar">Kubernetes を使用した Milvus クラスターのセットアップ</block>
  <block id="e557c94c22c1c941bd40b8277f7f7753" category="sidebar">SnapCenterによるベクターデータベース保護</block>
  <block id="ba5dd0875f60bb8bfd1c4511266f65f1" category="sidebar">ベクターデータベースのパフォーマンス検証</block>
  <block id="8d80ba264d116b7cc3e458ba8697ce83" category="sidebar">ベクターデータベースの使用例</block>
  <block id="e90bb805ac6728252476dc4b6c9f33b8" category="sidebar">データ管理ツールとストレージ</block>
  <block id="8825002f133fae0b139e8325ac7730cf" category="sidebar">自動運転向けStorageGRIDデータレイク</block>
  <block id="bf25ffbc01db3077dbf625f1f66b0b81" category="sidebar">SnapMirrorによる災害復旧</block>
  <block id="1e87a0e6a353196e3d5d6cd2e73a3e6e" category="sidebar">NetApp の検証済みリファレンス アーキテクチャと統合システムを使用して、エンタープライズ対応の AI インフラストラクチャを導入します。  NetApp AIPodソリューションから高性能ストレージ プラットフォームまで、当社の設計は要求の厳しい AI/ML ワークロードに必要なパフォーマンス、スケーラビリティ、信頼性を実現します。</block>
  <block id="994ec7a86f72507f5352d2b180d45f33" category="sidebar">NetApp AIインフラストラクチャと統合システム</block>
  <block id="1c869286ed71535693a9462972519af4" category="sidebar">NetApp AIPodリファレンスアーキテクチャ</block>
  <block id="b4f767e2f090ec487aa796e06a450c3b" category="sidebar">AIPodアーキテクチャ</block>
  <block id="b6c79f2c0318b6d7625fb67322575ef8" category="sidebar">AIPodの展開の詳細</block>
  <block id="8c660d55cc308e8a0142574e6cb06bb2" category="sidebar">AIPodの検証とサイズ設定のガイダンス</block>
  <block id="f5a73cfaecb9184b2e8146ed455050a9" category="sidebar">AIワークロード向けの高性能ストレージ</block>
  <block id="dca52c3c8e9f73ebf5e2f52c01c943af" category="sidebar">EFシリーズストレージを搭載したNVIDIA DGX SuperPOD</block>
  <block id="0cdb4340f983739886aeeabf55ded9a0" category="sidebar">Eシリーズストレージを搭載したIBM Spectrum Scale</block>
  <block id="103956252a2179a2f41c37f503662e57" category="sidebar">NetApp ONTAPとLenovo ThinkSystem</block>
  <block id="e5a53cbbfd61be59509da2fb28b87bd6" category="sidebar">エンタープライズ RAG システムやエッジ推論から、責任ある AI プラクティスやデータ移行戦略まで、 NetAppソリューションによる実際の AI 実装を探索します。これらのユースケースは、 NetAppが組織がセキュリティ、パフォーマンス、スケーラビリティを維持しながら、さまざまな環境に AI アプリケーションを導入できるようにする方法を示しています。</block>
  <block id="7438b9f1311e240ca42a988e9d13e00c" category="sidebar">NetApp AIのユースケースとアプリケーション</block>
  <block id="f5d80fd5b29670f59fa900f8c07fb329" category="sidebar">エンタープライズ RAG システムやエッジ推論から、責任ある AI プラクティスやデータ移行戦略まで、 NetAppソリューションによる実際の AI 実装を探索します。これらのユースケースは、 NetApp がセキュリティ、パフォーマンス、スケーラビリティを維持しながら、さまざまな環境で AI アプリケーションを実現する方法を示しています。</block>
  <block id="0d6f02845b71bc324cd82a725369e788" category="sidebar">エンタープライズAIアプリケーションとユースケース</block>
  <block id="a67b9cee4655d6177295261e4bcd604d" category="sidebar">エンタープライズRAG向けNetApp AIPod Mini</block>
  <block id="f5d3d706e83df8136ffa361f6bf3de44" category="sidebar">ジェネレーティブAIとNetAppの価値</block>
  <block id="e2c8fd379213f568475a9fd8d939677a" category="sidebar">NetAppとLenovoによるエッジAI推論</block>
  <block id="7625f6572992d4d6884af97bd58e8555" category="sidebar">ビッグデータ分析からAIへの移行</block>
  <block id="58f52c07cacafd13bf7c2b75bd52297b" category="sidebar">責任あるAI</block>
  <block id="726a429bb7d3cf42471e4ef6d5064f39" category="sidebar">プロトピア画像変換による責任あるAI</block>
  <block id="9aadc819040333a6a70c083f60934127" category="sidebar">AIストレージおよびインフラストラクチャソリューション</block>
  <block id="4ec66dae70419b5536af92b7e6af12eb" category="sidebar">EシリーズシステムでQuantum StorNextを設計する</block>
  <block id="fdc9cddf0d9dda4d36a935baaa555437" category="sidebar">EシリーズシステムでQuantum StorNextを導入</block>
  <block id="2107e3f2176d1159c57518d8100b979c" category="sidebar">Apache Spark、Hadoop、Kafka、エッジからクラウドまで拡張可能な最新のデータ レイク アーキテクチャなど、ビッグ データ ワークロード向けの NetApp の実績あるソリューションを使用して、データ分析インフラストラクチャを変革します。</block>
  <block id="a4c306bc134438ffdcde3dc25d141930" category="sidebar">NetAppの最新データ分析ソリューション</block>
  <block id="f6d439e305ff0317b08aeaad65bc202c" category="sidebar">NetApp の最新データ分析ソリューションは、AI 分野全体にわたるNetAppストレージの機能を実証する戦略的および技術的な機能のセットです。</block>
  <block id="0c5c9c87a184244b0a7327aaef882e8e" category="sidebar">Apache Kafka ソリューション</block>
  <block id="7d576967253ca2f566f9693183407367" category="sidebar">NetApp NFSストレージを使用したApache Kafkaワークロード</block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">NetApp ONTAPストレージ コントローラを使用した Confluent Kafka</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka のベストプラクティス</block>
  <block id="c9adcd46dfe28ab240bf984f9da39535" category="sidebar">AWS による Kafka のパフォーマンス検証</block>
  <block id="c6dc54040e7551a25c7f14dd83a3ca37" category="sidebar">Apache SparkとHadoopソリューション</block>
  <block id="75b5d408998484e1ea5a4ce3cc432cbe" category="sidebar">Apache Spark向けNetAppストレージソリューション</block>
  <block id="d2e5b5510723b29c7f85a6f53b0b30fe" category="sidebar">NetAppストレージを使用して Apache Spark ワークロードを展開する</block>
  <block id="d142861488d42c2de042afc4375049da" category="sidebar">Spark と Hadoop 向けのNetAppハイブリッド クラウド データ ソリューション</block>
  <block id="15b1a623b46c0553eb7e0a02392de6f9" category="sidebar">ユースケースとアーキテクチャ</block>
  <block id="7bbc21a3294c0070a8663140370d1f39" category="sidebar">Apache Sparkのテスト結果</block>
  <block id="8b809555e7e0cd658f51306db399d338" category="sidebar">クラウドデータ管理とAI</block>
  <block id="1d2114df6a9f8f5d7e8f597e9c70a6c1" category="sidebar">NetApp のファイルオブジェクト二重性と AWS SageMaker を使用したクラウドデータ管理</block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">ビッグデータ分析データから人工知能へ</block>
  <block id="55cd26df7471de5ffbc83646a94fddbb" category="sidebar">MLOpsAmazon FSx for NetApp ONTAP</block>
  <block id="2a15fc3906339e08c458c8e62e447da3" category="sidebar">Apache Spark ハイブリッドクラウドソリューション</block>
  <block id="e0afb7c0b35ca1c50d576d490c1f6f83" category="sidebar">最新のデータレイクと分析プラットフォーム</block>
  <block id="2f8caf1cb27d10780daee2d12dfe6cf5" category="sidebar">NetAppとDremioの次世代ハイブリッド氷山レイクハウスソリューション</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp Eシリーズ E5700とSplunk Enterprise</block>
  <block id="8cd58c89ff3d51a256ecfe3fe8bab20f" category="sidebar">その他のリソース</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="sidebar">さまざまな分析戦略に応じたさまざまなソリューション</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">ブログ: NetAppデータ分析のプレイグラウンドで Apache Spark が活躍</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">ブログ: データレイクと HPC からONTAP NFS へのデータ移行に XCP を使用する</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: ビッグデータ分析プレイリスト</block>
  <block id="5baf6ec1129c513e42641878b72ed0d8" category="sidebar">人工知能ソリューション</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="sidebar">ビデオ</block>
  <block id="45552f1d8df5302f6b20a45bdca4873c" category="sidebar">NetApp Trident の構成</block>
  <block id="629606c7cd29d3a21eb21c6ac5139f33" category="sidebar">AIPod展開用のTridentバックエンド</block>
  <block id="6c7cb31582a28a42e762b2046a1ce896" category="sidebar">AIPodデプロイメント用の Kubernetes StorageClasses</block>
  <block id="d9fd1af737bab40d222131485c9bb808" category="sidebar">Apache Airflow のデプロイメント</block>
  <block id="17f2e89c743299170fd62138fa80d495" category="sidebar">JupyterHub のデプロイメント</block>
  <block id="471efd78e003975a601bfbdaf70136d2" category="sidebar">NetApp SnapMirrorでデータを取り込む</block>
  <block id="7d6f6d1bc3093617ee4703c5e520774b" category="sidebar">MLflowの展開</block>
  <block id="7174f04026f1e5e87367c72c1c073824" category="sidebar">NetAppと MLflow によるデータセットからモデルへのトレーサビリティ</block>
  <block id="a38d89f197f605418a88b686e0175fa2" category="sidebar">Kubeflow のデプロイメント</block>
  <block id="b540e10006be068e5e5fd93d05b7b12c" category="sidebar">Jupyter Notebook ワークスペースのプロビジョニング</block>
  <block id="e8816281bfd02443de2002db66789462" category="sidebar">画像認識モデルのトレーニング - ワークフローの例</block>
  <block id="4c71560715665aa3108585868c989cdc" category="sidebar">Trident操作の例</block>
  <block id="1c6a3a6b23e40077c58b45d05d4d411f" category="sidebar">AIPod展開の高パフォーマンスジョブの例</block>
  <block id="dcdebd18dbab6da6d511c220479f6460" category="sidebar">単一ノードのAIワークロードを実行する</block>
  <block id="98053e2b2531af18e4f885fb8a731327" category="sidebar">同期分散AIワークロードを実行する</block>
  <block id="7406ea045ac944a9db15b50dba8cc04b" category="sidebar">Domino Data Lab とNetAppによるハイブリッド MLOps</block>
  <block id="1231369e1218613623e1b520c27ce190" category="sidebar">初期設定</block>
  <block id="e5726f3da1ad0304974cf103e75da470" category="sidebar">既存のNetAppボリュームをDominoに公開する</block>
  <block id="f62030848d7cb177a11eb3916356bb29" category="sidebar">異なる環境間で同じデータにアクセスする</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="sidebar">追加情報</block>
  <block id="f4c44872f09acb0f4e8f90890004d4ab" category="sidebar">NVIDIA NGCソフトウェアを使用する</block>
  <block id="a12d6a26832d73816bca1235e9f4d8a1" category="sidebar">ユースケース例 - TensorFlow トレーニングジョブ</block>
  <block id="0975e7e38dac95fd7ce3d2e3966e26be" category="sidebar">パート 1 - Amazon FSx for NetApp ONTAP をプライベート S3 バケットとして AWS SageMaker に統合する</block>
  <block id="b675f3bab2742c1723ed556f8535349d" category="sidebar">パート 2 - SageMaker でのモデルトレーニングのデータソースとしてAmazon FSx for NetApp ONTAP を活用する</block>
  <block id="7609ccc24e4c12c32d0ad617fe91161e" category="sidebar">パート3 - 簡素化されたMLOpsパイプラインを構築する</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">自動運転ワークロード向けNetApp StorageGRIDデータレイク</block>
  <block id="a20ee4ebc8e6614143815c881916cbba" category="sidebar">NetAppによるベクトルデータベースソリューション</block>
  <block id="e5df4bbe7b124f2fe5398d42696d57b3" category="sidebar">ベクターデータベース</block>
  <block id="9934c7eb2c2161e05fedd3b280e4eedc" category="sidebar">技術要件</block>
  <block id="951de808fb87ba9bc035ce3cf467b064" category="sidebar">SnapCenterを使用したベクター データベースの保護</block>
  <block id="f0a132dd5ea90d189f80995d831f9b91" category="sidebar">SnapMirrorを使用した災害復旧</block>
  <block id="e813a53d42d6bfe69e6907df9b0675d5" category="sidebar">PostGreSQL を使用した Instaclustr によるベクターデータベース: pgvector</block>
  <block id="7fad254d8199fbf6d695e96590444cff" category="sidebar">付録B: 準備データネットアプリ新パイ</block>
  <block id="4d4989117d6e4f26e57cc7135af8f508" category="sidebar">付録D: docker_compose.yml</block>
  <block id="46aa0a2ad138d7cd72baea1b2f96553c" category="sidebar">AI統合インフラストラクチャ</block>
  <block id="503011292be147bd4172e92de477a75e" category="sidebar">NVA-1173 NetApp AIPodとNVIDIA DGX システム</block>
  <block id="34df2039718349f1b8c838bff98ae8fa" category="sidebar">ハードウェア コンポーネント</block>
  <block id="7d19d593db0bb056876a9535cbced90a" category="sidebar">ソフトウェアコンポーネント</block>
  <block id="aee745c6de04f3d08c0e628809cab1e7" category="sidebar">展開例の詳細</block>
  <block id="56d2d7506e6dac3733b0a45a9eaf441d" category="sidebar">検証とサイジングのガイダンス</block>
  <block id="db182982505626c6e79adca149851ca6" category="sidebar">結論と追加情報</block>
  <block id="013e704990294f0b327123a61911f4cc" category="sidebar">NVIDIA DGX SuperPODとNetApp EFシリーズ</block>
  <block id="944c042dcc47f293062f941954082ceb" category="sidebar">Eシリーズストレージを搭載したNetApp上のBeeGFS</block>
  <block id="9af29e4b3d0045c948a7dd30b1c7f8ae" category="sidebar">EシリーズストレージでIBM Spectrum Scaleを導入</block>
  <block id="79bca636cb614580cfd2da67b668570e" category="sidebar">AI向けONTAPとLenovo ThinkSystem</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI向けNetApp ONTAPとLenovo ThinkSystem SR670</block>
  <block id="b669bc138f2f455218d4dce65e4693b4" category="sidebar">AIのユースケース</block>
  <block id="adb8741d27ea996906508affc4dfbc75" category="sidebar">RAG推論のためのNetApp AIPod Mini</block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">責任あるAIと機密推論 - NetApp AIとProtopia Image Transformation</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">ビッグデータ環境からAI環境へのデータの移行</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">エッジAI推論 - NetAppとLenovo ThinkSystem - ソリューション設計</block>
  <block id="df901f2197cd86d62a25f2f43e523352" category="sidebar">Quantum StorNextとNetApp Eシリーズシステムの設計ガイド</block>
  <block id="e313734313e7ef573613df8b6edae0af" category="sidebar">Quantum StorNextとNetApp Eシリーズシステムの導入ガイド</block>
  <block id="78daadab78234c06769e4f331411d302" category="sidebar">最新のデータ分析</block>
  <block id="a5428e6b4b42638886ab5870a883efb9" category="sidebar">NFS から Kafka へのワークロードにおける愚かな名前変更問題に対するNetAppソリューション</block>
  <block id="d7fd58c27a131209e8f320d109b293cc" category="sidebar">AWS のパフォーマンス概要と検証 - Cloud Volume ONTAP</block>
  <block id="076002e1839cd6d440e56b26850e1223" category="sidebar">AWS でのパフォーマンスの概要と検証 - FSx for NetApp ONTAP</block>
  <block id="0d7c7eeec9388fceaff3d06e03b45fe9" category="sidebar">AFFオンプレミスのパフォーマンス概要と検証</block>
  <block id="2835924be4bc657cfe3a5bd988b96845" category="sidebar">Confluent のパフォーマンス検証</block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">ユースケースの概要</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFSからNFSへ - 詳細な手順</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">合流型自己再バランスクラスター</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetAppハイブリッド クラウド データ ソリューション - 顧客のユースケースに基づいた Spark と Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">ユースケース1 - Hadoopデータのバックアップ</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">ユースケース 2 - クラウドからオンプレミスへのバックアップと災害復旧</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">ユースケース3 - 既存のHadoopデータでDevTestを有効にする</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">ユースケース4 - データ保護とマルチクラウド接続</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">ユースケース5 - 分析ワークロードの高速化</block>
  <block id="2c1c3f6b0e9a17650f389f1aab405e8a" category="sidebar">NetAppとDremioの次世代ハイブリッドアイスバーグレイクハウスソリューション</block>
  <block id="1256c51dea275f8f002d62c89274c4dc" category="sidebar">顧客の使用事例</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">さまざまな分析戦略のためのさまざまなソリューション ソリューション概要</block>
  <block id="2b95dd053e967c99de1428e8953dd453" category="sidebar">Splunk SmartStore 向けStorageGRID機能</block>
  <block id="42c2f45afefbd5150f5aa52986b2a3cc" category="sidebar">階層化とコスト削減</block>
  <block id="039a70e0c8e34414c8b3f34333f95ca8" category="sidebar">単一サイトのSmartStoreパフォーマンス</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">NetAppストレージ ソリューションを使用した Apache Spark ワークロード (導入ガイド)</block>
  <block id="74916818f2584b32e727fdc509b2f992" category="cell">P4X-GNR6980P-SRPL2-UCC</block>
  <block id="abaa679b5e80256d8e1d4fd65296a270" category="cell">インテル Xeon 6980P 2P 128C 2G 504M 500W SGX512</block>
  <block id="22f22b60e3e496fa07e67cfbf53cb70e" category="cell">RPL-E 6369P IP 8C/16T 3.3G 24MB 95W 1700 BO</block>
  <block id="fe1394c0024b947430d8383108eb2177" category="summary">NVIDIA DGX SuperPODとNetApp AFF A90</block>
  <block id="bf8899c5267692573fb1304655fb765a" category="doc">NVIDIA DGX SuperPOD搭載NetApp AFF A90ストレージ システム</block>
  <block id="7fa0ca2a0d7f53f3c8e59fc6c3e9ed2e" category="section-title">NVAの展開</block>
  <block id="8be806d9daf2bc32156e83bc0d005ec1" category="paragraph">NVIDIA DGX SuperPODとNetApp AFF A90ストレージ システムを組み合わせることで、 NVIDIA DGX システムの世界クラスのコンピューティング パフォーマンスとNetAppクラウド接続ストレージ システムを組み合わせ、機械学習 (ML)、人工知能 (AI)、高性能技術コンピューティング (HPC) 向けのデータ駆動型ワークフローが可能になります。このドキュメントでは、AFF A90ストレージ システムを DGX SuperPOD アーキテクチャに統合するための構成と展開の詳細について説明します。</block>
  <block id="9b418007fd18dc2176e46adcd30db45f" category="inline-image-macro">nvidiaロゴ</block>
  <block id="c94ba3511d0db1d6babbf53090c19530" category="paragraph"><block ref="c94ba3511d0db1d6babbf53090c19530" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6091ca16495cdce90805252a1c12f4e6" category="section-title">プログラム概要</block>
  <block id="c6f9b4ccfaf7da44e6c0c60854f0949d" category="paragraph">NVIDIA DGX SuperPOD™ は、組織向けのターンキー AI データ センター ソリューションを提供し、世界クラスのコンピューティング、ソフトウェア ツール、専門知識、継続的なイノベーションをシームレスに提供します。 DGX SuperPOD は、最小限のセットアップ時間と最大限の生産性で AI/ML および HPC ワークロードを展開するために必要なすべてを提供します。図 1 は、DGX SuperPOD の高レベル コンポーネントを示しています。</block>
  <block id="d144add61531a9bfe79e667824356b40" category="paragraph">図 1) NVIDIA DGX SuperPODとNetApp AFF A90ストレージ システム。</block>
  <block id="bbd4822469057d9beafe8509a7ebee14" category="paragraph"><block ref="bbd4822469057d9beafe8509a7ebee14" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283d31c0198ed7454a249b3e2b6eb174" category="paragraph">DGX SuperPOD には次のような利点があります。</block>
  <block id="3ff8aa027f2fe1f296899270ebbb43fd" category="list-text">AI/MLおよびHPCワークロードで実証済みのパフォーマンス</block>
  <block id="ca127ea10cbbac4cda1fefa3e946e9ba" category="list-text">インフラストラクチャの管理と監視から、事前に構築されたディープラーニング モデルとツールまで、統合されたハードウェアとソフトウェアのスタック。</block>
  <block id="a4cb23a9ac5d711552fe29021242bf26" category="list-text">インストールとインフラストラクチャ管理からワークロードのスケーリング、運用 AI の合理化まで、専用のサービスを提供します。</block>
  <block id="96cffe8fd08355ee862ba83cb15407d9" category="paragraph">組織が人工知能 (AI) と機械学習 (ML) の取り組みを採用するにつれて、堅牢でスケーラブルかつ効率的なインフラストラクチャ ソリューションに対する需要はかつてないほど高まっています。こうした取り組みの中心にあるのは、データのセキュリティ、アクセシビリティ、リソースの最適化を確保しながら、ますます複雑化する AI モデルを管理およびトレーニングするという課題です。 </block>
  <block id="61b865c697c4f21886d14a618df70f6d" category="paragraph">このソリューションには、次の主な利点があります。</block>
  <block id="aa88ccfa825dadd9cbb9acc84e508b2c" category="list-text">*スケーラビリティ*</block>
  <block id="4738ea23a01f5635ce1c45dabb47da5c" category="list-text">*データ管理とアクセス*</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="list-text">*安全*</block>
  <block id="3c858853158f1a99c39a781718ec762c" category="inline-link">NVA-1175 設計ガイド</block>
  <block id="bc3456dcc61fc69ddf5057eb2521a503" category="inline-link">+++ NVIDIA DGX SuperPODリファレンス アーキテクチャ+++</block>
  <block id="0db7341d4a6ac5f5ae439217ea22f2cf" category="paragraph">NVIDIA DGX SuperPOD には、要求の厳しい AI ワークロードに実証済みのパフォーマンスを提供するために必要なサーバー、ネットワーク、ストレージが含まれています。  NVIDIA DGX™ H200 および B200 システムは世界クラスのコンピューティング能力を提供し、 NVIDIA Quantum InfiniBand および Spectrum™ Ethernet ネットワーク スイッチは超低遅延と業界をリードするネットワーク パフォーマンスを提供します。 NetApp ONTAPストレージの業界をリードするデータ管理およびパフォーマンス機能が追加されたことで、顧客は AI/ML イニシアチブをより迅速に、そしてデータ移行と管理オーバーヘッドを削減して実現できるようになります。このソリューションの特定のコンポーネントの詳細については、<block ref="a5c1176c129a896b2b922e5580efc58f" category="inline-link-rx"></block>そして<block ref="1910ffa640b224c818fe3ba99c94129a" category="inline-link-rx"></block>ドキュメント。</block>
  <block id="c18232c17d0f8ffeae2d726834c91f89" category="paragraph">NVIDIA DGX SuperPOD は、最も要求の厳しいワークロードのパフォーマンスとスケールの要件を満たすように設計されています。</block>
  <block id="36ff5f6df178e197d3123e478db8410b" category="list-text">従来の分析ツールを使用した大規模な機械学習。</block>
  <block id="2d12f254287ce40df1f66968734498ba" category="list-text">大規模言語モデル、コンピューター ビジョン/画像分類、不正検出、その他無数のユース ケース向けの人工知能モデル トレーニング。</block>
  <block id="d8f31668d0cecb0b54a6d01e2f76c6cf" category="list-text">地震解析、数値流体力学、大規模可視化などの高性能コンピューティング。</block>
  <block id="f0414b39a05dd4079562350e267bf1b3" category="inline-link">+++ NVIDIA DGX SuperPODリファレンス アーキテクチャ+++</block>
  <block id="5f5d88c3d3b4a5616e3937b4fe349866" category="paragraph">DGX SuperPOD は、必要な接続性とパフォーマンスを提供し、インフラストラクチャのボトルネックを解消するために必要なすべてのコンポーネントを含むスケーラブル ユニット (SU) の概念に基づいています。お客様は 1 つまたは複数の SU から開始し、要件を満たすために必要に応じて SU を追加できます。詳細については、<block ref="b3bda9bcc3402290297547b224b66efa" category="inline-link-rx"></block> 。このドキュメントでは、単一の SU のストレージ コンポーネントと構成について説明します。</block>
  <block id="353fc344c9bee691edbf50c13067653c" category="paragraph">表 1 に、1SU のストレージ コンポーネントを実装するために必要なハードウェア コンポーネントを示します。  1 ～ 4 個のスケーラブル ユニットの具体的な部品と数量については、付録 A を参照してください。</block>
  <block id="6cef63cf1d59b401d88755cbea01a416" category="paragraph">表 1) ハードウェア要件。</block>
  <block id="46f0306a597ab13c222e7d6551ce9f96" category="cell">NetApp AFF A90ストレージシステム</block>
  <block id="c28cb49992003622546cc5f9509cfcff" category="cell">NetAppストレージ クラスタ相互接続スイッチ</block>
  <block id="9097f0013a59ba655e2c83bd26ae1ce7" category="cell">NVIDIA 800GB -&gt; 4x 200Gb スプリッターケーブル</block>
  <block id="aec453803363ab0e5ca6f6df8d465def" category="inline-link">+++DGX SuperPOD リリースノート+++</block>
  <block id="b6ffed0f516d3b52a4910321a2a889ba" category="paragraph">表 2 に、AFF A90ストレージ システムを DGX SuperPOD と統合するために必要な最小限のソフトウェア コンポーネントとバージョンを示します。 DGX SuperPOD には、ここに記載されていない他のソフトウェア コンポーネントも含まれます。詳細は<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block>詳細についてはこちらをご覧ください。</block>
  <block id="c50cf4cacfaa91c82ab6a24e939cbaca" category="paragraph">表 2) ソフトウェア要件。</block>
  <block id="518f98e82df6bde3bef11b7aa885a289" category="cell">9.16.1以上</block>
  <block id="df6c5bc905afa2504396faf036b87927" category="cell">NVIDIAベースコマンド マネージャー</block>
  <block id="6fe49606da6092b118e02ef2d0ef0d6c" category="cell">10.24.11以上</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX OS</block>
  <block id="ba2b41c4ccfe23325bd590218a62fa8a" category="cell">6.3.1以上</block>
  <block id="be49cc02b8372e6202cf52fbe8204ead" category="cell">NVIDIA OFED ドライバー</block>
  <block id="cf439b0da4b623c11f90db3c956758b1" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS 以上</block>
  <block id="c220bcc9beaaaf29d1905f9819577f0b" category="cell">NVIDIA Cumulus OS</block>
  <block id="f7bfb037c565dcf0f80631851ee87307" category="cell">5.10以上</block>
  <block id="ea1eee49815915fc6500c0bfc1fcef31" category="paragraph">NetApp ONTAPストレージを DGX SuperPOD と統合するには、次のタスクが必要です。</block>
  <block id="dc8a828d28f4f811808cdb82b54453ec" category="list-text">RoCE 搭載NetApp AFF A90ストレージ システムのネットワーク構成</block>
  <block id="37c6bfb67043d31447903c4665d6ed11" category="list-text">ストレージシステムのインストールと構成</block>
  <block id="4cafd7b33984b4cb34f95fe4314e4a49" category="list-text">NVIDIA Base Command™ Manager を使用した DGX クライアント構成</block>
  <block id="b8088d3f2b3972d6f986cf0a37543617" category="section-title">サイトの準備と基本的なインストール</block>
  <block id="bf0615788eed920e4e9f1a96749cfb34" category="inline-link">+++ AFF A90ハードウェアインストールドキュメント+++</block>
  <block id="e1006e935ca66a5f59a3fd40689fff46" category="paragraph">AFF A90ストレージ クラスターのサイト準備と基本インストールは、標準導入サービスの一部として、すべての DGX SuperPOD 導入に対してNetAppプロフェッショナル サービスによって実行されます。 NetApp PS は、設置場所の条件が設置に適していることを確認し、指定されたラックにハードウェアを設置します。また、顧客から提供されたネットワーク情報を使用して、OOB ネットワーク接続を接続し、基本的なクラスターのセットアップを完了します。付録 A – 部品表とラックの立面図には、参考用の標準的なラックの立面図が含まれています。  A90のインストールの詳細については、<block ref="7ddd605a062e7b77012eccf1c4bcffd7" category="inline-link-rx"></block> 。</block>
  <block id="321c92980ad0e1d922d02a2f704ca782" category="paragraph">標準的な導入が完了すると、 NetApp PS は、クライアント接続とチューニングのための Base Command Manager との統合を含む、以下の手順を使用してストレージ ソリューションの高度な構成を完了します。</block>
  <block id="00720789d4f50564af280240dfe0c1a0" category="section-title">ストレージシステムをDGX SuperPODストレージファブリックに接続する</block>
  <block id="93f38c7fefe0798b27b29ac2727c9aff" category="paragraph">AFF A90ストレージ システムは、コントローラごとに 4 つの 200 Gb イーサネット ポートを使用してストレージ ファブリック リーフ スイッチに接続され、各スイッチに 2 つの接続があります。 NVIDIA Spectrum SN5600 スイッチの 800Gb スイッチ ポートは、付録 A に記載されている適切な DAC または光スプリッタ構成を使用して、4 つの 200Gb ポートに分割されます。各スイッチ ポートの個々のポートは、単一障害点を排除するためにストレージ コントローラ全体に分散されます。下の図 2 は、ストレージ ファブリック接続のケーブル配線を示しています。</block>
  <block id="428c881d379aed620164886a529bf2ac" category="paragraph">図 2) ストレージ ネットワークのケーブル配線。</block>
  <block id="e97080670de5db4003a6abdd37d81eb5" category="paragraph"><block ref="e97080670de5db4003a6abdd37d81eb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb83bbea93dbe46008125af94bc508be" category="section-title">ストレージシステムをDGX SuperPODインバンドネットワークに接続する</block>
  <block id="3c4e3bd6ddc8a3cd692e2866674ec982" category="paragraph">NetApp ONTAPには業界をリードするマルチテナント機能が搭載されており、DGX SuperPOD アーキテクチャの高性能ストレージ システムとして動作するだけでなく、ホーム ディレクトリ、グループ ファイル共有、Base Command Manager クラスタ アーティファクトもサポートできます。インバンド ネットワークで使用するために、各AFF A90コントローラは、コントローラごとに 1 つの 200 Gb Ethernet 接続を使用してインバンド ネットワーク スイッチに接続され、ポートは LACP MLAG 構成で構成されます。下の図 3 は、ストレージ システムとインバンド ネットワークおよび OOB ネットワークとのケーブル接続を示しています。</block>
  <block id="651c2d0bd757128b4d9ed91fc5026a3d" category="paragraph">図 3) インバンドおよび OOB ネットワーク ケーブル配線。</block>
  <block id="92bf4c084f930281026def79beae3794" category="paragraph"><block ref="92bf4c084f930281026def79beae3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76edc3dadc8deca645fd525182eaad33" category="section-title">DGX SuperPOD 用にONTAPを構成する</block>
  <block id="41905234b7d34b88a1559733c741d5aa" category="inline-link">+++ ONTAPドキュメント+++</block>
  <block id="d4b2d66f490475665ea833d8f89c2cfd" category="paragraph">このソリューションは、複数のストレージ仮想マシン (SVM) を活用して、高パフォーマンスのストレージ アクセスと、管理 SVM 上のユーザー ホーム ディレクトリおよびその他のクラスター アーティファクトの両方のボリュームをホストします。各 SVM は、ストレージまたはインバンド ネットワーク上のネットワーク インターフェイスと、データ ストレージ用のFlexGroupボリュームで構成されます。データ SVM のパフォーマンスを確保するために、ストレージ QoS ポリシーが実装されています。  FlexGroup、Storage Virtual Machines、 ONTAP QoS機能の詳細については、<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> 。</block>
  <block id="fec48034cdf04f518f58b4f727f55543" category="section-title">ベースストレージを構成する</block>
  <block id="7e4b30d10f60fcb3bdf4c3382d601615" category="section-title">各コントローラに単一のアグリゲートを構成する</block>
  <block id="3c6858e020c27b4eb574d124f73c04d3" category="paragraph">クラスター内の各ノードに対して上記の手順を繰り返します。</block>
  <block id="241ba9d616774bbadf9c9f28ee386505" category="section-title">インバンドネットワークの各コントローラでifgrpsを構成する</block>
  <block id="610c7975125c56dc62b000999926f4d8" category="section-title">RoCE 用の物理ポートを構成する</block>
  <block id="ff00a412cfca01b43041104775ac8460" category="paragraph">NFS over RDMA を有効にするには、ネットワーク トラフィックがクライアントとサーバーの両方で適切にタグ付けされ、RDMA over Converged Ethernet (RoCE) を使用してネットワークによって適切に処理されるように構成する必要があります。これには、優先フロー制御 (PFC) の構成と、使用する PFC CoS キューの構成が含まれます。  NetApp ONTAP は、以下のコマンドが実行されると、ネットワーク QoS 構成に合わせて DSCP コード 26 も自動的に構成します。</block>
  <block id="e9dc479a2f60169b39fb74cc86d13a43" category="section-title">管理SVMの作成</block>
  <block id="ce25292d4b04b878f74951ed7b5fb173" category="section-title">管理SVMの作成と構成</block>
  <block id="c110d2ffde8993db523c41f0c524e68e" category="section-title">管理SVMでNFSサービスを構成する</block>
  <block id="5441effcbbef51defcc1340e745e28ad" category="section-title">インバンドネットワークインターフェースのIPサブネットを作成する</block>
  <block id="919d6feabfd1e5f5f04bedfd487f50c8" category="paragraph">*注:* 既存の顧客ネットワークに統合するために、展開時に顧客が提供する IP サブネット情報。</block>
  <block id="2bc9e41900e064c3368d9eca2dba546c" category="section-title">各ノードにIn-Band SVM用のネットワークインターフェースを作成する</block>
  <block id="44db41cf8b74978388680587aa8b7d55" category="section-title">管理SVM用のFlexGroupボリュームを作成する</block>
  <block id="20d5f1ad8803160edb381217d776701e" category="section-title">管理SVMのエクスポートポリシーを作成する</block>
  <block id="1624c693fdd8f06e52c87d0b2b576a19" category="section-title">データSVMの作成</block>
  <block id="9ff068915b90e059d15444fe8dc13aaa" category="section-title">データSVMの作成と構成</block>
  <block id="cb7d25e4139e72b33ef687ed8a0ae945" category="section-title">RDMA を有効にしたデータ SVM で NFS サービスを構成する</block>
  <block id="ca1f913932acc2aad423357d56f86ea7" category="section-title">データ SVM ネットワーク インターフェースの IP サブネットを作成する</block>
  <block id="3c2060cdeb230d3f42a725b2a9ca7e23" category="section-title">各ノードにデータSVM用のネットワークインターフェースを作成する</block>
  <block id="ca648b8fb4bf1f54cbf7a626468eada3" category="section-title">RDMA用のデータSVMネットワークインターフェースを構成する</block>
  <block id="afb51d28a404c42df2a054df2c6da14b" category="section-title">データSVMにエクスポートポリシーを作成する</block>
  <block id="d9a6b253dd081b231d9d1a14cec7a227" category="section-title">データSVMに静的ルートを作成する</block>
  <block id="4f3e59209435398e52c0df85d0034275" category="section-title">データSVM用のGDDを使用してFlexGroupボリュームを作成する</block>
  <block id="08ec3810f1dcb452442911f8d8173b1a" category="paragraph">GDD (Granular Data Distribution) により、大規模なデータ ファイルを複数のFlexGroup構成ボリュームとコントローラに分散して、単一ファイルのワークロードのパフォーマンスを最大限に高めることができます。  NetApp、すべての DGX SuperPOD 展開のデータ ボリュームで GDD を有効にすることを推奨しています。</block>
  <block id="7eb2bd842a06eb48d9bbfe4f644731d9" category="section-title">プライマリデータボリュームのストレージ効率を無効にする</block>
  <block id="8a0cdebf4e36c1af6ac542485413a77b" category="paragraph">ボリューム効率オフ -vserver spod_data -volume spod_data</block>
  <block id="46e5a2d41b69706b3dcd5e89c34e7c5e" category="section-title">データSVMのQoS最小ポリシーを作成する</block>
  <block id="065d35d3d9a4319f54773a754b2c0e6c" category="section-title">データSVMにQoSポリシーを適用する</block>
  <block id="2cc5056a61a5f1643bf387d49d197728" category="section-title">NVIDIA Base Command Manager を使用した DGX サーバーの構成</block>
  <block id="e546e9d0da56999b5973de8a7ad71572" category="paragraph">DGX クライアントがAFF A90ストレージ システムを使用できるように準備するには、次のタスクを実行します。このプロセスでは、ストレージ ファブリックのネットワーク インターフェイスと静的ルートが DGX システム ノードですでに構成されていることを前提としています。次のタスクは、高度な構成プロセスの一環としてNetAppプロフェッショナル サービスによって完了されます。</block>
  <block id="f9a9381a56f728d139ee191de307ef5f" category="section-title">必要なカーネルパラメータとその他の設定を使用して DGX サーバーイメージを構成する</block>
  <block id="256b6f56d994f129832d2b7567bb951f" category="paragraph">NetApp ONTAP は業界標準の NFS プロトコルを使用するため、DGX システムに追加のソフトウェアをインストールする必要はありません。クライアント システムから最適なパフォーマンスを引き出すには、DGX システム イメージにいくつかの変更を加える必要があります。以下の手順は両方とも、以下のコマンドを使用して BCM イメージ chroot モードに入った後に実行されます。</block>
  <block id="45fb2f19f77fc1d9d4dfdd092f805b42" category="section-title">/etc/sysctl.conf でシステム仮想メモリ設定を構成する</block>
  <block id="13b4c0be439ee4875352c0ff2a039c13" category="paragraph">デフォルトの Linux システム構成では、必ずしも最適なパフォーマンスを実現しない仮想メモリ設定が提供されます。 2TB RAM を搭載した DGX B200 システムの場合、デフォルト設定では 40GB のバッファ スペースが使用可能ですが、これにより一貫性のない I/O パターンが生成され、バッファをフラッシュするときにクライアントがストレージ システムに過負荷をかける可能性があります。以下の設定は、クライアント バッファ領域を 5 GB に制限し、フラッシュをより頻繁に強制して、ストレージ システムに過負荷をかけない一貫した I/O ストリームを作成します。</block>
  <block id="c35419f49457a55135a16f4a73d4fb6b" category="paragraph">イメージ chroot モードに入った後、/etc/sysctl.s/90-cm-sysctl.conf ファイルを編集し、次の行を追加します。</block>
  <block id="4caebde52be0001b1e59098dd149b653" category="paragraph">/etc/sysctl.conf ファイルを保存して閉じます。</block>
  <block id="d05565dbb5b9175c4df06e8d9d029a18" category="section-title">再起動後に実行されるスクリプトを使用して他のシステム設定を構成する</block>
  <block id="4e1ff13d493c47a47dde7cb5a24aceeb" category="paragraph">一部の設定は、実行するために OS が完全にオンラインである必要があり、再起動後は保持されません。  Base Command Manager 環境でこれらの設定を実行するには、ファイル /root/ntap_dgx_config.sh を作成し、次の行を入力します。</block>
  <block id="191be9d79602632b279bc3126e49847d" category="paragraph">*ファイルを保存して閉じます。ファイルの権限を変更して実行可能にします:*</block>
  <block id="13036c88d00af2d37c1d8e1ae332f79e" category="paragraph">次の行を編集して、起動時に root によって実行される cron ジョブを作成します。</block>
  <block id="a4d911dee959cadc8c53c92d6361fc05" category="paragraph">以下の crontab ファイルの例を参照してください。</block>
  <block id="e813523727c040149e1ecad0358d60b8" category="paragraph">exit または Ctrl-D を入力して、BCM イメージの chroot モードを終了します。</block>
  <block id="70f4c658a41ea1900dd94027c0ffa103" category="section-title">クライアントマウントポイントのBaseCommand Manager DGXカテゴリを構成する</block>
  <block id="9df3dcf41d131b1d0097435f6b290ba4" category="paragraph">DGX クライアントがAFF A90ストレージ システムをマウントするように構成するには、DGX システムで使用される BCM クライアント カテゴリを変更して、関連する情報とオプションを含める必要があります。以下の手順では、NFS マウント ポイントを構成する方法について説明します。</block>
  <block id="dcde3a7bf8f0a03f480df9078bfa9297" category="paragraph">NetApp * AFF A90ストレージ システム* を搭載したNVIDIA DGX SuperPOD は、 AI インフラストラクチャ ソリューションの大きな進歩を表しています。セキュリティ、データ管理、リソース利用、スケーラビリティに関する主要な課題に対処することで、組織は運用効率、データ保護、コラボレーションを維持しながら AI イニシアチブを加速できます。このソリューションの統合アプローチにより、AI 開発パイプラインの一般的なボトルネックが解消され、データ サイエンティストやエンジニアはインフラストラクチャ管理ではなくイノベーションに集中できるようになります。</block>
  <block id="77b69988a6b247bd3829a8e03ff332a6" category="inline-link">NVA-1175 NVIDIA DGX SuperPODとNetApp AFF A90ストレージ システムの設計ガイド</block>
  <block id="78200c657113173ee4bd06de792e86af" category="list-text"><block ref="78200c657113173ee4bd06de792e86af" category="inline-link-rx"></block></block>
  <block id="4b70410b9d727a1fc1d60d4483d86325" category="inline-link">NVIDIA DGX B200 SuperPOD リファレンス アーキテクチャ</block>
  <block id="54dbc563049b479cfef99d1d872020e4" category="list-text"><block ref="54dbc563049b479cfef99d1d872020e4" category="inline-link-rx"></block></block>
  <block id="d5023dae85155f754c6bfd520cbdc150" category="inline-link">+++ NVIDIA DGX H200 SuperPOD リファレンス アーキテクチャ+++</block>
  <block id="5d4678ba7793147c6b3109fcdbe3294f" category="list-text"><block ref="5d4678ba7793147c6b3109fcdbe3294f" category="inline-link-rx"></block></block>
  <block id="0018465bd63e2711758aea9e68126f6d" category="inline-link">+++ NVIDIA BaseCommand ソフトウェア+++</block>
  <block id="dd2a70a6cd8d74ddbed24590bf9efd37" category="list-text"><block ref="dd2a70a6cd8d74ddbed24590bf9efd37" category="inline-link-rx"></block></block>
  <block id="a2433670a2f11bda41782875f82e4c0e" category="inline-link">+++ NVIDIA Spectrum SN5600 イーサネットスイッチ+++</block>
  <block id="197d7b18bb595fa0c4339f599bb57c70" category="list-text"><block ref="197d7b18bb595fa0c4339f599bb57c70" category="inline-link-rx"></block></block>
  <block id="61345f1959bf0e90ce956f7fe87b97e6" category="inline-link">+++ NVIDIA DGX SuperPODリリースノート+++</block>
  <block id="a42d326cc55152a32997b9b244e9e4ea" category="list-text"><block ref="a42d326cc55152a32997b9b244e9e4ea" category="inline-link-rx"></block></block>
  <block id="18b5a5e73e5f66fb20d8f46f70d0c0ba" category="inline-link">+++ NetApp AFF A90 のインストール+++</block>
  <block id="cc99b2a6b638db71f55772efa9ae5a44" category="list-text"><block ref="cc99b2a6b638db71f55772efa9ae5a44" category="inline-link-rx"></block></block>
  <block id="326b3ec244c0b719f75faee5d63eda19" category="inline-link">+++ NetApp AIソリューションのドキュメント+++</block>
  <block id="2a6b527a76b4dd02f63188fa855840f7" category="list-text"><block ref="2a6b527a76b4dd02f63188fa855840f7" category="inline-link-rx"></block></block>
  <block id="7d3cb5a08ca45610a4bc66221efd1e06" category="inline-link">+++ NetApp ONTAPソフトウェア+++</block>
  <block id="7de45c9a3f46892f98b68ddb83483727" category="list-text"><block ref="7de45c9a3f46892f98b68ddb83483727" category="inline-link-rx"></block></block>
  <block id="b20609bf792bc04f91d5af3f95c34249" category="inline-link">+++ NetApp AFFストレージシステムのインストールと保守+++</block>
  <block id="f4f8a0ca5a3908b7ff3dc9977384172c" category="list-text"><block ref="f4f8a0ca5a3908b7ff3dc9977384172c" category="inline-link-rx"></block></block>
  <block id="784cd7f14efdcfe6b12e47d3ac14c2ea" category="list-text"><block ref="784cd7f14efdcfe6b12e47d3ac14c2ea" category="inline-link-rx"></block></block>
  <block id="2af6b6d1a0f9284afbd220786019c104" category="inline-link">+++pNFSとは+++</block>
  <block id="40b22abaae26a9e924653fdf64192dd5" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(pNFS に関する優れた情報が記載された古いドキュメント)</block>
  <block id="8b609f2b56884902c05d97d442f1d533" category="section-title">付録A: 部品表とラックの立面図</block>
  <block id="97ac09ecf630c90bdc4eae789d1cb26e" category="paragraph">表 3 には、1 台、2 台、3 台、および 4 台のスケーラブル ユニットのストレージを展開するために必要なNetAppコンポーネントの部品番号と数量を示します。</block>
  <block id="a399f4735d9b76eb2c734ce8b23a4051" category="paragraph">表 3) 1、2、3、および 4 SU のNetApp BOM。</block>
  <block id="12671d03ae10ac5096ddbf709e44e260" category="cell">パーツ番号</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">項目</block>
  <block id="4b35db9f95e91ac3ce4b119c8d590dc3" category="cell">1SUあたりの数量</block>
  <block id="10ae8487d40b09fd13a32fd5b761dff2" category="cell">2SUの数量</block>
  <block id="4f4a383868a5c8f1aff4d21e301cf77d" category="cell">3SUの数量</block>
  <block id="7e3f2097d4da066bf518435f0d22d629" category="cell">4SUの数量</block>
  <block id="a9eadd771f7974cbfb4a0f82da15155e" category="cell">AFF-A90A-100-C</block>
  <block id="a5b8692ce33078554d4df65b88479996" category="cell">AFF A90ストレージシステム</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="109799441719d48125200028617a078c" category="cell">X4025A-2-AC</block>
  <block id="ae1ffcee034fa197d7e6a3d49392ad1b" category="cell">2x7.6TBドライブパック</block>
  <block id="0a09c8844ba8f0936c20bd791130d6b6" category="cell">144</block>
  <block id="58a2fc6ed39fd083f55d4182bf88826d" category="cell">192</block>
  <block id="01fc28c75297fac48aca3e18491846a8" category="cell">X50131A-C</block>
  <block id="ef52c5c3e61828c1957bb235e48b9aaf" category="cell">IOモジュール、2PT、100/200/400GbE</block>
  <block id="76dc611d6ebaafc66cc0879c71b5db5c" category="cell">128</block>
  <block id="da07ac8264b7cdb99a4eb96ab4d91111" category="cell">X50130A-C</block>
  <block id="02104e3c4b3f8d428381d1c68b10320d" category="cell">IO モジュール、2PT、100GbE</block>
  <block id="90d67d58a9628ba253eee43c6dbc9559" category="cell">X-02659-00</block>
  <block id="eaba4c24f91259319d86e2dc6a375c2c" category="cell">キット、4ポスト、角穴または丸穴、24インチ～32インチレール</block>
  <block id="a08f2932fed05b33c4945eca514134dc" category="cell">X1558A-R6</block>
  <block id="3229af69927999e5df543d1f9fb22eb5" category="cell">電源コード、キャビネット内、48インチ、+ C13-C14、10A/250V</block>
  <block id="98f13708210194c475687be6106a3b84" category="cell">20</block>
  <block id="d645920e395fedad7bbbed0eca3fe2e0" category="cell">40</block>
  <block id="f033ab37c30201f73f142449d037028d" category="cell">80</block>
  <block id="e6aa165cded1f8e32159470ff027af2f" category="cell">X190200-CS</block>
  <block id="7e011d9eef19544d7078d2a70563144a" category="cell">クラスタスイッチ、N9336C 36Pt PTSX10/25/40/100G</block>
  <block id="76dedba1bf45af402ab07ddd57ff749e" category="cell">X66211A-2</block>
  <block id="2a1aeb324c9e886af32f12ad5049c6f7" category="cell">ケーブル、100GbE、QSFP28-QSFP28、Cu、2m</block>
  <block id="e2fd227baa44b6632aa7c2fef9002b8a" category="cell">X66211A-05</block>
  <block id="0dff9249f8d94512b43527f1f5b044c9" category="cell">ケーブル、100GbE、QSFP28-QSFP28、Cu、0.5m</block>
  <block id="6e421f2c1b8bf174d208a91d7f5dc0ae" category="cell">X6561-R6</block>
  <block id="95c7e45248e11b15430ec3c5d1d3dcc1" category="cell">ケーブル、イーサネット、CAT6、RJ45、5m</block>
  <block id="e369853df766fa44e1ed0ff613f563bd" category="cell">34</block>
  <block id="3295c76acbf4caaed33c36b1b5fc2cb1" category="cell">66</block>
  <block id="2a108c75662ccb5a38e6db46a016aa40" category="paragraph">表 4 は、AFF A90ストレージ システムを高性能ストレージおよびインバンド ネットワーク内の SN5600 スイッチに接続するために必要なNVIDIAケーブルの部品番号と数量を示しています。</block>
  <block id="c71399ea2a367ce779897d49ca77b4a0" category="paragraph">表 4) AFF A90ストレージ システムを高性能ストレージおよびインバンド ネットワーク内の SN5600 スイッチに接続するために必要なNVIDIAケーブル。</block>
  <block id="5557f1218ab08d91639048aab26f1de0" category="cell">MCP7Y40-N003</block>
  <block id="2b11e18cd1f4ae786c28a6a1bce455ed" category="cell">DAC 3m 26ga 2x400G ～ 4x200G OSFP ～ 4xQSFP112</block>
  <block id="19ca14e7ea6328a42e0eb13d585e4c22" category="cell">36</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="cell">または</block>
  <block id="84686a1d557f4fefd53eaff2d691796d" category="cell">MMS4X00-NS</block>
  <block id="e67c53a2100e086542158b7496d248a7" category="cell">ツインポート OSFP 2x400G 2xSR4 マルチモードトランシーバ デュアル MPO-12/APC</block>
  <block id="bbf6b7b52739d4479aae0bd6508ac746" category="cell">MFP7E20-N0XX</block>
  <block id="718b622b69fc995a4d3738ecaf2953b0" category="cell">マルチモードファイバースプリッター 400G-&gt; 2x200G XX = 03、05、07、10、15、20、30、40、50)メートル</block>
  <block id="7b55b9077a4e94ce71aba3fbb4b1ebcd" category="cell">MMA1Z00-NS400</block>
  <block id="1d1c4e0c3b72af208b18fbbfbf63c17b" category="cell">シングルポート 400G SR4 マルチモード QSFP112 トランシーバー シングル MPO-12/APC</block>
  <block id="098103233c14421a2092214651f99ac3" category="section-title">ラックの高さ</block>
  <block id="64441b5a3bcfb8a874107dfe4766feb6" category="paragraph">図 4 ～ 6 は、1 ～ 4 SU のラックの立面図の例を示しています。</block>
  <block id="c22e6da1b1ce3c83fb3004d53e804737" category="paragraph">図 4) 1 SU および 2 SU のラックの立面図。</block>
  <block id="7ef24ed03ec40ae9ef02f5c904953418" category="paragraph"><block ref="7ef24ed03ec40ae9ef02f5c904953418" category="inline-image-macro-rx" type="image"></block></block>
  <block id="64769808ba101c666bcd29615cc1e9d3" category="paragraph">図 5) 3 SU のラックの立面図。</block>
  <block id="02a5df2de00e7145cadd3753d42d3dc1" category="paragraph"><block ref="02a5df2de00e7145cadd3753d42d3dc1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d7011e8983f361d68e382e119c1819" category="paragraph">図 6) 4 SU のラックの立面図。</block>
  <block id="381008e8bad1425034ca5fa30cd57133" category="paragraph"><block ref="381008e8bad1425034ca5fa30cd57133" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9376ca935750f1ee987d9b2ce256bfbf" category="paragraph">NVIDIA DGX SuperPOD™ とNetApp AFF® A90 ストレージ システムを組み合わせることで、 NVIDIA DGX システムの世界クラスのコンピューティング パフォーマンスとNetAppクラウド接続ストレージ システムを組み合わせ、機械学習 (ML)、人工知能 (AI)、高性能技術コンピューティング (HPC) 向けのデータ駆動型ワークフローが可能になります。このドキュメントでは、イーサネット ストレージ ファブリックを備えたNetApp AFF A90ストレージ システムを使用した DGX SuperPOD ソリューションの高レベル アーキテクチャについて説明します。</block>
  <block id="180ea794b48cd487087e5b1dd21023f0" category="paragraph">NVIDIA DGX SuperPODの実証済みのコンピューティング パフォーマンスと、NetApp の業界をリードするデータ セキュリティ、データ ガバナンス、マルチテナント機能を組み合わせることで、お客様は次世代のワークロード向けに最も効率的で俊敏なインフラストラクチャを導入できます。このドキュメントでは、顧客が AI/ML イニシアチブの市場投入までの時間を短縮し、投資収益率を向上させるのに役立つ高レベルのアーキテクチャと主要な機能について説明します。</block>
  <block id="98e7b017fa4951d28f1516c0bee63969" category="section-title">プログラム概要</block>
  <block id="0e7a454160d4f81e5b82fe865851c0b5" category="paragraph">NVIDIA DGX SuperPOD は、組織向けのターンキー AI データ センター ソリューションを提供し、世界クラスのコンピューティング、ソフトウェア ツール、専門知識、継続的なイノベーションをシームレスに提供します。 DGX SuperPOD は、最小限のセットアップ時間と最大限の生産性で AI/ML および HPC ワークロードを展開するために必要なすべてを提供します。図 1 は、DGX SuperPOD の高レベル コンポーネントを示しています。</block>
  <block id="0df8fda8ee1a402c3eb7dc7582d3a710" category="paragraph"><block ref="0df8fda8ee1a402c3eb7dc7582d3a710" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d91208793b9a449dbecfd553707c79d6" category="list-text">インフラストラクチャの管理と監視から、事前に構築されたディープラーニング モデルとツールまで、統合されたハードウェアとソフトウェアのスタック。</block>
  <block id="84245e1cf723377c5a2991885cd57409" category="list-text">インストールとインフラストラクチャ管理からワークロードのスケーリングとプロダクションAIの合理化まで、専用サービス</block>
  <block id="5d8430a9387a385c7ee9a8b83ff28b12" category="paragraph">組織が人工知能 (AI) と機械学習 (ML) の取り組みを採用するにつれて、堅牢でスケーラブルかつ効率的なインフラストラクチャ ソリューションに対する需要はかつてないほど高まっています。こうした取り組みの中心にあるのは、データのセキュリティ、アクセシビリティ、リソースの最適化を確保しながら、ますます複雑化する AI モデルを管理およびトレーニングするという課題です。エージェント AI の進化と高度なモデル トレーニング要件により、コンピューティングおよびストレージ インフラストラクチャに対する前例のない需要が生じています。組織は現在、膨大なデータセットを処理し、複数の同時トレーニング ワークロードをサポートし、データ保護と規制コンプライアンスを確保しながら高性能コンピューティング環境を維持する必要があります。従来のインフラストラクチャ ソリューションでは、こうした要求を満たすのに苦労することが多く、運用の非効率性や AI プロジェクトの価値実現までの時間の遅延につながります。このソリューションには、次の主な利点があります。</block>
  <block id="1844a1480427b3b276783fd66fc58226" category="list-text">*スケーラビリティ* NetApp AFF A90ストレージ システムを搭載したNVIDIA DGX SuperPOD は、モジュラー アーキテクチャと柔軟な拡張機能により、比類のないスケーラビリティを実現します。組織は、既存のワークロードを中断したり複雑な再構成を必要とせずに、DGX コンピューティング ノードとAFF A90ストレージ システムを追加することで、AI インフラストラクチャをシームレスに拡張できます。</block>
  <block id="02a63d3f709e7b79dac689e7724d8821" category="list-text">*データ管理とアクセス*  NetApp AFF A90ストレージ システムを搭載したNVIDIA DGX SuperPOD は、包括的なエンタープライズ グレードの機能スイートを通じて優れたデータ管理を実現するNetApp ONTAPをベースとしています。  ONTAP のスナップショット機能とFlexClone機能を使用すると、チームはデータセットとベクター データベースのスペース効率の高いコピーを即座に作成し、並行して開発とテストを行うことができます。  FlexCacheおよび Snapmirror レプリケーション テクノロジーにより、企業全体のデータ ソースからの合理化された、スペース効率の高い自動化されたデータ パイプラインが可能になります。また、NAS およびオブジェクト プロトコルを使用したデータへのマルチプロトコル アクセスにより、取り込みおよびデータ エンジニアリング タスクに最適化された新しいワークフローが可能になります。</block>
  <block id="3b5ce4caaf6acea212e6608eb826a52c" category="list-text">*安全。* NetApp AFF A90ストレージ システムは、多層保護を通じてエンタープライズ グレードのセキュリティを提供します。インフラストラクチャ レベルでは、このソリューションは、ロールベースのアクセス制御 (RBAC)、多要素認証、詳細な監査ログ機能などの強力なアクセス制御メカニズムを実装します。プラットフォームの包括的な暗号化フレームワークは、業界標準のプロトコルとアルゴリズムを使用して、保存中と転送中の両方のデータを保護し、知的財産を保護し、規制要件への準拠を維持します。統合されたセキュリティ監視ツールは、潜在的なセキュリティの脅威をリアルタイムで可視化し、自動化された対応メカニズムは、リスクが業務に影響を与える前に軽減するのに役立ちます。</block>
  <block id="d2374eb265fd2592ef7b4b817140ba67" category="paragraph">このソリューションは、広範なデータ資産と従来の IT インフラストラクチャ ツールおよびプロセスとのより緊密な統合を必要とする HPC および AI/ML ワークロードを持つ組織を対象としています。</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">このソリューションの対象読者には、次のグループが含まれます。</block>
  <block id="f79b8cf1009178e9a2fd45c1f4ae4ef7" category="list-text">IT 部門と事業部門の意思決定者は、最も効率的なインフラストラクチャを計画し、最短の市場投入時間と ROI で AI/ML イニシアチブを実現します。</block>
  <block id="c328ed7f0a74043c4e73f7ea491b4eb7" category="list-text">AI/ML ワークフローの重要なデータ中心部分の効率を最大化することに関心のあるデータ サイエンティストおよびデータ エンジニア。</block>
  <block id="fa7b81174ad3677e1ed9da1ea8185c4d" category="list-text">自動化されたデータ ワークフローと既存のデータおよびプロセス ガバナンス標準への準拠を可能にする、信頼性が高く安全なインフラストラクチャを提供する必要がある IT アーキテクトおよびエンジニア。</block>
  <block id="dad37ea926873ef3d5ee869827ddc40c" category="paragraph">NVIDIA DGX SuperPOD には、要求の厳しい AI ワークロードに実証済みのパフォーマンスを提供するために必要なサーバー、ネットワーク、ストレージが含まれています。  NVIDIA DGX™ H200 およびNVIDIA DGX B200 システムは世界クラスのコンピューティング能力を提供し、 NVIDIA Quantum および Spectrum™ InfiniBand ネットワーク スイッチは超低遅延と業界をリードするネットワーク パフォーマンスを提供します。 NetApp ONTAPストレージの業界をリードするデータ管理およびパフォーマンス機能が追加されたことで、顧客は AI/ML イニシアチブをより迅速に、そしてデータ移行と管理オーバーヘッドを削減して実現できるようになります。次のセクションでは、AFF A90ストレージ システムを備えた DGX SuperPOD のストレージ コンポーネントについて説明します。</block>
  <block id="4caba5452d50c27473615492a421d0b7" category="section-title">NetApp ONTAPを搭載したNetApp AFF A90ストレージシステム</block>
  <block id="5b01f10375ddf0fa7a318292fb1ab544" category="paragraph">NetApp ONTAPデータ管理ソフトウェアを搭載したNetApp AFF A90は、組み込みのデータ保護機能、ランサムウェア対策機能、そして最も重要なビジネス ワークロードをサポートするために必要な高いパフォーマンス、拡張性、および回復力を提供します。ミッションクリティカルな業務の中断を排除し、パフォーマンス チューニングを最小限に抑え、ランサムウェア攻撃からデータを保護します。  NetApp AFF A90システムは、</block>
  <block id="5f443413f7f04549bcfdd089e04a0c3a" category="list-text">*パフォーマンス。*AFF A90 は、ディープラーニング、AI、高速分析などの次世代ワークロードだけでなく、Oracle、SAP HANA、Microsoft SQL Server、仮想化アプリケーションなどの従来のエンタープライズ データベースも簡単に管理します。NFS over RDMA、pNFS、セッション トランキングを使用すると、顧客は独自のソフトウェアを使用せずに、既存のデータ センター ネットワーク インフラストラクチャと業界標準のプロトコルを使用して、次世代アプリケーションに必要な高レベルのネットワーク パフォーマンスを実現できます。粒度データ分散により、個々のファイルをストレージ クラスター内のすべてのノードに分散することができ、pNFS と組み合わせることで、単一の大きなファイルに含まれるデータセットへの高パフォーマンスの並列アクセスが可能になります。</block>
  <block id="ae299319707718bf9587df62a89ca873" category="list-text">*知能。*データ駆動型インテリジェンス、将来を見据えたインフラストラクチャ、 NVIDIAおよび MLOps エコシステムとの緊密な統合に基づいて構築された AI 対応エコシステムにより、デジタル トランスフォーメーションを加速します。  ONTAP のスナップショット機能とFlexClone機能を使用すると、チームは並列開発とテストのためにスペース効率の高いデータセットのコピーを即座に作成できます。 FlexCacheおよび Snapmirror レプリケーション テクノロジーにより、企業全体のデータ ソースからの合理化された、スペース効率の高い自動化されたデータ パイプラインが可能になります。また、NAS およびオブジェクト プロトコルを使用したデータへのマルチプロトコル アクセスにより、取り込みおよびデータ エンジニアリング タスクに最適化された新しいワークフローが可能になります。データとトレーニングのチェックポイントを低コストのストレージに階層化して、プライマリ ストレージがいっぱいになるのを防ぐことができます。お客様は、単一のストレージ OS と業界で最も豊富なデータ サービス スイートを使用して、ハイブリッド クラウド全体でデータを最小限のコストでシームレスに管理、保護、およびモバイル化できます。</block>
  <block id="3a6d4fa926afe309c404561a18033103" category="list-text">*安全。* NetApp ONTAPストレージを搭載したNVIDIA DGX SuperPOD は、多層保護を通じてエンタープライズ グレードのセキュリティを実現します。インフラストラクチャ レベルでは、このソリューションは、ロールベースのアクセス制御 (RBAC)、多要素認証、詳細な監査ログ機能などの強力なアクセス制御メカニズムを実装します。プラットフォームの包括的な暗号化フレームワークは、業界標準のプロトコルとアルゴリズムを使用して、保存中と転送中の両方のデータを保護し、知的財産を保護し、規制要件への準拠を維持します。統合されたセキュリティ監視ツールは、潜在的なセキュリティの脅威をリアルタイムで可視化し、自動化された対応メカニズムは、リスクが業務に影響を与える前に軽減するのに役立ちます。  NetApp ONTAP は、極秘データの保存が検証されている唯一の強化されたエンタープライズ ストレージです。</block>
  <block id="5a79514564c762f34f82d2f86ba269f6" category="list-text">*マルチテナント*。 NetApp ONTAP は、ストレージ リソースの安全なマルチテナント使用を可能にする最も幅広い機能を提供します。ストレージ仮想マシンは、RBAC コントロールによるテナントベースの管理委任を提供します。包括的な QoS コントロールにより、重要なワークロードのパフォーマンスが保証されるとともに、最大限の使用率が可能になります。また、ボリューム レベルの暗号化のためのテナント管理キーなどのセキュリティ機能により、共有ストレージ メディア上のデータ セキュリティが保証されます。</block>
  <block id="234fe3186330a0015f240eaa46026f52" category="inline-link">+++ ONTAP RASS ホワイトペーパー+++</block>
  <block id="aa2c50d70660a4e07e28a4a1e62cbbeb" category="list-text">*信頼性。* NetApp は、高度な信頼性、可用性、保守性、管理性 (RASM) 機能を通じてミッションクリティカルな運用の中断を排除し、最高の稼働時間を実現します。詳細については、<block ref="06c9743ea9b1147ff9ba8b6afddf02b3" category="inline-link-rx"></block> 。さらに、 Active IQとData Infrastructure Insightsによって提供される AI ベースの予測分析により、システムの健全性を最適化することもできます。</block>
  <block id="dbefda683c705de53408671cbbab4e34" category="section-title">NVIDIA DGX B200 システム</block>
  <block id="c2e6165182afeb3c2d3013f3389087b6" category="inline-link">+++NVIDIA+++</block>
  <block id="2ed6f2103f37f8b4eec016533f493515" category="inline-link">+++NVリンク(™)+++</block>
  <block id="1697b07c98d5b223a74b615c776f0b65" category="inline-link">+++ NVIDIAブラックウェル+++</block>
  <block id="5e923560ec7f11fe71232bd344d8d81a" category="inline-link">+++建築+++</block>
  <block id="f7be9a2901218b858c97cd4113fbc2aa" category="paragraph">NVIDIA DGX™ B200 は、AI 導入のあらゆる段階にあるあらゆる規模の企業向けに、開発から展開までのパイプラインを実現する統合 AI プラットフォームです。第5世代のNVIDIA Blackwell GPUを8基搭載<block ref="8d33a92989a52a298d52379f9acef95c" category="inline-link-rx"></block><block ref="66ff52a072f2c292b9f50112a8543358" category="inline-link-rx"></block>DGX B200 は最先端のパフォーマンスを提供し、前世代の 3 倍のトレーニング パフォーマンスと 15 倍の推論パフォーマンスを実現します。活用<block ref="113af14b044c5bd4dc15be4b6100b100" category="inline-link-rx"></block><block ref="adaec91c8092748fe326913de2b3a1f0" category="inline-link-rx"></block>DGX B200 は、大規模な言語モデル、レコメンデーション システム、チャットボットなどの多様なワークロードを処理できるため、AI 変革を加速したい企業に最適です。</block>
  <block id="f94ad1ea1a52dd514a5e42a7eec71e94" category="section-title">NVIDIA Spectrum SN5600 イーサネットスイッチ</block>
  <block id="a1bd19971bc35fdd30c6a0b2eee21865" category="paragraph">SN5600 スマート リーフ、スパイン、スーパー スパイン スイッチは、高密度 2U フォーム ファクターで 64 ポートの 800GbE を提供します。  SN5600 は、トップオブラック (ToR) スイッチを使用した標準のリーフ/スパイン設計と、エンドオブロウ (EoR) トポロジの両方を可能にします。  SN5600 は、1 ～ 800GbE の組み合わせによる多様な接続を提供し、業界をリードする 51.2Tb/s の総スループットを誇ります。</block>
  <block id="ffe61852985d936bb555e1c150a3feca" category="section-title">NVIDIAベースコマンドソフトウェア</block>
  <block id="040380b5657454a9d0ce1064c83dd667" category="paragraph">NVIDIA Base Command™ はNVIDIA DGX プラットフォームを強化し、組織がNVIDIA AI イノベーションを最大限に活用できるようにします。これにより、あらゆる組織は、AI ワークフロー管理、エンタープライズ グレードのクラスター管理、コンピューティング、ストレージ、ネットワーク インフラストラクチャを高速化するライブラリ、AI ワークロードの実行に最適化されたシステム ソフトウェアを含む実績のあるプラットフォームを使用して、DGX インフラストラクチャの可能性を最大限に活用できるようになります。図 2 は、 NVIDIA Base Command ソフトウェア スタックを示しています。</block>
  <block id="9620c8c92a535942ede6a202c5bf5b0d" category="paragraph">図 2) NVIDIAベース コマンド ソフトウェア。</block>
  <block id="2e15a851530c5d474531243cfd838752" category="paragraph"><block ref="2e15a851530c5d474531243cfd838752" category="inline-image-macro-rx" type="image"></block></block>
  <block id="651beb53a2e8224545ff56fc0d0efd02" category="paragraph">NVIDIA Base Command Manager は、エッジ、データ センター、マルチ クラウドおよびハイブリッド クラウド環境における異種 AI およびハイパフォーマンス コンピューティング (HPC) クラスターの迅速な導入とエンドツーエンドの管理を実現します。数ノードから数十万ノードまでの規模のクラスターのプロビジョニングと管理を自動化し、 NVIDIA GPU アクセラレーションなどのシステムをサポートし、Kubernetes とのオーケストレーションを可能にします。  NetApp AFF A90ストレージ システムを DGX SuperPOD と統合するには、最適なパフォーマンスを得るためにシステム チューニングとマウント パラメータを設定するために Base Command Manager を最小限に構成する必要がありますが、DGX システムとAFF A90ストレージ システム間の高可用性マルチパス アクセスを実現するために追加のソフトウェアは必要ありません。</block>
  <block id="24f67e93854c90d735466339a375c002" category="paragraph">NVIDIA DGX SuperPOD は、最大規模で最も要求の厳しいワークロードのパフォーマンス要件を満たすように設計されています。</block>
  <block id="cfc814162b41538ad397b897a24c4937" category="list-text">大規模言語モデル、コンピューター ビジョン/画像分類、不正検出、その他無数のユース ケース向けの人工知能モデル トレーニング。</block>
  <block id="607aa89216cc994d4e20cfce8695d306" category="list-text">地震解析、数値流体力学、大規模可視化などの高性能コンピューティング。</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">ソリューション アーキテクチャ</block>
  <block id="d0eadc16af6d6df8893f37be51ed2bc6" category="paragraph">DGX SuperPOD は、32 台の DGX B200 システムと、必要な接続を提供し、インフラストラクチャのパフォーマンスのボトルネックを解消するために必要なその他のすべてのコンポーネントを含むスケーラブル ユニット (SU) の概念に基づいています。お客様は 1 つまたは複数の SU から開始し、要件を満たすために必要に応じて SU を追加できます。このドキュメントでは、単一の SU のストレージ構成について説明し、表 1 に大規模な構成に必要なコンポーネントを示します。</block>
  <block id="2a4a6621abe5b6f39b1534ead593f20a" category="inline-link">+++ NVIDIA DGX SuperPODリファレンス アーキテクチャ+++</block>
  <block id="60696b15e8be9fd24231177ac611836f" category="paragraph">DGX SuperPOD リファレンス アーキテクチャには複数のネットワークが含まれており、 AFF A90ストレージ システムはそれらのネットワークのいくつかに接続されています。  DGX SuperPODネットワークの詳細については、<block ref="562b92094dd1a3e9b7e68b6a6fb7de81" category="inline-link-rx"></block> 。</block>
  <block id="fdd68d018aab06584c6bc4e8351fa72b" category="paragraph">このソリューションでは、高性能ストレージ ファブリックは、スパイン/リーフ構成の 64 個の 800Gb ポートを備えたNVIDIA Spectrum SN5600 スイッチに基づくイーサネット ネットワークです。インバンド ネットワークは、ホーム ディレクトリや一般的なファイル共有などの他の機能へのユーザー アクセスを提供し、SN5600 スイッチに基づいています。また、アウト オブ バンド (OOB) ネットワークは、SN2201 スイッチを使用したデバイス レベルのシステム管理者アクセス用です。</block>
  <block id="3a812cac2db0a2d9638c3b252cc24b8e" category="paragraph">ストレージ ファブリックはリーフ スパイン アーキテクチャであり、DGX システムが 1 組のリーフ スイッチに接続し、ストレージ システムが別の 1 組のリーフ スイッチに接続します。複数の 800Gb ポートを使用して各リーフ スイッチをスパイン スイッチのペアに接続し、ネットワーク全体に複数の高帯域幅パスを作成して総合的なパフォーマンスと冗長性を実現します。  AFF A90ストレージ システムへの接続では、適切な銅線または光ブレークアウト ケーブルを使用して、各 800 Gb ポートが 4 つの 200 Gb ポートに分割されます。 NFS over RDMA を使用してストレージ システムをマウントするクライアントをサポートするために、ストレージ ファブリックは RDMA over Converged Ethernet (RoCE) 用に構成され、ネットワーク内でロスレス パケット配信を保証します。図 3 は、このソリューションのストレージ ネットワーク トポロジを示しています。</block>
  <block id="6a53d316acbe58b01a749e96481412aa" category="paragraph">図 3) ストレージ ファブリック トポロジ。</block>
  <block id="00031e516cb8c09c104ebdb164264d7f" category="paragraph"><block ref="00031e516cb8c09c104ebdb164264d7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316d243b972562ec3f8d06fcd980b1d6" category="paragraph">NetApp AFF A90ストレージ システムは、互いに高可用性パートナー (HA ペア) として動作する 2 つのコントローラと、最大 48 個の 2.5 インチ フォーム ファクタのソリッド ステート ディスク (SSD) を搭載した 4RU シャーシです。各コントローラは、4 つの 200Gb イーサネット接続を使用して両方の SN5600 ストレージ リーフ スイッチに接続され、各物理ポートには 2 つの論理 IP インターフェイスがあります。ストレージ クラスターは、クライアントがクラスター内のすべてのコントローラーに直接接続を確立できるようにする Parallel NFS (pNFS) を備えた NFS v4.1 をサポートしています。さらに、セッション トランキングにより、複数の物理インターフェイスのパフォーマンスが 1 つのセッションに結合され、シングル スレッドのワークロードでも、従来のイーサネット ボンディングよりも広いネットワーク帯域幅にアクセスできるようになります。これらすべての機能を RDMA と組み合わせることで、 AFF A90ストレージ システムは、 NVIDIA GPUDirect Storage™ を活用したワークロードに対して、低レイテンシと高スループットを直線的に拡張できるようになります。</block>
  <block id="2ecf799238706280879a7218f5c9384f" category="paragraph">インバンド ネットワークへの接続のために、 AFF A90コントローラには、LACP インターフェイス グループに構成された追加の 200 Gb イーサネット インターフェイスがあり、一般的な NFS v3 および v4 サービスと、必要に応じて共有ファイルシステムへの S3 アクセスを提供します。すべてのコントローラとストレージ クラスタ スイッチは、リモート管理アクセスのために OOB ネットワークに接続されています。</block>
  <block id="242354762ac710a9d168daccad8ea40d" category="paragraph">高いパフォーマンスとスケーラビリティを実現するために、ストレージ コントローラはストレージ クラスタを形成します。これにより、クラスタ ノードの全体的なパフォーマンスと容量がFlexGroupと呼ばれる単一の名前空間に統合され、データはクラスタ内のすべてのノードのディスクに分散されます。 ONTAP 9.16.1 でリリースされた新しい Granular Data Distribution 機能により、個々のファイルが分離され、 FlexGroup全体に分散されるため、単一ファイルのワークロードで最高レベルのパフォーマンスが実現します。下の図 4 は、pNFS と NFS セッション トランキングが FlexGroups および GDD と連携して、ストレージ システム内のすべてのネットワーク インターフェイスとディスクを活用して大容量ファイルへの並列アクセスを可能にする様子を示しています。</block>
  <block id="c3c4a8bbb2b351b3bf984cb2d6864b94" category="paragraph">図 4) pNFS、セッション トランキング、FlexGroups、GDD。</block>
  <block id="4f30b88a042ae485248ebaa1099b4a91" category="paragraph"><block ref="4f30b88a042ae485248ebaa1099b4a91" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ac50512926081a099344a18f27b3818" category="paragraph">このソリューションは、複数のストレージ仮想マシン (SVM) を活用して、高パフォーマンスのストレージ アクセスと、管理 SVM 上のユーザー ホーム ディレクトリおよびその他のクラスター アーティファクトの両方のボリュームをホストします。各 SVM はネットワーク インターフェイスとFlexGroupボリュームで構成され、データ SVM のパフォーマンスを確保するために QoS ポリシーが実装されています。  FlexGroup、Storage Virtual Machines、 ONTAP QoS機能の詳細については、<block ref="619babf0e51393513dd3986ae0aee969" category="inline-link-rx"></block> 。</block>
  <block id="2a57ec7828afba5c513d03e967cb3884" category="section-title">ソリューションのハードウェア要件</block>
  <block id="b761a63ce0a1bd27710c7207a50b8577" category="paragraph">表 1 には、1 つ、2 つ、4 つ、または 8 つのスケーラブル ユニットを実装するために必要なストレージ ハードウェア コンポーネントがリストされています。サーバーとネットワークの詳細なハードウェア要件については、<block ref="b8ab7d3cc54802757d9a49bb252840ab" category="inline-link-rx"></block> 。</block>
  <block id="a7504f8a3068ecf26f816d83dfcae5a8" category="cell">SUサイズ</block>
  <block id="eb94f28ae18769ccde6259223dde0683" category="cell">AFF A90 システム</block>
  <block id="258b220fa2ed31020ab102479476e757" category="cell">ストレージクラスタ相互接続スイッチ</block>
  <block id="9254819941449b706e4282e2f2e6a7b9" category="cell">使用可能容量（3.8TB SSDの場合の標準）</block>
  <block id="eb17bb52c3b173b3911725d1c9a194f0" category="cell">最大使用可能容量（15.3TB NVMe SSD搭載時）</block>
  <block id="c9d196f41b3911fefebc23e6efbc32f4" category="cell">RU（標準）</block>
  <block id="1fec42eb0945f00ee2125c78858d7366" category="cell">電力（標準）</block>
  <block id="f04a7a4ef42eb207cec5a3d7fcc9d3fa" category="cell">555 TB</block>
  <block id="104bf07415681a49e985f5dd5895d4d6" category="cell">13.75PB</block>
  <block id="4f10ff6d954a760dbf5b59fb54597722" category="cell">7,300ワット</block>
  <block id="830daef3058bf009b39d03050f58f3f4" category="cell">27.5PB</block>
  <block id="62aa76bddc36c76968deb0ae09c8063f" category="cell">14,600ワット</block>
  <block id="76a4dd9b098f9a8877b8b79d0c80c5d3" category="cell">2PB</block>
  <block id="3b07c527868f20c47db7e08e0e02ced5" category="cell">55PB</block>
  <block id="f4680500c767e37e35c38315af80e9f9" category="cell">29,200ワット</block>
  <block id="e79a79f20fe06b0beb657745cf11949a" category="cell">4PB</block>
  <block id="1609fc8f39b0baac216cbb19fb420ef2" category="cell">110PB</block>
  <block id="ec8956637a99787bd197eacd77acce5e" category="cell">102</block>
  <block id="bc6012118a1ec87da87af67c6b3a0f74" category="cell">58,400ワット</block>
  <block id="0f37a7e60b292d864a5ac969ec04cc27" category="paragraph">*注意:* NetApp、パフォーマンスを最大限に高めるために、 AFF A90 HA ペアごとに少なくとも 24 台のドライブを推奨しています。追加の内部ドライブ、大容量ドライブ、外部拡張ドライブ シェルフにより、システム パフォーマンスに影響を与えることなく、総容量を大幅に高めることができます。</block>
  <block id="d3469c07f7acce56e0d039ec0b164141" category="paragraph">表 2 に、 AFF A90ストレージ システムを DGX SuperPOD と統合するために必要なソフトウェア コンポーネントとバージョンを示します。 DGX SuperPOD には、ここに記載されていない他のソフトウェア コンポーネントも含まれます。詳細は<block ref="2523a697ed64d9038adf903273ea5150" category="inline-link-rx"></block>詳細についてはこちらをご覧ください。</block>
  <block id="0bd0e673df4c14cae45a11fac30c530b" category="cell">9.16.1</block>
  <block id="dbc8a3aaafc47a649eed1dcc0bc5155e" category="cell">10.24.11</block>
  <block id="c6d4f54ff5f7e221a70cdd46daa396b3" category="cell">6.3.1</block>
  <block id="09e619b353cb3d3ca08701e294bb9047" category="cell">MLNX_OFED_LINUX-23.10.3.2.0 LTS</block>
  <block id="51eed8fde1839744a1b920b0dacb0a0a" category="cell">5.10</block>
  <block id="f11a60eea5a7abfd75bb28890eaef1ec" category="paragraph">このストレージ ソリューションは、パフォーマンスとスケーラビリティがNVIDIA DGX SuperPODの要件を満たしていることを確認するために、 NetAppとNVIDIAによって複数の段階で検証されました。構成は、合成ワークロードと実際の ML/DL ワークロードの組み合わせを使用して検証され、最大のパフォーマンスとアプリケーションの相互運用性の両方が検証されました。以下の表 3 は、DGX SuperPOD の展開でよく見られる典型的なワークロードとそのデータ要件の例を示しています。</block>
  <block id="e203df30cd7f31417aee170026e44f70" category="paragraph">表 3) SuperPOD ワークロードの例。</block>
  <block id="a0db49ba470c1c9ae2128c3470339153" category="cell">レベル</block>
  <block id="0ba48588b95eb9052082d27db3380801" category="cell">作品の説明</block>
  <block id="c8ceada943dc5d58578660bf60d0762a" category="cell">データセットのサイズ</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">Standard</block>
  <block id="c7f0dd1953999823199f993b956164f6" category="cell">複数の同時 LLM または微調整トレーニング ジョブと定期的なチェックポイント。コンピューティング要件がデータ I/O 要件を大幅に上回ります。</block>
  <block id="f2db8117278a7bff3e0e0bff0571726d" category="cell">ほとんどのデータセットは、トレーニング中にローカル コンピューティング システムのメモリ キャッシュ内に収まります。データセットは単一のモダリティであり、モデルには数百万のパラメータがあります。</block>
  <block id="53123044b4b65d0ad1b7ed0cfa4c3480" category="cell">強化された</block>
  <block id="c9e72abf53e870d36e47df81d7f139bf" category="cell">複数の同時マルチモーダル トレーニング ジョブと定期的なチェックポイント。データ I/O パフォーマンスは、エンドツーエンドのトレーニング時間にとって重要な要素です。</block>
  <block id="981d20fc47284a9be8695e715a3d1d47" category="cell">データセットが大きすぎるため、ローカル コンピューティング システムのメモリ キャッシュに収まらないため、トレーニング中に多くの I/O が必要となり、頻繁な I/O の必要性を排除するには不十分です。データセットには複数のモダリティがあり、モデルには数十億（またはそれ以上）のパラメータがあります。</block>
  <block id="255eebee8e38299d9f7282ffa8b76db3" category="paragraph">表 4 は、上記のサンプル ワークロードのパフォーマンス ガイドラインを示しています。これらの値は、理想的な条件下でこれらのワークロードによって生成できるストレージ スループットを表します。</block>
  <block id="fe54d8f94c652ba49e4aba03f3107a9c" category="paragraph">表 4) DGX SuperPOD のパフォーマンス ガイドライン。</block>
  <block id="f5bab93f6f25cd702dcbcb4aad615260" category="cell">パフォーマンス特性</block>
  <block id="94f3edd272dbb778616c50e083536c63" category="cell">標準（GBps）</block>
  <block id="abaf1dc2e3d5bf424c74cd4566b0f1a3" category="cell">拡張（GBps）</block>
  <block id="c5b9e837f1006565fbb01cd3b64d3df7" category="cell">単一SU集計システム読み取り</block>
  <block id="3def184ad8f4755ff269862ea77393dd" category="cell">125</block>
  <block id="8eb042782ea4dd597d037482af02c144" category="cell">単一SU集約システム書き込み</block>
  <block id="44f683a84163b3523afe57c2e008bc8c" category="cell">62</block>
  <block id="f53ce0357707bf3db713c9d71337529d" category="cell">4 SU集計システム読み取り</block>
  <block id="b73ce398c39f506af761d2277d853a92" category="cell">160</block>
  <block id="cee631121c2ec9232f3a2f028ad5c89b" category="cell">500</block>
  <block id="bc96df788d872dc23329bae80cc02619" category="cell">4 SU 集約システム書き込み</block>
  <block id="6c9882bbac1c7093bd25041881277658" category="cell">250</block>
  <block id="ef6f2913d5f1e19a1aa781a5d72d6caa" category="inline-link">NVA-1175 NVIDIA DGX SuperPODとNetApp AFF A90ストレージシステムの導入ガイド</block>
  <block id="6f8af77cdc63a21a3e7b99a2511ed006" category="list-text"><block ref="6f8af77cdc63a21a3e7b99a2511ed006" category="inline-link-rx"></block></block>
  <block id="4498f6091821057a5b12bbe00bad6fb7" category="inline-link">NVIDIA DGX B200 SuperPOD リファレンス アーキテクチャ</block>
  <block id="e0ef89706b7f0268557664ed42040243" category="list-text"><block ref="e0ef89706b7f0268557664ed42040243" category="inline-link-rx"></block></block>
  <block id="076218ee0774bfaae3fcf92a3241a9fe" category="inline-link">NVIDIA DGX H200 SuperPOD リファレンス アーキテクチャ</block>
  <block id="b02d06e7da163e15a51f5a0277a72641" category="list-text"><block ref="b02d06e7da163e15a51f5a0277a72641" category="inline-link-rx"></block></block>
  <block id="e9cc843bc2157ef28fd2c0657e05a6f0" category="inline-link">NVIDIA BaseCommand ソフトウェア</block>
  <block id="5b147f17197401088429ad2165ca94db" category="list-text"><block ref="5b147f17197401088429ad2165ca94db" category="inline-link-rx"></block></block>
  <block id="f6f89e67f0d14eefc85ee96a3de66d60" category="list-text"><block ref="f6f89e67f0d14eefc85ee96a3de66d60" category="inline-link-rx"></block></block>
  <block id="8365b73ca224de7f689b1708ed448af9" category="inline-link">+++ NetApp AIソリューションのドキュメント+++</block>
  <block id="aed2dde7ddb9cf045a1de05c19aa6fe6" category="list-text"><block ref="aed2dde7ddb9cf045a1de05c19aa6fe6" category="inline-link-rx"></block></block>
  <block id="4245faba305e62f6fdc30b1ce8bf8ac3" category="inline-link">+++ NetApp AFFストレージシステムのインストールと保守+++</block>
  <block id="bf45808f34c6dcc540de81441ed8372a" category="list-text"><block ref="bf45808f34c6dcc540de81441ed8372a" category="inline-link-rx"></block></block>
  <block id="51af5c28c5aeade3eeee8efe1cf0c265" category="list-text"><block ref="0b4edeca10dea88e1e3ff87f6aece04a" category="inline-link-rx"></block>(pNFS に関する優れた情報が記載された古いドキュメント)</block>
  <block id="e84f1067b5e0c62707fee9cec31ec6e6" category="sidebar">NetApp AFF A90ストレージシステムとNVIDIA DGX SuperPOD - 設計</block>
  <block id="ebe830dbdb267fd10b3f4000455f19f2" category="sidebar">NetApp AFF A90ストレージシステムとNVIDIA DGX SuperPOD - 導入</block>
</blocks>